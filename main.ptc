\babel@toc {english}{}\relax 
\contentsline {chapter}{Preface}{8}{chapter*.2}%
\contentsline {section}{\numberline {0.1}Getting Started: About the Project and How to Navigate It}{8}{section.0.1}%
\contentsline {subsection}{\numberline {0.1.1}Why This Document?}{8}{subsection.0.1.1}%
\contentsline {subsection}{\numberline {0.1.2}Acknowledgments and Contributions}{8}{subsection.0.1.2}%
\contentsline {subsection}{\numberline {0.1.3}Your Feedback Matters}{9}{subsection.0.1.3}%
\contentsline {subsection}{\numberline {0.1.4}How to Navigate This Document}{9}{subsection.0.1.4}%
\contentsline {subsection}{\numberline {0.1.5}Staying Updated in the Field}{9}{subsection.0.1.5}%
\contentsline {subsection}{\numberline {0.1.6}The Importance of Practice}{9}{subsection.0.1.6}%
\contentsline {chapter}{\numberline {1}Lecture 1: Course Introduction}{10}{chapter.1}%
\ttl@starttoc {default@1}
\contentsline {section}{\numberline {1.1}Core Terms in the Field}{10}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Artificial Intelligence (AI)}{10}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Machine Learning (ML)}{10}{subsection.1.1.2}%
\contentsline {subsection}{\numberline {1.1.3}Deep Learning (DL)}{11}{subsection.1.1.3}%
\contentsline {subsection}{\numberline {1.1.4}Computer Vision (CV)}{12}{subsection.1.1.4}%
\contentsline {subsection}{\numberline {1.1.5}Connecting the Dots}{12}{subsection.1.1.5}%
\contentsline {section}{\numberline {1.2}Why Study Deep Learning for Computer Vision?}{12}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Motivation for Deep Learning in Computer Vision}{13}{subsection.1.2.1}%
\contentsline {section}{\numberline {1.3}Historical Milestones}{13}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Hubel and Wiesel (1959): How Vision Works?}{14}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Larry Roberts (1963): From Edges to Keypoints}{14}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}David Marr (1970s): From Features to a 3D Model}{15}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Recognition via Parts (1970s)}{16}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}Recognition via Edge Detection (1980s)}{17}{subsection.1.3.5}%
\contentsline {subsection}{\numberline {1.3.6}Recognition via Grouping (1990s)}{18}{subsection.1.3.6}%
\contentsline {subsection}{\numberline {1.3.7}Recognition via Matching and Benchmarking (2000s)}{19}{subsection.1.3.7}%
\contentsline {subsection}{\numberline {1.3.8}The ImageNet Dataset and Classification Challenge}{21}{subsection.1.3.8}%
\contentsline {subsection}{\numberline {1.3.9}AlexNet: A Revolution in Computer Vision (2012)}{22}{subsection.1.3.9}%
\contentsline {subsubsection}{Building on AlexNet: Evolution of CNNs and Beyond}{23}{section*.3}%
\contentsline {section}{\numberline {1.4}Milestones in the Evolution of Learning in Computer Vision}{25}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}The Perceptron (1958)}{25}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}The AI Winter and Multilayer Perceptrons (1969)}{26}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}The Neocognitron (1980)}{26}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Backpropagation and the Revival of Neural Networks (1986)}{27}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}LeNet and the Emergence of Convolutional Networks (1998)}{27}{subsection.1.4.5}%
\contentsline {subsection}{\numberline {1.4.6}The 2000s: The Era of Deep Learning}{28}{subsection.1.4.6}%
\contentsline {subsection}{\numberline {1.4.7}Deep Learning Explosion (2007-2020)}{29}{subsection.1.4.7}%
\contentsline {subsection}{\numberline {1.4.8}2012 to Present: Deep Learning is Everywhere}{29}{subsection.1.4.8}%
\contentsline {subsubsection}{Core Vision Tasks}{29}{section*.4}%
\contentsline {subsubsection}{Video and Temporal Analysis}{29}{section*.5}%
\contentsline {subsubsection}{Generative and Multimodal Models}{30}{section*.6}%
\contentsline {subsubsection}{Specialized Domains}{30}{section*.7}%
\contentsline {subsubsection}{State-of-the-Art Foundation Models}{30}{section*.8}%
\contentsline {subsubsection}{Computation is Cheaper: More GFLOPs per Dollar}{31}{section*.9}%
\contentsline {section}{\numberline {1.5}Key Challenges in CV and Future Directions}{32}{section.1.5}%
\contentsline {chapter}{\numberline {2}Lecture 2: Image Classification}{35}{chapter.2}%
\ttl@stoptoc {default@1}
\ttl@starttoc {default@2}
\contentsline {section}{\numberline {2.1}Introduction to Image Classification}{35}{section.2.1}%
\contentsline {section}{\numberline {2.2}Image Classification Challenges}{36}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The Semantic Gap}{36}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Robustness to Camera Movement}{36}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Intra-Class Variation}{37}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Fine-Grained Classification}{37}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Background Clutter}{38}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Illumination Changes}{38}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}Deformation and Object Scale}{39}{subsection.2.2.7}%
\contentsline {subsection}{\numberline {2.2.8}Occlusions}{39}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}Summary of Challenges}{40}{subsection.2.2.9}%
\contentsline {section}{\numberline {2.3}Image Classification as a Building Block for Other Tasks}{40}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Object Detection}{41}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Image Captioning}{42}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Decision-Making in Board Games}{43}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Summary}{44}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Constructing an Image Classifier}{44}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Feature-Based Image Classification: The Classical Approach}{44}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}From Hand-Crafted Rules to Data-Driven Learning}{45}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Programming with Data: The Modern Paradigm}{46}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Data-Driven Machine Learning: The New Frontier}{46}{subsection.2.4.4}%
\contentsline {section}{\numberline {2.5}Datasets in Image Classification}{47}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}MNIST: The Toy Dataset}{47}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}CIFAR: Real-World Object Recognition}{48}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}ImageNet: The Gold Standard}{49}{subsection.2.5.3}%
\contentsline {subsection}{\numberline {2.5.4}MIT Places: Scene Recognition}{50}{subsection.2.5.4}%
\contentsline {subsection}{\numberline {2.5.5}Comparing Dataset Sizes}{50}{subsection.2.5.5}%
\contentsline {subsection}{\numberline {2.5.6}Omniglot: Few-Shot Learning}{51}{subsection.2.5.6}%
\contentsline {subsection}{\numberline {2.5.7}Conclusion: Datasets Driving Progress}{51}{subsection.2.5.7}%
\contentsline {section}{\numberline {2.6}Nearest Neighbor Classifier: A Gateway to Understanding Classification}{52}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Why Begin with Nearest Neighbor?}{52}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Setting the Stage: From Pixels to Predictions}{52}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}Algorithm Description}{52}{subsection.2.6.3}%
\contentsline {subsection}{\numberline {2.6.4}Distance Metrics: The Core of Nearest Neighbor}{53}{subsection.2.6.4}%
\contentsline {subsection}{\numberline {2.6.5}Extending Nearest Neighbor: Applications Beyond Images}{55}{subsection.2.6.5}%
\contentsline {subsubsection}{Using Nearest Neighbor for Non-Image Data}{55}{section*.10}%
\contentsline {subsubsection}{Academic Paper Recommendation Example}{56}{section*.11}%
\contentsline {subsubsection}{Key Insights}{56}{section*.12}%
\contentsline {subsection}{\numberline {2.6.6}Hyperparameters in Nearest Neighbor}{56}{subsection.2.6.6}%
\contentsline {subsection}{\numberline {2.6.7}Cross-Validation}{57}{subsection.2.6.7}%
\contentsline {subsection}{\numberline {2.6.8}Implementation and Complexity}{58}{subsection.2.6.8}%
\contentsline {subsection}{\numberline {2.6.9}Visualization of Decision Boundaries}{60}{subsection.2.6.9}%
\contentsline {subsection}{\numberline {2.6.10}Improvements: k-Nearest Neighbors}{60}{subsection.2.6.10}%
\contentsline {subsection}{\numberline {2.6.11}Limitations and Universal Approximation}{61}{subsection.2.6.11}%
\contentsline {subsection}{\numberline {2.6.12}Using CNN Features for Nearest Neighbor Classification}{62}{subsection.2.6.12}%
\contentsline {subsection}{\numberline {2.6.13}Conclusion}{64}{subsection.2.6.13}%
\contentsline {chapter}{\numberline {3}Lecture 3: Linear Classifiers}{65}{chapter.3}%
\ttl@stoptoc {default@2}
\ttl@starttoc {default@3}
\contentsline {section}{\numberline {3.1}Linear Classifiers: A Foundation for Neural Networks}{65}{section.3.1}%
\contentsline {subsection}{Enrichment 0.1: Understanding the Role of Bias in Linear Classifiers}{67}{figure.3.2}%
\contentsline {subsection}{\numberline {3.1.1}A Toy Example: Grayscale Cat Image}{68}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}The Bias Trick}{69}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Linear Classifiers: The Algebraic Viewpoint}{70}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Scaling Properties and Insights}{70}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}From Algebra to Visual Interpretability}{71}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Linear Classifiers: The Visual Viewpoint}{72}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Template Matching Perspective}{72}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Interpreting Templates}{73}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Python Code Example: Visualizing Learned Templates}{73}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Template Limitations: Multiple Modes}{74}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5}Looking Ahead}{74}{subsection.3.3.5}%
\contentsline {section}{\numberline {3.4}Linear Classifiers: The Geometric Viewpoint}{74}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Images as High-Dimensional Points}{74}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Limitations of Linear Classifiers}{75}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}Historical Context: The Perceptron and XOR Limitation}{76}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}Challenges of High-Dimensional Geometry}{76}{subsection.3.4.4}%
\contentsline {section}{\numberline {3.5}Summary: Shortcomings of Linear Classifiers}{77}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Algebraic Viewpoint}{77}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Visual Viewpoint}{77}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}Geometric Viewpoint}{77}{subsection.3.5.3}%
\contentsline {subsection}{\numberline {3.5.4}Conclusion}{77}{subsection.3.5.4}%
\contentsline {section}{\numberline {3.6}Choosing the Weights for Linear Classifiers}{78}{section.3.6}%
\contentsline {section}{\numberline {3.7}Loss Functions}{78}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}Cross-Entropy Loss}{78}{subsection.3.7.1}%
\contentsline {subsubsection}{Softmax Function}{78}{section*.14}%
\contentsline {subsubsection}{Loss Computation}{78}{section*.15}%
\contentsline {paragraph}{Example: CIFAR-10 Image Classification}{79}{section*.16}%
\contentsline {paragraph}{Properties of Cross-Entropy Loss}{79}{section*.17}%
\contentsline {subsubsection}{Why "Cross-Entropy"?}{79}{section*.18}%
\contentsline {subsection}{\numberline {3.7.2}Multiclass SVM Loss}{80}{subsection.3.7.2}%
\contentsline {subsubsection}{Loss Definition}{80}{section*.19}%
\contentsline {subsubsection}{Example Computation}{80}{section*.20}%
\contentsline {paragraph}{Loss for the Cat Image}{80}{section*.21}%
\contentsline {paragraph}{Loss for the Car Image}{81}{section*.22}%
\contentsline {paragraph}{Loss for the Frog Image}{82}{section*.23}%
\contentsline {paragraph}{Total Loss}{82}{section*.24}%
\contentsline {subsubsection}{Key Questions and Insights}{83}{section*.25}%
\contentsline {subsection}{\numberline {3.7.3}Comparison of Cross-Entropy and Multiclass SVM Losses}{83}{subsection.3.7.3}%
\contentsline {subsubsection}{Conclusion}{83}{section*.26}%
\contentsline {chapter}{\numberline {4}Lecture 4: Regularization \& Optimization}{84}{chapter.4}%
\ttl@stoptoc {default@3}
\ttl@starttoc {default@4}
\contentsline {chapter}{\numberline {5}Lecture 5: Neural Networks}{85}{chapter.5}%
\ttl@stoptoc {default@4}
\ttl@starttoc {default@5}
\contentsline {chapter}{\numberline {6}Lecture 6: Backpropagation}{86}{chapter.6}%
\ttl@stoptoc {default@5}
\ttl@starttoc {default@6}
\contentsline {chapter}{\numberline {7}Lecture 7: Convolutional Networks}{87}{chapter.7}%
\ttl@stoptoc {default@6}
\ttl@starttoc {default@7}
\contentsline {chapter}{\numberline {8}Lecture 8: CNN Architectures I}{88}{chapter.8}%
\ttl@stoptoc {default@7}
\ttl@starttoc {default@8}
\contentsline {chapter}{\numberline {9}Lecture 9: Training Neural Networks I}{89}{chapter.9}%
\ttl@stoptoc {default@8}
\ttl@starttoc {default@9}
\contentsline {chapter}{\numberline {10}Lecture 10: Training Neural Networks II}{90}{chapter.10}%
\ttl@stoptoc {default@9}
\ttl@starttoc {default@10}
\contentsline {chapter}{\numberline {11}Lecture 11: CNN Architectures II}{91}{chapter.11}%
\ttl@stoptoc {default@10}
\ttl@starttoc {default@11}
\contentsline {section}{\numberline {11.1}Efficient Models for Edge Devices}{91}{section.11.1}%
\contentsline {chapter}{\numberline {12}Lecture 12: Deep Learning Software}{92}{chapter.12}%
\ttl@stoptoc {default@11}
\ttl@starttoc {default@12}
\contentsline {chapter}{\numberline {13}Lecture 13: Object Detection}{93}{chapter.13}%
\ttl@stoptoc {default@12}
\ttl@starttoc {default@13}
\contentsline {chapter}{\numberline {14}Lecture 14: Object Detectors}{94}{chapter.14}%
\ttl@stoptoc {default@13}
\ttl@starttoc {default@14}
\contentsline {chapter}{\numberline {15}Lecture 15: Image Segmentation}{95}{chapter.15}%
\ttl@stoptoc {default@14}
\ttl@starttoc {default@15}
\contentsline {chapter}{\numberline {16}Lecture 16: Recurrent Networks}{96}{chapter.16}%
\ttl@stoptoc {default@15}
\ttl@starttoc {default@16}
\contentsline {chapter}{\numberline {17}Lecture 17: Attention}{97}{chapter.17}%
\ttl@stoptoc {default@16}
\ttl@starttoc {default@17}
\contentsline {chapter}{\numberline {18}Lecture 18: Vision Transformers}{98}{chapter.18}%
\ttl@stoptoc {default@17}
\ttl@starttoc {default@18}
\contentsline {chapter}{\numberline {19}Lecture 19: Generative Models I}{99}{chapter.19}%
\ttl@stoptoc {default@18}
\ttl@starttoc {default@19}
\contentsline {chapter}{\numberline {20}Lecture 20: Generative Models II}{100}{chapter.20}%
\ttl@stoptoc {default@19}
\ttl@starttoc {default@20}
\contentsline {chapter}{\numberline {21}Lecture 21: Visualizing Models \& Generating Images}{101}{chapter.21}%
\ttl@stoptoc {default@20}
\ttl@starttoc {default@21}
\contentsline {chapter}{\numberline {22}Lecture 22: Self-Supervised Learning}{102}{chapter.22}%
\ttl@stoptoc {default@21}
\ttl@starttoc {default@22}
\contentsline {chapter}{\numberline {23}Lecture 23: 3D vision}{103}{chapter.23}%
\ttl@stoptoc {default@22}
\ttl@starttoc {default@23}
\contentsline {chapter}{\numberline {24}Lecture 24: Videos}{104}{chapter.24}%
\ttl@stoptoc {default@23}
\ttl@starttoc {default@24}
\contentsline {chapter}{\numberline {25}Model Compression: Quantization and Pruning}{105}{chapter.25}%
\ttl@stoptoc {default@24}
\ttl@starttoc {default@25}
\contentsline {chapter}{\numberline {26}Foundation Models in Computer Vision}{106}{chapter.26}%
\ttl@stoptoc {default@25}
\ttl@starttoc {default@26}
\contentsline {chapter}{\numberline {27}MAMBA: Multi-Agent Multi-Body Analysis}{107}{chapter.27}%
\ttl@stoptoc {default@26}
\ttl@starttoc {default@27}
\contentsfinish 
