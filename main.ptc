\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}Lecture 1: Course Introduction}{7}{chapter.1}%
\ttl@starttoc {default@1}
\contentsline {section}{\numberline {1.1}Getting Started: About the Project and How to Navigate It}{7}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Why This Document?}{7}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Acknowledgments and Contributions}{7}{subsection.1.1.2}%
\contentsline {subsection}{\numberline {1.1.3}Your Feedback Matters}{8}{subsection.1.1.3}%
\contentsline {subsection}{\numberline {1.1.4}How to Navigate This Document}{8}{subsection.1.1.4}%
\contentsline {subsection}{\numberline {1.1.5}Staying Updated in the Field}{8}{subsection.1.1.5}%
\contentsline {subsection}{\numberline {1.1.6}The Importance of Practice}{8}{subsection.1.1.6}%
\contentsline {section}{\numberline {1.2}Lecture Notes}{9}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Core Terms in the Field}{9}{subsection.1.2.1}%
\contentsline {subsubsection}{Artificial Intelligence (AI)}{9}{section*.2}%
\contentsline {subsubsection}{Machine Learning (ML)}{9}{section*.3}%
\contentsline {subsubsection}{Deep Learning (DL)}{9}{section*.4}%
\contentsline {subsubsection}{Computer Vision (CV)}{10}{section*.5}%
\contentsline {subsubsection}{Connecting the Dots}{10}{section*.6}%
\contentsline {subsubsection}{Why Study Deep Learning for Computer Vision?}{10}{section*.7}%
\contentsline {subsection}{\numberline {1.2.2}Motivation for Deep Learning in Computer Vision}{11}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Historical Milestones}{11}{subsection.1.2.3}%
\contentsline {subsubsection}{Hubel and Wiesel (1959)}{11}{section*.8}%
\contentsline {subsubsection}{Larry Roberts (1963)}{12}{section*.9}%
\contentsline {subsubsection}{David Marr (1970s)}{13}{section*.10}%
\contentsline {subsubsection}{Recognition via Parts (1970s)}{13}{section*.11}%
\contentsline {subsubsection}{Recognition via Edge Detection (1980s)}{14}{section*.12}%
\contentsline {subsubsection}{Recognition via Grouping (1990s)}{15}{section*.13}%
\contentsline {subsubsection}{Recognition via Matching and Benchmarking (2000s)}{16}{section*.14}%
\contentsline {subsubsection}{The ImageNet Dataset and Classification Challenge}{18}{section*.15}%
\contentsline {subsubsection}{AlexNet: A Revolution in Computer Vision (2012)}{19}{section*.16}%
\contentsline {subsection}{\numberline {1.2.4}Milestones in the Evolution of Learning in Computer Vision}{21}{subsection.1.2.4}%
\contentsline {subsubsection}{The Perceptron (1958)}{21}{section*.17}%
\contentsline {subsubsection}{The AI Winter and Multilayer Perceptrons (1969)}{22}{section*.18}%
\contentsline {subsubsection}{The Neocognitron (1980)}{22}{section*.19}%
\contentsline {subsubsection}{Backpropagation and the Revival of Neural Networks (1986)}{23}{section*.20}%
\contentsline {subsubsection}{LeNet and the Emergence of Convolutional Networks (1998)}{24}{section*.21}%
\contentsline {subsubsection}{The 2000s: The Era of Deep Learning}{24}{section*.22}%
\contentsline {subsubsection}{Deep Learning Explosion (2007-2020)}{25}{section*.23}%
\contentsline {subsection}{\numberline {1.2.5}2012 to Present: Deep Learning is Everywhere}{25}{subsection.1.2.5}%
\contentsline {subsubsection}{Core Vision Tasks}{26}{section*.24}%
\contentsline {subsubsection}{Video and Temporal Analysis}{26}{section*.25}%
\contentsline {subsubsection}{Generative and Multimodal Models}{26}{section*.26}%
\contentsline {subsubsection}{Specialized Domains}{26}{section*.27}%
\contentsline {subsubsection}{State-of-the-Art Foundation Models}{26}{section*.28}%
\contentsline {subsubsection}{Computation is Cheaper: More GFLOPs per Dollar}{27}{section*.29}%
\contentsline {subsection}{\numberline {1.2.6}Key Challenges in CV and Future Directions}{28}{subsection.1.2.6}%
\contentsline {chapter}{\numberline {2}Lecture 2: Image Classification}{31}{chapter.2}%
\ttl@stoptoc {default@1}
\ttl@starttoc {default@2}
\contentsline {section}{\numberline {2.1}Introduction to Image Classification}{31}{section.2.1}%
\contentsline {section}{\numberline {2.2}Image Classification Challenges}{32}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The Semantic Gap}{32}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Robustness to Camera Movement}{32}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Intra-Class Variation}{33}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Fine-Grained Classification}{33}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Background Clutter}{34}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Illumination Changes}{34}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}Deformation and Object Scale}{35}{subsection.2.2.7}%
\contentsline {subsection}{\numberline {2.2.8}Occlusions}{35}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}Summary of Challenges}{36}{subsection.2.2.9}%
\contentsline {section}{\numberline {2.3}Image Classification as a Building Block for Other Tasks}{36}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Object Detection}{37}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Image Captioning}{38}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Decision-Making in Board Games}{39}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Summary}{40}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Constructing an Image Classifier}{40}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Feature-Based Image Classification: The Classical Approach}{40}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}From Hand-Crafted Rules to Data-Driven Learning}{41}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Programming with Data: The Modern Paradigm}{42}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Data-Driven Machine Learning: The New Frontier}{42}{subsection.2.4.4}%
\contentsline {section}{\numberline {2.5}Datasets in Image Classification}{43}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}MNIST: The Toy Dataset}{43}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}CIFAR: Real-World Object Recognition}{44}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}ImageNet: The Gold Standard}{45}{subsection.2.5.3}%
\contentsline {subsection}{\numberline {2.5.4}MIT Places: Scene Recognition}{46}{subsection.2.5.4}%
\contentsline {subsection}{\numberline {2.5.5}Comparing Dataset Sizes}{46}{subsection.2.5.5}%
\contentsline {subsection}{\numberline {2.5.6}Omniglot: Few-Shot Learning}{47}{subsection.2.5.6}%
\contentsline {subsection}{\numberline {2.5.7}Conclusion: Datasets Driving Progress}{47}{subsection.2.5.7}%
\contentsline {section}{\numberline {2.6}Nearest Neighbor Classifier: A Gateway to Understanding Classification}{48}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Why Begin with Nearest Neighbor?}{48}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Setting the Stage: From Pixels to Predictions}{48}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}Algorithm Description}{48}{subsection.2.6.3}%
\contentsline {subsection}{\numberline {2.6.4}Distance Metrics: The Core of Nearest Neighbor}{49}{subsection.2.6.4}%
\contentsline {subsection}{\numberline {2.6.5}Extending Nearest Neighbor: Applications Beyond Images}{51}{subsection.2.6.5}%
\contentsline {subsubsection}{Using Nearest Neighbor for Non-Image Data}{51}{section*.30}%
\contentsline {subsubsection}{Academic Paper Recommendation Example}{52}{section*.31}%
\contentsline {subsubsection}{Key Insights}{52}{section*.32}%
\contentsline {subsection}{\numberline {2.6.6}Hyperparameters in Nearest Neighbor}{52}{subsection.2.6.6}%
\contentsline {subsection}{\numberline {2.6.7}Cross-Validation}{53}{subsection.2.6.7}%
\contentsline {subsection}{\numberline {2.6.8}Implementation and Complexity}{54}{subsection.2.6.8}%
\contentsline {subsection}{\numberline {2.6.9}Visualization of Decision Boundaries}{56}{subsection.2.6.9}%
\contentsline {subsection}{\numberline {2.6.10}Improvements: k-Nearest Neighbors}{56}{subsection.2.6.10}%
\contentsline {subsection}{\numberline {2.6.11}Limitations and Universal Approximation}{57}{subsection.2.6.11}%
\contentsline {subsection}{\numberline {2.6.12}Using CNN Features for Nearest Neighbor Classification}{58}{subsection.2.6.12}%
\contentsline {subsection}{\numberline {2.6.13}Conclusion}{60}{subsection.2.6.13}%
\contentsline {chapter}{\numberline {3}Lecture 3: Linear Classifiers}{61}{chapter.3}%
\ttl@stoptoc {default@2}
\ttl@starttoc {default@3}
\contentsline {chapter}{\numberline {4}Lecture 4: Regularization \& Optimization}{62}{chapter.4}%
\ttl@stoptoc {default@3}
\ttl@starttoc {default@4}
\contentsline {chapter}{\numberline {5}Lecture 5: Neural Networks}{63}{chapter.5}%
\ttl@stoptoc {default@4}
\ttl@starttoc {default@5}
\contentsline {chapter}{\numberline {6}Lecture 6: Backpropagation}{64}{chapter.6}%
\ttl@stoptoc {default@5}
\ttl@starttoc {default@6}
\contentsline {chapter}{\numberline {7}Lecture 7: Convolutional Networks}{65}{chapter.7}%
\ttl@stoptoc {default@6}
\ttl@starttoc {default@7}
\contentsline {chapter}{\numberline {8}Lecture 8: CNN Architectures I}{66}{chapter.8}%
\ttl@stoptoc {default@7}
\ttl@starttoc {default@8}
\contentsline {chapter}{\numberline {9}Lecture 9: Training Neural Networks I}{67}{chapter.9}%
\ttl@stoptoc {default@8}
\ttl@starttoc {default@9}
\contentsline {chapter}{\numberline {10}Lecture 10: Training Neural Networks II}{68}{chapter.10}%
\ttl@stoptoc {default@9}
\ttl@starttoc {default@10}
\contentsline {chapter}{\numberline {11}Lecture 11: CNN Architectures II}{69}{chapter.11}%
\ttl@stoptoc {default@10}
\ttl@starttoc {default@11}
\contentsline {section}{\numberline {11.1}Efficient Models for Edge Devices}{69}{section.11.1}%
\contentsline {chapter}{\numberline {12}Lecture 12: Deep Learning Software}{70}{chapter.12}%
\ttl@stoptoc {default@11}
\ttl@starttoc {default@12}
\contentsline {chapter}{\numberline {13}Lecture 13: Object Detection}{71}{chapter.13}%
\ttl@stoptoc {default@12}
\ttl@starttoc {default@13}
\contentsline {chapter}{\numberline {14}Lecture 14: Object Detectors}{72}{chapter.14}%
\ttl@stoptoc {default@13}
\ttl@starttoc {default@14}
\contentsline {chapter}{\numberline {15}Lecture 15: Image Segmentation}{73}{chapter.15}%
\ttl@stoptoc {default@14}
\ttl@starttoc {default@15}
\contentsline {chapter}{\numberline {16}Lecture 16: Recurrent Networks}{74}{chapter.16}%
\ttl@stoptoc {default@15}
\ttl@starttoc {default@16}
\contentsline {chapter}{\numberline {17}Lecture 17: Attention}{75}{chapter.17}%
\ttl@stoptoc {default@16}
\ttl@starttoc {default@17}
\contentsline {chapter}{\numberline {18}Lecture 18: Vision Transformers}{76}{chapter.18}%
\ttl@stoptoc {default@17}
\ttl@starttoc {default@18}
\contentsline {chapter}{\numberline {19}Lecture 19: Generative Models I}{77}{chapter.19}%
\ttl@stoptoc {default@18}
\ttl@starttoc {default@19}
\contentsline {chapter}{\numberline {20}Lecture 20: Generative Models II}{78}{chapter.20}%
\ttl@stoptoc {default@19}
\ttl@starttoc {default@20}
\contentsline {chapter}{\numberline {21}Lecture 21: Visualizing Models \& Generating Images}{79}{chapter.21}%
\ttl@stoptoc {default@20}
\ttl@starttoc {default@21}
\contentsline {chapter}{\numberline {22}Lecture 22: Self-Supervised Learning}{80}{chapter.22}%
\ttl@stoptoc {default@21}
\ttl@starttoc {default@22}
\contentsline {chapter}{\numberline {23}Lecture 23: 3D vision}{81}{chapter.23}%
\ttl@stoptoc {default@22}
\ttl@starttoc {default@23}
\contentsline {chapter}{\numberline {24}Lecture 24: Videos}{82}{chapter.24}%
\ttl@stoptoc {default@23}
\ttl@starttoc {default@24}
\contentsline {chapter}{\numberline {25}Model Compression: Quantization and Pruning}{83}{chapter.25}%
\ttl@stoptoc {default@24}
\ttl@starttoc {default@25}
\contentsline {chapter}{\numberline {26}Foundation Models in Computer Vision}{84}{chapter.26}%
\ttl@stoptoc {default@25}
\ttl@starttoc {default@26}
\contentsline {chapter}{\numberline {27}MAMBA: Multi-Agent Multi-Body Analysis}{85}{chapter.27}%
\ttl@stoptoc {default@26}
\ttl@starttoc {default@27}
\contentsfinish 
