\babel@toc {english}{}\relax 
\contentsline {chapter}{Preface}{25}{chapter*.2}%
\contentsline {section}{\numberline {0.1}Getting Started: About the Project and How to Navigate It}{25}{section.0.1}%
\contentsline {subsection}{\numberline {0.1.1}Why This Document?}{25}{subsection.0.1.1}%
\contentsline {subsection}{\numberline {0.1.2}Acknowledgments and Contributions}{26}{subsection.0.1.2}%
\contentsline {subsection}{\numberline {0.1.3}Your Feedback Matters}{26}{subsection.0.1.3}%
\contentsline {subsection}{\numberline {0.1.4}How to Use This Document Effectively}{26}{subsection.0.1.4}%
\contentsline {subsection}{\numberline {0.1.5}Staying Updated in the Field}{27}{subsection.0.1.5}%
\contentsline {subsection}{\numberline {0.1.6}The Importance of Practice}{28}{subsection.0.1.6}%
\contentsline {subsection}{\numberline {0.1.7}Final Remarks}{28}{subsection.0.1.7}%
\contentsline {chapter}{\numberline {1}Lecture 1: Course Introduction}{29}{chapter.1}%
\ttl@starttoc {default@1}
\contentsline {section}{\numberline {1.1}Core Terms in the Field}{29}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Artificial Intelligence (AI)}{29}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Machine Learning (ML)}{29}{subsection.1.1.2}%
\contentsline {subsection}{\numberline {1.1.3}Deep Learning (DL)}{30}{subsection.1.1.3}%
\contentsline {subsection}{\numberline {1.1.4}Computer Vision (CV)}{31}{subsection.1.1.4}%
\contentsline {subsection}{\numberline {1.1.5}Connecting the Dots}{31}{subsection.1.1.5}%
\contentsline {section}{\numberline {1.2}Why Study Deep Learning for Computer Vision?}{31}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Motivation for Deep Learning in Computer Vision}{32}{subsection.1.2.1}%
\contentsline {section}{\numberline {1.3}Historical Milestones}{32}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Hubel and Wiesel (1959): How Vision Works?}{33}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Larry Roberts (1963): From Edges to Keypoints}{33}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}David Marr (1970s): From Features to a 3D Model}{34}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Recognition via Parts (1970s)}{34}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}Recognition via Edge Detection (1980s)}{35}{subsection.1.3.5}%
\contentsline {subsection}{\numberline {1.3.6}Recognition via Grouping (1990s)}{36}{subsection.1.3.6}%
\contentsline {subsection}{\numberline {1.3.7}Recognition via Matching and Benchmarking (2000s)}{37}{subsection.1.3.7}%
\contentsline {subsection}{\numberline {1.3.8}The ImageNet Dataset and Classification Challenge}{39}{subsection.1.3.8}%
\contentsline {subsection}{\numberline {1.3.9}AlexNet: A Revolution in Computer Vision (2012)}{40}{subsection.1.3.9}%
\contentsline {subsubsection}{Building on AlexNet: Evolution of CNNs and Beyond}{40}{section*.16}%
\contentsline {section}{\numberline {1.4}Milestones in the Evolution of Learning in Computer Vision}{42}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}The Perceptron (1958)}{42}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}The AI Winter and Multilayer Perceptrons (1969)}{43}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}The Neocognitron (1980)}{44}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Backpropagation and the Revival of Neural Networks (1986)}{44}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}LeNet and the Emergence of Convolutional Networks (1998)}{45}{subsection.1.4.5}%
\contentsline {subsection}{\numberline {1.4.6}The 2000s: The Era of Deep Learning}{45}{subsection.1.4.6}%
\contentsline {subsection}{\numberline {1.4.7}Deep Learning Explosion (2007-2020)}{46}{subsection.1.4.7}%
\contentsline {subsection}{\numberline {1.4.8}2012 to Present: Deep Learning is Everywhere}{46}{subsection.1.4.8}%
\contentsline {subsubsection}{Core Vision Tasks}{46}{section*.24}%
\contentsline {subsubsection}{Video and Temporal Analysis}{46}{section*.25}%
\contentsline {subsubsection}{Generative and Multimodal Models}{47}{section*.26}%
\contentsline {subsubsection}{Specialized Domains}{47}{section*.27}%
\contentsline {subsubsection}{State-of-the-Art Foundation Models}{47}{section*.28}%
\contentsline {subsubsection}{Computation is Cheaper: More GFLOPs per Dollar}{48}{section*.31}%
\contentsline {section}{\numberline {1.5}Key Challenges in CV and Future Directions}{50}{section.1.5}%
\contentsline {chapter}{\numberline {2}Lecture 2: Image Classification}{52}{chapter.2}%
\ttl@stoptoc {default@1}
\ttl@starttoc {default@2}
\contentsline {section}{\numberline {2.1}Introduction to Image Classification}{52}{section.2.1}%
\contentsline {section}{\numberline {2.2}Image Classification Challenges}{53}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The Semantic Gap}{53}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Robustness to Camera Movement}{53}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Intra-Class Variation}{54}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Fine-Grained Classification}{54}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Background Clutter}{55}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Illumination Changes}{55}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}Deformation and Object Scale}{56}{subsection.2.2.7}%
\contentsline {subsection}{\numberline {2.2.8}Occlusions}{56}{subsection.2.2.8}%
\contentsline {subsection}{\numberline {2.2.9}Summary of Challenges}{57}{subsection.2.2.9}%
\contentsline {section}{\numberline {2.3}Image Classification as a Building Block for Other Tasks}{57}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Object Detection}{58}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Image Captioning}{59}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Decision-Making in Board Games}{60}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Summary: Leveraging Image Classification}{61}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Constructing an Image Classifier}{61}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Feature-Based Image Classification: The Classical Approach}{61}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}From Hand-Crafted Rules to Data-Driven Learning}{62}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Programming with Data: The Modern Paradigm}{63}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Data-Driven Machine Learning: The New Frontier}{63}{subsection.2.4.4}%
\contentsline {section}{\numberline {2.5}Datasets in Image Classification}{64}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}MNIST: The Toy Dataset}{64}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}CIFAR: Real-World Object Recognition}{64}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}ImageNet: The Gold Standard}{66}{subsection.2.5.3}%
\contentsline {subsection}{\numberline {2.5.4}MIT Places: Scene Recognition}{67}{subsection.2.5.4}%
\contentsline {subsection}{\numberline {2.5.5}Comparing Dataset Sizes}{67}{subsection.2.5.5}%
\contentsline {subsection}{\numberline {2.5.6}Omniglot: Few-Shot Learning}{68}{subsection.2.5.6}%
\contentsline {subsection}{\numberline {2.5.7}Conclusion: Datasets Driving Progress}{68}{subsection.2.5.7}%
\contentsline {section}{\numberline {2.6}Nearest Neighbor Classifier: A Gateway to Understanding Classification}{69}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Why Begin with Nearest Neighbor?}{69}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Setting the Stage: From Pixels to Predictions}{69}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}Algorithm Description}{69}{subsection.2.6.3}%
\contentsline {subsection}{\numberline {2.6.4}Distance Metrics: The Core of Nearest Neighbor}{70}{subsection.2.6.4}%
\contentsline {subsection}{\numberline {2.6.5}Extending Nearest Neighbor: Applications Beyond Images}{73}{subsection.2.6.5}%
\contentsline {subsubsection}{Using Nearest Neighbor for Non-Image Data}{73}{section*.67}%
\contentsline {subsubsection}{Academic Paper Recommendation Example}{73}{section*.68}%
\contentsline {subsubsection}{Key Insights}{74}{section*.70}%
\contentsline {subsection}{\numberline {2.6.6}Hyperparameters in Nearest Neighbor}{74}{subsection.2.6.6}%
\contentsline {subsection}{\numberline {2.6.7}Cross-Validation}{75}{subsection.2.6.7}%
\contentsline {subsection}{\numberline {2.6.8}Implementation and Complexity}{77}{subsection.2.6.8}%
\contentsline {subsection}{\numberline {2.6.9}Visualization of Decision Boundaries}{78}{subsection.2.6.9}%
\contentsline {subsection}{\numberline {2.6.10}Improvements: k-Nearest Neighbors}{78}{subsection.2.6.10}%
\contentsline {subsection}{\numberline {2.6.11}Limitations and Universal Approximation}{79}{subsection.2.6.11}%
\contentsline {subsection}{\numberline {2.6.12}Using CNN Features for Nearest Neighbor Classification}{80}{subsection.2.6.12}%
\contentsline {subsection}{\numberline {2.6.13}Conclusion: From Nearest Neighbor to Advanced ML Frontiers}{82}{subsection.2.6.13}%
\contentsline {chapter}{\numberline {3}Lecture 3: Linear Classifiers}{83}{chapter.3}%
\ttl@stoptoc {default@2}
\ttl@starttoc {default@3}
\contentsline {section}{\numberline {3.1}Linear Classifiers: A Foundation for Neural Networks}{83}{section.3.1}%
\contentsline {subsection}{Enrichment 3.1.1: Understanding the Role of Bias in Linear Classifiers}{86}{section*.84}%
\contentsline {paragraph}{Without Bias (\(b=0\)):}{86}{section*.85}%
\contentsline {paragraph}{With Bias (\(b = 3\)):}{86}{section*.86}%
\contentsline {subsection}{\numberline {3.1.2}A Toy Example: Grayscale Cat Image}{87}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}The Bias Trick}{88}{subsection.3.1.3}%
\contentsline {section}{\numberline {3.2}Linear Classifiers: The Algebraic Viewpoint}{90}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Scaling Properties and Insights}{90}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}From Algebra to Visual Interpretability}{91}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Linear Classifiers: The Visual Viewpoint}{91}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Template Matching Perspective}{92}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Interpreting Templates}{93}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Python Code Example: Visualizing Learned Templates}{93}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Template Limitations: Multiple Modes}{94}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5}Looking Ahead}{94}{subsection.3.3.5}%
\contentsline {section}{\numberline {3.4}Linear Classifiers: The Geometric Viewpoint}{94}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Images as High-Dimensional Points}{94}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Limitations of Linear Classifiers}{95}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}Historical Context: The Perceptron and XOR Limitation}{96}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}Challenges of High-Dimensional Geometry}{96}{subsection.3.4.4}%
\contentsline {section}{\numberline {3.5}Summary: Shortcomings of Linear Classifiers}{97}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Algebraic Viewpoint}{97}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Visual Viewpoint}{97}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}Geometric Viewpoint}{97}{subsection.3.5.3}%
\contentsline {subsection}{\numberline {3.5.4}Conclusion: Linear Classifiers Aren't Enough}{97}{subsection.3.5.4}%
\contentsline {subsection}{\numberline {3.5.5}Choosing the Weights for Linear Classifiers}{97}{subsection.3.5.5}%
\contentsline {section}{\numberline {3.6}Loss Functions}{98}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Core Requirements for Loss Functions}{98}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Desirable Properties (Depending on the Task)}{98}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Cross-Entropy Loss}{99}{subsection.3.6.3}%
\contentsline {subsubsection}{Softmax Function}{99}{section*.97}%
\contentsline {paragraph}{Advanced Note: Boltzmann Perspective.}{99}{section*.98}%
\contentsline {subsubsection}{Loss Computation}{99}{section*.99}%
\contentsline {paragraph}{Example: CIFAR-10 Image Classification}{99}{section*.100}%
\contentsline {paragraph}{Properties of Cross-Entropy Loss}{100}{section*.102}%
\contentsline {subsubsection}{Why "Cross-Entropy"?}{100}{section*.103}%
\contentsline {subsubsection}{Enrichment 3.6.3.1: Why Cross-Entropy Uses Logarithms, Not Squared Errors}{101}{section*.104}%
\contentsline {subsection}{\numberline {3.6.4}Multiclass SVM Loss}{104}{subsection.3.6.4}%
\contentsline {subsubsection}{Loss Definition}{104}{section*.105}%
\contentsline {subsubsection}{Example Computation}{104}{section*.106}%
\contentsline {paragraph}{Loss for the Cat Image}{105}{section*.107}%
\contentsline {paragraph}{Loss for the Car Image}{105}{section*.109}%
\contentsline {paragraph}{Loss for the Frog Image}{106}{section*.111}%
\contentsline {paragraph}{Total Loss}{107}{section*.113}%
\contentsline {subsubsection}{Key Questions and Insights}{107}{section*.115}%
\contentsline {subsection}{\numberline {3.6.5}Comparison of Cross-Entropy and Multiclass SVM Losses}{107}{subsection.3.6.5}%
\contentsline {subsubsection}{Debugging with Initial Loss Values}{108}{section*.117}%
\contentsline {subsubsection}{Conclusion: SVM, Cross Entropy, and the Evolving Landscape of Loss Functions}{109}{section*.118}%
\contentsline {chapter}{\numberline {4}Lecture 4: Regularization \& Optimization}{110}{chapter.4}%
\ttl@stoptoc {default@3}
\ttl@starttoc {default@4}
\contentsline {section}{\numberline {4.1}Introduction to Regularization}{110}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}How Regularization is Used?}{111}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Regularization: Simpler Models Are Preferred}{111}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Types of Regularization: L1 and L2}{112}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}L1 Regularization (Lasso)}{112}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}L2 Regularization (Ridge)}{112}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Choosing Between L1 and L2 Regularization}{113}{subsection.4.2.3}%
\contentsline {subsection}{Enrichment 4.2.4: Can We Combine L1 and L2 Regularization?}{113}{section*.120}%
\contentsline {paragraph}{When to Use Elastic Net?}{114}{section*.121}%
\contentsline {paragraph}{When Not to Use Elastic Net?}{114}{section*.122}%
\contentsline {paragraph}{Summary:}{114}{section*.123}%
\contentsline {subsection}{\numberline {4.2.5}Expressing Preferences Through Regularization}{114}{subsection.4.2.5}%
\contentsline {section}{\numberline {4.3}Impact of Feature Scaling on Regularization}{115}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Practical Implication}{115}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Example: Rescaling and Lasso Regression.}{115}{subsection.4.3.2}%
\contentsline {section}{\numberline {4.4}Regularization as a Catalyst for Better Optimization}{115}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Regularization as Part of Optimization}{115}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Augmenting the Loss Surface with Curvature}{115}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Mitigating Instability in High Dimensions}{116}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}Improving Conditioning for Faster Convergence}{116}{subsection.4.4.4}%
\contentsline {section}{\numberline {4.5}Optimization: Traversing the Loss Landscape}{116}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}The Loss Landscape Intuition}{117}{subsection.4.5.1}%
\contentsline {subsection}{Enrichment 4.5.2: Why Explicit Analytical Solutions Are Often Impractical}{117}{section*.126}%
\contentsline {subsubsection}{Enrichment 4.5.2.1: High Dimensionality}{117}{section*.127}%
\contentsline {subsubsection}{Enrichment 4.5.2.2: Non-Convexity of the Loss Landscape}{117}{section*.128}%
\contentsline {subsubsection}{Enrichment 4.5.2.3: Complexity of Regularization Terms}{118}{section*.129}%
\contentsline {subsubsection}{Enrichment 4.5.2.4: Lack of Generalizability and Flexibility}{118}{section*.130}%
\contentsline {subsubsection}{Enrichment 4.5.2.5: Memory and Computational Cost}{118}{section*.131}%
\contentsline {subsection}{\numberline {4.5.3}Optimization Idea \#1: Random Search}{119}{subsection.4.5.3}%
\contentsline {subsection}{\numberline {4.5.4}Optimization Idea \#2: Following the Slope}{119}{subsection.4.5.4}%
\contentsline {subsection}{\numberline {4.5.5}Gradients: The Mathematical Basis}{120}{subsection.4.5.5}%
\contentsline {subsubsection}{Why Does the Gradient Point to the Steepest Ascent?}{120}{section*.134}%
\contentsline {subsubsection}{Why Does the Negative Gradient Indicate the Steepest Descent?}{121}{section*.135}%
\contentsline {section}{\numberline {4.6}From Gradient Computation to Gradient Descent}{122}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Gradient Computation Methods}{122}{subsection.4.6.1}%
\contentsline {subsubsection}{Numerical Gradient: Approximating Gradients via Finite Differences}{122}{section*.137}%
\contentsline {paragraph}{Process:}{122}{section*.138}%
\contentsline {paragraph}{Advantages:}{123}{section*.140}%
\contentsline {paragraph}{Disadvantages:}{123}{section*.141}%
\contentsline {subsubsection}{Analytical Gradient: Exact Gradients via Calculus}{123}{section*.142}%
\contentsline {paragraph}{Advantages:}{123}{section*.144}%
\contentsline {paragraph}{Relation to Gradient Descent:}{123}{section*.145}%
\contentsline {subsection}{\numberline {4.6.2}Gradient Descent: The Iterative Optimization Algorithm}{124}{subsection.4.6.2}%
\contentsline {subsubsection}{Motivation and Concept}{124}{section*.146}%
\contentsline {paragraph}{Steps of Gradient Descent:}{124}{section*.147}%
\contentsline {subsubsection}{Hyperparameters of Gradient Descent}{124}{section*.149}%
\contentsline {paragraph}{1. Learning Rate (\( \eta \)):}{124}{section*.150}%
\contentsline {paragraph}{2. Weight Initialization:}{124}{section*.151}%
\contentsline {paragraph}{3. Stopping Criterion:}{125}{section*.152}%
\contentsline {section}{\numberline {4.7}Visualizing Gradient Descent}{125}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Understanding Gradient Descent Through Visualization}{125}{subsection.4.7.1}%
\contentsline {subsection}{\numberline {4.7.2}Properties of Gradient Descent}{125}{subsection.4.7.2}%
\contentsline {subsubsection}{Curved Paths Toward the Minimum}{125}{section*.154}%
\contentsline {subsubsection}{Slowing Down Near the Minimum}{126}{section*.155}%
\contentsline {subsection}{\numberline {4.7.3}Why Gradient Descent Moves \emph {All} Parameters Together}{126}{subsection.4.7.3}%
\contentsline {paragraph}{The gradient is one \( d \)-dimensional arrow}{126}{section*.156}%
\contentsline {paragraph}{Axis-aligned moves may crawl or diverge}{126}{section*.157}%
\contentsline {paragraph}{When does coordinate descent shine?}{127}{section*.158}%
\contentsline {paragraph}{Take-away}{127}{section*.159}%
\contentsline {subsection}{\numberline {4.7.4}Batch Gradient Descent}{127}{subsection.4.7.4}%
\contentsline {section}{\numberline {4.8}Stochastic Gradient Descent (SGD)}{127}{section.4.8}%
\contentsline {subsection}{\numberline {4.8.1}Introduction to Stochastic Gradient Descent}{127}{subsection.4.8.1}%
\contentsline {subsubsection}{Minibatch Gradient Computation}{128}{section*.160}%
\contentsline {subsubsection}{Data Sampling and Epochs}{128}{section*.162}%
\contentsline {subsubsection}{Why "Stochastic"?}{129}{section*.163}%
\contentsline {subsection}{\numberline {4.8.2}Advantages and Challenges of SGD}{129}{subsection.4.8.2}%
\contentsline {subsubsection}{Advantages}{129}{section*.165}%
\contentsline {subsubsection}{Challenges of SGD}{129}{section*.166}%
\contentsline {paragraph}{High Condition Numbers}{129}{section*.167}%
\contentsline {paragraph}{Saddle Points and Local Minima}{130}{section*.169}%
\contentsline {paragraph}{Noisy Gradients}{130}{section*.171}%
\contentsline {subsection}{\numberline {4.8.3}Looking Ahead: Improving SGD}{131}{subsection.4.8.3}%
\contentsline {section}{\numberline {4.9}SGD with Momentum}{131}{section.4.9}%
\contentsline {subsection}{\numberline {4.9.1}Motivation}{131}{subsection.4.9.1}%
\contentsline {subsection}{\numberline {4.9.2}How SGD with Momentum Works}{131}{subsection.4.9.2}%
\contentsline {subsubsection}{Update Equations}{132}{section*.173}%
\contentsline {subsection}{\numberline {4.9.3}Intuition Behind Momentum}{132}{subsection.4.9.3}%
\contentsline {subsection}{\numberline {4.9.4}Benefits of Momentum}{133}{subsection.4.9.4}%
\contentsline {subsection}{\numberline {4.9.5}Downsides of Momentum}{134}{subsection.4.9.5}%
\contentsline {subsection}{\numberline {4.9.6}Nesterov Momentum: A Look-Ahead Strategy}{134}{subsection.4.9.6}%
\contentsline {subsubsection}{Overview}{134}{section*.177}%
\contentsline {subsubsection}{Mathematical Formulation}{134}{section*.178}%
\contentsline {subsubsection}{Motivation and Advantages}{135}{section*.180}%
\contentsline {subsubsection}{Reformulation for Practical Implementation}{135}{section*.181}%
\contentsline {subsubsection}{Comparison with SGD and SGD+Momentum}{135}{section*.182}%
\contentsline {subsubsection}{Limitations of Nesterov Momentum and the Need for Adaptivity}{136}{section*.183}%
\contentsline {paragraph}{Motivation for a Better Optimizer: AdaGrad}{137}{section*.184}%
\contentsline {section}{\numberline {4.10}AdaGrad: Adaptive Gradient Algorithm}{137}{section.4.10}%
\contentsline {subsection}{\numberline {4.10.1}How AdaGrad Works}{137}{subsection.4.10.1}%
\contentsline {paragraph}{Updating the Weight Matrix Components}{138}{section*.186}%
\contentsline {paragraph}{Why Does This Work?}{138}{section*.187}%
\contentsline {subsection}{\numberline {4.10.2}Advantages of AdaGrad}{138}{subsection.4.10.2}%
\contentsline {subsection}{\numberline {4.10.3}Disadvantages of AdaGrad}{138}{subsection.4.10.3}%
\contentsline {section}{\numberline {4.11}RMSProp: Root Mean Square Propagation}{139}{section.4.11}%
\contentsline {subsection}{\numberline {4.11.1}Motivation for RMSProp}{139}{subsection.4.11.1}%
\contentsline {subsection}{\numberline {4.11.2}How RMSProp Works}{139}{subsection.4.11.2}%
\contentsline {subsection}{\numberline {4.11.3}Updating the Weight Matrix Components}{139}{subsection.4.11.3}%
\contentsline {subsection}{\numberline {4.11.4}Advantages of RMSProp}{140}{subsection.4.11.4}%
\contentsline {subsection}{\numberline {4.11.5}Downsides of RMSProp}{140}{subsection.4.11.5}%
\contentsline {subsubsection}{No Momentum Carry-Over}{140}{section*.189}%
\contentsline {subsubsection}{Bias in Early Updates}{141}{section*.190}%
\contentsline {subsubsection}{Sensitivity to Hyperparameters}{141}{section*.191}%
\contentsline {subsection}{\numberline {4.11.6}Motivation for Adam, a SOTA Optimizer}{141}{subsection.4.11.6}%
\contentsline {section}{\numberline {4.12}Adam: Adaptive Moment Estimation}{142}{section.4.12}%
\contentsline {subsection}{\numberline {4.12.1}Motivation for Adam}{142}{subsection.4.12.1}%
\contentsline {subsection}{\numberline {4.12.2}How Adam Works}{142}{subsection.4.12.2}%
\contentsline {subsection}{\numberline {4.12.3}Bias Correction}{143}{subsection.4.12.3}%
\contentsline {subsection}{\numberline {4.12.4}Why Adam Works Well in Practice}{144}{subsection.4.12.4}%
\contentsline {subsection}{\numberline {4.12.5}Comparison with Other Optimizers}{145}{subsection.4.12.5}%
\contentsline {subsection}{\numberline {4.12.6}Advantages of Adam}{145}{subsection.4.12.6}%
\contentsline {subsection}{\numberline {4.12.7}Limitations of Adam}{145}{subsection.4.12.7}%
\contentsline {paragraph}{Looking Ahead}{145}{section*.196}%
\contentsline {section}{\numberline {4.13}AdamW: Decoupling Weight Decay from L2 Regularization}{146}{section.4.13}%
\contentsline {subsection}{\numberline {4.13.1}Motivation for AdamW}{146}{subsection.4.13.1}%
\contentsline {subsection}{\numberline {4.13.2}How AdamW Works}{146}{subsection.4.13.2}%
\contentsline {subsection}{\numberline {4.13.3}Note on Weight Decay in AdamW}{147}{subsection.4.13.3}%
\contentsline {subsection}{\numberline {4.13.4}The AdamW Improvement}{147}{subsection.4.13.4}%
\contentsline {subsection}{\numberline {4.13.5}Advantages of AdamW}{148}{subsection.4.13.5}%
\contentsline {subsection}{\numberline {4.13.6}Why AdamW is the Default Optimizer}{148}{subsection.4.13.6}%
\contentsline {subsection}{\numberline {4.13.7}Limitations of AdamW}{148}{subsection.4.13.7}%
\contentsline {section}{\numberline {4.14}Second-Order Optimization}{148}{section.4.14}%
\contentsline {subsection}{\numberline {4.14.1}Overview of Second-Order Optimization}{148}{subsection.4.14.1}%
\contentsline {subsection}{\numberline {4.14.2}Quadratic Approximation Using the Hessian}{149}{subsection.4.14.2}%
\contentsline {subsection}{\numberline {4.14.3}Practical Challenges of Second-Order Methods}{149}{subsection.4.14.3}%
\contentsline {subsection}{\numberline {4.14.4}First-Order Methods Approximating Second-Order Behavior}{150}{subsection.4.14.4}%
\contentsline {subsection}{\numberline {4.14.5}Improving Second-Order Optimization: BFGS and L-BFGS}{150}{subsection.4.14.5}%
\contentsline {subsubsection}{BFGS: An Approximation of the Hessian Matrix}{151}{section*.202}%
\contentsline {subsubsection}{L-BFGS: Reducing Memory Requirements}{151}{section*.203}%
\contentsline {subsubsection}{Advantages and Limitations of BFGS and L-BFGS}{152}{section*.204}%
\contentsline {paragraph}{Advantages:}{152}{section*.205}%
\contentsline {paragraph}{Limitations:}{152}{section*.206}%
\contentsline {subsubsection}{Applications of L-BFGS}{152}{section*.207}%
\contentsline {subsection}{\numberline {4.14.6}Summary of Second-Order Optimization Approaches}{152}{subsection.4.14.6}%
\contentsline {chapter}{\numberline {5}Lecture 5: Neural Networks}{153}{chapter.5}%
\ttl@stoptoc {default@4}
\ttl@starttoc {default@5}
\contentsline {section}{\numberline {5.1}Introduction to Neural Networks}{153}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Limitations of Linear Classifiers}{153}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Feature Transforms as a Solution}{153}{subsection.5.1.2}%
\contentsline {subsubsection}{Feature Transforms in Action}{153}{section*.208}%
\contentsline {subsection}{\numberline {5.1.3}Challenges in Manual Feature Transformations}{155}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Data-Driven Feature Transformations}{155}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}Combining Multiple Representations}{156}{subsection.5.1.5}%
\contentsline {subsection}{\numberline {5.1.6}Real-World Example: 2011 ImageNet Winner}{156}{subsection.5.1.6}%
\contentsline {section}{\numberline {5.2}Neural Networks: The Basics}{157}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Motivation for Neural Networks}{157}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Fully Connected Networks}{158}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Interpreting Neural Networks}{159}{subsection.5.2.3}%
\contentsline {paragraph}{Network Pruning: Pruning Redundant Representations}{160}{section*.219}%
\contentsline {section}{\numberline {5.3}Building Neural Networks}{160}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Activation Functions: Non-Linear Bridges Between Layers}{161}{subsection.5.3.1}%
\contentsline {paragraph}{Why Non-Linearity Matters.}{161}{section*.222}%
\contentsline {subsection}{\numberline {5.3.2}A Simple Neural Network in 20 Lines}{162}{subsection.5.3.2}%
\contentsline {section}{\numberline {5.4}Biological Inspiration}{163}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Biological Analogy: a Loose Analogy}{164}{subsection.5.4.1}%
\contentsline {section}{\numberline {5.5}Space Warping: Another Motivation for Artificial Neural Networks}{164}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Linear Transformations and Their Limitations}{164}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Introducing Non-Linearity with ReLU}{165}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}Making Data Linearly Separable}{166}{subsection.5.5.3}%
\contentsline {subsection}{\numberline {5.5.4}Scaling Up: Increasing Representation Power}{166}{subsection.5.5.4}%
\contentsline {subsection}{\numberline {5.5.5}Regularizing Neural Networks}{167}{subsection.5.5.5}%
\contentsline {section}{\numberline {5.6}Universal Approximation Theorem}{167}{section.5.6}%
\contentsline {subsection}{\numberline {5.6.1}Practical Context: The Bump Function}{167}{subsection.5.6.1}%
\contentsline {subsection}{\numberline {5.6.2}Questions for Further Exploration}{168}{subsection.5.6.2}%
\contentsline {subsection}{\numberline {5.6.3}Reality Check: Universal Approximation is Not Enough}{168}{subsection.5.6.3}%
\contentsline {subsection}{Enrichment 5.6.4: Deep Networks vs Shallow Networks}{169}{section*.235}%
\contentsline {subsubsection}{Enrichment 5.6.4.1: Why Not Just Use a Very Deep and Wide Network?}{170}{section*.236}%
\contentsline {section}{\numberline {5.7}Convex Functions: A Special Case}{170}{section.5.7}%
\contentsline {subsection}{\numberline {5.7.1}Non-Convex Functions}{171}{subsection.5.7.1}%
\contentsline {subsection}{\numberline {5.7.2}Convex Optimization in Linear Classifiers}{171}{subsection.5.7.2}%
\contentsline {subsection}{\numberline {5.7.3}Challenges with Neural Networks}{172}{subsection.5.7.3}%
\contentsline {subsection}{\numberline {5.7.4}Bridging to Backpropagation: Efficient Gradient Computation}{172}{subsection.5.7.4}%
\contentsline {chapter}{\numberline {6}Lecture 6: Backpropagation}{173}{chapter.6}%
\ttl@stoptoc {default@5}
\ttl@starttoc {default@6}
\contentsline {section}{\numberline {6.1}Introduction: The Challenge of Computing Gradients}{173}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}A Bad Idea: Manually Deriving Gradients}{174}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}A Better Idea: Utilizing Computational Graphs (Backpropagation)}{174}{subsection.6.1.2}%
\contentsline {paragraph}{Why Use Computational Graphs?}{175}{section*.242}%
\contentsline {section}{\numberline {6.2}Toy Example of Backpropagation: $f(x,y,z) = (x + y)\,z$}{175}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Forward Pass}{176}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Backward Pass: Computing Gradients}{176}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}Why Backpropagation?}{176}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Local \& Scalable Gradients Computation}{176}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Pairing Backpropagation Gradients \& Optimizers is Easy}{177}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Modularity and Custom Nodes}{178}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Utilizing Patterns in Gradient Flow}{178}{subsection.6.3.4}%
\contentsline {subsection}{\numberline {6.3.5}Addition Gate: The Gradient Distributor}{178}{subsection.6.3.5}%
\contentsline {subsection}{\numberline {6.3.6}Copy Gate: The Gradient Adder}{179}{subsection.6.3.6}%
\contentsline {subsection}{\numberline {6.3.7}Multiplication Gate: The Gradient Swapper}{179}{subsection.6.3.7}%
\contentsline {subsection}{\numberline {6.3.8}Max Gate: The Gradient Router}{179}{subsection.6.3.8}%
\contentsline {section}{\numberline {6.4}Implementing Backpropagation in Code}{180}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Flat Backpropagation: A Direct Approach}{181}{subsection.6.4.1}%
\contentsline {paragraph}{Why Flat Backpropagation Works Well.}{181}{section*.249}%
\contentsline {section}{\numberline {6.5}A More Modular Approach: Computational Graphs in Practice}{181}{section.6.5}%
\contentsline {subsection}{\numberline {6.5.1}Topological Ordering in Computational Graphs}{182}{subsection.6.5.1}%
\contentsline {subsection}{\numberline {6.5.2}The API: Forward and Backward Methods}{182}{subsection.6.5.2}%
\contentsline {subsection}{\numberline {6.5.3}Advantages of a Modular Computational Graph}{182}{subsection.6.5.3}%
\contentsline {section}{\numberline {6.6}Implementing Backpropagation with PyTorch Autograd}{183}{section.6.6}%
\contentsline {subsection}{\numberline {6.6.1}Example: Multiplication Gate in Autograd}{183}{subsection.6.6.1}%
\contentsline {subsection}{\numberline {6.6.2}Extending Autograd for Custom Functions}{183}{subsection.6.6.2}%
\contentsline {section}{\numberline {6.7}Beyond Scalars: Backpropagation for Vectors and Tensors}{184}{section.6.7}%
\contentsline {subsection}{\numberline {6.7.1}Gradients vs.\ Jacobians}{185}{subsection.6.7.1}%
\contentsline {subsection}{\numberline {6.7.2}Extending Backpropagation to Vectors}{185}{subsection.6.7.2}%
\contentsline {subsection}{\numberline {6.7.3}Example: Backpropagation for Elementwise ReLU}{186}{subsection.6.7.3}%
\contentsline {subsection}{\numberline {6.7.4}Efficient Computation via Local Gradient Slices}{188}{subsection.6.7.4}%
\contentsline {subsection}{\numberline {6.7.5}Backpropagation with Matrices: A Concrete Example}{188}{subsection.6.7.5}%
\contentsline {paragraph}{Numerical Setup.}{188}{section*.257}%
\contentsline {paragraph}{Slice Logic for One Input Element.}{189}{section*.259}%
\contentsline {paragraph}{Another Example: \(\mathbf {X}_{2,3}\).}{189}{section*.261}%
\contentsline {subsection}{\numberline {6.7.6}Implicit Multiplication for the Entire Gradient}{190}{subsection.6.7.6}%
\contentsline {paragraph}{Why Slices Are the Solution.}{191}{section*.264}%
\contentsline {subsection}{\numberline {6.7.7}A Chain View of Backpropagation}{191}{subsection.6.7.7}%
\contentsline {subsubsection}{Reverse-Mode Automatic Differentiation}{191}{section*.265}%
\contentsline {subsubsection}{Forward-Mode Automatic Differentiation}{192}{section*.267}%
\contentsline {paragraph}{When Is Forward-Mode Automatic Differentiation is Useful?}{192}{section*.269}%
\contentsline {subsection}{\numberline {6.7.8}Computing Higher-Order Derivatives with Backpropagation}{193}{subsection.6.7.8}%
\contentsline {paragraph}{Why Compute Hessians?}{193}{section*.271}%
\contentsline {paragraph}{Efficient Hessian Computation: Hessian-Vector Products}{193}{section*.272}%
\contentsline {subsection}{\numberline {6.7.9}Application: Gradient-Norm Regularization}{194}{subsection.6.7.9}%
\contentsline {subsection}{\numberline {6.7.10}Automatic Differentiation: Summary of Key Insights}{194}{subsection.6.7.10}%
\contentsline {chapter}{\numberline {7}Lecture 7: Convolutional Networks}{195}{chapter.7}%
\ttl@stoptoc {default@6}
\ttl@starttoc {default@7}
\contentsline {section}{\numberline {7.1}Introduction: The Limitations of Fully-Connected Networks}{195}{section.7.1}%
\contentsline {section}{\numberline {7.2}Components of Convolutional Neural Networks}{196}{section.7.2}%
\contentsline {section}{\numberline {7.3}Convolutional Layers: Preserving Spatial Structure}{196}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Input and Output Dimensions}{197}{subsection.7.3.1}%
\contentsline {paragraph}{Common Filter Sizes}{197}{section*.277}%
\contentsline {paragraph}{Why Are Kernel Sizes Typically Odd?}{198}{section*.278}%
\contentsline {subsection}{\numberline {7.3.2}Filter Application and Output Calculation}{198}{subsection.7.3.2}%
\contentsline {subsection}{Enrichment 7.3.3: Understanding Convolution Through the Sobel Operator}{199}{section*.280}%
\contentsline {subsubsection}{Enrichment 7.3.3.1: Using the Sobel Kernel for Edge Detection}{199}{section*.282}%
\contentsline {paragraph}{Approximating Image Gradients with the Sobel Operator}{199}{section*.283}%
\contentsline {paragraph}{Basic Difference Operators}{200}{section*.284}%
\contentsline {paragraph}{The Sobel Filters: Adding Robustness}{200}{section*.285}%
\contentsline {subsubsection}{Enrichment 7.3.3.2: Why Does the Sobel Filter Use These Weights?}{200}{section*.286}%
\contentsline {subsubsection}{Enrichment 7.3.3.3: Computing the Gradient Magnitude}{200}{section*.287}%
\contentsline {paragraph}{Hands-On Exploration}{202}{section*.292}%
\contentsline {section}{Enrichment 7.4: Convolutional Layers with Multi-Channel Filters}{203}{section*.293}%
\contentsline {subsection}{Enrichment 7.4.1: Extending Convolution to Multi-Channel Inputs}{204}{section*.295}%
\contentsline {paragraph}{Multi-Channel Convolution Process}{205}{section*.298}%
\contentsline {paragraph}{Sliding the Filter Across the Image}{205}{section*.300}%
\contentsline {paragraph}{From Single Filters to Complete Convolutional Layers}{206}{section*.302}%
\contentsline {paragraph}{What Our Example Missed: Padding and Stride}{206}{section*.303}%
\contentsline {paragraph}{Are Kernel Values Restricted?}{206}{section*.304}%
\contentsline {paragraph}{Negative and Large Output Values}{206}{section*.305}%
\contentsline {subsection}{\numberline {7.4.2}Multiple Filters and Output Channels}{207}{subsection.7.4.2}%
\contentsline {subsection}{\numberline {7.4.3}Two Interpretations of Convolutional Outputs}{207}{subsection.7.4.3}%
\contentsline {subsection}{\numberline {7.4.4}Batch Processing with Convolutional Layers}{207}{subsection.7.4.4}%
\contentsline {section}{\numberline {7.5}Building Convolutional Neural Networks}{208}{section.7.5}%
\contentsline {subsection}{\numberline {7.5.1}Stacking Convolutional Layers}{208}{subsection.7.5.1}%
\contentsline {subsection}{\numberline {7.5.2}Adding Fully Connected Layers for Classification}{209}{subsection.7.5.2}%
\contentsline {subsection}{\numberline {7.5.3}The Need for Non-Linearity}{209}{subsection.7.5.3}%
\contentsline {subsection}{\numberline {7.5.4}Summary}{210}{subsection.7.5.4}%
\contentsline {section}{\numberline {7.6}Controlling Spatial Dimensions in Convolutional Layers}{210}{section.7.6}%
\contentsline {subsection}{\numberline {7.6.1}How Convolution Affects Spatial Size}{210}{subsection.7.6.1}%
\contentsline {subsection}{\numberline {7.6.2}Mitigating Shrinking Feature Maps: Padding}{211}{subsection.7.6.2}%
\contentsline {paragraph}{Choosing the Padding Size}{211}{section*.311}%
\contentsline {paragraph}{Preserving Border Information with Padding}{211}{section*.312}%
\contentsline {subsection}{\numberline {7.6.3}Receptive Fields: Understanding What Each Pixel Sees}{212}{subsection.7.6.3}%
\contentsline {paragraph}{The Problem of Limited Receptive Field Growth}{213}{section*.314}%
\contentsline {subsection}{\numberline {7.6.4}Controlling Spatial Reduction with Strides}{214}{subsection.7.6.4}%
\contentsline {section}{\numberline {7.7}Understanding What Convolutional Filters Learn}{214}{section.7.7}%
\contentsline {subsection}{\numberline {7.7.1}MLPs vs. CNNs: Learning Spatial Structure}{214}{subsection.7.7.1}%
\contentsline {subsection}{\numberline {7.7.2}Learning Local Features: The First Layer}{214}{subsection.7.7.2}%
\contentsline {subsection}{\numberline {7.7.3}Building More Complex Patterns in Deeper Layers}{215}{subsection.7.7.3}%
\contentsline {paragraph}{Hierarchical Learning via Composition}{215}{section*.318}%
\contentsline {section}{\numberline {7.8}Parameters and Computational Complexity in Convolutional Networks}{215}{section.7.8}%
\contentsline {subsection}{\numberline {7.8.1}Example: Convolutional Layer Setup}{216}{subsection.7.8.1}%
\contentsline {subsection}{\numberline {7.8.2}Output Volume Calculation}{216}{subsection.7.8.2}%
\contentsline {subsection}{\numberline {7.8.3}Number of Learnable Parameters}{216}{subsection.7.8.3}%
\contentsline {subsection}{\numberline {7.8.4}Multiply-Accumulate Operations (MACs)}{217}{subsection.7.8.4}%
\contentsline {paragraph}{MACs Calculation:}{217}{section*.320}%
\contentsline {subsection}{\numberline {7.8.5}MACs and FLOPs}{217}{subsection.7.8.5}%
\contentsline {subsection}{\numberline {7.8.6}Why Multiply-Add Operations (MACs) Matter}{217}{subsection.7.8.6}%
\contentsline {subsection}{Enrichment 7.8.7: Backpropagation for Convolutional Neural Networks}{217}{section*.321}%
\contentsline {paragraph}{Key Idea: Convolution as a Graph Node}{217}{section*.322}%
\contentsline {paragraph}{Computing \(\tfrac {dO}{dF}\)}{218}{section*.324}%
\contentsline {paragraph}{Computing \(\tfrac {dL}{dX}\)}{219}{section*.325}%
\contentsline {section}{Enrichment 7.9: Parameter Sharing in Convolutional Neural Networks}{220}{section*.327}%
\contentsline {subsection}{Enrichment 7.9.1: Parameter Sharing in CNNs vs. MLPs}{220}{section*.328}%
\contentsline {subsection}{Enrichment 7.9.2: Motivation for Parameter Sharing}{220}{section*.329}%
\contentsline {subsection}{Enrichment 7.9.3: How Parameter Sharing Works}{220}{section*.330}%
\contentsline {subsection}{Enrichment 7.9.4: When Does Parameter Sharing Not Make Complete Sense?}{220}{section*.331}%
\contentsline {subsection}{Enrichment 7.9.5: Alternative Approaches When Parameter Sharing Fails}{221}{section*.332}%
\contentsline {subsubsection}{Enrichment 7.9.5.1: Locally-Connected Layers}{221}{section*.333}%
\contentsline {subsubsection}{Enrichment 7.9.5.2: Understanding Locally-Connected Layers}{221}{section*.334}%
\contentsline {subsubsection}{Enrichment 7.9.5.3: Limitations of Locally-Connected Layers}{221}{section*.335}%
\contentsline {subsubsection}{Enrichment 7.9.5.4: Hybrid Approaches}{222}{section*.336}%
\contentsline {subsubsection}{Enrichment 7.9.5.5: A Glimpse at Attention Mechanisms}{222}{section*.337}%
\contentsline {section}{\numberline {7.10}Special Types of Convolutions: 1x1, 1D, and 3D Convolutions}{223}{section.7.10}%
\contentsline {subsection}{\numberline {7.10.1}1x1 Convolutions}{223}{subsection.7.10.1}%
\contentsline {subsubsection}{Dimensionality Reduction and Feature Selection}{223}{section*.338}%
\contentsline {subsubsection}{Efficiency of 1x1 Convolutions as a Bottleneck}{223}{section*.340}%
\contentsline {paragraph}{Example: Transforming 256 Channels to 256 Channels with a 3x3 Kernel.}{224}{section*.341}%
\contentsline {paragraph}{Parameter and FLOP Savings.}{224}{section*.342}%
\contentsline {subsection}{\numberline {7.10.2}1D Convolutions}{224}{subsection.7.10.2}%
\contentsline {paragraph}{Numerical Example: 1D Convolution on Multichannel Time Series Data}{224}{section*.343}%
\contentsline {paragraph}{Computing the Output}{225}{section*.344}%
\contentsline {paragraph}{Applications of 1D Convolutions}{225}{section*.345}%
\contentsline {subsection}{\numberline {7.10.3}3D Convolutions}{226}{subsection.7.10.3}%
\contentsline {paragraph}{Numerical Example: 3D Convolution on Volumetric Data}{226}{section*.347}%
\contentsline {paragraph}{3D Convolution Formula}{227}{section*.348}%
\contentsline {paragraph}{Computing the Output}{227}{section*.349}%
\contentsline {paragraph}{Final Output Tensor}{228}{section*.350}%
\contentsline {paragraph}{Applications of 3D Convolutions}{228}{section*.351}%
\contentsline {paragraph}{Advantages of 3D Convolutions}{228}{section*.352}%
\contentsline {paragraph}{Challenges of 3D Convolutions}{228}{section*.353}%
\contentsline {subsection}{\numberline {7.10.4}Efficient Convolutions for Mobile and Embedded Systems}{228}{subsection.7.10.4}%
\contentsline {subsection}{\numberline {7.10.5}Spatial Separable Convolutions}{228}{subsection.7.10.5}%
\contentsline {paragraph}{Concept and Intuition}{228}{section*.354}%
\contentsline {paragraph}{Limitations and Transition to Depthwise Separable Convolutions}{229}{section*.355}%
\contentsline {subsection}{\numberline {7.10.6}Depthwise Separable Convolutions}{229}{subsection.7.10.6}%
\contentsline {paragraph}{Concept and Motivation}{229}{section*.356}%
\contentsline {paragraph}{Computational Efficiency}{230}{section*.357}%
\contentsline {paragraph}{Standard \((K \times K)\) Convolution}{230}{section*.358}%
\contentsline {paragraph}{Depthwise Separable Convolution}{230}{section*.359}%
\contentsline {subsubsection}{Example: \((K=3,\tmspace +\thickmuskip {.2777em}C_{\mathrm {in}}=128,\tmspace +\thickmuskip {.2777em}C_{\mathrm {out}}=256,\tmspace +\thickmuskip {.2777em}H=W=32)\)}{230}{section*.360}%
\contentsline {paragraph}{Reduction Factor}{232}{section*.362}%
\contentsline {paragraph}{Practical Usage and Examples}{232}{section*.363}%
\contentsline {paragraph}{Trade-Offs}{232}{section*.364}%
\contentsline {subsection}{\numberline {7.10.7}Summary of Specialized Convolutions}{232}{subsection.7.10.7}%
\contentsline {section}{\numberline {7.11}Pooling Layers}{234}{section.7.11}%
\contentsline {subsection}{\numberline {7.11.1}Types of Pooling}{234}{subsection.7.11.1}%
\contentsline {paragraph}{Pooling Methods}{234}{section*.367}%
\contentsline {subsection}{\numberline {7.11.2}Effect of Pooling}{234}{subsection.7.11.2}%
\contentsline {subsection}{Enrichment 7.11.3: Pooling Layers in Backpropagation}{235}{section*.370}%
\contentsline {subsubsection}{Forward Pass of Pooling Layers}{235}{section*.371}%
\contentsline {paragraph}{Example of Forward Pass}{235}{section*.372}%
\contentsline {subsubsection}{Backpropagation Through Pooling Layers}{236}{section*.373}%
\contentsline {paragraph}{Max Pooling Backpropagation}{236}{section*.374}%
\contentsline {paragraph}{Impact on Gradient Flow}{236}{section*.375}%
\contentsline {paragraph}{Mitigation Strategies}{236}{section*.376}%
\contentsline {paragraph}{Average Pooling Backpropagation}{237}{section*.377}%
\contentsline {subsubsection}{Generalization of Backpropagation for Pooling}{237}{section*.378}%
\contentsline {subsection}{\numberline {7.11.4}Global Pooling Layers}{237}{subsection.7.11.4}%
\contentsline {subsubsection}{General Advantages}{237}{section*.379}%
\contentsline {subsubsection}{Global Average Pooling (GAP)}{237}{section*.380}%
\contentsline {paragraph}{Operation}{237}{section*.381}%
\contentsline {paragraph}{Upsides}{238}{section*.382}%
\contentsline {paragraph}{Downsides}{238}{section*.383}%
\contentsline {paragraph}{Backpropagation}{238}{section*.384}%
\contentsline {subsubsection}{Global Max Pooling (GMP)}{238}{section*.385}%
\contentsline {paragraph}{Operation.}{238}{section*.386}%
\contentsline {paragraph}{Upsides}{238}{section*.387}%
\contentsline {paragraph}{Downsides}{238}{section*.388}%
\contentsline {paragraph}{Backpropagation}{238}{section*.389}%
\contentsline {subsubsection}{Comparison of GAP and GMP}{238}{section*.390}%
\contentsline {subsubsection}{Contrasting with Regular Pooling}{239}{section*.391}%
\contentsline {paragraph}{Window Size}{239}{section*.392}%
\contentsline {paragraph}{When to Use Global Pooling}{239}{section*.393}%
\contentsline {paragraph}{When to Use Regular Pooling}{239}{section*.394}%
\contentsline {section}{\numberline {7.12}Classical CNN Architectures}{240}{section.7.12}%
\contentsline {subsection}{\numberline {7.12.1}LeNet-5 Architecture}{240}{subsection.7.12.1}%
\contentsline {subsubsection}{Detailed Layer Breakdown}{241}{section*.396}%
\contentsline {subsubsection}{Summary of LeNet-5}{242}{section*.397}%
\contentsline {subsubsection}{Key Architectural Trends in CNNs, Illustrated by LeNet-5}{242}{section*.398}%
\contentsline {paragraph}{Hierarchical Feature Learning}{242}{section*.399}%
\contentsline {paragraph}{Alternating Convolution and Pooling}{242}{section*.400}%
\contentsline {paragraph}{Transition to Fully Connected (FC) Layers}{242}{section*.401}%
\contentsline {subsection}{\numberline {7.12.2}How Are CNN Architectures Designed?}{242}{subsection.7.12.2}%
\contentsline {section}{Enrichment 7.13: Vanishing \& Exploding Gradients: A Barrier to DL}{243}{section*.402}%
\contentsline {paragraph}{Context}{243}{section*.403}%
\contentsline {subsection}{Enrichment 7.13.1: Understanding the Problem}{243}{section*.404}%
\contentsline {subsubsection}{The Role of Gradients in Deep Networks}{243}{section*.405}%
\contentsline {subsubsection}{Gradient Computation in Deep Networks}{243}{section*.406}%
\contentsline {paragraph}{Key Components of Gradient Propagation}{243}{section*.407}%
\contentsline {subsubsection}{Impact of Depth in Neural Networks}{244}{section*.408}%
\contentsline {subsubsection}{Practical Example: Vanishing Gradients with Sigmoid Activation}{246}{section*.409}%
\contentsline {subsubsection}{Effect of Activation Gradients}{247}{section*.411}%
\contentsline {subsubsection}{Effect of Weight Multiplications}{247}{section*.412}%
\contentsline {subsubsection}{Conclusion: Vanishing Gradients}{247}{section*.413}%
\contentsline {section}{\numberline {7.14}Batch Normalization}{249}{section.7.14}%
\contentsline {subsection}{\numberline {7.14.1}Understanding Mean, Variance, and Normalization}{249}{subsection.7.14.1}%
\contentsline {paragraph}{Mean:}{249}{section*.414}%
\contentsline {paragraph}{Variance:}{249}{section*.415}%
\contentsline {paragraph}{Standard Deviation:}{249}{section*.416}%
\contentsline {paragraph}{Effect of Normalization:}{249}{section*.417}%
\contentsline {subsection}{\numberline {7.14.2}Internal Covariate Shift and Batch Normalizationâ€™s Role}{250}{subsection.7.14.2}%
\contentsline {paragraph}{What is Covariate Shift?}{250}{section*.418}%
\contentsline {paragraph}{What is Internal Covariate Shift?}{250}{section*.419}%
\contentsline {subsection}{\numberline {7.14.3}Batch Normalization Process}{250}{subsection.7.14.3}%
\contentsline {paragraph}{Why is this flexibility useful?}{251}{section*.421}%
\contentsline {subsubsection}{Batch Normalization for Convolutional Neural Networks (CNNs)}{252}{section*.422}%
\contentsline {subsection}{\numberline {7.14.4}Batch Normalization and Optimization}{253}{subsection.7.14.4}%
\contentsline {subsubsection}{Beyond Covariate Shift: Why Does BatchNorm Improve Training?}{253}{section*.424}%
\contentsline {subsubsection}{Why Does BatchNorm Smooth the Loss Surface?}{254}{section*.427}%
\contentsline {paragraph}{1. Hessian Eigenvalues and Loss Surface Curvature}{254}{section*.428}%
\contentsline {paragraph}{Computing Eigenvalues}{254}{section*.429}%
\contentsline {paragraph}{Interpretation of Eigenvalues}{255}{section*.430}%
\contentsline {paragraph}{2. Reducing the Lipschitz Constant}{255}{section*.431}%
\contentsline {paragraph}{3. Implicit Regularization via Mini-Batch Noise}{255}{section*.432}%
\contentsline {paragraph}{4. Decoupling Weight Norm from Direction: A Geometric Reparameterization}{256}{section*.433}%
\contentsline {paragraph}{5. Stabilizing Deep Networks and Preventing Dead Activations}{256}{section*.434}%
\contentsline {subsubsection}{Conclusion: Why BatchNorm Helpsâ€”With Caution}{257}{section*.435}%
\contentsline {subsubsection}{Batch Normalization in Test Time}{258}{section*.436}%
\contentsline {subsubsection}{Limitations of BatchNorm}{258}{section*.438}%
\contentsline {subsection}{Enrichment 7.14.5: Batch Normalization Placement}{259}{section*.439}%
\contentsline {subsubsection}{Batch Normalization Placement: Typical Ordering}{259}{section*.440}%
\contentsline {paragraph}{Mathematical Rationale}{259}{section*.441}%
\contentsline {subsection}{\numberline {7.14.6}Alternative Normalization Methods (LN, IN, GN, ...)}{260}{subsection.7.14.6}%
\contentsline {subsubsection}{Layer Normalization (LN)}{260}{section*.442}%
\contentsline {paragraph}{Core Idea}{260}{section*.443}%
\contentsline {paragraph}{Definition (Fully Connected Layers)}{260}{section*.445}%
\contentsline {paragraph}{Extension to Convolutional Layers}{261}{section*.446}%
\contentsline {paragraph}{Interpretation}{261}{section*.448}%
\contentsline {paragraph}{Advantages of Layer Normalization}{261}{section*.449}%
\contentsline {subsubsection}{Instance Normalization (IN)}{262}{section*.450}%
\contentsline {paragraph}{Interpretation}{262}{section*.452}%
\contentsline {paragraph}{Advantages of Instance Normalization}{262}{section*.453}%
\contentsline {subsubsection}{Group Normalization (GN)}{263}{section*.454}%
\contentsline {paragraph}{Interpretation}{263}{section*.456}%
\contentsline {paragraph}{Advantages of Group Normalization}{263}{section*.457}%
\contentsline {subsubsection}{Why Do IN, LN, and GN Improve Optimization?}{264}{section*.458}%
\contentsline {paragraph}{Common Benefits Across IN, LN, and GN}{264}{section*.459}%
\contentsline {paragraph}{Summary: How These Methods Enhance Training}{264}{section*.460}%
\contentsline {subsection}{Enrichment 7.14.7: Backpropagation for Batch Normalization}{264}{section*.461}%
\contentsline {paragraph}{Chain Rule in the Graph}{265}{section*.462}%
\contentsline {subparagraph}{Gradients w.r.t.\ \(\gamma \) and \(\beta \)}{265}{subparagraph*.463}%
\contentsline {subparagraph}{Gradient w.r.t.\ \(\hat {x}_i\)}{265}{subparagraph*.464}%
\contentsline {paragraph}{Gradients Involving \(\mu \) and \(\sigma ^2\)}{265}{section*.465}%
\contentsline {paragraph}{Final: Gradients w.r.t.\ Each \(x_i\)}{266}{section*.466}%
\contentsline {paragraph}{Computational Efficiency}{266}{section*.467}%
\contentsline {paragraph}{Extension to LN, IN, GN}{266}{section*.468}%
\contentsline {paragraph}{Conclusion}{266}{section*.469}%
\contentsline {subsection}{Enrichment 7.14.8: Batch Normalization \& \(\ell _2\) Regularization}{267}{section*.470}%
\contentsline {paragraph}{Context and References}{267}{section*.471}%
\contentsline {paragraph}{1. \(\ell _2\) Regularization Without BatchNorm}{267}{section*.472}%
\contentsline {paragraph}{2. BN Cancels Weight Norm in the Forward Pass}{267}{section*.473}%
\contentsline {paragraph}{3. Why \(\ell _2\) Still Matters: Learning Dynamics Perspective}{268}{section*.474}%
\contentsline {paragraph}{4. Coexisting With Learning Rate Schedules}{269}{section*.475}%
\contentsline {paragraph}{5. Behavior of BNâ€™s \(\gamma , \beta \)}{269}{section*.476}%
\contentsline {paragraph}{6. Recommendations}{269}{section*.477}%
\contentsline {paragraph}{7. Conclusion: BN \& L2 Are Complementary, Not Contradictory}{270}{section*.478}%
\contentsline {chapter}{\numberline {8}Lecture 8: CNN Architectures I}{271}{chapter.8}%
\ttl@stoptoc {default@7}
\ttl@starttoc {default@8}
\contentsline {section}{\numberline {8.1}Introduction: From Building Blocks to SOTA CNNs}{271}{section.8.1}%
\contentsline {section}{\numberline {8.2}AlexNet}{271}{section.8.2}%
\contentsline {subsection}{\numberline {8.2.1}Architecture Details}{272}{subsection.8.2.1}%
\contentsline {paragraph}{First Convolutional Layer (Conv1)}{272}{section*.479}%
\contentsline {paragraph}{Memory Requirements}{272}{section*.480}%
\contentsline {paragraph}{Number of Learnable Parameters}{272}{section*.481}%
\contentsline {paragraph}{Computational Cost}{272}{section*.482}%
\contentsline {paragraph}{Max Pooling Layer}{272}{section*.483}%
\contentsline {paragraph}{Memory and Computational Cost}{273}{section*.484}%
\contentsline {subsection}{\numberline {8.2.2}Final Fully Connected Layers}{273}{subsection.8.2.2}%
\contentsline {paragraph}{Computational Cost}{273}{section*.485}%
\contentsline {subsection}{\numberline {8.2.3}Key Takeaways from AlexNet}{274}{subsection.8.2.3}%
\contentsline {subsection}{\numberline {8.2.4}ZFNet: An Improvement on AlexNet}{274}{subsection.8.2.4}%
\contentsline {subsubsection}{Key Modifications in ZFNet}{275}{section*.489}%
\contentsline {section}{\numberline {8.3}VGG: A Principled CNN Architecture}{275}{section.8.3}%
\contentsline {paragraph}{Historical Context.}{275}{section*.490}%
\contentsline {paragraph}{Core Design Principles.}{275}{section*.492}%
\contentsline {subsection}{\numberline {8.3.1}Network Structure}{275}{subsection.8.3.1}%
\contentsline {subsection}{\numberline {8.3.2}Key Architectural Insights}{276}{subsection.8.3.2}%
\contentsline {subsubsection}{Small-Kernel Convolutions (\(3\times 3\))}{276}{section*.494}%
\contentsline {subsubsection}{Pooling \(\,2\times 2\), Stride=2, No Padding}{276}{section*.495}%
\contentsline {subsubsection}{Doubling Channels After Each Pool}{276}{section*.496}%
\contentsline {subsection}{\numberline {8.3.3}Why This Strategy Works}{277}{subsection.8.3.3}%
\contentsline {paragraph}{Balanced Computation.}{277}{section*.497}%
\contentsline {paragraph}{Influence on Later Architectures.}{277}{section*.498}%
\contentsline {subsection}{\numberline {8.3.4}Practical Observations}{277}{subsection.8.3.4}%
\contentsline {subsection}{\numberline {8.3.5}Training Very Deep Networks: The VGG Approach}{277}{subsection.8.3.5}%
\contentsline {subsubsection}{Incremental Training Strategy}{277}{section*.499}%
\contentsline {subsubsection}{Optimization and Training Details}{278}{section*.500}%
\contentsline {subsubsection}{Effectiveness of the Approach}{278}{section*.501}%
\contentsline {section}{\numberline {8.4}GoogLeNet: Efficiency and Parallelism}{278}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Stem Network: Efficient Early Downsampling}{279}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}The Inception Module: Parallel Feature Extraction}{279}{subsection.8.4.2}%
\contentsline {subsubsection}{Why Does the Inception Module Improve Gradient Flow?}{280}{section*.505}%
\contentsline {paragraph}{Structure of the Inception Module}{281}{section*.506}%
\contentsline {subsection}{\numberline {8.4.3}Global Average Pooling (GAP)}{281}{subsection.8.4.3}%
\contentsline {subsection}{\numberline {8.4.4}Auxiliary Classifiers: A Workaround for Vanishing Gradients}{282}{subsection.8.4.4}%
\contentsline {paragraph}{Why Were Auxiliary Classifiers Needed?}{282}{section*.508}%
\contentsline {paragraph}{How Do They Help?}{282}{section*.509}%
\contentsline {paragraph}{Auxiliary Classifier Design}{282}{section*.510}%
\contentsline {paragraph}{Gradient Flow and Regularization}{283}{section*.512}%
\contentsline {paragraph}{Relevance Today}{283}{section*.513}%
\contentsline {paragraph}{Conclusion}{283}{section*.514}%
\contentsline {section}{\numberline {8.5}The Rise of Residual Networks (ResNets)}{284}{section.8.5}%
\contentsline {subsection}{\numberline {8.5.1}Challenges in Training Deep Neural Networks}{284}{subsection.8.5.1}%
\contentsline {subsection}{\numberline {8.5.2}The Need for Residual Connections}{284}{subsection.8.5.2}%
\contentsline {subsection}{\numberline {8.5.3}Introducing Residual Blocks}{285}{subsection.8.5.3}%
\contentsline {paragraph}{Intuition Behind Residual Connections}{286}{section*.518}%
\contentsline {subsection}{\numberline {8.5.4}Architectural Design of ResNets}{286}{subsection.8.5.4}%
\contentsline {subsection}{\numberline {8.5.5}Bottleneck Blocks for Deeper Networks}{287}{subsection.8.5.5}%
\contentsline {subsection}{\numberline {8.5.6}ResNet Winning Streak and Continued Influence}{288}{subsection.8.5.6}%
\contentsline {subsection}{\numberline {8.5.7}Further Improvements: Pre-Activation Blocks}{288}{subsection.8.5.7}%
\contentsline {subsection}{\numberline {8.5.8}Architectural Comparisons and Evolution Beyond ResNet}{289}{subsection.8.5.8}%
\contentsline {subsubsection}{The 2016 ImageNet Challenge: Lack of Novelty}{289}{section*.523}%
\contentsline {subsubsection}{Comparing Model Complexity and Efficiency}{289}{section*.524}%
\contentsline {subsubsection}{Beyond ResNets: Refinements and Lightweight Models}{290}{section*.526}%
\contentsline {chapter}{\numberline {9}Lecture 9: Training Neural Networks I}{291}{chapter.9}%
\ttl@stoptoc {default@8}
\ttl@starttoc {default@9}
\contentsline {section}{\numberline {9.1}Introduction to Training Neural Networks}{291}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Categories of Practical Training Subjects}{291}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Activation Functions}{292}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Sigmoid Activation Function}{292}{subsection.9.2.1}%
\contentsline {subsubsection}{Issues with the Sigmoid Function}{292}{section*.527}%
\contentsline {subsubsection}{The Tanh Activation Function}{294}{section*.530}%
\contentsline {subsection}{\numberline {9.2.2}Rectified Linear Units (ReLU) and Its Variants}{295}{subsection.9.2.2}%
\contentsline {subsubsection}{Issues with ReLU}{295}{section*.532}%
\contentsline {subsubsection}{Mitigation Strategies for ReLU Issues}{296}{section*.534}%
\contentsline {subsubsection}{Leaky ReLU and Parametric ReLU (PReLU)}{297}{section*.535}%
\contentsline {subsubsection}{Exponential Linear Unit (ELU)}{297}{section*.537}%
\contentsline {subsubsection}{Scaled Exponential Linear Unit (SELU)}{298}{section*.539}%
\contentsline {paragraph}{Definition and Self-Normalization Properties}{299}{section*.540}%
\contentsline {paragraph}{Derivation of \(\alpha \) and \(\lambda \)}{299}{section*.541}%
\contentsline {paragraph}{Weight Initialization and Network Architecture Considerations}{299}{section*.542}%
\contentsline {paragraph}{Practical Considerations and Limitations}{299}{section*.543}%
\contentsline {subsubsection}{Gaussian Error Linear Unit (GELU)}{300}{section*.545}%
\contentsline {paragraph}{Definition}{300}{section*.546}%
\contentsline {paragraph}{Advantages of GELU}{301}{section*.548}%
\contentsline {paragraph}{Comparisons with ReLU and ELU}{301}{section*.549}%
\contentsline {paragraph}{Computational Considerations}{302}{section*.550}%
\contentsline {subsection}{Enrichment 9.2.3: Swish: A Self-Gated Activation Function}{302}{section*.551}%
\contentsline {subsubsection}{Advantages of Swish}{303}{section*.553}%
\contentsline {subsubsection}{Disadvantages of Swish}{303}{section*.554}%
\contentsline {subsubsection}{Comparison to Other Top-Tier Activations}{303}{section*.555}%
\contentsline {subsubsection}{Conclusion}{304}{section*.556}%
\contentsline {subsection}{\numberline {9.2.4}Choosing the Right Activation Function}{304}{subsection.9.2.4}%
\contentsline {subsubsection}{General Guidelines for Choosing an Activation Function}{304}{section*.558}%
\contentsline {section}{\numberline {9.3}Data Pre-Processing}{305}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}Why Pre-Processing Matters}{305}{subsection.9.3.1}%
\contentsline {subsection}{\numberline {9.3.2}Avoiding Poor Training Dynamics}{305}{subsection.9.3.2}%
\contentsline {subsection}{\numberline {9.3.3}Common Pre-Processing Techniques}{306}{subsection.9.3.3}%
\contentsline {subsection}{\numberline {9.3.4}Normalization for Robust Optimization}{307}{subsection.9.3.4}%
\contentsline {subsection}{\numberline {9.3.5}Maintaining Consistency During Inference}{307}{subsection.9.3.5}%
\contentsline {subsection}{\numberline {9.3.6}Pre-Processing in Well-Known Architectures}{307}{subsection.9.3.6}%
\contentsline {section}{\numberline {9.4}Weight Initialization}{308}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Constant Initialization}{308}{subsection.9.4.1}%
\contentsline {subsubsection}{Zero Initialization}{308}{section*.562}%
\contentsline {subsubsection}{Nonzero Constant Initialization}{309}{section*.563}%
\contentsline {paragraph}{Forward Pass Analysis}{309}{section*.564}%
\contentsline {paragraph}{Backpropagation and Gradient Symmetry}{309}{section*.565}%
\contentsline {paragraph}{Implications and Conclusion}{310}{section*.566}%
\contentsline {subsection}{\numberline {9.4.2}Breaking Symmetry: Random Initialization}{310}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}Variance-Based Initialization: Ensuring Stable Information Flow}{310}{subsection.9.4.3}%
\contentsline {paragraph}{Key Requirements for Stable Propagation}{311}{section*.567}%
\contentsline {paragraph}{Forward Pass Analysis}{311}{section*.568}%
\contentsline {paragraph}{Why Is This Important?}{311}{section*.569}%
\contentsline {paragraph}{Why Does Forward Signal Variance Also Matter?}{311}{section*.570}%
\contentsline {paragraph}{Challenges in Achieving Stable Variance}{312}{section*.571}%
\contentsline {subsection}{\numberline {9.4.4}Xavier Initialization}{312}{subsection.9.4.4}%
\contentsline {subsubsection}{Motivation}{312}{section*.572}%
\contentsline {subsubsection}{Mathematical Formulation}{313}{section*.574}%
\contentsline {subsubsection}{Assumptions}{313}{section*.575}%
\contentsline {subsubsection}{Derivation of Xavier Initialization}{314}{section*.576}%
\contentsline {paragraph}{Forward Pass: Maintaining Activation Variance}{314}{section*.577}%
\contentsline {paragraph}{Backward Pass: Maintaining Gradient Variance}{314}{section*.578}%
\contentsline {paragraph}{Balancing Forward and Backward Variance}{315}{section*.579}%
\contentsline {subsubsection}{Final Xavier Initialization Formulation}{316}{section*.580}%
\contentsline {subsubsection}{Limitations of Xavier Initialization}{316}{section*.581}%
\contentsline {subsection}{\numberline {9.4.5}Kaiming He Initialization}{317}{subsection.9.4.5}%
\contentsline {subsubsection}{Motivation}{317}{section*.582}%
\contentsline {paragraph}{Mathematical Notation}{318}{section*.585}%
\contentsline {subsubsection}{Assumptions}{318}{section*.586}%
\contentsline {subsubsection}{Forward and Backward Pass Derivation}{319}{section*.587}%
\contentsline {paragraph}{Forward Pass Analysis}{319}{section*.588}%
\contentsline {paragraph}{Backward Pass Analysis}{320}{section*.589}%
\contentsline {subsubsection}{Final Kaiming Initialization Formulation}{320}{section*.590}%
\contentsline {subsubsection}{Implementation in Deep Learning Frameworks}{320}{section*.591}%
\contentsline {subsubsection}{Initialization in Residual Networks (ResNets)}{321}{section*.592}%
\contentsline {paragraph}{Why Doesn't Kaiming Initialization Work for ResNets?}{321}{section*.593}%
\contentsline {paragraph}{Fixup Initialization}{321}{section*.594}%
\contentsline {subsection}{\numberline {9.4.6}Conclusion: Choosing the Right Initialization Strategy}{322}{subsection.9.4.6}%
\contentsline {subsubsection}{Ongoing Research and Open Questions}{322}{section*.596}%
\contentsline {section}{\numberline {9.5}Regularization Techniques}{323}{section.9.5}%
\contentsline {subsection}{\numberline {9.5.1}Dropout}{323}{subsection.9.5.1}%
\contentsline {subsubsection}{Why Does Dropout Work?}{324}{section*.599}%
\contentsline {subsubsection}{Dropout at Test Time}{325}{section*.601}%
\contentsline {subsubsection}{Inverted Dropout}{327}{section*.605}%
\contentsline {subsubsection}{Where is Dropout Used in CNNs?}{328}{section*.607}%
\contentsline {subsection}{Enrichment 9.5.2: Ordering of Dropout and Batch Normalization}{328}{section*.609}%
\contentsline {subsubsection}{Enrichment 9.5.2.1: Impact of Dropout Placement on BN}{329}{section*.610}%
\contentsline {subsubsection}{Enrichment 9.5.2.2: Why BN Before Dropout is Preferred}{329}{section*.611}%
\contentsline {subsection}{\numberline {9.5.3}Other Regularization Techniques}{330}{subsection.9.5.3}%
\contentsline {subsubsection}{Data Augmentation as Implicit Regularization}{330}{section*.612}%
\contentsline {subsubsection}{DropConnect}{332}{section*.616}%
\contentsline {paragraph}{Comparison Between Dropout and DropConnect}{332}{section*.618}%
\contentsline {paragraph}{Effectiveness and Use Cases}{333}{section*.619}%
\contentsline {paragraph}{Summary}{333}{section*.620}%
\contentsline {subsubsection}{Fractional Max Pooling}{333}{section*.621}%
\contentsline {subsubsection}{Stochastic Depth}{334}{section*.623}%
\contentsline {subsubsection}{CutOut}{334}{section*.625}%
\contentsline {subsubsection}{MixUp}{335}{section*.627}%
\contentsline {subsubsection}{Summary and Regularization Guidelines}{336}{section*.629}%
\contentsline {chapter}{\numberline {10}Lecture 10: Training Neural Networks II}{337}{chapter.10}%
\ttl@stoptoc {default@9}
\ttl@starttoc {default@10}
\contentsline {section}{\numberline {10.1}Learning Rate Schedules}{337}{section.10.1}%
\contentsline {subsection}{\numberline {10.1.1}The Importance of Learning Rate Selection}{337}{subsection.10.1.1}%
\contentsline {subsection}{\numberline {10.1.2}Step Learning Rate Schedule}{338}{subsection.10.1.2}%
\contentsline {subsubsection}{Practical Considerations}{339}{section*.632}%
\contentsline {subsection}{\numberline {10.1.3}Cosine Learning Rate Decay}{339}{subsection.10.1.3}%
\contentsline {subsection}{\numberline {10.1.4}Linear Learning Rate Decay}{340}{subsection.10.1.4}%
\contentsline {subsection}{\numberline {10.1.5}Inverse Square Root Decay}{341}{subsection.10.1.5}%
\contentsline {subsection}{\numberline {10.1.6}Constant Learning Rate}{342}{subsection.10.1.6}%
\contentsline {subsection}{\numberline {10.1.7}Adaptive Learning Rate Mechanisms}{343}{subsection.10.1.7}%
\contentsline {subsection}{\numberline {10.1.8}Early Stopping}{343}{subsection.10.1.8}%
\contentsline {section}{\numberline {10.2}Hyperparameter Selection}{344}{section.10.2}%
\contentsline {subsection}{\numberline {10.2.1}Grid Search}{344}{subsection.10.2.1}%
\contentsline {subsection}{\numberline {10.2.2}Random Search}{344}{subsection.10.2.2}%
\contentsline {subsection}{\numberline {10.2.3}Steps for Hyperparameter Tuning}{345}{subsection.10.2.3}%
\contentsline {subsection}{\numberline {10.2.4}Interpreting Learning Curves}{347}{subsection.10.2.4}%
\contentsline {subsection}{\numberline {10.2.5}Model Ensembles and Averaging Techniques}{351}{subsection.10.2.5}%
\contentsline {subsection}{\numberline {10.2.6}Exponential Moving Average (EMA) and Polyak Averaging}{352}{subsection.10.2.6}%
\contentsline {section}{\numberline {10.3}Transfer Learning}{352}{section.10.3}%
\contentsline {subsection}{\numberline {10.3.1}How to Perform Transfer Learning with CNNs?}{356}{subsection.10.3.1}%
\contentsline {subsection}{\numberline {10.3.2}Transfer Learning Beyond Classification}{357}{subsection.10.3.2}%
\contentsline {subsection}{\numberline {10.3.3}Does Transfer Learning Always Win?}{358}{subsection.10.3.3}%
\contentsline {subsection}{Enrichment 10.3.4: Regularization in the Era of Finetuning}{359}{section*.658}%
\contentsline {paragraph}{1. Freezing Most of the Backbone}{359}{section*.659}%
\contentsline {paragraph}{2. Regularizing Small Trainable Heads: Caution With Dropout}{359}{section*.660}%
\contentsline {paragraph}{3. Training From Scratch on Large Datasets}{359}{section*.661}%
\contentsline {paragraph}{4. Implicit and Soft Regularization Prevail}{359}{section*.662}%
\contentsline {paragraph}{5. Summary}{359}{section*.663}%
\contentsline {chapter}{\numberline {11}Lecture 11: CNN Architectures II}{360}{chapter.11}%
\ttl@stoptoc {default@10}
\ttl@starttoc {default@11}
\contentsline {section}{\numberline {11.1}Post-ResNet Architectures}{360}{section.11.1}%
\contentsline {section}{\numberline {11.2}Grouped Convolutions}{361}{section.11.2}%
\contentsline {subsection}{\numberline {11.2.1}Grouped Convolutions in PyTorch}{366}{subsection.11.2.1}%
\contentsline {subsubsection}{Key Observations}{367}{section*.675}%
\contentsline {subsubsection}{When to Use Grouped Convolutions?}{367}{section*.676}%
\contentsline {section}{\numberline {11.3}ResNeXt: Next-Generation Residual Networks}{367}{section.11.3}%
\contentsline {subsection}{\numberline {11.3.1}Motivation: Why ResNeXt?}{368}{subsection.11.3.1}%
\contentsline {subsection}{\numberline {11.3.2}Key Innovation: Aggregated Transformations}{368}{subsection.11.3.2}%
\contentsline {subsection}{\numberline {11.3.3}ResNeXt and Grouped Convolutions}{369}{subsection.11.3.3}%
\contentsline {subsection}{\numberline {11.3.4}Advantages of ResNeXt Over ResNet}{369}{subsection.11.3.4}%
\contentsline {subsection}{\numberline {11.3.5}ResNeXt Model Naming Convention}{370}{subsection.11.3.5}%
\contentsline {section}{\numberline {11.4}Squeeze-and-Excitation Networks (SENet)}{370}{section.11.4}%
\contentsline {subsection}{\numberline {11.4.1}Squeeze-and-Excitation (SE) Block}{371}{subsection.11.4.1}%
\contentsline {subsubsection}{Squeeze: Global Information Embedding}{371}{section*.680}%
\contentsline {subsubsection}{Excitation: Adaptive Recalibration}{371}{section*.681}%
\contentsline {subsubsection}{Channel Recalibration}{372}{section*.682}%
\contentsline {subsubsection}{How SE Blocks Enhance ResNet Bottleneck Blocks}{372}{section*.684}%
\contentsline {subsubsection}{Why Does SE Improve Performance?}{373}{section*.685}%
\contentsline {subsubsection}{Performance Gains, Scalability, and Integration of SE Blocks}{373}{section*.686}%
\contentsline {subsubsection}{Impact on Various Tasks}{373}{section*.688}%
\contentsline {subsubsection}{Practical Applications and Widespread Adoption}{374}{section*.689}%
\contentsline {subsection}{\numberline {11.4.2}SE Blocks and the End of the ImageNet Classification Challenge}{374}{subsection.11.4.2}%
\contentsline {subsection}{\numberline {11.4.3}Challenges and Solutions for SE Networks}{375}{subsection.11.4.3}%
\contentsline {subsubsection}{Challenges of SE Networks}{375}{section*.691}%
\contentsline {subsubsection}{Solutions to SE Network Challenges}{375}{section*.692}%
\contentsline {subsubsection}{Shifting Research Directions: Efficiency and Mobile Deployability}{376}{section*.693}%
\contentsline {subsubsection}{What Comes Next?}{376}{section*.694}%
\contentsline {section}{\numberline {11.5}Efficient Architectures for Edge Devices}{376}{section.11.5}%
\contentsline {subsection}{\numberline {11.5.1}MobileNet: Depthwise Separable Convolutions}{377}{subsection.11.5.1}%
\contentsline {subsubsection}{Width Multiplier: Thinner Models}{378}{section*.697}%
\contentsline {subsubsection}{Resolution Multiplier: Reduced Representations}{378}{section*.698}%
\contentsline {subsubsection}{Computational Cost of Depthwise Separable Convolutions}{378}{section*.699}%
\contentsline {paragraph}{Summary of Multipliers}{379}{section*.700}%
\contentsline {subsubsection}{MobileNetV1 vs. Traditional Architectures}{379}{section*.701}%
\contentsline {subsubsection}{Depthwise Separable vs. Standard Convolutions in MobileNet}{379}{section*.703}%
\contentsline {subsubsection}{Summary and Next Steps}{379}{section*.705}%
\contentsline {subsection}{\numberline {11.5.2}ShuffleNet: Efficient Channel Mixing via Grouped Convolutions}{380}{subsection.11.5.2}%
\contentsline {subsubsection}{The ShuffleNet Unit}{381}{section*.708}%
\contentsline {paragraph}{Core Design Features}{381}{section*.709}%
\contentsline {paragraph}{Structure of a ShuffleNet Unit}{381}{section*.710}%
\contentsline {paragraph}{Stride-2 Modification}{382}{section*.712}%
\contentsline {subsubsection}{ShuffleNet Architecture}{382}{section*.713}%
\contentsline {paragraph}{Stage-wise Construction:}{382}{section*.714}%
\contentsline {paragraph}{Scaling Factor}{383}{section*.715}%
\contentsline {paragraph}{Design Rationale}{383}{section*.716}%
\contentsline {subsubsection}{Computational Efficiency of ShuffleNet}{383}{section*.717}%
\contentsline {subsubsection}{Inference Speed and Practical Performance}{383}{section*.718}%
\contentsline {subsubsection}{Performance Comparison: ShuffleNet vs. MobileNet}{384}{section*.719}%
\contentsline {subsubsection}{Beyond ShuffleNet: Evolution of Efficient CNN Architectures}{384}{section*.721}%
\contentsline {subsection}{\numberline {11.5.3}MobileNetV2: Inverted Bottleneck and Linear Residual}{384}{subsection.11.5.3}%
\contentsline {paragraph}{Understanding Feature Representations and Manifolds}{384}{section*.722}%
\contentsline {paragraph}{ReLU and Information Collapse}{384}{section*.723}%
\contentsline {subsubsection}{The MobileNetV2 Block: Inverted Residuals and Linear Bottleneck}{385}{section*.725}%
\contentsline {paragraph}{Detailed Block Architecture}{385}{section*.726}%
\contentsline {subsubsection}{Why is the Inverted Block Fitting to Efficient Networks?}{386}{section*.728}%
\contentsline {paragraph}{1. Depthwise Convolutions Maintain Low Computational Cost}{386}{section*.729}%
\contentsline {paragraph}{2. Moderate Expansion Factor \((t)\) Balances Efficiency}{386}{section*.730}%
\contentsline {paragraph}{3. Comparison to MobileNetV1}{386}{section*.731}%
\contentsline {paragraph}{4. Comparison to ResNet Bottleneck Blocks}{387}{section*.732}%
\contentsline {paragraph}{5. Linear Bottleneck Preserves Subtle Features}{387}{section*.733}%
\contentsline {paragraph}{Summary}{387}{section*.734}%
\contentsline {subsubsection}{ReLU6 and Its Role in Low-Precision Inference}{387}{section*.735}%
\contentsline {paragraph}{Practical Observations and Alternatives}{388}{section*.736}%
\contentsline {subsubsection}{MobileNetV2 Architecture and Performance}{388}{section*.738}%
\contentsline {subsubsection}{Comparison to MobileNetV1, ShuffleNet, and NASNet}{389}{section*.740}%
\contentsline {subsection}{\numberline {11.5.4}Neural Architecture Search (NAS) and MobileNetV3}{390}{subsection.11.5.4}%
\contentsline {subsubsection}{How NAS Works? Policy Gradient Optimization}{390}{section*.742}%
\contentsline {paragraph}{What is a Policy Gradient?}{390}{section*.743}%
\contentsline {paragraph}{Updating the Controller Using Policy Gradients}{390}{section*.744}%
\contentsline {paragraph}{Searching for Reusable Block Designs}{391}{section*.746}%
\contentsline {subsubsection}{MobileNetV3: NAS-Optimized Mobile Network}{392}{section*.748}%
\contentsline {subsubsection}{The MobileNetV3 Block Architecture and Refinements}{392}{section*.749}%
\contentsline {paragraph}{Structure of the MobileNetV3 Block}{392}{section*.750}%
\contentsline {paragraph}{Differences from Previous MobileNet Blocks}{392}{section*.751}%
\contentsline {subsubsection}{Why is MobileNetV3 More Efficient?}{393}{section*.752}%
\contentsline {paragraph}{Key Optimizations That Improve Efficiency}{393}{section*.753}%
\contentsline {paragraph}{Empirical Comparison of MobileNetV3}{393}{section*.754}%
\contentsline {subsubsection}{The Computational Cost of NAS and Its Limitations}{394}{section*.757}%
\contentsline {paragraph}{Why is NAS Expensive?}{394}{section*.758}%
\contentsline {subsubsection}{ShuffleNetV2 and Practical Design Rules}{395}{section*.760}%
\contentsline {paragraph}{Why ShuffleNetV2?}{395}{section*.761}%
\contentsline {paragraph}{Four Key Guidelines for Practical Efficiency}{395}{section*.762}%
\contentsline {paragraph}{From ShuffleNetV1 to ShuffleNetV2}{396}{section*.763}%
\contentsline {paragraph}{Performance vs.\ MobileNetV3}{396}{section*.764}%
\contentsline {subsubsection}{The Need for Model Scaling and EfficientNets}{396}{section*.765}%
\contentsline {paragraph}{Beyond Hand-Designed and NAS-Optimized Models}{396}{section*.766}%
\contentsline {paragraph}{Introducing EfficientNet}{396}{section*.767}%
\contentsline {section}{\numberline {11.6}EfficientNet Compound Model Scaling}{397}{section.11.6}%
\contentsline {subsection}{\numberline {11.6.1}How Should We Scale a Model}{397}{subsection.11.6.1}%
\contentsline {paragraph}{The Problem with Independent Scaling}{397}{section*.769}%
\contentsline {subsection}{\numberline {11.6.2}How EfficientNet Works}{398}{subsection.11.6.2}%
\contentsline {paragraph}{Step 1: Designing a Baseline Architecture}{398}{section*.771}%
\contentsline {paragraph}{EfficientNet-B0 Architecture}{399}{section*.772}%
\contentsline {paragraph}{Step 2: Finding Optimal Scaling Factors}{399}{section*.774}%
\contentsline {paragraph}{Step 3: Scaling to Different Model Sizes}{399}{section*.775}%
\contentsline {subsection}{\numberline {11.6.3}Why is EfficientNet More Effective}{399}{subsection.11.6.3}%
\contentsline {paragraph}{Balanced Scaling Improves Efficiency}{399}{section*.776}%
\contentsline {paragraph}{Comparison with MobileNetV3}{400}{section*.777}%
\contentsline {paragraph}{Comparison with Other Networks}{400}{section*.778}%
\contentsline {subsection}{\numberline {11.6.4}Limitations of EfficientNet}{400}{subsection.11.6.4}%
\contentsline {paragraph}{Whatâ€™s Next? EfficientNetV2 and Beyond}{401}{section*.780}%
\contentsline {paragraph}{Conclusion}{401}{section*.781}%
\contentsline {section}{\numberline {11.7}EfficientNet-Lite Optimizing EfficientNet for Edge Devices}{401}{section.11.7}%
\contentsline {subsection}{\numberline {11.7.1}Motivation for EfficientNet-Lite}{401}{subsection.11.7.1}%
\contentsline {subsection}{\numberline {11.7.2}EfficientNet-Lite Architecture}{401}{subsection.11.7.2}%
\contentsline {subsection}{\numberline {11.7.3}Performance and Comparison with Other Models}{401}{subsection.11.7.3}%
\contentsline {paragraph}{Model Size vs. Accuracy Trade-off}{402}{section*.783}%
\contentsline {section}{\numberline {11.8}EfficientNetV2: Faster Training and Improved Efficiency}{403}{section.11.8}%
\contentsline {subsection}{\numberline {11.8.1}Motivation for EfficientNetV2}{403}{subsection.11.8.1}%
\contentsline {subsection}{\numberline {11.8.2}Fused-MBConv: Improving Early Layers}{403}{subsection.11.8.2}%
\contentsline {subsection}{\numberline {11.8.3}Progressive Learning: Efficient Training with Smaller Images}{404}{subsection.11.8.3}%
\contentsline {subsection}{\numberline {11.8.4}FixRes: Addressing Train-Test Resolution Discrepancy}{404}{subsection.11.8.4}%
\contentsline {paragraph}{The Problem: Region of Classification (RoC) Mismatch}{404}{section*.786}%
\contentsline {paragraph}{FixRes Solution}{405}{section*.787}%
\contentsline {paragraph}{Implementation in EfficientNetV2}{405}{section*.789}%
\contentsline {subsection}{\numberline {11.8.5}Non-Uniform Scaling for Improved Efficiency}{405}{subsection.11.8.5}%
\contentsline {subsection}{\numberline {11.8.6}EfficientNetV2 Architecture}{406}{subsection.11.8.6}%
\contentsline {subsection}{\numberline {11.8.7}EfficientNetV2 vs. EfficientNetV1}{406}{subsection.11.8.7}%
\contentsline {subsection}{\numberline {11.8.8}EfficientNetV2 vs.\ Other Models}{407}{subsection.11.8.8}%
\contentsline {paragraph}{Training Speed and Efficiency}{408}{section*.792}%
\contentsline {paragraph}{Key Takeaways}{408}{section*.794}%
\contentsline {section}{\numberline {11.9}NFNets: Normalizer-Free ResNets}{409}{section.11.9}%
\contentsline {subsection}{\numberline {11.9.1}Motivation: Why Do We Need NFNets?}{409}{subsection.11.9.1}%
\contentsline {subsection}{\numberline {11.9.2}Variance Explosion Without BatchNorm}{409}{subsection.11.9.2}%
\contentsline {paragraph}{Variance Scaling in Residual Networks}{409}{section*.795}%
\contentsline {paragraph}{Role of Weight Initialization}{409}{section*.796}%
\contentsline {subsection}{\numberline {11.9.3}Why Not Rescale the Residual Branch?}{409}{subsection.11.9.3}%
\contentsline {subsection}{\numberline {11.9.4}NFNets: Weight Normalization Instead of BN}{410}{subsection.11.9.4}%
\contentsline {paragraph}{Why This Works}{410}{section*.797}%
\contentsline {paragraph}{Relation to Earlier Weight Standardization}{410}{section*.798}%
\contentsline {subsection}{\numberline {11.9.5}NFNets Architecture and ResNet-D}{411}{subsection.11.9.5}%
\contentsline {subsection}{\numberline {11.9.6}Comparison Across Diverse Architectures}{411}{subsection.11.9.6}%
\contentsline {paragraph}{Key Takeaways}{411}{section*.800}%
\contentsline {subsection}{\numberline {11.9.7}Further Reading and Resources}{412}{subsection.11.9.7}%
\contentsline {section}{\numberline {11.10}Revisiting ResNets: Improved Training and Scaling Strategies}{413}{section.11.10}%
\contentsline {subsection}{\numberline {11.10.1}Training Enhancements for ResNets}{413}{subsection.11.10.1}%
\contentsline {paragraph}{Key Enhancements}{413}{section*.802}%
\contentsline {subsection}{\numberline {11.10.2}Scaling ResNets for Efficient Training}{413}{subsection.11.10.2}%
\contentsline {subsection}{\numberline {11.10.3}ResNet-RS vs. EfficientNet: A Re-Evaluation}{414}{subsection.11.10.3}%
\contentsline {paragraph}{Comparison of ResNet-RS and EfficientNet}{414}{section*.804}%
\contentsline {paragraph}{Key Observations}{414}{section*.806}%
\contentsline {paragraph}{Conclusion}{415}{section*.807}%
\contentsline {section}{\numberline {11.11}RegNets: Network Design Spaces}{415}{section.11.11}%
\contentsline {subsection}{\numberline {11.11.1}RegNet Architecture}{415}{subsection.11.11.1}%
\contentsline {paragraph}{Block Design: Generalizing ResNeXt}{416}{section*.809}%
\contentsline {subsection}{\numberline {11.11.2}Optimizing the Design Space}{416}{subsection.11.11.2}%
\contentsline {paragraph}{Random Sampling and Performance Trends}{416}{section*.811}%
\contentsline {paragraph}{Reducing the Design Space}{417}{section*.812}%
\contentsline {paragraph}{Final Six Parameters}{417}{section*.813}%
\contentsline {paragraph}{Why This Works}{417}{section*.815}%
\contentsline {paragraph}{Conclusion}{418}{section*.816}%
\contentsline {subsection}{\numberline {11.11.3}Performance and Applications}{418}{subsection.11.11.3}%
\contentsline {paragraph}{Key Takeaways}{419}{section*.819}%
\contentsline {paragraph}{Conclusion}{419}{section*.820}%
\contentsline {section}{\numberline {11.12}Summary of Efficient Network Architectures}{420}{section.11.12}%
\contentsline {subsubsection}{Grouped Convolutions and ResNeXt}{420}{section*.821}%
\contentsline {subsubsection}{Squeeze-and-Excitation (SE) Blocks}{420}{section*.822}%
\contentsline {subsubsection}{MobileNet and ShuffleNet: Depthwise Separable Convolutions and Channel Mixing}{420}{section*.823}%
\contentsline {subsubsection}{MobileNetV2: Inverted Residual Blocks}{420}{section*.824}%
\contentsline {subsubsection}{NAS and MobileNetV3, ShuffleNetV2 Insights}{420}{section*.825}%
\contentsline {subsubsection}{EfficientNet: Compound Scaling}{420}{section*.826}%
\contentsline {subsubsection}{EfficientNet-Lite and EfficientNetV2}{421}{section*.827}%
\contentsline {subsubsection}{NFNets: BN-Free Training}{421}{section*.828}%
\contentsline {subsubsection}{Revisiting ResNets: Scaling and Training Recipes}{421}{section*.829}%
\contentsline {subsubsection}{RegNets: Optimizing the Design Space}{421}{section*.830}%
\contentsline {subsubsection}{Key Takeaways}{421}{section*.831}%
\contentsline {chapter}{\numberline {12}Lecture 12: Deep Learning Software}{422}{chapter.12}%
\ttl@stoptoc {default@11}
\ttl@starttoc {default@12}
\contentsline {section}{\numberline {12.1}Deep Learning Frameworks: Evolution and Landscape}{422}{section.12.1}%
\contentsline {subsection}{\numberline {12.1.1}The Purpose of Deep Learning Frameworks}{423}{subsection.12.1.1}%
\contentsline {subsection}{\numberline {12.1.2}Recall: Computational Graphs}{423}{subsection.12.1.2}%
\contentsline {section}{\numberline {12.2}PyTorch: Fundamental Concepts}{424}{section.12.2}%
\contentsline {subsection}{\numberline {12.2.1}Tensors and Basic Computation}{424}{subsection.12.2.1}%
\contentsline {subsection}{\numberline {12.2.2}Autograd: Automatic Differentiation}{425}{subsection.12.2.2}%
\contentsline {subsection}{\numberline {12.2.3}Computational Graphs and Modular Computation}{426}{subsection.12.2.3}%
\contentsline {subsubsection}{Building the Computational Graph}{426}{section*.834}%
\contentsline {subsubsection}{Loss Computation and Backpropagation}{427}{section*.838}%
\contentsline {subsubsection}{Extending Computational Graphs with Python Functions}{428}{section*.840}%
\contentsline {subsubsection}{Custom Autograd Functions}{429}{section*.841}%
\contentsline {subsubsection}{Summary: Backpropagation and Graph Optimization}{430}{section*.843}%
\contentsline {subsection}{\numberline {12.2.4}High-Level Abstractions in PyTorch: \texttt {torch.nn} and Optimizers}{430}{subsection.12.2.4}%
\contentsline {subsubsection}{Using \texttt {torch.nn.Sequential}}{430}{section*.844}%
\contentsline {subsubsection}{Using Optimizers: Automating Gradient Descent}{431}{section*.845}%
\contentsline {subsubsection}{Defining Custom \texttt {nn.Module} Subclasses}{432}{section*.846}%
\contentsline {subsubsection}{Key Takeaways}{432}{section*.847}%
\contentsline {subsection}{\numberline {12.2.5}Combining Custom Modules with Sequential Models}{432}{subsection.12.2.5}%
\contentsline {subsubsection}{Example: Parallel Block}{433}{section*.848}%
\contentsline {subsection}{\numberline {12.2.6}Efficient Data Loading with \texttt {torch.utils.data}}{434}{subsection.12.2.6}%
\contentsline {subsubsection}{Example: Using \texttt {DataLoader} for Mini-batching}{434}{section*.851}%
\contentsline {subsection}{\numberline {12.2.7}Using Pretrained Models with TorchVision}{435}{subsection.12.2.7}%
\contentsline {subsubsection}{Key Takeaways}{435}{section*.852}%
\contentsline {section}{\numberline {12.3}Dynamic vs. Static Computational Graphs in PyTorch}{436}{section.12.3}%
\contentsline {subsubsection}{Example: Dynamic Graph Construction}{436}{section*.853}%
\contentsline {subsection}{\numberline {12.3.1}Static Graphs and Just-in-Time (JIT) Compilation}{436}{subsection.12.3.1}%
\contentsline {subsection}{\numberline {12.3.2}Using JIT to Create Static Graphs}{437}{subsection.12.3.2}%
\contentsline {subsection}{\numberline {12.3.3}Handling Conditionals in Static Graphs}{437}{subsection.12.3.3}%
\contentsline {subsection}{\numberline {12.3.4}Optimizing Computation Graphs with JIT}{438}{subsection.12.3.4}%
\contentsline {subsection}{\numberline {12.3.5}Benefits and Limitations of Static Graphs}{439}{subsection.12.3.5}%
\contentsline {subsection}{\numberline {12.3.6}When Are Dynamic Graphs Necessary?}{439}{subsection.12.3.6}%
\contentsline {section}{\numberline {12.4}TensorFlow: Dynamic and Static Computational Graphs}{439}{section.12.4}%
\contentsline {subsection}{\numberline {12.4.1}Defining Computational Graphs in TensorFlow 2.0}{439}{subsection.12.4.1}%
\contentsline {subsection}{\numberline {12.4.2}Static Graphs with \texttt {tf.function}}{440}{subsection.12.4.2}%
\contentsline {section}{\numberline {12.5}Keras: High-Level API for TensorFlow}{440}{section.12.5}%
\contentsline {section}{\numberline {12.6}TensorBoard: Visualizing Training Metrics}{441}{section.12.6}%
\contentsline {section}{\numberline {12.7}Comparison: PyTorch vs. TensorFlow}{442}{section.12.7}%
\contentsline {paragraph}{Conclusion}{442}{section*.859}%
\contentsline {chapter}{\numberline {13}Lecture 13: Object Detection}{443}{chapter.13}%
\ttl@stoptoc {default@12}
\ttl@starttoc {default@13}
\contentsline {section}{\numberline {13.1}Object Detection: Introduction}{443}{section.13.1}%
\contentsline {subsection}{\numberline {13.1.1}Computer Vision Tasks: Beyond Classification}{443}{subsection.13.1.1}%
\contentsline {subsection}{\numberline {13.1.2}What is Object Detection?}{444}{subsection.13.1.2}%
\contentsline {subsection}{\numberline {13.1.3}Challenges in Object Detection}{444}{subsection.13.1.3}%
\contentsline {subsection}{\numberline {13.1.4}Bounding Boxes and Intersection over Union (IoU)}{444}{subsection.13.1.4}%
\contentsline {subsection}{\numberline {13.1.5}Evaluating Bounding Boxes: Intersection over Union (IoU)}{445}{subsection.13.1.5}%
\contentsline {subsection}{\numberline {13.1.6}Multitask Loss: Classification and Regression}{446}{subsection.13.1.6}%
\contentsline {section}{\numberline {13.2}From Single-Object to Multi-Object Detection}{446}{section.13.2}%
\contentsline {subsection}{\numberline {13.2.1}Challenges in Detecting Multiple Objects}{447}{subsection.13.2.1}%
\contentsline {subsection}{\numberline {13.2.2}Sliding Window Approach}{447}{subsection.13.2.2}%
\contentsline {subsection}{\numberline {13.2.3}Region Proposal Methods}{448}{subsection.13.2.3}%
\contentsline {section}{\numberline {13.3}Naive Solution: Region-Based CNN (R-CNN)}{449}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}Bounding Box Regression: Refining Object Localization}{450}{subsection.13.3.1}%
\contentsline {paragraph}{Why a Logarithmic Transformation?}{451}{section*.871}%
\contentsline {subsection}{\numberline {13.3.2}Training R-CNN}{452}{subsection.13.3.2}%
\contentsline {paragraph}{1) Collecting Positive and Negative Examples}{452}{section*.872}%
\contentsline {paragraph}{2) Fine-Tuning the CNN on Region Proposals (Classification Only)}{452}{section*.874}%
\contentsline {paragraph}{3) Training the Bounding Box Regressors}{453}{section*.875}%
\contentsline {paragraph}{4) Forming the Final Detector}{454}{section*.876}%
\contentsline {subsubsection}{Training Considerations for Object Detection}{454}{section*.877}%
\contentsline {subsection}{\numberline {13.3.3}Selecting Final Predictions for Object Detection}{455}{subsection.13.3.3}%
\contentsline {section}{\numberline {13.4}Non-Maximum Suppression (NMS)}{455}{section.13.4}%
\contentsline {subsection}{\numberline {13.4.1}Motivation: The Need for NMS}{455}{subsection.13.4.1}%
\contentsline {subsection}{\numberline {13.4.2}NMS Algorithm}{456}{subsection.13.4.2}%
\contentsline {subsection}{\numberline {13.4.3}Example: Step-by-Step Execution}{456}{subsection.13.4.3}%
\contentsline {subsection}{\numberline {13.4.4}Limitations of NMS}{457}{subsection.13.4.4}%
\contentsline {subsection}{\numberline {13.4.5}Refining NMS for Overlapping Objects}{457}{subsection.13.4.5}%
\contentsline {section}{\numberline {13.5}Evaluating Object Detectors: Mean Average Precision (mAP)}{457}{section.13.5}%
\contentsline {subsection}{\numberline {13.5.1}Key Evaluation Metrics}{458}{subsection.13.5.1}%
\contentsline {paragraph}{Precision and Recall}{458}{section*.881}%
\contentsline {paragraph}{\textbf {Trade-offs Between Precision and Recall}}{458}{section*.882}%
\contentsline {paragraph}{\textbf {Isn't F1 Score Suffice?}}{458}{section*.883}%
\contentsline {paragraph}{\textbf {Precision-Recall (PR) Curve and Average Precision (AP)}}{459}{section*.884}%
\contentsline {paragraph}{\textbf {Why the 0.5 IoU Threshold?}}{459}{section*.885}%
\contentsline {paragraph}{\textbf {Why AP is Preferable to the F1 Score:}}{459}{section*.886}%
\contentsline {subsection}{\numberline {13.5.2}Step-by-Step Example: Computing AP for a Single Class}{460}{subsection.13.5.2}%
\contentsline {subsection}{\numberline {13.5.3}Mean Average Precision (mAP)}{463}{subsection.13.5.3}%
\contentsline {subsection}{\numberline {13.5.4}COCO mAP: A Stricter Measure}{463}{subsection.13.5.4}%
\contentsline {subsubsection}{COCO mAP for Different Object Sizes}{463}{section*.893}%
\contentsline {paragraph}{When and Why Object Size-Specific mAP Matters}{464}{section*.895}%
\contentsline {subsubsection}{Prioritizing Specific Classes in Object Detection}{464}{section*.896}%
\contentsline {subsection}{\numberline {13.5.5}Evaluating Object Detectors: Key Takeaways}{465}{subsection.13.5.5}%
\contentsline {subsection}{Enrichment 13.5.6: Mosaic Augmentation for Object Detection}{466}{section*.897}%
\contentsline {paragraph}{Motivation and Advantages}{466}{section*.898}%
\contentsline {paragraph}{Implementation Considerations}{466}{section*.900}%
\contentsline {paragraph}{Domain-Dependent Utility}{467}{section*.902}%
\contentsline {paragraph}{Conclusion}{467}{section*.903}%
\contentsline {chapter}{\numberline {14}Lecture 14: Object Detectors}{468}{chapter.14}%
\ttl@stoptoc {default@13}
\ttl@starttoc {default@14}
\contentsline {section}{\numberline {14.1}Beyond R-CNN: Advancing Object Detection}{468}{section.14.1}%
\contentsline {subsection}{\numberline {14.1.1}Looking Ahead: Beyond CNN-Based Object Detectors}{468}{subsection.14.1.1}%
\contentsline {section}{\numberline {14.2}Fast R-CNN: Accelerating Object Detection}{469}{section.14.2}%
\contentsline {subsection}{\numberline {14.2.1}Key Idea: Shared Feature Extraction}{469}{subsection.14.2.1}%
\contentsline {subsection}{\numberline {14.2.2}Using Fully Convolutional Deep Backbones for Feature Extraction}{470}{subsection.14.2.2}%
\contentsline {subsection}{\numberline {14.2.3}Region of Interest (RoI) Pooling}{471}{subsection.14.2.3}%
\contentsline {paragraph}{Mapping Region Proposals onto the Feature Map}{471}{section*.907}%
\contentsline {paragraph}{Dividing the Region into Fixed Bins}{471}{section*.908}%
\contentsline {paragraph}{Max Pooling within Each Bin}{471}{section*.909}%
\contentsline {paragraph}{Summary: Key Steps in RoI Pooling}{472}{section*.911}%
\contentsline {paragraph}{Limitations of RoI Pooling}{472}{section*.912}%
\contentsline {subsection}{\numberline {14.2.4}RoIAlign}{473}{subsection.14.2.4}%
\contentsline {subsubsection}{RoIAlign: A Visual Example}{474}{section*.914}%
\contentsline {paragraph}{Step 1: Projection of Region Proposal onto the Feature Map}{474}{section*.915}%
\contentsline {paragraph}{Step 2: Selecting Interpolation Points in Each Bin}{474}{section*.917}%
\contentsline {subparagraph}{Why Choose 0.25 and 0.75 for Sampling?}{475}{subparagraph*.919}%
\contentsline {paragraph}{Step 3: Mapping Sampled Points onto the Feature Grid}{476}{section*.920}%
\contentsline {paragraph}{Step 4: Computing Bilinear Interpolation Weights}{477}{section*.922}%
\contentsline {subparagraph}{Normalization Constant and Its Interpretation}{477}{subparagraph*.923}%
\contentsline {subparagraph}{Weight Computation for Each Corner}{477}{subparagraph*.924}%
\contentsline {paragraph}{Step 5: Computing the Interpolated Feature Value}{480}{section*.929}%
\contentsline {subparagraph}{\textbf {Example Computation}}{480}{subparagraph*.930}%
\contentsline {paragraph}{Step 6: Aggregating Interpolated Values}{481}{section*.931}%
\contentsline {subparagraph}{\textbf {Final Output}}{481}{subparagraph*.932}%
\contentsline {paragraph}{Key Takeaways}{481}{section*.934}%
\contentsline {paragraph}{RoIAlign Important Implementation Parts in PyTorch}{482}{section*.935}%
\contentsline {section}{\numberline {14.3}Faster R-CNN: Faster Proposals Using RPNs}{485}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}Fast R-CNN Bottleneck: Region Proposal Computation}{485}{subsection.14.3.1}%
\contentsline {subsection}{\numberline {14.3.2}Towards Faster Region Proposals: Learning Proposals with CNNs}{485}{subsection.14.3.2}%
\contentsline {subsection}{\numberline {14.3.3}Region Proposal Networks (RPNs)}{486}{subsection.14.3.3}%
\contentsline {paragraph}{\textbf {How RPNs Work}}{486}{section*.937}%
\contentsline {paragraph}{\textbf {Anchor Boxes: Handling Scale and Aspect Ratio Variations}}{486}{section*.938}%
\contentsline {paragraph}{\textbf {Bounding Box Refinement: Aligning Anchors to Objects}}{488}{section*.942}%
\contentsline {paragraph}{\textbf {Training RPNs: Assigning Labels to Anchors}}{488}{section*.944}%
\contentsline {paragraph}{\textbf {Loss Function for RPN Training}}{489}{section*.945}%
\contentsline {subparagraph}{\textbf {Assigning Ground-Truth Bounding Boxes to Anchors}}{489}{subparagraph*.946}%
\contentsline {paragraph}{\textbf {Smooth \( L_1 \) Loss for Bounding Box Regression}}{489}{section*.947}%
\contentsline {paragraph}{\textbf {Why Use Negative Anchors?}}{490}{section*.948}%
\contentsline {subsubsection}{Enrichment 14.3.3.1: Training Region Proposal Networks (RPNs)}{490}{section*.949}%
\contentsline {paragraph}{1. Input Feature Map}{490}{section*.950}%
\contentsline {paragraph}{2. Sliding Window: Shared 3\(\times \)3 Conv}{490}{section*.951}%
\contentsline {paragraph}{3. RPN Heads: Anchor-wise Classification and Regression}{490}{section*.952}%
\contentsline {paragraph}{4. Anchor Labeling and Ground Truth Assignment}{491}{section*.953}%
\contentsline {paragraph}{5. Bounding-Box Regression Targets}{491}{section*.954}%
\contentsline {paragraph}{6. Loss Computation}{491}{section*.955}%
\contentsline {paragraph}{\textbf {Inference: Generating Region Proposals}}{492}{section*.957}%
\contentsline {paragraph}{\textbf {RPNs Improve Region Proposal Generation}}{492}{section*.958}%
\contentsline {subsection}{\numberline {14.3.4}Faster R-CNN Loss in Practice: Joint Training with Four Losses}{493}{subsection.14.3.4}%
\contentsline {paragraph}{\textbf {Joint Training in Faster R-CNN}}{493}{section*.959}%
\contentsline {paragraph}{\textbf {How RPN Improves Inference Speed}}{493}{section*.960}%
\contentsline {subsection}{\numberline {14.3.5}Feature Pyramid Networks (FPNs): Multi-Scale Feature Learning}{494}{subsection.14.3.5}%
\contentsline {subsubsection}{Feature Pyramid Networks: A More Efficient Approach}{494}{section*.963}%
\contentsline {subsubsection}{Enhancing Low-Level Features with High-Level Semantics}{495}{section*.965}%
\contentsline {paragraph}{How Upsampling Works in FPNs}{496}{section*.967}%
\contentsline {subsubsection}{Combining Results from Multiple Feature Levels}{496}{section*.968}%
\contentsline {paragraph}{Advantages of FPNs}{496}{section*.969}%
\contentsline {paragraph}{\textbf {The Two-Stage Object Detection Pipeline}}{497}{section*.970}%
\contentsline {section}{\numberline {14.4}RetinaNet: A Breakthrough in Single-Stage Object Detection}{498}{section.14.4}%
\contentsline {subsection}{\numberline {14.4.1}Why Single-Stage Detectors Can Be Faster}{498}{subsection.14.4.1}%
\contentsline {subsection}{\numberline {14.4.2}The Class Imbalance Problem in Dense Detection}{498}{subsection.14.4.2}%
\contentsline {subsection}{\numberline {14.4.3}Focal Loss: Addressing Class Imbalance}{499}{subsection.14.4.3}%
\contentsline {subsection}{\numberline {14.4.4}RetinaNet Architecture and Pipeline}{501}{subsection.14.4.4}%
\contentsline {section}{\numberline {14.5}FCOS: An Anchor-Free, Fully Convolutional Detector}{502}{section.14.5}%
\contentsline {subsection}{\numberline {14.5.1}Core Pipeline and Feature Map Interpretation}{502}{subsection.14.5.1}%
\contentsline {subsection}{\numberline {14.5.2}Bounding Box Regression}{504}{subsection.14.5.2}%
\contentsline {subsection}{\numberline {14.5.3}Centerness: Filtering Low-Quality Predictions}{504}{subsection.14.5.3}%
\contentsline {subsection}{\numberline {14.5.4}Multi-Level Feature Prediction with FPN}{505}{subsection.14.5.4}%
\contentsline {subsection}{\numberline {14.5.5}Loss Function: Focal Loss and IoU Loss}{506}{subsection.14.5.5}%
\contentsline {subsection}{\numberline {14.5.6}Inference: Selecting Final Detections}{506}{subsection.14.5.6}%
\contentsline {subsection}{\numberline {14.5.7}Advantages of FCOS}{506}{subsection.14.5.7}%
\contentsline {section}{Enrichment 14.6: YOLO - You Only Look Once}{507}{section*.979}%
\contentsline {subsection}{Enrichment 14.6.1: Background}{507}{section*.980}%
\contentsline {subsection}{Enrichment 14.6.2: Step-by-Step: How YOLOv1 Processes an Input Image}{507}{section*.981}%
\contentsline {paragraph}{1. Input Image and Preprocessing}{507}{section*.982}%
\contentsline {paragraph}{2. Feature Extraction (DarkNet + Additional Convolution Layers)}{507}{section*.983}%
\contentsline {paragraph}{3. Flattening and Fully Connected Layers}{507}{section*.984}%
\contentsline {paragraph}{4. Understanding the Output Format}{508}{section*.985}%
\contentsline {paragraph}{5. Why a Sigmoid?}{508}{section*.986}%
\contentsline {paragraph}{6. Converting Predictions to Actual Bounding Boxes}{508}{section*.987}%
\contentsline {paragraph}{7. Loss and Training (High Level)}{509}{section*.988}%
\contentsline {paragraph}{8. Why It Works (and Its Trade-offs)}{509}{section*.989}%
\contentsline {paragraph}{9. Final Detections and NMS}{509}{section*.990}%
\contentsline {paragraph}{Summary}{510}{section*.991}%
\contentsline {subsection}{Enrichment 14.6.3: Evolution of YOLO}{510}{section*.993}%
\contentsline {section}{\numberline {14.7}Conclusion: The Evolution of Object Detection}{511}{section.14.7}%
\contentsline {paragraph}{From R-CNN to Faster R-CNN: Learning Region Proposals}{511}{section*.994}%
\contentsline {paragraph}{Improving Multi-Scale Detection: Feature Pyramid Networks (FPN)}{511}{section*.995}%
\contentsline {paragraph}{RetinaNet: A Breakthrough for One-Stage Detectors}{511}{section*.996}%
\contentsline {paragraph}{FCOS: Moving Toward Anchor-Free Detection}{511}{section*.997}%
\contentsline {paragraph}{YOLO: A Widely Used Real-Time Detector}{512}{section*.998}%
\contentsline {paragraph}{Looking Ahead: Transformers and SOTA Detectors}{512}{section*.999}%
\contentsline {paragraph}{Summary}{512}{section*.1000}%
\contentsline {chapter}{\numberline {15}Lecture 15: Image Segmentation}{513}{chapter.15}%
\ttl@stoptoc {default@14}
\ttl@starttoc {default@15}
\contentsline {section}{\numberline {15.1}From Object Detection to Segmentation}{513}{section.15.1}%
\contentsline {section}{Enrichment 15.2: Why is Object Detection Not Enough?}{514}{section*.1002}%
\contentsline {section}{\numberline {15.3}Advancements in Semantic Segmentation}{515}{section.15.3}%
\contentsline {subsection}{\numberline {15.3.1}Early Approaches: Sliding Window Method}{515}{subsection.15.3.1}%
\contentsline {subsection}{\numberline {15.3.2}Fully Convolutional Networks (FCNs)}{515}{subsection.15.3.2}%
\contentsline {subsection}{\numberline {15.3.3}Challenges in FCNs for Semantic Segmentation}{516}{subsection.15.3.3}%
\contentsline {subsection}{\numberline {15.3.4}Encoder-Decoder Architectures}{516}{subsection.15.3.4}%
\contentsline {section}{\numberline {15.4}Upsampling and Unpooling}{517}{section.15.4}%
\contentsline {subsection}{\numberline {15.4.1}Bed of Nails Unpooling}{518}{subsection.15.4.1}%
\contentsline {paragraph}{Limitations of Bed of Nails Unpooling}{518}{section*.1007}%
\contentsline {subsection}{\numberline {15.4.2}Nearest-Neighbor Unpooling}{519}{subsection.15.4.2}%
\contentsline {subsection}{\numberline {15.4.3}Bilinear Interpolation for Upsampling}{520}{subsection.15.4.3}%
\contentsline {subsubsection}{Bilinear Interpolation: Generalized Case}{520}{section*.1010}%
\contentsline {subsubsection}{Advantages of Bilinear Interpolation}{522}{section*.1012}%
\contentsline {subsubsection}{Limitations and Transition to Bicubic Interpolation}{522}{section*.1013}%
\contentsline {subsection}{\numberline {15.4.4}Bicubic Interpolation for Upsampling}{522}{subsection.15.4.4}%
\contentsline {subsubsection}{Why Bicubic Interpolation?}{522}{section*.1014}%
\contentsline {subsubsection}{Mathematical Reasoning}{522}{section*.1015}%
\contentsline {subsubsection}{Bicubic Interpolation: Generalized Case}{523}{section*.1016}%
\contentsline {subsubsection}{Advantages and Limitations}{524}{section*.1018}%
\contentsline {subsection}{\numberline {15.4.5}Max Unpooling}{524}{subsection.15.4.5}%
\contentsline {subsubsection}{Max Unpooling in the Context of Noh et al. (ICCV 2015)}{524}{section*.1019}%
\contentsline {subsubsection}{Why Max Unpooling is More Effective Than Bed of Nails Unpooling}{525}{section*.1021}%
\contentsline {subsubsection}{Bridging to Transposed Convolution}{525}{section*.1022}%
\contentsline {subsection}{\numberline {15.4.6}Transposed Convolution}{526}{subsection.15.4.6}%
\contentsline {subsubsection}{Understanding the Similarity to Standard Convolution}{526}{section*.1023}%
\contentsline {subsubsection}{Step-by-Step Process of Transposed Convolution}{526}{section*.1024}%
\contentsline {subsubsection}{1D Transposed Convolution}{528}{section*.1028}%
\contentsline {subsubsection}{Advantages of Transposed Convolution}{529}{section*.1030}%
\contentsline {subsubsection}{Connection to Standard Convolution}{529}{section*.1031}%
\contentsline {subsection}{\numberline {15.4.7}Convolution and Transposed Convolution as Matrix Multiplication}{529}{subsection.15.4.7}%
\contentsline {subsubsection}{Convolution via Matrix Multiplication}{529}{section*.1032}%
\contentsline {subsubsection}{Transposed Convolution via Matrix Multiplication (Stride = 1)}{530}{section*.1034}%
\contentsline {subsubsection}{Transposed Convolution and Gradient Derivation}{531}{section*.1036}%
\contentsline {subsubsection}{Advantages of Transposed Convolution}{532}{section*.1037}%
\contentsline {subsubsection}{Challenges and Considerations}{532}{section*.1038}%
\contentsline {subsection}{\numberline {15.4.8}Conclusion: Choosing the Right Upsampling Method}{532}{subsection.15.4.8}%
\contentsline {subsubsection}{Guidelines for Choosing an Upsampling Method}{532}{section*.1040}%
\contentsline {subsubsection}{Final Thoughts}{533}{section*.1041}%
\contentsline {section}{\numberline {15.5}Instance Segmentation}{533}{section.15.5}%
\contentsline {subsection}{\numberline {15.5.1}Mask R-CNN: A Two-Stage Framework for Instance Segmentation}{534}{subsection.15.5.1}%
\contentsline {subsubsection}{Faster R-CNN Backbone}{534}{section*.1042}%
\contentsline {subsubsection}{Key Additions in Mask R-CNN}{534}{section*.1043}%
\contentsline {subsubsection}{Segmentation Mask Prediction: Fixed Size Output}{534}{section*.1044}%
\contentsline {subsubsection}{Training Mask R-CNN and Loss Functions}{534}{section*.1045}%
\contentsline {subsubsection}{Bilinear Interpolation vs. Bicubic Interpolation}{535}{section*.1046}%
\contentsline {subsubsection}{Class-Aware Mask Selection}{535}{section*.1047}%
\contentsline {subsubsection}{Gradient Flow in Mask R-CNN}{535}{section*.1048}%
\contentsline {subsubsection}{Summary}{536}{section*.1049}%
\contentsline {subsection}{\numberline {15.5.2}Extending the Object Detection Paradigm}{536}{subsection.15.5.2}%
\contentsline {section}{Enrichment 15.6: U-Net: A Fully Conv Architecture for Segmentation}{539}{section*.1054}%
\contentsline {subsection}{Enrichment 15.6.1: Overview}{539}{section*.1055}%
\contentsline {subsection}{Enrichment 15.6.2: U-Net Architecture}{539}{section*.1056}%
\contentsline {subsection}{Enrichment 15.6.3: Skip Connections and Concatenation}{540}{section*.1058}%
\contentsline {subsection}{Enrichment 15.6.4: Training U-Net}{540}{section*.1059}%
\contentsline {subsection}{Enrichment 15.6.5: Comparison with Mask R-CNN}{540}{section*.1060}%
\contentsline {subsection}{Enrichment 15.6.6: Impact and Evolution of U-Net}{541}{section*.1061}%
\contentsline {chapter}{\numberline {16}Lecture 16: Recurrent Networks}{542}{chapter.16}%
\ttl@stoptoc {default@15}
\ttl@starttoc {default@16}
\contentsline {section}{\numberline {16.1}Introduction to Recurrent Neural Networks (RNNs)}{542}{section.16.1}%
\contentsline {subsection}{\numberline {16.1.1}Why Study Sequential Models?}{542}{subsection.16.1.1}%
\contentsline {subsection}{\numberline {16.1.2}RNNs as a General-Purpose Sequence Model}{543}{subsection.16.1.2}%
\contentsline {subsection}{\numberline {16.1.3}RNNs for Visual Attention and Image Generation}{543}{subsection.16.1.3}%
\contentsline {subsubsection}{Visual Attention: Sequential Image Processing}{543}{section*.1063}%
\contentsline {subsubsection}{Autoregressive Image Generation with RNNs}{544}{section*.1064}%
\contentsline {subsection}{\numberline {16.1.4}Limitations of Traditional Neural Networks for Sequential Data}{544}{subsection.16.1.4}%
\contentsline {subsection}{\numberline {16.1.5}Overview of Recurrent Neural Networks (RNNs) and Their Evolution}{544}{subsection.16.1.5}%
\contentsline {subsubsection}{RNN Progression: From Vanilla to Gated Units}{544}{section*.1066}%
\contentsline {paragraph}{Vanilla RNNs}{544}{section*.1067}%
\contentsline {paragraph}{Long Short-Term Memory (LSTM)}{544}{section*.1068}%
\contentsline {paragraph}{Gated Recurrent Units (GRUs)}{545}{section*.1069}%
\contentsline {paragraph}{Bidirectional RNNs}{545}{section*.1070}%
\contentsline {subsubsection}{Motivation Toward Transformers}{545}{section*.1071}%
\contentsline {subsubsection}{Bridging to Detailed Explanations}{545}{section*.1072}%
\contentsline {section}{\numberline {16.2}Recurrent Neural Networks (RNNs) - How They Work}{546}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}RNN Computational Graph}{546}{subsection.16.2.1}%
\contentsline {subsubsection}{Many-to-Many}{546}{section*.1073}%
\contentsline {subsubsection}{Many-to-One}{547}{section*.1075}%
\contentsline {subsubsection}{One-to-Many}{548}{section*.1077}%
\contentsline {subsection}{\numberline {16.2.2}Seq2Seq: Sequence-to-Sequence Learning}{548}{subsection.16.2.2}%
\contentsline {subsubsection}{Significance of Seq2Seq Models}{550}{section*.1080}%
\contentsline {section}{\numberline {16.3}Example Usage of Seq2Seq: Language Modeling}{550}{section.16.3}%
\contentsline {subsection}{\numberline {16.3.1}Formulating the Problem}{550}{subsection.16.3.1}%
\contentsline {subsection}{\numberline {16.3.2}One-Hot Encoding of Input Characters}{551}{subsection.16.3.2}%
\contentsline {subsubsection}{Advantages of One-Hot Encoding}{551}{section*.1081}%
\contentsline {subsection}{\numberline {16.3.3}Processing the First Character}{551}{subsection.16.3.3}%
\contentsline {subsection}{\numberline {16.3.4}Computing Loss Across Time Steps}{552}{subsection.16.3.4}%
\contentsline {subsection}{\numberline {16.3.5}Generating Text with a Trained RNN}{552}{subsection.16.3.5}%
\contentsline {subsection}{\numberline {16.3.6}Using an Embedding Layer for Character Inputs}{553}{subsection.16.3.6}%
\contentsline {subsection}{\numberline {16.3.7}Conclusion and Next Steps}{554}{subsection.16.3.7}%
\contentsline {section}{\numberline {16.4}Backpropagation Through Time (BPTT)}{554}{section.16.4}%
\contentsline {subsection}{\numberline {16.4.1}Mathematical Formulation of BPTT and Memory Constraints}{554}{subsection.16.4.1}%
\contentsline {subsection}{\numberline {16.4.2}Truncated Backpropagation Through Time}{555}{subsection.16.4.2}%
\contentsline {subsubsection}{Loss Processing in Truncated BPTT}{555}{section*.1085}%
\contentsline {subsection}{\numberline {16.4.3}Why BPTT Fails for Long Sequences}{556}{subsection.16.4.3}%
\contentsline {section}{\numberline {16.5}Why RNNs Use \textit {tanh} Instead of ReLU}{556}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}Recurrent Computation and Gradient Behavior}{556}{subsection.16.5.1}%
\contentsline {subsubsection}{Repeated Multiplication and the Hidden State}{556}{section*.1086}%
\contentsline {paragraph}{Spectral Properties of \(\mathbf {W}_{hh}\).}{557}{section*.1087}%
\contentsline {subsubsection}{How Large or Small States Affect Gradients}{557}{section*.1088}%
\contentsline {paragraph}{Effect of Activation Function}{557}{section*.1089}%
\contentsline {subsection}{\numberline {16.5.2}Mathematical Rationale for \textit {tanh} in RNNs}{557}{subsection.16.5.2}%
\contentsline {subsubsection}{How \textit {tanh} Curbs Exploding Gradients}{558}{section*.1090}%
\contentsline {paragraph}{1. Bounded Outputs:}{558}{section*.1091}%
\contentsline {paragraph}{2. Derivative Control:}{558}{section*.1092}%
\contentsline {paragraph}{3. Zero-Centered Activation:}{558}{section*.1093}%
\contentsline {paragraph}{A Caveat: Vanishing Gradients Still Remain}{558}{section*.1094}%
\contentsline {subsection}{\numberline {16.5.3}Why ReLU6 or Leaky ReLU Are Not a Full Remedy}{559}{subsection.16.5.3}%
\contentsline {paragraph}{ReLU6: The Saturation Issue}{559}{section*.1095}%
\contentsline {paragraph}{Leaky ReLU: A Partial Fix with Remaining Instability}{559}{section*.1096}%
\contentsline {subsection}{\numberline {16.5.4}Why Gradient Clipping Alone is Insufficient}{559}{subsection.16.5.4}%
\contentsline {paragraph}{Clipping Does Not Prevent Hidden State Growth}{560}{section*.1097}%
\contentsline {section}{\numberline {16.6}Example Usages of Recurrent Neural Networks}{561}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}RNNs for Text-Based Tasks}{561}{subsection.16.6.1}%
\contentsline {subsubsection}{Generating Text with RNNs}{561}{section*.1098}%
\contentsline {subsection}{\numberline {16.6.2}Understanding What RNNs Learn}{561}{subsection.16.6.2}%
\contentsline {paragraph}{Visualization of Hidden State Activations}{561}{section*.1099}%
\contentsline {subsubsection}{Interpretable Hidden Units}{562}{section*.1101}%
\contentsline {paragraph}{Quote Detection Cell}{562}{section*.1102}%
\contentsline {paragraph}{Line Length Tracking Cell}{563}{section*.1104}%
\contentsline {paragraph}{Other Interpretable Hidden Units}{563}{section*.1106}%
\contentsline {subsubsection}{Key Takeaways from Interpretable Units}{563}{section*.1107}%
\contentsline {subsection}{\numberline {16.6.3}Image Captioning}{564}{subsection.16.6.3}%
\contentsline {subsection}{\numberline {16.6.4}Image Captioning Results}{565}{subsection.16.6.4}%
\contentsline {subsection}{\numberline {16.6.5}Failure Cases in Image Captioning}{565}{subsection.16.6.5}%
\contentsline {subsection}{\numberline {16.6.6}Bridging to LSTMs and GRUs: The Need for Gated Memory}{566}{subsection.16.6.6}%
\contentsline {section}{\numberline {16.7}Long Short-Term Memory (LSTM) Overview}{567}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}LSTM Gating Mechanism}{567}{subsection.16.7.1}%
\contentsline {subsection}{\numberline {16.7.2}LSTM Gate Computation}{567}{subsection.16.7.2}%
\contentsline {subsection}{\numberline {16.7.3}LSTM State Updates}{568}{subsection.16.7.3}%
\contentsline {subsection}{\numberline {16.7.4}Gradient Flow in LSTMs}{569}{subsection.16.7.4}%
\contentsline {subsubsection}{Why the Cell State $\mathbf {c}_t$ Preserves Long-Term Information}{569}{section*.1112}%
\contentsline {subsubsection}{Why $\mathbf {f}_t$ Prevents Vanishing Gradients}{570}{section*.1113}%
\contentsline {subsubsection}{Why $\mathbf {f}_t$ Can Be Learned to Stay Near 1}{570}{section*.1114}%
\contentsline {subsubsection}{Why Forget Gates Do Not Cause Exponential Decay Like RNN Activations}{571}{section*.1115}%
\contentsline {subsubsection}{How Hidden-State Gradients Differ}{571}{section*.1116}%
\contentsline {paragraph}{Consequence for Training}{571}{section*.1117}%
\contentsline {subsubsection}{Why Weight-Gradient Vanishing Is Less Critical}{571}{section*.1118}%
\contentsline {subsubsection}{Mitigating Exploding Gradients}{572}{section*.1119}%
\contentsline {section}{\numberline {16.8}Resemblance of LSTMs to Highway Networks and ResNets}{572}{section.16.8}%
\contentsline {subsection}{\numberline {16.8.1}Highway Networks and LSTMs}{572}{subsection.16.8.1}%
\contentsline {subsection}{\numberline {16.8.2}ResNets and LSTMs}{573}{subsection.16.8.2}%
\contentsline {paragraph}{Differences Between ResNets and Highway Networks}{573}{section*.1121}%
\contentsline {subsection}{\numberline {16.8.3}Summary of LSTM, Highway, and ResNet Connections}{574}{subsection.16.8.3}%
\contentsline {section}{\numberline {16.9}Stacking Layers in RNNs and LSTMs}{574}{section.16.9}%
\contentsline {subsection}{\numberline {16.9.1}Architecture of Stacked RNNs and LSTMs}{574}{subsection.16.9.1}%
\contentsline {subsection}{\numberline {16.9.2}Practical Limitations of Deep RNN Architectures}{575}{subsection.16.9.2}%
\contentsline {subsection}{\numberline {16.9.3}Deep RNNs: Balancing Depth and Efficiency}{575}{subsection.16.9.3}%
\contentsline {section}{Enrichment 16.10: Other RNN Variants: GRU}{576}{section*.1125}%
\contentsline {subsection}{Enrichment 16.10.1: GRU Architecture}{576}{section*.1126}%
\contentsline {paragraph}{Key Observations:}{577}{section*.1128}%
\contentsline {subsection}{Enrichment 16.10.2: Gradient Flow in GRUs}{577}{section*.1129}%
\contentsline {subsection}{Enrichment 16.10.3: Advantages of GRUs over LSTMs}{578}{section*.1133}%
\contentsline {subsection}{Enrichment 16.10.4: Limitations of GRUs}{578}{section*.1134}%
\contentsline {subsection}{Enrichment 16.10.5: Comparison with LSTMs}{578}{section*.1135}%
\contentsline {subsection}{Enrichment 16.10.6: Bridging to Advanced Architectures}{579}{section*.1136}%
\contentsline {section}{\numberline {16.11}Summary and Future Directions}{579}{section.16.11}%
\contentsline {subsection}{\numberline {16.11.1}Neural Architecture Search for Improved RNNs}{579}{subsection.16.11.1}%
\contentsline {subsection}{\numberline {16.11.2}Summary of RNN Architectures}{580}{subsection.16.11.2}%
\contentsline {subsection}{\numberline {16.11.3}Beyond RNNs: From Recurrence to Attention}{580}{subsection.16.11.3}%
\contentsline {chapter}{\numberline {17}Lecture 17: Attention}{581}{chapter.17}%
\ttl@stoptoc {default@16}
\ttl@starttoc {default@17}
\contentsline {section}{\numberline {17.1}Limitations of Sequence-to-Sequence with RNNs}{581}{section.17.1}%
\contentsline {section}{\numberline {17.2}Introducing the Attention Mechanism}{582}{section.17.2}%
\contentsline {subsubsection}{Intuition Behind Attention}{584}{section*.1143}%
\contentsline {subsection}{\numberline {17.2.1}Benefits of Attention}{584}{subsection.17.2.1}%
\contentsline {subsection}{\numberline {17.2.2}Attention Interpretability}{584}{subsection.17.2.2}%
\contentsline {subsubsection}{Attention Maps: Visualizing Model Decisions}{584}{section*.1144}%
\contentsline {subsubsection}{Understanding Attention Patterns}{585}{section*.1146}%
\contentsline {subsubsection}{Why Attention Interpretability Matters}{586}{section*.1147}%
\contentsline {section}{\numberline {17.3}Applying Attention to Image Captioning}{586}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}Feature Representation and Attention Computation}{586}{subsection.17.3.1}%
\contentsline {subsection}{\numberline {17.3.2}Generalizing to Any Timestep \( t \)}{588}{subsection.17.3.2}%
\contentsline {subsection}{\numberline {17.3.3}Example: Captioning an Image of a Cat}{588}{subsection.17.3.3}%
\contentsline {subsection}{\numberline {17.3.4}Visualizing Attention in Image Captioning}{589}{subsection.17.3.4}%
\contentsline {subsubsection}{Hard vs. Soft Attention}{589}{section*.1150}%
\contentsline {subsection}{\numberline {17.3.5}Biological Inspiration: Saccades in Human Vision}{590}{subsection.17.3.5}%
\contentsline {subsection}{\numberline {17.3.6}Beyond Captioning: Generalizing Attention Mechanisms}{591}{subsection.17.3.6}%
\contentsline {section}{\numberline {17.4}Attention Layer}{592}{section.17.4}%
\contentsline {subsection}{\numberline {17.4.1}Scaled Dot-Product Attention}{592}{subsection.17.4.1}%
\contentsline {paragraph}{Why Scale by \(\sqrt {D_Q}\)?}{593}{section*.1153}%
\contentsline {paragraph}{Scaling and Softmax Temperature}{593}{section*.1154}%
\contentsline {paragraph}{Why Dot Product?}{594}{section*.1155}%
\contentsline {subsection}{\numberline {17.4.2}Extending to Multiple Query Vectors}{594}{subsection.17.4.2}%
\contentsline {paragraph}{Benefits of Multiple Queries:}{594}{section*.1156}%
\contentsline {subsection}{\numberline {17.4.3}Introducing Key and Value Vectors}{595}{subsection.17.4.3}%
\contentsline {paragraph}{Why Separate Keys and Values?}{595}{section*.1157}%
\contentsline {subsection}{\numberline {17.4.4}An Analogy: Search Engines}{595}{subsection.17.4.4}%
\contentsline {subsubsection}{Empire State Building Example}{595}{section*.1158}%
\contentsline {subsubsection}{Why This Separation Matters}{596}{section*.1159}%
\contentsline {subsection}{\numberline {17.4.5}Bridging to Visualization and Further Understanding}{596}{subsection.17.4.5}%
\contentsline {subsubsection}{Overview of the Attention Layer Steps}{596}{section*.1160}%
\contentsline {subsection}{\numberline {17.4.6}Towards Self-Attention}{598}{subsection.17.4.6}%
\contentsline {section}{\numberline {17.5}Self-Attention}{599}{section.17.5}%
\contentsline {subsection}{\numberline {17.5.1}Mathematical Formulation of Self-Attention}{599}{subsection.17.5.1}%
\contentsline {subsection}{\numberline {17.5.2}Non-Linearity in Self-Attention}{600}{subsection.17.5.2}%
\contentsline {subsection}{\numberline {17.5.3}Permutation Equivariance in Self-Attention}{601}{subsection.17.5.3}%
\contentsline {subsubsection}{When is Permutation Equivariance a Problem?}{601}{section*.1164}%
\contentsline {subsection}{\numberline {17.5.4}Positional Encodings: Introduction}{602}{subsection.17.5.4}%
\contentsline {paragraph}{Why Not Use Simple Positional Indices?}{602}{section*.1165}%
\contentsline {subsection}{\numberline {17.5.5}Sinusoidal Positional Encoding}{602}{subsection.17.5.5}%
\contentsline {subsubsection}{Mathematical Definition}{603}{section*.1166}%
\contentsline {paragraph}{Intuition: Multiple Frequencies for Local \& Global Positioning}{603}{section*.1167}%
\contentsline {subsubsection}{Removing Ambiguity with Sine and Cosine}{603}{section*.1169}%
\contentsline {subsubsection}{Why Use \(\displaystyle 10000\) in the Denominator?}{604}{section*.1171}%
\contentsline {subsubsection}{Frequency Variation and Intuition}{604}{section*.1172}%
\contentsline {paragraph}{Concrete Example:}{606}{section*.1174}%
\contentsline {subsubsection}{How Relative Position Awareness Emerges}{606}{section*.1175}%
\contentsline {paragraph}{Why This Matters for Relative Positioning}{606}{section*.1176}%
\contentsline {subsubsection}{Does Positional Information Vanish in Deeper Layers?}{607}{section*.1178}%
\contentsline {subsubsection}{Why Sinusoidal Encoding Solves Previous Limitations}{607}{section*.1179}%
\contentsline {subsubsection}{Conclusion on Sinusoidal Positional Encoding}{607}{section*.1180}%
\contentsline {subsection}{\numberline {17.5.6}Learned Positional Encodings: An Alternative Approach}{608}{subsection.17.5.6}%
\contentsline {paragraph}{Definition and Mechanics}{608}{section*.1181}%
\contentsline {paragraph}{Examples of Learned Positional Encodings}{608}{section*.1182}%
\contentsline {subparagraph}{Highlighting Crucial Positions or Transitions}{608}{subparagraph*.1183}%
\contentsline {paragraph}{Why Task-Specific Optimization of Position is Useful}{608}{section*.1184}%
\contentsline {subsubsection}{Pros \& Cons of Learned Positional Embeddings}{609}{section*.1185}%
\contentsline {paragraph}{Conclusion on Learned Positional Embeddings}{610}{section*.1186}%
\contentsline {subsection}{\numberline {17.5.7}Masked Self-Attention Layer}{611}{subsection.17.5.7}%
\contentsline {subsubsection}{Why Do We Need Masking?}{611}{section*.1187}%
\contentsline {subsubsection}{Applying the Mask in Attention Computation}{611}{section*.1188}%
\contentsline {subsubsection}{How Masking Affects the Attention Weights}{611}{section*.1189}%
\contentsline {subsubsection}{Example of Masking in a Short Sequence}{612}{section*.1191}%
\contentsline {subsubsection}{Handling Batches with Variable-Length Sequences}{612}{section*.1192}%
\contentsline {paragraph}{Why is Padding Necessary?}{612}{section*.1193}%
\contentsline {subsubsection}{Moving on to Input Processing with Self-Attention}{613}{section*.1194}%
\contentsline {subsection}{\numberline {17.5.8}Processing Inputs with Self-Attention}{614}{subsection.17.5.8}%
\contentsline {subsubsection}{Parallelization in Self-Attention}{614}{section*.1195}%
\contentsline {subsubsection}{Handling Batches of Sequences with Different Lengths}{615}{section*.1196}%
\contentsline {subsubsection}{Why is Self-Attention Parallelizable?}{616}{section*.1197}%
\contentsline {subsubsection}{Computational Complexity of Self-Attention, RNNs, and Convolutions}{616}{section*.1198}%
\contentsline {subsubsection}{When is Self-Attention Computationally Efficient?}{616}{section*.1199}%
\contentsline {subsubsection}{Conclusion: When to Use Self-Attention?}{617}{section*.1200}%
\contentsline {subsection}{\numberline {17.5.9}Multi-Head Self-Attention Layer}{618}{subsection.17.5.9}%
\contentsline {subsubsection}{Motivation}{618}{section*.1201}%
\contentsline {paragraph}{Analogy with Convolutional Kernels}{618}{section*.1202}%
\contentsline {paragraph}{Diversity in Attention Patterns}{618}{section*.1203}%
\contentsline {subsubsection}{How Multi-Head Attention Works}{618}{section*.1204}%
\contentsline {paragraph}{Splitting Dimensions}{618}{section*.1205}%
\contentsline {paragraph}{Computing Multi-Head Attention}{619}{section*.1206}%
\contentsline {paragraph}{Concatenation and Output Projection}{619}{section*.1207}%
\contentsline {subsubsection}{Optimized Implementation and Linear Projection}{620}{section*.1209}%
\contentsline {subsubsection}{PyTorch Implementation of Multi-Head Attention}{621}{section*.1210}%
\contentsline {subsubsection}{Stepping Stone to Transformers and Vision Applications}{621}{section*.1211}%
\contentsline {subsection}{\numberline {17.5.10}Self-Attention for Vision Applications}{622}{subsection.17.5.10}%
\contentsline {paragraph}{Generating Queries, Keys, and Values}{622}{section*.1212}%
\contentsline {paragraph}{Reshaping for Attention Computation}{622}{section*.1213}%
\contentsline {paragraph}{Computing Attention Scores}{622}{section*.1214}%
\contentsline {paragraph}{Normalizing Attention Weights}{623}{section*.1215}%
\contentsline {paragraph}{Computing the Attention Output}{623}{section*.1216}%
\contentsline {paragraph}{Reshaping, Final Projection, and Residual Connection}{623}{section*.1217}%
\contentsline {paragraph}{Summary}{624}{section*.1219}%
\contentsline {subsubsection}{Bridging Towards Transformers}{624}{section*.1220}%
\contentsline {section}{\numberline {17.6}Transformer}{625}{section.17.6}%
\contentsline {subsection}{\numberline {17.6.1}Motivation and Introduction}{625}{subsection.17.6.1}%
\contentsline {subsubsection}{Three Ways of Processing Sequences}{625}{section*.1221}%
\contentsline {paragraph}{Recurrent Neural Networks (RNNs)}{625}{section*.1222}%
\contentsline {paragraph}{1D Convolution for Sequence Processing}{625}{section*.1223}%
\contentsline {paragraph}{Self-Attention Mechanism}{626}{section*.1224}%
\contentsline {subsection}{\numberline {17.6.2}Why the Transformer?}{626}{subsection.17.6.2}%
\contentsline {subsection}{\numberline {17.6.3}Seq2Seq Original Transformer Workflow}{628}{subsection.17.6.3}%
\contentsline {subsubsection}{Transformer Encoder Block: Structure and Reasoning}{630}{section*.1228}%
\contentsline {subsubsection}{Transformer Decoder Block: Structure and Reasoning}{631}{section*.1229}%
\contentsline {subsubsection}{Transitioning to Unified Transformer Blocks}{632}{section*.1230}%
\contentsline {subsection}{\numberline {17.6.4}The Modern Transformer Block}{633}{subsection.17.6.4}%
\contentsline {subsubsection}{Structure of the Modern Transformer Block}{633}{section*.1232}%
\contentsline {subsubsection}{PyTorch Implementation}{634}{section*.1233}%
\contentsline {subsubsection}{Why the Modern Transformer Block?}{635}{section*.1234}%
\contentsline {subsubsection}{Key Benefits of the Modern Transformer Block}{635}{section*.1236}%
\contentsline {subsubsection}{Further Reading and Resources}{637}{section*.1239}%
\contentsline {subsubsection}{Bridging Towards Vision Transformers}{637}{section*.1240}%
\contentsline {chapter}{\numberline {18}Lecture 18: Vision Transformers}{638}{chapter.18}%
\ttl@stoptoc {default@17}
\ttl@starttoc {default@18}
\contentsline {section}{\numberline {18.1}Bringing Transformers to Vision Tasks}{638}{section.18.1}%
\contentsline {section}{\numberline {18.2}Integrating Attention into Convolutional Neural Networks (CNNs)}{639}{section.18.2}%
\contentsline {subsection}{\numberline {18.2.1}How Does It Work?}{639}{subsection.18.2.1}%
\contentsline {subsection}{\numberline {18.2.2}Limitations of Adding Attention to CNNs}{639}{subsection.18.2.2}%
\contentsline {section}{\numberline {18.3}Replacing Convolution with Local Attention Mechanisms}{641}{section.18.3}%
\contentsline {subsection}{\numberline {18.3.1}How Does Local Attention Work?}{641}{subsection.18.3.1}%
\contentsline {subsection}{\numberline {18.3.2}Why is Local Attention More Flexible than Convolutions?}{642}{subsection.18.3.2}%
\contentsline {subsection}{\numberline {18.3.3}Computational Complexity Comparison: Local Attention vs.\ Convolution}{642}{subsection.18.3.3}%
\contentsline {paragraph}{Convolutional Complexity}{642}{section*.1243}%
\contentsline {paragraph}{Local Attention Complexity}{642}{section*.1244}%
\contentsline {paragraph}{Why is Local Attention More Expensive?}{643}{section*.1245}%
\contentsline {paragraph}{Summary}{643}{section*.1246}%
\contentsline {paragraph}{From Local Attention to ViTs}{643}{section*.1247}%
\contentsline {section}{\numberline {18.4}Vision Transformers (ViTs): From Pixels to Patches}{644}{section.18.4}%
\contentsline {subsection}{\numberline {18.4.1}Splitting an Image into Patches}{644}{subsection.18.4.1}%
\contentsline {subsection}{\numberline {18.4.2}Class Token and Positional Encoding}{645}{subsection.18.4.2}%
\contentsline {subsection}{\numberline {18.4.3}Final Processing: From Context Token to Classification}{646}{subsection.18.4.3}%
\contentsline {subsection}{\numberline {18.4.4}Vision Transformer: Process Summary and Implementation}{646}{subsection.18.4.4}%
\contentsline {subsubsection}{Vision Transformer Processing Steps}{646}{section*.1250}%
\contentsline {subsubsection}{PyTorch Implementation of a Vision Transformer}{647}{section*.1251}%
\contentsline {subsection}{\numberline {18.4.5}Computational Complexity: ViT vs.\ Pixel-Level Self-Attention}{651}{subsection.18.4.5}%
\contentsline {subsubsection}{Pixel-Level Self-Attention}{651}{section*.1252}%
\contentsline {subsubsection}{Patch-Based Self-Attention (ViT)}{651}{section*.1253}%
\contentsline {subsubsection}{Key Takeaways}{651}{section*.1254}%
\contentsline {subsection}{\numberline {18.4.6}Limitations and Data Requirements of Vision Transformers}{652}{subsection.18.4.6}%
\contentsline {subsubsection}{Large-Scale Pretraining is Critical}{652}{section*.1255}%
\contentsline {subsubsection}{Why Do ViTs Require More Data?}{652}{section*.1257}%
\contentsline {paragraph}{1. No Built-in Locality or Weight Sharing}{653}{section*.1258}%
\contentsline {paragraph}{2. Higher Parameter Count and Capacity}{653}{section*.1259}%
\contentsline {paragraph}{3. Less Implicit Regularization}{653}{section*.1260}%
\contentsline {paragraph}{4. Absence of Hierarchical Representations}{653}{section*.1261}%
\contentsline {paragraph}{A Note on Inductive Bias}{654}{section*.1262}%
\contentsline {subsection}{\numberline {18.4.7}Understanding ViT Model Variants}{654}{subsection.18.4.7}%
\contentsline {subsubsection}{Model Configurations}{654}{section*.1263}%
\contentsline {subsubsection}{Transfer Performance Across Datasets}{655}{section*.1265}%
\contentsline {subsection}{\numberline {18.4.8}Improving ViT Training Efficiency}{655}{subsection.18.4.8}%
\contentsline {paragraph}{Regularization Techniques:}{656}{section*.1267}%
\contentsline {paragraph}{Data Augmentation Strategies:}{656}{section*.1268}%
\contentsline {subsubsection}{Towards Data-Efficient Vision Transformers: Introducing DeiT}{656}{section*.1269}%
\contentsline {section}{\numberline {18.5}Data-Efficient Image Transformers (DeiTs)}{657}{section.18.5}%
\contentsline {subsection}{\numberline {18.5.1}Cross-Entropy and KL Divergence: Theory, Intuition, and Role in Distillation}{657}{subsection.18.5.1}%
\contentsline {paragraph}{Cross-Entropy Loss}{657}{section*.1270}%
\contentsline {paragraph}{KL Divergence: Full Distribution Matching}{658}{section*.1272}%
\contentsline {paragraph}{Illustrative Example: CE vs KL}{658}{section*.1273}%
\contentsline {paragraph}{Hard vs.\ Soft Distillation: Choosing the Right Signal}{659}{section*.1274}%
\contentsline {subsection}{\numberline {18.5.2}DeiT Distillation Token and Training Strategy}{659}{subsection.18.5.2}%
\contentsline {subsubsection}{Distillation via Tokens: Setup}{659}{section*.1275}%
\contentsline {paragraph}{Hard Distillation in Practice.}{660}{section*.1276}%
\contentsline {subsubsection}{Soft Distillation: Temperature and KL Loss}{660}{section*.1278}%
\contentsline {subsubsection}{Why Use a CNN Teacher?}{661}{section*.1279}%
\contentsline {subsubsection}{Learned Token Behavior}{661}{section*.1280}%
\contentsline {subsubsection}{Fine-Tuning: High Resolution and Distillation Retention}{662}{section*.1282}%
\contentsline {paragraph}{Two-Phase Training Rationale}{662}{section*.1283}%
\contentsline {paragraph}{Why Higher Resolution Helps}{662}{section*.1284}%
\contentsline {paragraph}{Upscaling and L2-Norm Preservation}{662}{section*.1285}%
\contentsline {paragraph}{Teacher Adaptation with FixRes}{662}{section*.1286}%
\contentsline {paragraph}{Dual Supervision in Fine-Tuning}{662}{section*.1287}%
\contentsline {subsubsection}{Why This Works in Data-Limited Settings}{662}{section*.1288}%
\contentsline {subsection}{\numberline {18.5.3}Model Variants}{663}{subsection.18.5.3}%
\contentsline {subsection}{\numberline {18.5.4}Conclusion and Outlook: From DeiT to DeiT III and Beyond}{663}{subsection.18.5.4}%
\contentsline {subsubsection}{DeiT III: Revenge of the ViT}{664}{section*.1291}%
\contentsline {paragraph}{Open Questions Raised by DeiT}{664}{section*.1292}%
\contentsline {subsubsection}{Toward Hierarchical Vision Transformers}{664}{section*.1293}%
\contentsline {section}{\numberline {18.6}Swin Transformer: Hierarchical Vision Transformers with Shifted Windows}{666}{section.18.6}%
\contentsline {subsection}{\numberline {18.6.1}How Swin Works}{666}{subsection.18.6.1}%
\contentsline {paragraph}{Patch Tokenization}{666}{section*.1295}%
\contentsline {subsection}{\numberline {18.6.2}Window-Based Self-Attention (W-MSA)}{667}{subsection.18.6.2}%
\contentsline {subsection}{\numberline {18.6.3}Limitation: No Cross-Window Communication}{668}{subsection.18.6.3}%
\contentsline {subsection}{\numberline {18.6.4}Solution: Shifted Windows (SW-MSA)}{668}{subsection.18.6.4}%
\contentsline {paragraph}{How it works}{668}{section*.1298}%
\contentsline {paragraph}{Benefits of SW-MSA}{668}{section*.1299}%
\contentsline {paragraph}{Challenges Introduced by Shifted Windows}{669}{section*.1301}%
\contentsline {subsection}{\numberline {18.6.5}Cyclic Shifted Window-Masked Self Attention (Cyclic SW-MSA)}{671}{subsection.18.6.5}%
\contentsline {subsubsection}{Masking in SW-MSA}{671}{section*.1306}%
\contentsline {paragraph}{Step-by-Step Construction of the Mask}{671}{section*.1307}%
\contentsline {paragraph}{Why Use \(-100.0\) in the Mask?}{672}{section*.1308}%
\contentsline {paragraph}{Expanded Receptive Fields}{673}{section*.1309}%
\contentsline {subsection}{\numberline {18.6.6}Patch Merging in Swin Transformers}{674}{subsection.18.6.6}%
\contentsline {subsection}{\numberline {18.6.7}Positional Encoding in Swin Transformers}{675}{subsection.18.6.7}%
\contentsline {paragraph}{Relative Position Bias in Swin Transformers}{675}{section*.1316}%
\contentsline {paragraph}{Hierarchical Windows and Relative Offsets}{675}{section*.1317}%
\contentsline {paragraph}{Why Relative Position Bias for Hierarchical Transformers?}{676}{section*.1318}%
\contentsline {paragraph}{Implementation Detail}{676}{section*.1319}%
\contentsline {paragraph}{Practical Benefits}{676}{section*.1320}%
\contentsline {subsection}{\numberline {18.6.8}Conclusion: The Swin Transformer Architecture and Variants}{677}{subsection.18.6.8}%
\contentsline {section}{\numberline {18.7}Extensions and Successors to Swin}{678}{section.18.7}%
\contentsline {subsection}{\numberline {18.7.1}Swin Evolution: Swin Transformer V2}{678}{subsection.18.7.1}%
\contentsline {paragraph}{1) Scaled Cosine Attention}{679}{section*.1326}%
\contentsline {paragraph}{2) Log-Spaced Continuous Position Bias (Log-CPB)}{679}{section*.1327}%
\contentsline {paragraph}{3) Residual Post-Norm}{680}{section*.1328}%
\contentsline {paragraph}{Implications and Results}{680}{section*.1330}%
\contentsline {subsection}{\numberline {18.7.2}Multiscale Vision Transformer (MViT)}{681}{subsection.18.7.2}%
\contentsline {paragraph}{1.\ Pooling Attention (MHPA)}{681}{section*.1331}%
\contentsline {paragraph}{How Does Pooling Work?}{682}{section*.1333}%
\contentsline {paragraph}{Multiscale Hierarchy via Pooling}{682}{section*.1334}%
\contentsline {paragraph}{2.\ Hierarchical Token Downsampling}{682}{section*.1335}%
\contentsline {paragraph}{3.\ Global Attention vs.\ Local Windows}{682}{section*.1336}%
\contentsline {paragraph}{Originally Designed for Video, Effective for Images}{683}{section*.1337}%
\contentsline {paragraph}{Empirical Strengths}{683}{section*.1338}%
\contentsline {subsection}{\numberline {18.7.3}Improved Multiscale Vision Transformers: MViTv2}{683}{subsection.18.7.3}%
\contentsline {subsubsection}{Decomposed Relative Positional Embeddings}{683}{section*.1339}%
\contentsline {paragraph}{Motivation}{683}{section*.1340}%
\contentsline {paragraph}{Decomposed Formulation}{683}{section*.1341}%
\contentsline {paragraph}{Integration into Attention}{684}{section*.1342}%
\contentsline {subsubsection}{Residual Pooling Connections}{684}{section*.1343}%
\contentsline {paragraph}{Problem}{684}{section*.1344}%
\contentsline {paragraph}{Solution.}{684}{section*.1345}%
\contentsline {paragraph}{Empirical Impact}{684}{section*.1346}%
\contentsline {subsubsection}{Performance Benefits}{684}{section*.1347}%
\contentsline {subsubsection}{Summary}{685}{section*.1348}%
\contentsline {paragraph}{Looking Ahead}{685}{section*.1349}%
\contentsline {section}{\numberline {18.8}MLP-Mixer: All-MLP Vision Architecture}{686}{section.18.8}%
\contentsline {subsection}{\numberline {18.8.1}The MLP-Mixer Architecture}{686}{subsection.18.8.1}%
\contentsline {paragraph}{Token-Mixing and Channel-Mixing Blocks}{686}{section*.1351}%
\contentsline {paragraph}{CNN Equivalence}{687}{section*.1352}%
\contentsline {subsection}{\numberline {18.8.2}Results and Limitations}{687}{subsection.18.8.2}%
\contentsline {subsection}{\numberline {18.8.3}Looking Ahead: Applying Transformers to Object Detection}{687}{subsection.18.8.3}%
\contentsline {section}{\numberline {18.9}Detection Transformer (DeTR)}{688}{section.18.9}%
\contentsline {paragraph}{Architecture Overview}{688}{section*.1354}%
\contentsline {paragraph}{Why Transformers for Detection?}{688}{section*.1355}%
\contentsline {subsection}{\numberline {18.9.1}Matching Predictions and Ground Truth with No-Object Padding}{689}{subsection.18.9.1}%
\contentsline {paragraph}{Challenge:}{689}{section*.1356}%
\contentsline {paragraph}{Solution: No-Object Padding}{689}{section*.1357}%
\contentsline {paragraph}{Hungarian Matching:}{689}{section*.1359}%
\contentsline {paragraph}{Implementation Snippet:}{690}{section*.1360}%
\contentsline {paragraph}{Why This Matters:}{690}{section*.1361}%
\contentsline {subsection}{\numberline {18.9.2}Hungarian Matching Loss and Bounding Box Optimization}{690}{subsection.18.9.2}%
\contentsline {paragraph}{Step 1: Optimal Bipartite Matching}{690}{section*.1362}%
\contentsline {paragraph}{Step 2: Matching Cost Definition}{691}{section*.1363}%
\contentsline {paragraph}{Step 3: Final Loss Computation}{691}{section*.1364}%
\contentsline {paragraph}{Bounding Box Loss: Smooth L1 and GIoU Components}{691}{section*.1365}%
\contentsline {subparagraph}{1. Smooth L1 Loss (Huber Variant)}{691}{subparagraph*.1366}%
\contentsline {subparagraph}{2. Generalized IoU (GIoU) Loss}{692}{subparagraph*.1367}%
\contentsline {subparagraph}{3. Combining Smooth L1 and GIoU}{693}{subparagraph*.1369}%
\contentsline {paragraph}{Conclusion}{693}{section*.1370}%
\contentsline {subsection}{\numberline {18.9.3}Architecture Overview: CNN Backbone + Transformer Decoder}{693}{subsection.18.9.3}%
\contentsline {paragraph}{1.\ CNN Backbone}{693}{section*.1371}%
\contentsline {paragraph}{2.\ Transformer Encoder}{693}{section*.1372}%
\contentsline {paragraph}{3.\ Learned Object Queries and Transformer Decoder}{694}{section*.1374}%
\contentsline {paragraph}{4.\ Interpreting Object Queries}{695}{section*.1376}%
\contentsline {paragraph}{5.\ Why Attention is a Natural Fit}{695}{section*.1378}%
\contentsline {subsection}{\numberline {18.9.4}DeTR Results, Impact, and Follow-Up Work}{696}{subsection.18.9.4}%
\contentsline {paragraph}{From Detection to Segmentation}{696}{section*.1380}%
\contentsline {paragraph}{Real-World Usage: HuggingFace Implementation}{697}{section*.1383}%
\contentsline {paragraph}{Follow-Up Works and Extensions}{697}{section*.1384}%
\contentsline {paragraph}{Broader Impact}{697}{section*.1385}%
\contentsline {paragraph}{Conclusion}{697}{section*.1386}%
\contentsline {chapter}{\numberline {19}Lecture 19: Generative Models I}{698}{chapter.19}%
\ttl@stoptoc {default@18}
\ttl@starttoc {default@19}
\contentsline {section}{\numberline {19.1}Supervised vs.\ Unsupervised Learning}{698}{section.19.1}%
\contentsline {subsection}{\numberline {19.1.1}Supervised Learning}{698}{subsection.19.1.1}%
\contentsline {subsection}{\numberline {19.1.2}Unsupervised Learning}{698}{subsection.19.1.2}%
\contentsline {section}{\numberline {19.2}Discriminative vs.\ Generative Models}{699}{section.19.2}%
\contentsline {subsection}{\numberline {19.2.1}Discriminative Models}{700}{subsection.19.2.1}%
\contentsline {subsection}{\numberline {19.2.2}Generative Models}{700}{subsection.19.2.2}%
\contentsline {subsection}{\numberline {19.2.3}Conditional Generative Models}{701}{subsection.19.2.3}%
\contentsline {subsection}{\numberline {19.2.4}Model Relationships via Bayes' Rule}{701}{subsection.19.2.4}%
\contentsline {subsection}{\numberline {19.2.5}Summary of Generative Model Taxonomy}{702}{subsection.19.2.5}%
\contentsline {section}{\numberline {19.3}Autoregressive Models and Explicit Density Estimation}{703}{section.19.3}%
\contentsline {subsection}{\numberline {19.3.1}Maximum Likelihood Estimation}{703}{subsection.19.3.1}%
\contentsline {subsection}{\numberline {19.3.2}Autoregressive Factorization}{704}{subsection.19.3.2}%
\contentsline {subsection}{\numberline {19.3.3}Recurrent Pixel Networks: Overview and Motivation}{704}{subsection.19.3.3}%
\contentsline {paragraph}{Autoregressive Architectures in PixelRNN}{704}{section*.1394}%
\contentsline {subsubsection}{PixelCNN}{705}{section*.1396}%
\contentsline {paragraph}{Image Generation as Sequential Prediction}{706}{section*.1397}%
\contentsline {paragraph}{Autoregressive Generation Process}{706}{section*.1398}%
\contentsline {paragraph}{Masked Convolution for Feature Extraction}{707}{section*.1400}%
\contentsline {paragraph}{Red Channel: Feature Processing and Softmax}{708}{section*.1401}%
\contentsline {paragraph}{Green Channel: Conditioning on Red}{708}{section*.1402}%
\contentsline {paragraph}{Blue Channel: Conditioning on Red and Green}{709}{section*.1404}%
\contentsline {paragraph}{Moving to the Next Pixel}{710}{section*.1405}%
\contentsline {paragraph}{Training PixelCNNs Efficiently}{710}{section*.1407}%
\contentsline {paragraph}{Why Move Beyond PixelCNN? Blind Spots, Receptive Fields, and Inference Latency}{711}{section*.1408}%
\contentsline {subparagraph}{1. Receptive Field Growth is Local and Incremental}{711}{subparagraph*.1409}%
\contentsline {subparagraph}{2. Blind Spots: Missing Valid Context Pixels}{711}{subparagraph*.1410}%
\contentsline {subparagraph}{3. Inference Time: Slow Sequential Generation}{711}{subparagraph*.1411}%
\contentsline {subparagraph}{Motivation for Recurrent Alternatives}{712}{subparagraph*.1412}%
\contentsline {subsubsection}{Row LSTM}{713}{section*.1413}%
\contentsline {paragraph}{From Convolution Stacks to Convolutional Recurrence}{713}{section*.1414}%
\contentsline {paragraph}{What is a Convolutional LSTM?}{713}{section*.1415}%
\contentsline {paragraph}{Triangular Receptive Field}{714}{section*.1416}%
\contentsline {paragraph}{Looking Ahead}{714}{section*.1418}%
\contentsline {subsubsection}{Diagonal BiLSTM}{715}{section*.1419}%
\contentsline {paragraph}{Skewing the Input for Diagonal Convolutions}{715}{section*.1421}%
\contentsline {paragraph}{Causal Correction for Bidirectionality}{716}{section*.1423}%
\contentsline {paragraph}{Convolutional LSTM Logic}{716}{section*.1425}%
\contentsline {paragraph}{Why Diagonal BiLSTM is the Most Expressive Variant}{717}{section*.1427}%
\contentsline {paragraph}{Residual Connections in PixelRNNs}{718}{section*.1428}%
\contentsline {paragraph}{Looking Ahead}{718}{section*.1430}%
\contentsline {subsubsection}{Multi-Scale PixelRNN}{719}{section*.1431}%
\contentsline {paragraph}{Two-Stage Architecture}{719}{section*.1432}%
\contentsline {paragraph}{Conditioning via Upsampling and Biasing}{719}{section*.1433}%
\contentsline {paragraph}{Why Multi-Scale Helps}{720}{section*.1435}%
\contentsline {paragraph}{Trade-Offs and Usage}{721}{section*.1436}%
\contentsline {subsubsection}{Results and Qualitative Samples}{721}{section*.1437}%
\contentsline {subsubsection}{Enrichment 19.3.3.1: Beyond PixelRNN: Advanced Autoregressive Variants}{722}{section*.1439}%
\contentsline {paragraph}{Gated PixelCNN}{722}{section*.1440}%
\contentsline {paragraph}{PixelCNN++}{722}{section*.1441}%
\contentsline {paragraph}{ImageGPT}{722}{section*.1442}%
\contentsline {paragraph}{Looking Ahead: From Autoregressive Models to VAEs}{723}{section*.1443}%
\contentsline {section}{\numberline {19.4}Variational Autoencoders (VAEs)}{724}{section.19.4}%
\contentsline {subsection}{\numberline {19.4.1}Regular (Non-Variational) Autoencoders}{724}{subsection.19.4.1}%
\contentsline {paragraph}{Usage in Transfer Learning}{724}{section*.1445}%
\contentsline {paragraph}{Architecture Patterns}{725}{section*.1447}%
\contentsline {paragraph}{Limitations of Vanilla Autoencoders}{725}{section*.1448}%
\contentsline {subsection}{\numberline {19.4.2}Introducing the VAE}{726}{subsection.19.4.2}%
\contentsline {paragraph}{Core Goals}{726}{section*.1449}%
\contentsline {paragraph}{Why a Latent Variable Model?}{726}{section*.1450}%
\contentsline {paragraph}{Probabilistic Decoder}{727}{section*.1452}%
\contentsline {paragraph}{Why Not a Full Covariance Matrix?}{728}{section*.1454}%
\contentsline {paragraph}{Diagonal Assumption and Trade-Offs}{728}{section*.1455}%
\contentsline {paragraph}{Marginal Likelihood: What We Want to Optimize}{728}{section*.1456}%
\contentsline {subsubsection}{Training VAEs and Developing the ELBO}{729}{section*.1457}%
\contentsline {paragraph}{The Role of Bayes' Rule}{729}{section*.1458}%
\contentsline {paragraph}{Why This Matters}{729}{section*.1459}%
\contentsline {paragraph}{Switching Objectives: Approximating the Posterior}{729}{section*.1460}%
\contentsline {paragraph}{Rewriting the Log Likelihood}{729}{section*.1461}%
\contentsline {paragraph}{Interpreting the ELBO}{731}{section*.1462}%
\contentsline {chapter}{\numberline {20}Lecture 20: Generative Models II}{732}{chapter.20}%
\ttl@stoptoc {default@19}
\ttl@starttoc {default@20}
\contentsline {section}{\numberline {20.1}VAE Training and Data Generation}{732}{section.20.1}%
\contentsline {subsection}{\numberline {20.1.1}Encoder and Decoder Architecture: MNIST Example}{732}{subsection.20.1.1}%
\contentsline {subsection}{\numberline {20.1.2}Training Pipeline: Step-by-Step}{733}{subsection.20.1.2}%
\contentsline {paragraph}{The ELBO Objective}{733}{section*.1465}%
\contentsline {subsubsection}{Why a Diagonal Gaussian Prior?}{735}{section*.1467}%
\contentsline {subsection}{\numberline {20.1.3}How Can We Generate Data Using VAEs?}{736}{subsection.20.1.3}%
\contentsline {paragraph}{Sampling Procedure}{736}{section*.1468}%
\contentsline {section}{\numberline {20.2}Results and Applications of VAEs}{737}{section.20.2}%
\contentsline {subsection}{\numberline {20.2.1}Qualitative Generation Results}{737}{subsection.20.2.1}%
\contentsline {subsection}{\numberline {20.2.2}Latent Space Traversals}{737}{subsection.20.2.2}%
\contentsline {paragraph}{Editing with VAEs via Latent Traversals}{738}{section*.1472}%
\contentsline {paragraph}{Takeaway}{740}{section*.1476}%
\contentsline {section}{\numberline {20.3}Summary \& Examples: Variational Autoencoders}{740}{section.20.3}%
\contentsline {paragraph}{Pros:}{740}{section*.1477}%
\contentsline {paragraph}{Cons:}{740}{section*.1478}%
\contentsline {paragraph}{Active Research Directions:}{740}{section*.1479}%
\contentsline {subsection}{\numberline {20.3.1}VQ-VAE-2: Combining VAEs with Autoregressive Models}{741}{subsection.20.3.1}%
\contentsline {paragraph}{Motivation}{741}{section*.1481}%
\contentsline {paragraph}{Architecture Overview}{741}{section*.1482}%
\contentsline {paragraph}{How does autoregressive sampling begin?}{742}{section*.1483}%
\contentsline {paragraph}{How does this enable generation?}{743}{section*.1484}%
\contentsline {paragraph}{Summary Table: Dimensional Flow and Index Usage}{743}{section*.1485}%
\contentsline {paragraph}{Next: Training and Inference Flow}{743}{section*.1487}%
\contentsline {subsubsection}{Training the VQ-VAE-2 Autoencoder}{744}{section*.1489}%
\contentsline {paragraph}{Objective Overview}{744}{section*.1490}%
\contentsline {paragraph}{1. Reconstruction Loss (\( \mathcal {L}_{\text {recon}} \))}{744}{section*.1491}%
\contentsline {paragraph}{2. Codebook Update (\( \mathcal {L}_{\text {codebook}} \))}{744}{section*.1492}%
\contentsline {subparagraph}{(a) Gradient-Based Codebook Loss (as in the original paper)}{745}{subparagraph*.1493}%
\contentsline {subparagraph}{(b) EMA-Based Codebook Update (Used in Practice)}{745}{subparagraph*.1494}%
\contentsline {subparagraph}{Summary of Update Strategies}{745}{subparagraph*.1495}%
\contentsline {paragraph}{3. Commitment Loss (\( \mathcal {L}_{\text {commit}} \))}{746}{section*.1496}%
\contentsline {paragraph}{Why Two Losses with Stop-Gradients Are Needed}{746}{section*.1497}%
\contentsline {paragraph}{Compact Notation for Vector Quantization Loss}{746}{section*.1498}%
\contentsline {paragraph}{Training Summary}{746}{section*.1499}%
\contentsline {paragraph}{Training Summary with EMA Codebook Updates}{747}{section*.1500}%
\contentsline {subsubsection}{Training the Autoregressive Priors}{747}{section*.1501}%
\contentsline {paragraph}{Motivation}{747}{section*.1502}%
\contentsline {paragraph}{Hierarchical Modeling}{747}{section*.1503}%
\contentsline {paragraph}{Overall Training Details}{748}{section*.1504}%
\contentsline {paragraph}{Sampling Procedure}{748}{section*.1505}%
\contentsline {paragraph}{Initialization Note}{748}{section*.1506}%
\contentsline {paragraph}{Advantages of VQ-VAE-2 with Autoregressive Priors}{748}{section*.1507}%
\contentsline {paragraph}{Results \& Summary}{749}{section*.1508}%
\contentsline {section}{\numberline {20.4}Generative Adversarial Networks (GANs)}{750}{section.20.4}%
\contentsline {paragraph}{Bridging from Autoregressive Models, VAEs to GANs}{750}{section*.1511}%
\contentsline {paragraph}{Enter GANs}{750}{section*.1512}%
\contentsline {subsection}{\numberline {20.4.1}Setup: Implicit Generation via Adversarial Learning}{750}{subsection.20.4.1}%
\contentsline {paragraph}{Sampling from the True Distribution}{750}{section*.1513}%
\contentsline {paragraph}{Discriminator as a Learned Judge}{751}{section*.1514}%
\contentsline {paragraph}{Adversarial Training Dynamics}{751}{section*.1515}%
\contentsline {paragraph}{Core Intuition}{752}{section*.1517}%
\contentsline {subsection}{\numberline {20.4.2}GAN Training Objective}{752}{subsection.20.4.2}%
\contentsline {paragraph}{Difficulties in Optimization}{753}{section*.1519}%
\contentsline {paragraph}{Modified Generator Loss (Non-Saturating Trick)}{753}{section*.1521}%
\contentsline {paragraph}{Solution: Switch the Objective}{754}{section*.1522}%
\contentsline {paragraph}{Looking Ahead: Why This Objective?}{754}{section*.1524}%
\contentsline {subsection}{\numberline {20.4.3}Why the GAN Training Objective Is Optimal}{755}{subsection.20.4.3}%
\contentsline {paragraph}{Step-by-Step Derivation}{755}{section*.1525}%
\contentsline {paragraph}{Justification of the Mathematical Transformations}{755}{section*.1526}%
\contentsline {paragraph}{Solving the Inner Maximization (Discriminator)}{755}{section*.1527}%
\contentsline {paragraph}{Plugging the Optimal Discriminator into the Objective}{756}{section*.1528}%
\contentsline {paragraph}{Rewriting as KL Divergences}{756}{section*.1529}%
\contentsline {paragraph}{Introducing the Jensenâ€“Shannon Divergence (JSD)}{757}{section*.1530}%
\contentsline {paragraph}{Final Result: Objective Minimizes JSD}{757}{section*.1531}%
\contentsline {paragraph}{Summary}{757}{section*.1532}%
\contentsline {paragraph}{Important Caveats and Limitations of the Theoretical Result}{757}{section*.1533}%
\contentsline {section}{\numberline {20.5}GANs in Practice: From Early Milestones to Modern Advances}{758}{section.20.5}%
\contentsline {subsection}{\numberline {20.5.1}The Original GAN (2014)}{758}{subsection.20.5.1}%
\contentsline {subsection}{\numberline {20.5.2}Deep Convolutional GAN (DCGAN)}{758}{subsection.20.5.2}%
\contentsline {paragraph}{Architectural Innovations and Design Principles}{758}{section*.1535}%
\contentsline {paragraph}{Why it Works}{760}{section*.1537}%
\contentsline {paragraph}{Latent Space Interpolation}{760}{section*.1539}%
\contentsline {subsubsection}{Latent Vector Arithmetic}{761}{section*.1541}%
\contentsline {subsection}{\numberline {20.5.3}Evaluating Generative Adversarial Networks (GANs)}{762}{subsection.20.5.3}%
\contentsline {paragraph}{The Core Challenge}{762}{section*.1544}%
\contentsline {paragraph}{Manual Inspection and Preference Ranking}{762}{section*.1546}%
\contentsline {paragraph}{Nearest Neighbor Retrieval}{762}{section*.1547}%
\contentsline {paragraph}{Inception Score (IS)}{762}{section*.1549}%
\contentsline {paragraph}{Fr\'echet Inception Distance (FID)}{763}{section*.1550}%
\contentsline {paragraph}{What Does the Formula Measure?}{763}{section*.1551}%
\contentsline {paragraph}{Theoretical Background: 2-Wasserstein Distance}{763}{section*.1552}%
\contentsline {paragraph}{How to Interpret FID Scores}{763}{section*.1553}%
\contentsline {paragraph}{Why FID Is Preferred}{764}{section*.1554}%
\contentsline {paragraph}{FID Limitations}{764}{section*.1555}%
\contentsline {paragraph}{FID Summary}{764}{section*.1556}%
\contentsline {paragraph}{Other Quantitative Metrics}{764}{section*.1557}%
\contentsline {paragraph}{Summary}{764}{section*.1559}%
\contentsline {subsection}{\numberline {20.5.4}GAN Explosion}{765}{subsection.20.5.4}%
\contentsline {paragraph}{Next Steps: Improving GANs}{765}{section*.1561}%
\contentsline {subsection}{\numberline {20.5.5}Wasserstein GAN (WGAN): Earth Moverâ€™s Distance}{765}{subsection.20.5.5}%
\contentsline {paragraph}{Supports and Low-Dimensional Manifolds}{766}{section*.1562}%
\contentsline {paragraph}{Why the JS Divergence Fails in High Dimensions}{766}{section*.1563}%
\contentsline {paragraph}{Why Non-Saturating GANs Still Suffer}{766}{section*.1564}%
\contentsline {paragraph}{The Need for a Better Distance Metric}{767}{section*.1565}%
\contentsline {paragraph}{Wasserstein-1 Distance: Transporting Mass}{767}{section*.1566}%
\contentsline {paragraph}{Example: Optimal Transport Plans as Joint Tables}{767}{section*.1567}%
\contentsline {paragraph}{Why This Matters}{768}{section*.1568}%
\contentsline {paragraph}{From Intractable Transport to Practical Training}{769}{section*.1570}%
\contentsline {paragraph}{What These Expectations Mean in Practice}{769}{section*.1571}%
\contentsline {paragraph}{How the Training Works}{769}{section*.1572}%
\contentsline {paragraph}{Why This Makes Sense â€” Even if Samples Differ Sharply}{769}{section*.1573}%
\contentsline {paragraph}{Summary}{770}{section*.1574}%
\contentsline {paragraph}{Side-by-Side: Standard GAN vs.\ WGAN}{770}{section*.1575}%
\contentsline {paragraph}{Whatâ€™s Missing: Enforcing the 1-Lipschitz Constraint}{770}{section*.1577}%
\contentsline {paragraph}{Weight Clipping: A Crude Approximation}{771}{section*.1578}%
\contentsline {paragraph}{Benefits of WGAN}{771}{section*.1579}%
\contentsline {paragraph}{Limitations of Weight Clipping in Practice}{772}{section*.1582}%
\contentsline {subsection}{\numberline {20.5.6}WGAN-GP: Gradient Penalty for Stable Lipschitz Enforcement}{774}{subsection.20.5.6}%
\contentsline {paragraph}{Theoretical Motivation: Lipschitz Continuity and Gradient Norms}{774}{section*.1583}%
\contentsline {paragraph}{The WGAN-GP Loss Function}{774}{section*.1584}%
\contentsline {subparagraph}{Why Interpolated Points? Intuition and Implementation in WGAN-GP}{774}{subparagraph*.1585}%
\contentsline {subparagraph}{Conceptual Motivation: \emph {Where} Should Lipschitz Matter?}{774}{subparagraph*.1586}%
\contentsline {subparagraph}{Why This Avoids Over-Regularization}{775}{subparagraph*.1587}%
\contentsline {subparagraph}{Code Walkthrough: Penalty Computation for a Single Critic Update}{775}{subparagraph*.1588}%
\contentsline {subparagraph}{Resulting Dynamics \& Why It Helps}{776}{subparagraph*.1589}%
\contentsline {subparagraph}{Interpreting the Loss Components}{776}{subparagraph*.1590}%
\contentsline {subparagraph}{Key Benefits of the Gradient Penalty vs.\ Weight Clipping}{776}{subparagraph*.1591}%
\contentsline {paragraph}{Architectural Robustness}{777}{section*.1593}%
\contentsline {paragraph}{State-of-the-Art Results on CIFAR-10}{778}{section*.1595}%
\contentsline {paragraph}{Conclusion}{778}{section*.1596}%
\contentsline {section}{Enrichment 20.6: The StyleGAN Family}{779}{section*.1597}%
\contentsline {subsection}{Enrichment 20.6.1: ProGAN Overview: A Stability-Oriented Design}{779}{section*.1598}%
\contentsline {paragraph}{Training Strategy}{779}{section*.1599}%
\contentsline {paragraph}{Why This Works}{780}{section*.1600}%
\contentsline {subsubsection}{Enrichment 20.6.1.1: Limitations of ProGAN: Toward Style-Based Generators}{782}{section*.1602}%
\contentsline {subsection}{Enrichment 20.6.2: StyleGAN: Style-Based Synthesis via Latent Modulation}{782}{section*.1603}%
\contentsline {paragraph}{(1) Mapping Network (\(\mathcal {Z} \to \mathcal {W}\)):}{783}{section*.1606}%
\contentsline {paragraph}{Why Not Just Increase the Dimensionality of \( z \)?}{783}{section*.1607}%
\contentsline {paragraph}{(2) Modulating Each Layer via AdaIN (Block A):}{784}{section*.1608}%
\contentsline {paragraph}{(3) Fixed Learned Input (Constant Tensor):}{785}{section*.1609}%
\contentsline {paragraph}{(4) Stochastic Detail Injection (Block B):}{785}{section*.1610}%
\contentsline {paragraph}{(5) Style Mixing Regularization: Breaking Co-Adaptation Across Layers}{786}{section*.1611}%
\contentsline {paragraph}{(6) Perceptual Path Length (PPL): Quantifying Disentanglement in Latent Space}{786}{section*.1612}%
\contentsline {paragraph}{What Is LPIPS?}{787}{section*.1613}%
\contentsline {paragraph}{Why PPL Matters â€” and How It Relates to Training}{787}{section*.1614}%
\contentsline {paragraph}{(7) Loss Functions: From WGAN-GP to Non-Saturating GAN + R\textsubscript {1}}{787}{section*.1615}%
\contentsline {paragraph}{Summary and Additional Contributions}{788}{section*.1616}%
\contentsline {subsection}{Enrichment 20.6.3: StyleGAN2: Eliminating Artifacts, Improving Training Stability}{789}{section*.1619}%
\contentsline {subsubsection}{Enrichment 20.6.3.1: Background: From StyleGAN1 to StyleGAN2}{789}{section*.1620}%
\contentsline {subsubsection}{Enrichment 20.6.3.2: Weight Demodulation: A Principled Replacement for AdaIN}{790}{section*.1622}%
\contentsline {subsubsection}{Enrichment 20.6.3.3: Noise Injection Relocation: Separating Style and Stochasticity}{791}{section*.1624}%
\contentsline {subsubsection}{Enrichment 20.6.3.4: Path Length Regularization: Smoother Latent Traversals}{792}{section*.1625}%
\contentsline {subsubsection}{Enrichment 20.6.3.5: Lazy R\textsubscript {1} Regularization and Evolved Loss Strategy}{793}{section*.1626}%
\contentsline {paragraph}{Discriminator Loss:}{793}{section*.1627}%
\contentsline {paragraph}{Generator Loss:}{793}{section*.1628}%
\contentsline {paragraph}{Joint Optimization Logic:}{793}{section*.1629}%
\contentsline {subsubsection}{Enrichment 20.6.3.6: No Progressive Growing}{794}{section*.1630}%
\contentsline {paragraph}{1. Multi-Scale Skip Connections in the Generator}{794}{section*.1632}%
\contentsline {paragraph}{2. Residual Blocks in the Discriminator}{794}{section*.1633}%
\contentsline {paragraph}{3. Tracking Per-Resolution Contributions}{795}{section*.1634}%
\contentsline {subsubsection}{Enrichment 20.6.3.7: StyleGAN3: Eliminating Texture Sticking}{796}{section*.1636}%
\contentsline {paragraph}{Why Does Texture Sticking Occur?}{796}{section*.1638}%
\contentsline {paragraph}{How StyleGAN3 Fixes It: Core Innovations}{796}{section*.1639}%
\contentsline {paragraph}{Training Changes and Equivariance Goals}{797}{section*.1640}%
\contentsline {paragraph}{Latent and Spatial Disentanglement}{797}{section*.1641}%
\contentsline {paragraph}{Impact in Practice}{798}{section*.1642}%
\contentsline {paragraph}{Takeaway}{798}{section*.1643}%
\contentsline {section}{Enrichment 20.7: Conditional GANs: Label-Aware Image Synthesis}{799}{section*.1644}%
\contentsline {subsection}{Enrichment 20.7.1: Conditional Batch Normalization (CBN)}{799}{section*.1646}%
\contentsline {paragraph}{Motivation}{799}{section*.1647}%
\contentsline {paragraph}{How CBN Works}{800}{section*.1648}%
\contentsline {paragraph}{CBN in the Generator}{800}{section*.1650}%
\contentsline {subsubsection}{Enrichment 20.7.1.1: Projection-Based Conditioning in Discriminators}{801}{section*.1651}%
\contentsline {paragraph}{Advantages of Projection-Based Conditioning:}{801}{section*.1652}%
\contentsline {subsubsection}{Enrichment 20.7.1.2: Training Conditional GANs with CBN}{801}{section*.1653}%
\contentsline {paragraph}{Generator \( G(z, y) \): Label-Aware Synthesis}{801}{section*.1654}%
\contentsline {paragraph}{Discriminator \( D(x, y) \): Realness and Label Consistency}{802}{section*.1655}%
\contentsline {paragraph}{Training Pipeline with CBN Conditioning:}{802}{section*.1656}%
\contentsline {paragraph}{Log-Loss Intuition:}{803}{section*.1657}%
\contentsline {paragraph}{Limitations of CBN-Only Conditioning}{803}{section*.1658}%
\contentsline {subsection}{Enrichment 20.7.2: Spectral Normalization for Stable GAN Training}{804}{section*.1659}%
\contentsline {subsubsection}{Enrichment 20.7.2.1: Spectral Normalization - Mathematical Background}{804}{section*.1660}%
\contentsline {paragraph}{Eigenvalues and Eigenvectors: Invariant Directions in Linear Maps}{804}{section*.1661}%
\contentsline {paragraph}{Singular Value Decomposition (SVD): Structure and Signal in Data}{806}{section*.1662}%
\contentsline {paragraph}{SVD: Structure, Meaning, and Application to Real-World Data}{807}{section*.1663}%
\contentsline {paragraph}{Spectral Structure via \( X^\top X \) and \( XX^\top \)}{809}{section*.1664}%
\contentsline {paragraph}{Economy (or Truncated) SVD}{809}{section*.1665}%
\contentsline {paragraph}{How is SVD Computed in Practice?}{810}{section*.1666}%
\contentsline {paragraph}{Spectral Norm of a Weight Matrix}{812}{section*.1667}%
\contentsline {paragraph}{Fast Spectralâ€“Norm Estimation via Power Iteration}{812}{section*.1668}%
\contentsline {paragraph}{Alternative Loss: Hinge Loss Formulation}{814}{section*.1670}%
\contentsline {paragraph}{Interpretation and Benefits}{815}{section*.1671}%
\contentsline {subsection}{Enrichment 20.7.3: Self-Attention GANs (SAGAN)}{816}{section*.1672}%
\contentsline {paragraph}{Architecture Overview}{816}{section*.1674}%
\contentsline {paragraph}{Why It Helps}{816}{section*.1675}%
\contentsline {paragraph}{Training Details and Stabilization}{817}{section*.1676}%
\contentsline {paragraph}{Loss Function}{817}{section*.1677}%
\contentsline {paragraph}{Quantitative Results}{817}{section*.1678}%
\contentsline {paragraph}{Summary}{817}{section*.1679}%
\contentsline {subsection}{Enrichment 20.7.4: BigGANs: Scaling Up GANs}{817}{section*.1680}%
\contentsline {paragraph}{Key Innovations and Techniques}{817}{section*.1681}%
\contentsline {subsubsection}{Enrichment 20.7.4.1: Skip-\( z \) Connections: Hierarchical Latent Injection}{819}{section*.1683}%
\contentsline {paragraph}{Mechanism:}{819}{section*.1684}%
\contentsline {paragraph}{Comparison to Standard CBN:}{820}{section*.1685}%
\contentsline {paragraph}{BigGAN-deep Simplification:}{820}{section*.1686}%
\contentsline {subsubsection}{Enrichment 20.7.4.2: Residual Architecture: Deep and Stable Generators}{820}{section*.1687}%
\contentsline {paragraph}{Motivation and Design:}{820}{section*.1688}%
\contentsline {paragraph}{BigGAN vs. BigGAN-deep:}{820}{section*.1689}%
\contentsline {subsubsection}{Enrichment 20.7.4.3: Truncation Trick in BigGAN: Quality vs. Diversity}{823}{section*.1692}%
\contentsline {paragraph}{Truncated Normal Distributions in Latent Space}{823}{section*.1693}%
\contentsline {paragraph}{Why Truncate?}{823}{section*.1694}%
\contentsline {paragraph}{How Is \( \tau \) Chosen?}{823}{section*.1695}%
\contentsline {paragraph}{Implementation in Practice}{823}{section*.1696}%
\contentsline {paragraph}{Tradeoffs and Limitations}{824}{section*.1697}%
\contentsline {paragraph}{When Truncation Fails}{824}{section*.1698}%
\contentsline {paragraph}{How to Make Truncation Work Reliably}{824}{section*.1699}%
\contentsline {subsubsection}{Enrichment 20.7.4.4: Orthogonal Regularization: A Smoothness Prior for Truncated Latents}{824}{section*.1700}%
\contentsline {subsubsection}{Enrichment 20.7.4.5: Exponential Moving Average (EMA) of Generator Weights}{825}{section*.1701}%
\contentsline {subsubsection}{Enrichment 20.7.4.6: Discriminator-to-Generator Update Ratio}{826}{section*.1702}%
\contentsline {paragraph}{Results and Legacy}{827}{section*.1703}%
\contentsline {subsection}{Enrichment 20.7.5: StackGAN: Two-Stage Text-to-Image Synthesis}{828}{section*.1704}%
\contentsline {paragraph}{From Overview to Components:}{830}{section*.1707}%
\contentsline {subsubsection}{Enrichment 20.7.5.1: Conditioning Augmentation (CA)}{831}{section*.1708}%
\contentsline {paragraph}{Solution: Learn a Distribution Over Conditioning Vectors}{831}{section*.1709}%
\contentsline {paragraph}{Sampling via Reparameterization Trick}{831}{section*.1710}%
\contentsline {paragraph}{KL Divergence Regularization}{831}{section*.1711}%
\contentsline {paragraph}{Benefits of Conditioning Augmentation}{831}{section*.1712}%
\contentsline {paragraph}{Summary Table: Conditioning Augmentation}{832}{section*.1713}%
\contentsline {subsubsection}{Enrichment 20.7.5.2: Stage-I Generator: Coarse Sketching from Noise and Caption}{832}{section*.1714}%
\contentsline {paragraph}{Motivation: Why Two Stages?}{832}{section*.1715}%
\contentsline {paragraph}{Architecture of Stage-I Generator}{832}{section*.1716}%
\contentsline {paragraph}{Output Normalization: Why Tanh?}{833}{section*.1717}%
\contentsline {paragraph}{From Latent Tensor to Displayable Image}{833}{section*.1718}%
\contentsline {paragraph}{How Channel Reduction Works in Upsampling Blocks}{833}{section*.1719}%
\contentsline {paragraph}{Summary of Stage-I Generator}{833}{section*.1720}%
\contentsline {subsubsection}{Enrichment 20.7.5.3: Stage-II Generator: Refinement with Residual Conditioning}{834}{section*.1721}%
\contentsline {paragraph}{Why Two Stages Are Beneficial}{834}{section*.1722}%
\contentsline {paragraph}{Inputs to Stage-II Generator}{834}{section*.1723}%
\contentsline {paragraph}{Network Structure and Residual Design}{834}{section*.1724}%
\contentsline {paragraph}{Semantic Reinforcement via Dual Conditioning}{834}{section*.1725}%
\contentsline {paragraph}{Discriminator in Stage-II}{835}{section*.1726}%
\contentsline {paragraph}{Overall Effect of Stage-II}{835}{section*.1727}%
\contentsline {paragraph}{Summary of Stage-II Generator}{835}{section*.1728}%
\contentsline {subsubsection}{Enrichment 20.7.5.4: Training Procedure and Multi-Stage Objectives}{835}{section*.1729}%
\contentsline {subsubsection}{Enrichment 20.7.5.5: Legacy and Extensions: StackGAN++ and Beyond}{836}{section*.1730}%
\contentsline {subsection}{Enrichment 20.7.6: VQ-GAN: Taming Transformers for High-Res Image Synthesis}{837}{section*.1731}%
\contentsline {subsubsection}{Enrichment 20.7.6.1: VQ-GAN: Overview and Motivation}{837}{section*.1732}%
\contentsline {subsubsection}{Enrichment 20.7.6.2: Training Objectives and Losses in VQ-GAN}{838}{section*.1734}%
\contentsline {paragraph}{Total Loss}{839}{section*.1735}%
\contentsline {paragraph}{1. Perceptual Reconstruction Loss \( \mathcal {L}_{\text {rec}} \)}{839}{section*.1736}%
\contentsline {paragraph}{2. Adversarial Patch Loss \( \mathcal {L}_{\text {GAN}} \)}{839}{section*.1737}%
\contentsline {paragraph}{3. Vector Quantization Commitment and Codebook Loss \( \mathcal {L}_{\text {VQ}} \)}{839}{section*.1738}%
\contentsline {paragraph}{Combined Optimization Strategy}{839}{section*.1739}%
\contentsline {paragraph}{Why This Loss Works}{839}{section*.1740}%
\contentsline {paragraph}{Training Summary}{840}{section*.1741}%
\contentsline {subsubsection}{Enrichment 20.7.6.3: Discrete Codebooks and Token Quantization}{840}{section*.1742}%
\contentsline {paragraph}{Latent Grid and Codebook Structure}{840}{section*.1743}%
\contentsline {paragraph}{Nearest-Neighbor Quantization}{840}{section*.1744}%
\contentsline {paragraph}{Gradient Flow via Stop-Gradient and Codebook Updates}{840}{section*.1745}%
\contentsline {paragraph}{Codebook Capacity and Token Usage}{841}{section*.1746}%
\contentsline {paragraph}{Spatial Token Grid as Transformer Input}{841}{section*.1747}%
\contentsline {paragraph}{Comparison to VQ-VAE-2}{841}{section*.1748}%
\contentsline {paragraph}{Summary}{841}{section*.1749}%
\contentsline {subsubsection}{Enrichment 20.7.6.4: Autoregressive Transformer for Token Modeling}{841}{section*.1750}%
\contentsline {paragraph}{Token Sequence Construction}{841}{section*.1751}%
\contentsline {paragraph}{Autoregressive Training Objective}{841}{section*.1752}%
\contentsline {paragraph}{Positional Encoding and Embedding Table}{842}{section*.1753}%
\contentsline {paragraph}{Sampling for Image Generation}{842}{section*.1754}%
\contentsline {paragraph}{Windowed Attention for Long Sequences}{842}{section*.1755}%
\contentsline {paragraph}{Comparison with Pixel-Level Modeling}{842}{section*.1756}%
\contentsline {subsubsection}{Transformer Variants: Decoder-Only and Encoderâ€“Decoder}{842}{section*.1757}%
\contentsline {paragraph}{Training Setup}{843}{section*.1758}%
\contentsline {paragraph}{Summary}{843}{section*.1759}%
\contentsline {subsubsection}{Enrichment 20.7.6.5: Token Sampling and Grid Resolution}{843}{section*.1760}%
\contentsline {paragraph}{Autoregressive Sampling Pipeline}{844}{section*.1761}%
\contentsline {paragraph}{Impact of Latent Grid Resolution}{844}{section*.1762}%
\contentsline {paragraph}{Sliding Window Attention (Optional Variant)}{844}{section*.1763}%
\contentsline {paragraph}{Summary}{844}{section*.1764}%
\contentsline {subsubsection}{Enrichment 20.7.6.6: VQ-GAN: Summary and Outlook}{845}{section*.1765}%
\contentsline {paragraph}{Why VQ-GAN Works}{845}{section*.1766}%
\contentsline {paragraph}{Future Directions and Influence}{845}{section*.1767}%
\contentsline {section}{Enrichment 20.8: Additional Important GAN Works}{846}{section*.1768}%
\contentsline {subsection}{Enrichment 20.8.1: SRGAN: Photo-Realistic Super-Resolution}{846}{section*.1769}%
\contentsline {paragraph}{Motivation and Limitations of Pixel-Wise Supervision}{846}{section*.1770}%
\contentsline {paragraph}{Why Use VGG-Based Perceptual Loss?}{846}{section*.1771}%
\contentsline {paragraph}{Architecture Overview}{847}{section*.1772}%
\contentsline {paragraph}{Upsampling Strategy: Sub-Pixel Convolution Blocks}{847}{section*.1773}%
\contentsline {paragraph}{Discriminator Design}{848}{section*.1774}%
\contentsline {paragraph}{Perceptual Loss Function}{849}{section*.1777}%
\contentsline {paragraph}{Training Strategy}{849}{section*.1778}%
\contentsline {paragraph}{Quantitative and Perceptual Results}{849}{section*.1779}%
\contentsline {subsection}{Enrichment 20.8.2: pix2pix: Paired Image-to-Image Translation with cGANs}{850}{section*.1780}%
\contentsline {paragraph}{Motivation and Formulation}{850}{section*.1781}%
\contentsline {subsubsection}{Enrichment 20.8.2.1: Generator Architecture and L1 Loss}{851}{section*.1783}%
\contentsline {paragraph}{Generator Architecture: U-Net with Skip Connections}{851}{section*.1784}%
\contentsline {paragraph}{The Role of L1 Loss}{851}{section*.1785}%
\contentsline {paragraph}{Why Not WGAN or WGAN-GP?}{851}{section*.1786}%
\contentsline {subsubsection}{Enrichment 20.8.2.2: Discriminator Design and PatchGAN}{852}{section*.1787}%
\contentsline {paragraph}{Discriminator Design and Patch-Level Realism (PatchGAN)}{852}{section*.1788}%
\contentsline {subsubsection}{Enrichment 20.8.2.3: Full Training Objective and Optimization}{853}{section*.1789}%
\contentsline {paragraph}{Generator Loss: Combining Adversarial and Reconstruction Objectives}{853}{section*.1790}%
\contentsline {subsubsection}{Enrichment 20.8.2.4: Summary and Generalization Across Tasks}{854}{section*.1791}%
\contentsline {subsection}{Enrichment 20.8.3: CycleGAN: Unpaired Image-to-Image Translation}{854}{section*.1792}%
\contentsline {subsubsection}{Enrichment 20.8.3.1: Motivation: Beyond Paired Supervision in Image Translation}{854}{section*.1793}%
\contentsline {subsubsection}{Enrichment 20.8.3.2: Typical Use Cases}{855}{section*.1795}%
\contentsline {subsubsection}{Enrichment 20.8.3.3: CycleGAN Architecture: Dual Generators and Discriminators}{856}{section*.1797}%
\contentsline {subsubsection}{Enrichment 20.8.3.4: CycleGAN: Loss Functions and Training Objectives}{856}{section*.1798}%
\contentsline {subsubsection}{Enrichment 20.8.3.5: Network Architecture and Practical Training Considerations}{859}{section*.1800}%
\contentsline {subsubsection}{Enrichment 20.8.3.6: Ablation Study: Impact of Loss Components in CycleGAN}{860}{section*.1801}%
\contentsline {paragraph}{Effect of Removing Loss Components}{860}{section*.1802}%
\contentsline {paragraph}{Quantitative Results (from the CycleGAN Paper)}{860}{section*.1803}%
\contentsline {paragraph}{Qualitative Analysis}{861}{section*.1806}%
\contentsline {paragraph}{Summary}{861}{section*.1808}%
\contentsline {subsubsection}{Enrichment 20.8.3.7: Summary and Transition to Additional Generative Approaches}{861}{section*.1809}%
\contentsline {section}{Enrichment 20.9: Diffusion Models: Modern Generative Modeling}{862}{section*.1810}%
\contentsline {subsubsection}{Enrichment 20.9.0.1: Motivation: Limitations of Previous Generative Models}{862}{section*.1811}%
\contentsline {paragraph}{Autoregressive Models (PixelCNN, PixelRNN, ...)}{862}{section*.1812}%
\contentsline {paragraph}{Variational Autoencoders (VAEs)}{862}{section*.1813}%
\contentsline {paragraph}{Generative Adversarial Networks (GANs)}{862}{section*.1814}%
\contentsline {paragraph}{Hybrid Approaches (VQ-VAE, VQ-GAN)}{862}{section*.1815}%
\contentsline {paragraph}{The Case for Diffusion Models}{862}{section*.1816}%
\contentsline {subsection}{Enrichment 20.9.1: Introduction to Diffusion Models}{863}{section*.1817}%
\contentsline {paragraph}{Mathematical Foundation and Dual Processes}{863}{section*.1818}%
\contentsline {paragraph}{Noise Schedules: How Fast Should the Data Be Destroyed?}{863}{section*.1819}%
\contentsline {paragraph}{Why Is the Process Markovian?}{864}{section*.1820}%
\contentsline {paragraph}{Coupled Roles of Signal Attenuation and Noise Injection}{864}{section*.1821}%
\contentsline {paragraph}{Why Diagonal Covariance?}{865}{section*.1822}%
\contentsline {paragraph}{Closed-Form Marginals of the Forward Process}{865}{section*.1823}%
\contentsline {paragraph}{Why Many Small Steps?}{866}{section*.1824}%
\contentsline {paragraph}{Preparing for the Reverse Process}{867}{section*.1826}%
\contentsline {paragraph}{A Tractable Alternative: Conditioning on \( \mathbf {x}_0 \)}{868}{section*.1827}%
\contentsline {paragraph}{Visual Intuition}{868}{section*.1828}%
\contentsline {paragraph}{Step 1: Define the joint distribution}{868}{section*.1830}%
\contentsline {paragraph}{Step 2: Apply Gaussian conditioning}{869}{section*.1831}%
\contentsline {paragraph}{Step 3: Simplifying the Posterior Mean and Variance}{869}{section*.1832}%
\contentsline {paragraph}{Interpretation:}{870}{section*.1833}%
\contentsline {paragraph}{Final Result}{870}{section*.1834}%
\contentsline {paragraph}{Why This Posterior Is Useful for Training}{870}{section*.1835}%
\contentsline {paragraph}{Why \( q(\mathbf {x}_{t-1} \mid \mathbf {x}_t, \mathbf {x}_0) \) Is Not Used at Inference}{871}{section*.1836}%
\contentsline {paragraph}{Intuition for the Denoising Process}{871}{section*.1837}%
\contentsline {paragraph}{Building a Principled Loss Function}{871}{section*.1838}%
\contentsline {subsection}{Enrichment 20.9.2: Denoising Diffusion Probabilistic Models (DDPM)}{873}{section*.1839}%
\contentsline {subsubsection}{Enrichment 20.9.2.1: Summary of Core Variables in Diffusion Models}{873}{section*.1840}%
\contentsline {paragraph}{Forward Noise Schedule and Signal Retention}{873}{section*.1841}%
\contentsline {paragraph}{Reverse Posterior and Posterior Parameters}{874}{section*.1842}%
\contentsline {paragraph}{Learned Reverse Mean and Sampling Parameterization}{876}{section*.1843}%
\contentsline {subsubsection}{Enrichment 20.9.2.2: ELBO Formulation and Loss Decomposition}{877}{section*.1844}%
\contentsline {paragraph}{Maximum Likelihood in Latent-Variable Generative Models}{877}{section*.1845}%
\contentsline {paragraph}{Introducing a Tractable Proposal Distribution}{877}{section*.1847}%
\contentsline {paragraph}{Why the Importance Ratio Is Well-Defined}{878}{section*.1849}%
\contentsline {paragraph}{From Integral to Expectation: Importance Sampling Identity}{878}{section*.1850}%
\contentsline {paragraph}{Applying Jensenâ€™s Inequality: A Lower Bound for Optimization}{879}{section*.1851}%
\contentsline {paragraph}{Factorization of the Model and Variational Distributions}{879}{section*.1853}%
\contentsline {paragraph}{Inserting a Tractable Posterior into the ELBO}{879}{section*.1854}%
\contentsline {paragraph}{Decomposing the Log-Ratio}{880}{section*.1855}%
\contentsline {paragraph}{ELBO in KL-Compatible Form}{881}{section*.1856}%
\contentsline {paragraph}{Rewriting as KL Expectations}{881}{section*.1857}%
\contentsline {paragraph}{Final KL-Based ELBO for Diffusion Models}{882}{section*.1858}%
\contentsline {paragraph}{Interpreting the ELBO Components}{882}{section*.1859}%
\contentsline {paragraph}{Why the KL Divergence Is Tractable and Useful for Training}{883}{section*.1860}%
\contentsline {subsubsection}{Enrichment 20.9.2.3: Noise Prediction Objective and Simplification}{884}{section*.1862}%
\contentsline {paragraph}{From ELBO to Mean Prediction}{884}{section*.1863}%
\contentsline {paragraph}{Fixing the Variance}{884}{section*.1864}%
\contentsline {paragraph}{Rewriting the Mean via Noise Prediction}{884}{section*.1865}%
\contentsline {subsubsection}{Enrichment 20.9.2.4: Training and Inference in DDPMs}{887}{section*.1866}%
\contentsline {paragraph}{Connection to the Model Distribution \boldmath \( p_\theta (x_{t-1} \mid x_t) \).}{888}{section*.1867}%
\contentsline {paragraph}{Interpreting the Update.}{888}{section*.1868}%
\contentsline {paragraph}{Stochasticity and Sample Diversity.}{888}{section*.1869}%
\contentsline {paragraph}{Final Step Refinement.}{888}{section*.1870}%
\contentsline {subsubsection}{Enrichment 20.9.2.5: Architecture, Datasets, and Implementation Details}{889}{section*.1871}%
\contentsline {paragraph}{Backbone Architecture: Why U-Net Fits Denoising in Diffusion Models}{889}{section*.1872}%
\contentsline {subparagraph}{Why an Encoderâ€“Decoder?}{889}{subparagraph*.1873}%
\contentsline {subparagraph}{Multiscale Hierarchy and Architectural Intuition}{889}{subparagraph*.1874}%
\contentsline {subparagraph}{Walkthrough: Layer-by-Layer Data Flow}{890}{subparagraph*.1875}%
\contentsline {subparagraph}{Why U-Net Matches the Diffusion Objective}{890}{subparagraph*.1876}%
\contentsline {paragraph}{Resolution and Depth Scaling}{891}{section*.1877}%
\contentsline {paragraph}{Time Embedding via Sinusoidal Positional Encoding}{891}{section*.1878}%
\contentsline {paragraph}{How the Time Embedding is Used}{891}{section*.1879}%
\contentsline {paragraph}{Why Not Simpler Alternatives?}{891}{section*.1880}%
\contentsline {paragraph}{Model Scale and Dataset Diversity}{893}{section*.1881}%
\contentsline {paragraph}{Summary}{893}{section*.1882}%
\contentsline {subsubsection}{Enrichment 20.9.2.6: Empirical Evaluation and Latent-Space Behavior}{894}{section*.1883}%
\contentsline {paragraph}{Noise Prediction Yields Stable Training and Best Sample Quality}{894}{section*.1884}%
\contentsline {paragraph}{Image Interpolation in Latent Space}{894}{section*.1885}%
\contentsline {paragraph}{Coarse-to-Fine Interpolation and Structural Completion}{895}{section*.1887}%
\contentsline {paragraph}{Progressive Lossy Compression via Reverse Denoising}{896}{section*.1889}%
\contentsline {subsection}{Enrichment 20.9.3: Denoising Diffusion Implicit Models (DDIM)}{897}{section*.1891}%
\contentsline {paragraph}{Motivation}{897}{section*.1892}%
\contentsline {paragraph}{From DDPM Sampling to DDIM Inversion}{897}{section*.1893}%
\contentsline {paragraph}{1. From Forward Diffusion to Inversion}{897}{section*.1894}%
\contentsline {paragraph}{2. Reverse Step to Arbitrary \( s < t \)}{898}{section*.1895}%
\contentsline {paragraph}{3.\ Why the â€œsingleâ€“noiseâ€ picture is still correct}{900}{section*.1898}%
\contentsline {paragraph}{4. Optional Stochastic Extension}{901}{section*.1899}%
\contentsline {paragraph}{5. Advantages of DDIM Sampling}{902}{section*.1900}%
\contentsline {subsection}{Enrichment 20.9.4: Guidance Techniques in Diffusion Models}{903}{section*.1901}%
\contentsline {paragraph}{Training Procedure}{905}{section*.1904}%
\contentsline {paragraph}{Sampling with Classifier-Free Guidance}{906}{section*.1905}%
\contentsline {paragraph}{Why Classifier-Free Guidance Works: A Score-Based and Intuitive View}{907}{section*.1906}%
\contentsline {paragraph}{Interpretation}{908}{section*.1907}%
\contentsline {paragraph}{Typical Settings}{909}{section*.1908}%
\contentsline {paragraph}{Advantages}{909}{section*.1910}%
\contentsline {paragraph}{Adoption in Large-Scale Models}{909}{section*.1911}%
\contentsline {subsection}{Enrichment 20.9.5: Cascaded Diffusion Models}{910}{section*.1912}%
\contentsline {paragraph}{Motivation and Overview}{910}{section*.1913}%
\contentsline {paragraph}{Architecture: U-Net Design for Cascaded Diffusion Models}{911}{section*.1915}%
\contentsline {paragraph}{Empirical Performance of CDMs}{913}{section*.1917}%
\contentsline {subsection}{Enrichment 20.9.6: Progressive Distillation for Fast Sampling}{914}{section*.1918}%
\contentsline {paragraph}{Motivation}{914}{section*.1919}%
\contentsline {paragraph}{Pseudocode: Progressive Distillation Loop}{915}{section*.1921}%
\contentsline {paragraph}{Prerequisites Required to Understand The Progressive Distillation Loop}{916}{section*.1922}%
\contentsline {paragraph}{What Is SNR and Why Use It?}{917}{section*.1923}%
\contentsline {paragraph}{Cosine Schedule and Angular Construction}{917}{section*.1924}%
\contentsline {paragraph}{Teacher Trajectory Construction via Two DDIM Steps}{917}{section*.1925}%
\contentsline {paragraph}{Empirical Results and Sample Quality}{921}{section*.1926}%
\contentsline {paragraph}{Conclusion}{922}{section*.1928}%
\contentsline {subsection}{Enrichment 20.9.7: Velocity-Space Sampling: Learning Denoising Trajectories}{923}{section*.1929}%
\contentsline {section}{Enrichment 20.10: Flow Matching: Beating Diffusion Using Flows}{925}{section*.1930}%
\contentsline {paragraph}{Further Reading}{927}{section*.1931}%
\contentsline {subsection}{Enrichment 20.10.1: Generative Flows: Learning by Trajectory Integration}{927}{section*.1932}%
\contentsline {paragraph}{Motivation: From Mapping to Likelihood.}{927}{section*.1933}%
\contentsline {paragraph}{From KL to Log-Likelihood}{927}{section*.1934}%
\contentsline {paragraph}{How Does \( p_1 \) Arise from a Flow?}{927}{section*.1935}%
\contentsline {paragraph}{The Role of the Continuity Equation}{929}{section*.1937}%
\contentsline {paragraph}{Flux: Constructing \( p_t(x) v_t(x) \)}{929}{section*.1938}%
\contentsline {paragraph}{Divergence: Understanding \( \nabla \cdot (p_t v_t) \)}{930}{section*.1939}%
\contentsline {paragraph}{Putting the Continuity Equation in Plain English}{930}{section*.1940}%
\contentsline {paragraph}{Broader Implications for Continuous-Time Generative Models}{931}{section*.1941}%
\contentsline {paragraph}{Interpretation}{932}{section*.1943}%
\contentsline {paragraph}{Why Pure CNFâ€“Likelihood Training Is Not Scalable?}{933}{section*.1944}%
\contentsline {paragraph}{Flow Matching: A New Approach}{934}{section*.1945}%
\contentsline {subsection}{Enrichment 20.10.2: Development of the Flow Matching Objective}{935}{section*.1946}%
\contentsline {paragraph}{From Density Path to Vector Field}{935}{section*.1947}%
\contentsline {paragraph}{The Naive Flow Matching Objective}{935}{section*.1948}%
\contentsline {paragraph}{Why the Naive Objective Is Intractable}{936}{section*.1950}%
\contentsline {paragraph}{A Local Solution via Conditional Paths}{936}{section*.1951}%
\contentsline {paragraph}{Recovering the Marginal Vector Field}{937}{section*.1952}%
\contentsline {paragraph}{Why This Identity Is Valid}{937}{section*.1953}%
\contentsline {paragraph}{From Validity to Practicality: The Need for a Tractable Objective}{939}{section*.1954}%
\contentsline {paragraph}{Conditional Flow Matching (CFM): A Sample-Based Reformulation}{939}{section*.1955}%
\contentsline {paragraph}{Why This Is Powerful}{940}{section*.1956}%
\contentsline {subsection}{Enrichment 20.10.3: Conditional Probability Paths and Vector Fields}{940}{section*.1957}%
\contentsline {paragraph}{Motivation}{940}{section*.1958}%
\contentsline {paragraph}{Canonical Gaussian Conditional Paths}{940}{section*.1959}%
\contentsline {paragraph}{Deriving the Velocity Field from the Continuity Equation}{941}{section*.1960}%
\contentsline {paragraph}{General Gaussian Conditional Paths and Affine Flow Maps}{941}{section*.1961}%
\contentsline {paragraph}{The Canonical Affine Flow and Induced Velocity Field}{941}{section*.1962}%
\contentsline {paragraph}{The Conditional Flow Matching Loss}{942}{section*.1964}%
\contentsline {paragraph}{From Theory to Practice: Training with Conditional Flow Matching}{943}{section*.1966}%
\contentsline {paragraph}{Implementation Notes}{943}{section*.1968}%
\contentsline {paragraph}{Summary}{944}{section*.1969}%
\contentsline {subsection}{Enrichment 20.10.4: Choosing Conditional Paths - Diffusion vs OT}{945}{section*.1970}%
\contentsline {subsubsection}{Choosing Conditional Paths â€“ Diffusion vs OT}{945}{section*.1971}%
\contentsline {paragraph}{Variance Exploding (VE) Conditional Paths}{945}{section*.1972}%
\contentsline {paragraph}{Variance Preserving (VP) Conditional Paths}{945}{section*.1973}%
\contentsline {paragraph}{Limitations of Diffusion-Based Conditional Paths}{946}{section*.1974}%
\contentsline {subsubsection}{Optimal Transport Conditional Probability Paths}{946}{section*.1975}%
\contentsline {paragraph}{What Is Optimal Transport?}{946}{section*.1976}%
\contentsline {paragraph}{Affine OT Flow Between Gaussians}{947}{section*.1977}%
\contentsline {paragraph}{The OT Vector Field}{947}{section*.1978}%
\contentsline {paragraph}{The Corresponding Flow Map and CFM Loss}{947}{section*.1979}%
\contentsline {paragraph}{Vector Field Geometry: Diffusion vs. Optimal Transport}{947}{section*.1980}%
\contentsline {paragraph}{Why Optimal Transport Defines a Superior Learning Signal}{949}{section*.1982}%
\contentsline {paragraph}{OT-based Conditional Flow Matching Inference}{950}{section*.1984}%
\contentsline {paragraph}{Takeaway}{950}{section*.1985}%
\contentsline {subsection}{Enrichment 20.10.5: Implementation, Experiments, and Related Work}{951}{section*.1986}%
\contentsline {paragraph}{Implementation Details}{951}{section*.1987}%
\contentsline {paragraph}{Empirical Results: OT vs.\ Diffusion}{951}{section*.1988}%
\contentsline {paragraph}{Quantitative Benchmarks}{951}{section*.1990}%
\contentsline {paragraph}{Additional Comparisons}{952}{section*.1992}%
\contentsline {paragraph}{Related Work and Positioning}{952}{section*.1993}%
\contentsline {paragraph}{Outlook}{953}{section*.1994}%
\contentsline {section}{Enrichment 20.11: Additional Pioneering Works in Generative AI}{954}{section*.1995}%
\contentsline {subsection}{Enrichment 20.11.1: GLIDE: Text-Guided Diffusion with Classifier-Free Guidance}{954}{section*.1996}%
\contentsline {paragraph}{Model Architecture and Conditioning Mechanism}{954}{section*.1997}%
\contentsline {paragraph}{Super-Resolution Modules in \textsc {GLIDE}}{958}{section*.1999}%
\contentsline {paragraph}{Relationship to Cascaded Diffusion Models (CDMs)}{958}{section*.2000}%
\contentsline {paragraph}{Full Generation Pipeline of \textsc {GLIDE}}{959}{section*.2001}%
\contentsline {paragraph}{ADM U-Net Architecture in \textsc {GLIDE}}{959}{section*.2002}%
\contentsline {paragraph}{Summary of the GLIDE System}{960}{section*.2003}%
\contentsline {paragraph}{Text-Guided Editing and Inpainting Capabilities}{961}{section*.2004}%
\contentsline {paragraph}{Sketch-Based Conditional Editing with SDEdit}{963}{section*.2007}%
\contentsline {paragraph}{Classifier-Free Guidance vs.\ CLIP Guidance}{964}{section*.2009}%
\contentsline {paragraph}{Failure Cases and Architectural Limitations}{966}{section*.2012}%
\contentsline {subsection}{Enrichment 20.11.2: DALLÂ·E 1: Discrete Tokens for Text-to-Image Generation}{967}{section*.2014}%
\contentsline {paragraph}{Motivation: Turning Images into Token Sequences for GPT-Style Modelling}{967}{section*.2015}%
\contentsline {paragraph}{How VQ-VAE Enables Discrete Tokenization}{969}{section*.2017}%
\contentsline {paragraph}{Clarifying Terminology: dVAE vs. VQ-VAE}{974}{section*.2020}%
\contentsline {paragraph}{Training Datasets and Sample Generation Pipeline}{975}{section*.2021}%
\contentsline {paragraph}{Experimental Results and Motivation for DALL$\cdot $E~2}{977}{section*.2023}%
\contentsline {subsection}{Enrichment 20.11.3: DALL$\cdot $E~2: Diffusion Priors over CLIP Embeddings}{980}{section*.2027}%
\contentsline {paragraph}{System Overview and Architectural Shift}{980}{section*.2028}%
\contentsline {paragraph}{Diffusion Prior: Bridging Text and Image Embeddings}{981}{section*.2030}%
\contentsline {subparagraph}{Training Objective}{982}{subparagraph*.2031}%
\contentsline {subparagraph}{Model Architecture}{983}{subparagraph*.2032}%
\contentsline {paragraph}{Diffusion-Based Decoder}{986}{section*.2034}%
\contentsline {paragraph}{Semantic Interpolation and Reconstruction in CLIP Latents}{987}{section*.2035}%
\contentsline {paragraph}{Robustness and Generalization of the Decoder}{991}{section*.2040}%
\contentsline {paragraph}{Dataset Construction and Semantic Pretraining}{992}{section*.2042}%
\contentsline {paragraph}{Image Quality and Diversity: Qualitative and Quantitative Results}{993}{section*.2043}%
\contentsline {paragraph}{Design Limitations and Architectural Tradeoffs}{994}{section*.2045}%
\contentsline {paragraph}{Stepping Towards Latent Diffusion Models}{994}{section*.2046}%
\contentsline {subsection}{Enrichment 20.11.4: Latent Diffusion Models (LDMs)}{996}{section*.2047}%
\contentsline {paragraph}{Overview and Conceptual Shift}{996}{section*.2048}%
\contentsline {paragraph}{Autoencoder Architecture and Training Objective}{996}{section*.2049}%
\contentsline {paragraph}{Autoencoder Architecture and Latent Normalization}{998}{section*.2051}%
\contentsline {subparagraph}{Encoder and Decoder Design}{998}{subparagraph*.2052}%
\contentsline {subparagraph}{Latent Normalization for Diffusion Compatibility}{998}{subparagraph*.2053}%
\contentsline {paragraph}{Denoising Diffusion in Latent Space}{999}{section*.2054}%
\contentsline {subparagraph}{Architecture of the Denoising U-Net}{999}{subparagraph*.2055}%
\contentsline {subsubsection}{Enrichment 20.11.4.1: Decoder Fidelity Without Explicit Text Conditioning}{1001}{section*.2056}%
\contentsline {paragraph}{Why It Still Works}{1001}{section*.2057}%
\contentsline {paragraph}{Trade-offs and Alternatives}{1001}{section*.2058}%
\contentsline {paragraph}{Conclusion}{1001}{section*.2059}%
\contentsline {paragraph}{Classifier-Free Guidance (CFG)}{1002}{section*.2060}%
\contentsline {paragraph}{Empirical Results and Ablations}{1002}{section*.2061}%
\contentsline {paragraph}{Limitations and Transition to Newer Works Like \emph {Imagen}}{1003}{section*.2063}%
\contentsline {subsection}{Enrichment 20.11.5: Imagen: Scaling Language Fidelity in Text2Img Models}{1004}{section*.2064}%
\contentsline {paragraph}{Motivation and Context}{1004}{section*.2065}%
\contentsline {subsubsection}{Cascaded Diffusion Pipeline}{1005}{section*.2066}%
\contentsline {subsubsection}{Classifier-Free Guidance and Dynamic Thresholding}{1006}{section*.2068}%
\contentsline {paragraph}{Problem: Oversaturation from Large Guidance}{1006}{section*.2069}%
\contentsline {paragraph}{NaÃ¯ve Solution: Static Thresholding}{1006}{section*.2070}%
\contentsline {paragraph}{Dynamic Thresholding: an Adaptive Alternative to Static Clipping}{1007}{section*.2071}%
\contentsline {subsubsection}{Experimental Findings and DrawBench Evaluation}{1008}{section*.2073}%
\contentsline {paragraph}{Scaling the Text Encoder}{1008}{section*.2074}%
\contentsline {paragraph}{DrawBench: A Diverse Prompt Evaluation Suite}{1009}{section*.2076}%
\contentsline {paragraph}{Qualitative Samples}{1010}{section*.2078}%
\contentsline {subsubsection}{Enrichment 20.11.5.1: Toward Fine-Grained Control and Editable Generation}{1010}{section*.2080}%
\contentsline {paragraph}{From Fidelity to Controllability}{1010}{section*.2081}%
\contentsline {paragraph}{Why Prompt-Aware Attention Control Is Needed}{1011}{section*.2082}%
\contentsline {paragraph}{Key Approaches and Innovations}{1011}{section*.2083}%
\contentsline {subsection}{Enrichment 20.11.6: Prompt-to-Prompt (P2P): Cross-Attention Editing in DMs}{1012}{section*.2084}%
\contentsline {paragraph}{Motivation and Core Insight}{1012}{section*.2085}%
\contentsline {subparagraph}{Cross-Attention as the Mechanism for Prompt Influence}{1013}{subparagraph*.2087}%
\contentsline {subparagraph}{Editing by Cross-Attention Injection}{1014}{subparagraph*.2089}%
\contentsline {subparagraph}{Use Case: Content Modifications via Prompt Edits}{1018}{subparagraph*.2091}%
\contentsline {subparagraph}{Use Case: Object Preservation Across Scene Changes}{1019}{subparagraph*.2093}%
\contentsline {subparagraph}{Use Case: Controlled Blending via Partial Attention Injection}{1021}{subparagraph*.2095}%
\contentsline {subparagraph}{Use Case: Emphasizing and De-emphasizing Concepts}{1022}{subparagraph*.2097}%
\contentsline {subparagraph}{Use Case: Text-Guided Stylization while Preserving Layout}{1023}{subparagraph*.2099}%
\contentsline {subparagraph}{Use Case: Editing Real Images via Inversion and Prompt-to-Prompt}{1024}{subparagraph*.2101}%
\contentsline {subparagraph}{Limitations and Transition to Personalized Editing}{1024}{subparagraph*.2103}%
\contentsline {subsection}{Enrichment 20.11.7: DreamBooth: Personalized Text-to-Image Generation}{1026}{section*.2104}%
\contentsline {paragraph}{Motivation and Core Insight}{1026}{section*.2105}%
\contentsline {subparagraph}{Model Setup and Identifier Creation}{1026}{subparagraph*.2107}%
\contentsline {subparagraph}{Training Objective and Prior Preservation}{1031}{subparagraph*.2112}%
\contentsline {paragraph}{Main Loss: Denoising Objective}{1031}{section*.2113}%
\contentsline {paragraph}{Preventing Overfitting: Prior Preservation Loss}{1031}{section*.2114}%
\contentsline {paragraph}{Effect and Interpretation}{1032}{section*.2116}%
\contentsline {subparagraph}{Subject-Driven Generation in New Contexts}{1033}{subparagraph*.2117}%
\contentsline {subsection}{Enrichment 20.11.8: ControlNet â€“ Structured Conditioning for Diffusion Models}{1037}{section*.2123}%
\contentsline {subparagraph}{Motivation and Background}{1037}{subparagraph*.2124}%
\contentsline {subparagraph}{Block Injection and Architectural Motivation}{1038}{subparagraph*.2126}%
\contentsline {subsubsection}{Enrichment 20.11.8.1: ControlNet Architecture}{1038}{section*.2127}%
\contentsline {paragraph}{Injecting Spatial Conditioning into Frozen Networks}{1038}{section*.2128}%
\contentsline {paragraph}{ControlNet Architectural Design}{1039}{section*.2129}%
\contentsline {paragraph}{Motivation for Additive Injection: Why Not Inject \( c \) Directly?}{1039}{section*.2130}%
\contentsline {paragraph}{Component Breakdown}{1039}{section*.2131}%
\contentsline {paragraph}{How Can the Output Change If the U-Net Is Frozen? And Why Is Denoising Still Valid?}{1040}{section*.2132}%
\contentsline {paragraph}{Training Objective}{1041}{section*.2133}%
\contentsline {paragraph}{Why ControlNet Preserves Denoising Capability}{1041}{section*.2134}%
\contentsline {subsubsection}{Enrichment 20.11.8.2: Training Behavior and Sudden Convergence}{1044}{section*.2137}%
\contentsline {subparagraph}{Classifier-Free Guidance and Resolution-Aware Weighting}{1045}{subparagraph*.2139}%
\contentsline {subparagraph}{Resolution-Aware Weighting (CFG-RW)}{1045}{subparagraph*.2140}%
\contentsline {paragraph}{Why resolution matters}{1045}{section*.2141}%
\contentsline {paragraph}{Why It Works}{1046}{section*.2142}%
\contentsline {paragraph}{Training Intuition With CFG-RW}{1046}{section*.2143}%
\contentsline {subparagraph}{Limitations of ControlNet and the Need for Semantic Conditioning}{1047}{subparagraph*.2145}%
\contentsline {paragraph}{Preprocessing Dependency}{1047}{section*.2146}%
\contentsline {paragraph}{Lack of Semantic Awareness}{1047}{section*.2147}%
\contentsline {paragraph}{Limited Compositionality and Scalability}{1047}{section*.2148}%
\contentsline {subsection}{Enrichment 20.11.9: IP-Adapter â€” Semantic Image Prompting for DMs}{1048}{section*.2149}%
\contentsline {subparagraph}{Motivation and Background}{1048}{subparagraph*.2150}%
\contentsline {subparagraph}{Introducing IP-Adapter: A Lightweight and Compatible Solution}{1048}{subparagraph*.2151}%
\contentsline {paragraph}{Why IP-Adapter Works Without Compromising the Base Model}{1049}{section*.2152}%
\contentsline {subparagraph}{1. Image Guidance via Decoupled Cross-Attention in U-Net Blocks}{1049}{subparagraph*.2153}%
\contentsline {subparagraph}{2. The Base U-Net Remains Fully Frozen}{1049}{subparagraph*.2154}%
\contentsline {subparagraph}{3. Safe Integration via Additive Fusion}{1049}{subparagraph*.2155}%
\contentsline {subparagraph}{4. Denoising Logic is Preserved by Construction}{1049}{subparagraph*.2156}%
\contentsline {subparagraph}{5. \(\lambda \) Offers Explicit, Safe, Inference-Time Control}{1049}{subparagraph*.2157}%
\contentsline {subparagraph}{6. Summary: Why This Architecture is Effective and Non-Destructive}{1050}{subparagraph*.2158}%
\contentsline {paragraph}{ControlNet vs. IP-Adapter: Structural vs. Semantic Conditioning}{1050}{section*.2159}%
\contentsline {subparagraph}{ControlNet: Explicit Structural Conditioning}{1050}{subparagraph*.2160}%
\contentsline {subparagraph}{ControlNet \& Raw Images}{1050}{subparagraph*.2161}%
\contentsline {paragraph}{Key Architectural Components and Detailed Integration}{1053}{section*.2163}%
\contentsline {subparagraph}{Versatility and Generalization without Fine-Tuning}{1055}{subparagraph*.2165}%
\contentsline {paragraph}{Comparative Evaluation Across Structural Control Tasks}{1057}{section*.2167}%
\contentsline {paragraph}{Image-to-Image Translation, Inpainting, and Multimodal Prompting}{1058}{section*.2169}%
\contentsline {paragraph}{Ablation: Validating Architectural Design}{1060}{section*.2173}%
\contentsline {paragraph}{Looking Forward}{1063}{section*.2176}%
\contentsline {subsection}{Enrichment 20.11.10: Transfusion: Unified Multimodal Generation}{1064}{section*.2177}%
\contentsline {paragraph}{Motivation and Overview}{1064}{section*.2178}%
\contentsline {paragraph}{Architecture and Training Pipeline of Transfusion}{1066}{section*.2180}%
\contentsline {subparagraph}{Part 1: Image Tokenization Pipeline}{1066}{subparagraph*.2181}%
\contentsline {subparagraph}{Part 2: Text Tokenization Pipeline}{1067}{subparagraph*.2183}%
\contentsline {subparagraph}{Part 3: Multimodal Sequence Construction}{1068}{subparagraph*.2184}%
\contentsline {subparagraph}{Part 4: Transformer Processing with Hybrid Attention}{1068}{subparagraph*.2185}%
\contentsline {subparagraph}{Part 5: Training Objectives and Loss Functions}{1069}{subparagraph*.2187}%
\contentsline {subparagraph}{Part 6: Key Advantages of the Training Design}{1070}{subparagraph*.2188}%
\contentsline {paragraph}{Empirical Results and Qualitative Examples}{1071}{section*.2189}%
\contentsline {subparagraph}{Showcase: High-Quality Multi-Modal Generation}{1071}{subparagraph*.2190}%
\contentsline {subparagraph}{Zero-Shot Image Editing via Fine-Tuning}{1072}{subparagraph*.2192}%
\contentsline {paragraph}{Ablation Studies and Experimental Insights}{1073}{section*.2194}%
\contentsline {subparagraph}{Interpreting Evaluation Metrics}{1073}{subparagraph*.2195}%
\contentsline {subparagraph}{Attention Masking: Causal vs.\ Bidirectional}{1073}{subparagraph*.2196}%
\contentsline {subparagraph}{Patch Size Variations}{1073}{subparagraph*.2198}%
\contentsline {subparagraph}{Encoding Architecture: Linear vs. U-Net}{1074}{subparagraph*.2200}%
\contentsline {subparagraph}{Noise Scheduling in Image-to-Text Training}{1074}{subparagraph*.2202}%
\contentsline {subparagraph}{Comparison to Specialized Generative Models}{1074}{subparagraph*.2204}%
\contentsline {paragraph}{Summary}{1075}{section*.2206}%
\contentsline {subsection}{Enrichment 20.11.11: Visual Autoregressive Modeling (VAR)}{1076}{section*.2207}%
\contentsline {subparagraph}{Multi-Scale Architecture for Coarse-to-Fine Generation: How VAR Works}{1077}{subparagraph*.2209}%
\contentsline {paragraph}{Overview: A Two-Stage Pipeline for Image Generation}{1077}{section*.2210}%
\contentsline {paragraph}{Stage 1: Multi-Scale VQ-VAE for Hierarchical Tokenization}{1077}{section*.2211}%
\contentsline {subparagraph}{Hierarchical Token Encoding via Residual Refinement}{1078}{subparagraph*.2212}%
\contentsline {subparagraph}{Token Decoding and Image Reconstruction}{1078}{subparagraph*.2213}%
\contentsline {subparagraph}{Training Objective for the VQ-VAE}{1079}{subparagraph*.2214}%
\contentsline {paragraph}{Stage 2: Scale-Aware Autoregressive Transformer}{1079}{section*.2215}%
\contentsline {subparagraph}{From Tokens to Embeddings: Transformer Inputs}{1079}{subparagraph*.2216}%
\contentsline {subparagraph}{Why a Second Stage is Needed}{1080}{subparagraph*.2217}%
\contentsline {subparagraph}{Autoregressive Modeling Across Scales}{1080}{subparagraph*.2218}%
\contentsline {subparagraph}{Training Procedure}{1080}{subparagraph*.2219}%
\contentsline {subparagraph}{Inference and Generation}{1081}{subparagraph*.2220}%
\contentsline {subparagraph}{Final Decoding and Image Reconstruction}{1081}{subparagraph*.2221}%
\contentsline {paragraph}{Benefits of the VAR Design}{1082}{section*.2223}%
\contentsline {paragraph}{Experimental Results: High-Quality Generation and Editing}{1082}{section*.2224}%
\contentsline {subparagraph}{Comparison with Other Generative Paradigms}{1083}{subparagraph*.2226}%
\contentsline {paragraph}{Scaling Trends, Model Comparison, and Future Outlook}{1085}{section*.2228}%
\contentsline {subparagraph}{Scaling Efficiency and Sample Quality}{1085}{subparagraph*.2229}%
\contentsline {subparagraph}{Comparison to Diffusion and Autoregressive Models}{1086}{subparagraph*.2231}%
\contentsline {paragraph}{Qualitative Scaling Effects of VAR}{1086}{section*.2232}%
\contentsline {subparagraph}{Limitations and Future Directions}{1088}{subparagraph*.2234}%
\contentsline {chapter}{\numberline {21}Lecture 21: Visualizing Models \& Generating Images}{1089}{chapter.21}%
\ttl@stoptoc {default@20}
\ttl@starttoc {default@21}
\contentsline {section}{\numberline {21.1}Visualizing Layer Filters}{1089}{section.21.1}%
\contentsline {subsection}{\numberline {21.1.1}Visualizing First Layer Filters}{1089}{subsection.21.1.1}%
\contentsline {paragraph}{Architecture Comparison}{1089}{section*.2235}%
\contentsline {paragraph}{Interpretation and Limitations}{1090}{section*.2237}%
\contentsline {subsection}{\numberline {21.1.2}Visualizing Higher Layer Filters}{1090}{subsection.21.1.2}%
\contentsline {paragraph}{Example: ConvNetJS Visualization}{1091}{section*.2238}%
\contentsline {paragraph}{Interpretation and Motivation for Indirect Methods}{1091}{section*.2240}%
\contentsline {section}{\numberline {21.2}Last Layer Features: Nearest Neighbors, Dimensionality Reduction}{1092}{section.21.2}%
\contentsline {subsection}{\numberline {21.2.1}Semantic Similarity via Nearest Neighbors}{1092}{subsection.21.2.1}%
\contentsline {subsection}{\numberline {21.2.2}Dimensionality Reduction and Embedding Visualization}{1093}{subsection.21.2.2}%
\contentsline {paragraph}{Interpretation and Applications}{1094}{section*.2244}%
\contentsline {section}{\numberline {21.3}Visualizing Activations and Maximally Activating Patches}{1095}{section.21.3}%
\contentsline {paragraph}{How to Visualize Activations}{1095}{section*.2245}%
\contentsline {paragraph}{Why Do Activation Maps Reveal Spatial Information?}{1096}{section*.2247}%
\contentsline {paragraph}{What Do Activations Reveal?}{1097}{section*.2248}%
\contentsline {paragraph}{What Can We Do With Activation Maps?}{1097}{section*.2249}%
\contentsline {subsection}{\numberline {21.3.1}Maximally Activating Patches}{1098}{subsection.21.3.1}%
\contentsline {paragraph}{Methodology}{1098}{section*.2250}%
\contentsline {paragraph}{Intuition and Insights}{1099}{section*.2252}%
\contentsline {paragraph}{From â€œWhat It Seesâ€ to â€œWhat It Usesâ€}{1099}{section*.2253}%
\contentsline {section}{\numberline {21.4}Saliency via Occlusion and Backpropagation}{1100}{section.21.4}%
\contentsline {subsection}{\numberline {21.4.1}Occlusion Sensitivity}{1100}{subsection.21.4.1}%
\contentsline {paragraph}{Methodology}{1100}{section*.2255}%
\contentsline {paragraph}{From Patch Scores to Pixel-Level Saliency}{1100}{section*.2256}%
\contentsline {paragraph}{Intuition and Interpretation}{1101}{section*.2257}%
\contentsline {subsubsection}{Enrichment 21.4.1.1: Advantages and Limitations of Occlusion Sensitivity}{1101}{section*.2258}%
\contentsline {subsection}{\numberline {21.4.2}Saliency via Gradient Backpropagation}{1101}{subsection.21.4.2}%
\contentsline {paragraph}{Interpretation and Use Cases}{1102}{section*.2260}%
\contentsline {paragraph}{Towards Unsupervised Segmentation}{1102}{section*.2261}%
\contentsline {section}{\numberline {21.5}Guided Backpropagation of Intermediate Features}{1103}{section.21.5}%
\contentsline {subsection}{\numberline {21.5.1}Backpropagation to Visualize Intermediate Neurons}{1103}{subsection.21.5.1}%
\contentsline {subsection}{\numberline {21.5.2}Guided Backpropagation: Cleaner Gradient Visualizations}{1103}{subsection.21.5.2}%
\contentsline {paragraph}{Why Does This Help? Intuition and Impact}{1104}{section*.2264}%
\contentsline {subsection}{\numberline {21.5.3}Visualizing Intermediate Feature Detectors}{1105}{subsection.21.5.3}%
\contentsline {paragraph}{From Saliency to Synthesis}{1105}{section*.2266}%
\contentsline {section}{\numberline {21.6}Gradient Ascent and Class Visualization}{1105}{section.21.6}%
\contentsline {paragraph}{Objective Function}{1106}{section*.2267}%
\contentsline {paragraph}{Optimization via Gradient Ascent}{1106}{section*.2268}%
\contentsline {subsection}{\numberline {21.6.1}Regularization: Making Images Look Natural}{1106}{subsection.21.6.1}%
\contentsline {paragraph}{Advanced Regularizers}{1107}{section*.2271}%
\contentsline {subsection}{\numberline {21.6.2}Visualizing Intermediate Features}{1108}{subsection.21.6.2}%
\contentsline {subsubsection}{Multifaceted Feature Visualization via Generative Models}{1108}{section*.2274}%
\contentsline {paragraph}{Realism vs. Fidelity}{1109}{section*.2277}%
\contentsline {section}{\numberline {21.7}Adversarial Examples: A Deep Dive into Model Vulnerability}{1110}{section.21.7}%
\contentsline {subsection}{\numberline {21.7.1}Fundamental Attack Mechanisms}{1110}{subsection.21.7.1}%
\contentsline {subsection}{\numberline {21.7.2}Taxonomy of Adversarial Attacks}{1111}{subsection.21.7.2}%
\contentsline {paragraph}{White-box attacks}{1111}{section*.2279}%
\contentsline {paragraph}{Black-box attacks}{1112}{section*.2280}%
\contentsline {subsection}{\numberline {21.7.3}Milestones in Robustness Evaluation}{1113}{subsection.21.7.3}%
\contentsline {subsection}{\numberline {21.7.4}Defense Toolbox and Its Limitations}{1113}{subsection.21.7.4}%
\contentsline {subsection}{\numberline {21.7.5}Real-World Relevance and Persistent Risks}{1114}{subsection.21.7.5}%
\contentsline {subsection}{\numberline {21.7.6}Open Challenges and Theoretical Connections}{1114}{subsection.21.7.6}%
\contentsline {section}{\numberline {21.8}Class Activation Mapping (CAM) and Grad-CAM}{1114}{section.21.8}%
\contentsline {paragraph}{Mechanism of CAM}{1114}{section*.2282}%
\contentsline {paragraph}{Limitations of CAM}{1116}{section*.2285}%
\contentsline {subsection}{\numberline {21.8.1}Generalization via Grad-CAM}{1116}{subsection.21.8.1}%
\contentsline {paragraph}{Comparative Visualization Examples}{1118}{section*.2287}%
\contentsline {subsection}{\numberline {21.8.2}Comparison Between CAM and Grad-CAM}{1119}{subsection.21.8.2}%
\contentsline {paragraph}{From Explanation to Synthesis: A Path Toward Feature Inversion}{1120}{section*.2291}%
\contentsline {section}{\numberline {21.9}Feature Inversion}{1120}{section.21.9}%
\contentsline {paragraph}{Problem Formulation}{1120}{section*.2292}%
\contentsline {paragraph}{Comparison to Gradient Ascent}{1120}{section*.2293}%
\contentsline {paragraph}{Effect of Layer Depth}{1121}{section*.2295}%
\contentsline {paragraph}{Interpretability Insights}{1122}{section*.2297}%
\contentsline {paragraph}{Applications}{1122}{section*.2298}%
\contentsline {paragraph}{Beyond Feature Inversion}{1122}{section*.2299}%
\contentsline {section}{\numberline {21.10}DeepDream: Amplifying Neural Perceptions}{1122}{section.21.10}%
\contentsline {paragraph}{Optimization Objective}{1123}{section*.2301}%
\contentsline {paragraph}{Amplifying Layer-wise Semantics}{1123}{section*.2302}%
\contentsline {paragraph}{Dreaming Deeper}{1125}{section*.2306}%
\contentsline {paragraph}{Interpretability Value}{1126}{section*.2309}%
\contentsline {section}{\numberline {21.11}Texture Synthesis}{1126}{section.21.11}%
\contentsline {subsection}{\numberline {21.11.1}Classical Approaches}{1127}{subsection.21.11.1}%
\contentsline {paragraph}{Limitations of Pixel Matching}{1128}{section*.2313}%
\contentsline {subsection}{\numberline {21.11.2}Neural Texture Synthesis via Gram Matrices}{1128}{subsection.21.11.2}%
\contentsline {paragraph}{Constructing the Gram Matrix}{1128}{section*.2314}%
\contentsline {paragraph}{Why Gram Matrices?}{1128}{section*.2316}%
\contentsline {paragraph}{Optimization Pipeline}{1129}{section*.2318}%
\contentsline {paragraph}{Effect of Matching Higher Layers}{1130}{section*.2320}%
\contentsline {paragraph}{Impact and Legacy}{1130}{section*.2322}%
\contentsline {section}{\numberline {21.12}Neural Style Transfer}{1131}{section.21.12}%
\contentsline {subsection}{\numberline {21.12.1}Neural Style Transfer: Content and Style Fusion}{1131}{subsection.21.12.1}%
\contentsline {paragraph}{Intuition}{1131}{section*.2323}%
\contentsline {paragraph}{Optimization Objective}{1131}{section*.2325}%
\contentsline {paragraph}{Optimization via Gradient Descent}{1132}{section*.2327}%
\contentsline {paragraph}{Stylization Results}{1134}{section*.2329}%
\contentsline {paragraph}{Controlling Style Intensity}{1135}{section*.2332}%
\contentsline {paragraph}{Effect of Style Image Scale}{1135}{section*.2334}%
\contentsline {paragraph}{Combining Styles}{1136}{section*.2336}%
\contentsline {paragraph}{Limitations}{1136}{section*.2338}%
\contentsline {subsection}{\numberline {21.12.2}Fast Neural Style Transfer}{1137}{subsection.21.12.2}%
\contentsline {paragraph}{Training Setup}{1137}{section*.2339}%
\contentsline {paragraph}{Key Insight}{1137}{section*.2341}%
\contentsline {paragraph}{Stylization Examples}{1138}{section*.2342}%
\contentsline {paragraph}{Instance Normalization}{1138}{section*.2344}%
\contentsline {paragraph}{Conditional Instance Normalization for Multi-Style Transfer}{1139}{section*.2346}%
\contentsline {paragraph}{Summary and Emerging Directions}{1139}{section*.2348}%
\contentsline {chapter}{\numberline {22}Lecture 22: Self-Supervised Learning}{1140}{chapter.22}%
\ttl@stoptoc {default@21}
\ttl@starttoc {default@22}
\contentsline {section}{\numberline {22.1}Motivation and Definition}{1140}{section.22.1}%
\contentsline {subsection}{\numberline {22.1.1}What is Self-Supervised Learning (SSL)?}{1140}{subsection.22.1.1}%
\contentsline {paragraph}{Learning Representations Without Labels}{1140}{section*.2349}%
\contentsline {paragraph}{Pretraining Then Transferring}{1140}{section*.2350}%
\contentsline {paragraph}{Embedding Geometry and Semantic Similarity}{1141}{section*.2352}%
\contentsline {paragraph}{Why Pretext Tasks Work}{1141}{section*.2353}%
\contentsline {paragraph}{Categories of Pretext Tasks}{1141}{section*.2354}%
\contentsline {paragraph}{Backbones, Augmentations, and Losses}{1142}{section*.2355}%
\contentsline {paragraph}{Summary}{1142}{section*.2356}%
\contentsline {subsection}{\numberline {22.1.2}Why Self-Supervised Learning?}{1142}{subsection.22.1.2}%
\contentsline {paragraph}{Supervised Learning is Expensive}{1142}{section*.2357}%
\contentsline {paragraph}{But Unlabeled Data is Free (and Plentiful)}{1142}{section*.2358}%
\contentsline {paragraph}{Learning Like Humans}{1143}{section*.2359}%
\contentsline {paragraph}{SSL as the Backbone of Foundation Models}{1143}{section*.2360}%
\contentsline {subsection}{\numberline {22.1.3}LeCun's AI Cake: SSL as the Base Layer}{1143}{subsection.22.1.3}%
\contentsline {paragraph}{The Cake Analogy}{1143}{section*.2361}%
\contentsline {paragraph}{Practical Significance}{1143}{section*.2363}%
\contentsline {subsection}{\numberline {22.1.4}Practical Integration into Deep Learning Pipelines}{1144}{subsection.22.1.4}%
\contentsline {paragraph}{How SSL is Used in Practice}{1144}{section*.2364}%
\contentsline {paragraph}{Flexible Transfer and Modularity}{1144}{section*.2365}%
\contentsline {paragraph}{Strategic Impact and Adoption}{1144}{section*.2366}%
\contentsline {section}{\numberline {22.2}A Taxonomy of Self-Supervised Representation Learning Methods}{1145}{section.22.2}%
\contentsline {subsection}{\numberline {22.2.1}Contrastive Methods}{1145}{subsection.22.2.1}%
\contentsline {paragraph}{Discriminative Representations via Similarity and Dissimilarity}{1145}{section*.2367}%
\contentsline {paragraph}{Insight}{1145}{section*.2368}%
\contentsline {subsection}{\numberline {22.2.2}Distillation-Based Methods}{1145}{subsection.22.2.2}%
\contentsline {paragraph}{Teacher-Student Framework without Negatives}{1145}{section*.2369}%
\contentsline {paragraph}{Insight}{1145}{section*.2370}%
\contentsline {subsection}{\numberline {22.2.3}Feature Decorrelation Methods}{1146}{subsection.22.2.3}%
\contentsline {paragraph}{Promoting Redundancy Reduction}{1146}{section*.2371}%
\contentsline {paragraph}{Insight}{1146}{section*.2372}%
\contentsline {subsection}{\numberline {22.2.4}Clustering-Based Methods}{1146}{subsection.22.2.4}%
\contentsline {paragraph}{Learning via Group-Level Semantics}{1146}{section*.2373}%
\contentsline {paragraph}{Insight}{1146}{section*.2374}%
\contentsline {section}{\numberline {22.3}Contrastive Methods}{1147}{section.22.3}%
\contentsline {subsection}{\numberline {22.3.1}Motivation for Contrastive Learning}{1147}{subsection.22.3.1}%
\contentsline {paragraph}{Core Idea}{1147}{section*.2377}%
\contentsline {paragraph}{Instance Discrimination as a Pretext Task}{1147}{section*.2378}%
\contentsline {paragraph}{Avoiding Trivial Solutions}{1147}{section*.2379}%
\contentsline {paragraph}{Scalability and Generalization}{1148}{section*.2380}%
\contentsline {paragraph}{Key Advantages}{1148}{section*.2381}%
\contentsline {paragraph}{From Semantic Similarity to Objective Formulation}{1149}{section*.2383}%
\contentsline {paragraph}{Contrastive Learning as Mutual Information Maximization}{1149}{section*.2384}%
\contentsline {paragraph}{Towards a Unified Loss Function}{1149}{section*.2385}%
\contentsline {subsection}{\numberline {22.3.2}Origin and Intuition Behind Contrastive Loss}{1150}{subsection.22.3.2}%
\contentsline {paragraph}{From Dimensionality Reduction to Discriminative Embeddings}{1150}{section*.2386}%
\contentsline {paragraph}{Why the Margin Matters}{1150}{section*.2387}%
\contentsline {paragraph}{A Visual Summary of the Learning Objective}{1150}{section*.2389}%
\contentsline {paragraph}{Why Not Use \( \frac {1}{D_W} \)?}{1151}{section*.2391}%
\contentsline {paragraph}{From Supervision to Self-Supervision}{1151}{section*.2392}%
\contentsline {paragraph}{Triplet Setup: Anchor, Positive, Negative}{1152}{section*.2394}%
\contentsline {subsection}{\numberline {22.3.3}The NT-Xent Loss: Normalized Temperature-Scaled Cross-Entropy}{1153}{subsection.22.3.3}%
\contentsline {paragraph}{Overview and Purpose}{1153}{section*.2396}%
\contentsline {paragraph}{Pairwise Contrastive Loss: NT-Xent Formulation}{1153}{section*.2397}%
\contentsline {paragraph}{Batch Aggregation and the \( \frac {1}{2N} \) Factor}{1153}{section*.2398}%
\contentsline {paragraph}{The Role of Symmetry}{1154}{section*.2399}%
\contentsline {paragraph}{Illustration of the Loss Mechanism}{1154}{section*.2400}%
\contentsline {paragraph}{Role of the Projection Head}{1155}{section*.2402}%
\contentsline {paragraph}{Log-Softmax Intuition}{1155}{section*.2403}%
\contentsline {paragraph}{Summary}{1155}{section*.2405}%
\contentsline {subsection}{\numberline {22.3.4}SimCLR: A Simple Framework for Contrastive Learning}{1156}{subsection.22.3.4}%
\contentsline {paragraph}{Overview}{1156}{section*.2406}%
\contentsline {paragraph}{Architecture Components}{1156}{section*.2407}%
\contentsline {paragraph}{Design Principles Behind SimCLR}{1156}{section*.2408}%
\contentsline {paragraph}{Training Configuration and Stability}{1156}{section*.2409}%
\contentsline {paragraph}{Performance Benchmarks}{1157}{section*.2410}%
\contentsline {paragraph}{Visualization of SimCLR Pipeline}{1157}{section*.2411}%
\contentsline {paragraph}{Limitations and the Road to MoCo}{1158}{section*.2413}%
\contentsline {subsection}{\numberline {22.3.5}Momentum Contrast (MoCo)}{1158}{subsection.22.3.5}%
\contentsline {paragraph}{Motivation: Avoiding Large Batch Sizes}{1158}{section*.2414}%
\contentsline {paragraph}{Core Architecture}{1158}{section*.2415}%
\contentsline {paragraph}{Contrastive Loss in MoCo}{1158}{section*.2416}%
\contentsline {paragraph}{MoCo Training Pipeline}{1159}{section*.2417}%
\contentsline {paragraph}{Why MoCo Works: Scale, Stability, and Efficiency}{1159}{section*.2418}%
\contentsline {paragraph}{What the Queue Enables}{1159}{section*.2419}%
\contentsline {paragraph}{Momentum Hyperparameter Tuning and Ablation Results}{1160}{section*.2421}%
\contentsline {paragraph}{Other Key Ablations and Design Justifications}{1161}{section*.2423}%
\contentsline {paragraph}{Performance and Comparison with SimCLR}{1162}{section*.2425}%
\contentsline {paragraph}{From MoCo v1 to MoCo v2}{1162}{section*.2427}%
\contentsline {subsection}{\numberline {22.3.6}MoCo v2 and MoCo v3}{1163}{subsection.22.3.6}%
\contentsline {paragraph}{From MoCo v1 to v2: Architectural Refinements}{1163}{section*.2428}%
\contentsline {paragraph}{MoCo v3: Adapting Momentum Contrast to Vision Transformers}{1163}{section*.2431}%
\contentsline {paragraph}{Why Symmetric Loss?}{1165}{section*.2432}%
\contentsline {paragraph}{Explanation}{1165}{section*.2433}%
\contentsline {paragraph}{Performance Highlights}{1165}{section*.2434}%
\contentsline {paragraph}{Takeaway}{1166}{section*.2437}%
\contentsline {subsection}{\numberline {22.3.7}SimCLR v2: Scaling Contrastive Learning for Semi-Supervised Settings}{1166}{subsection.22.3.7}%
\contentsline {paragraph}{Motivation and Overview}{1166}{section*.2438}%
\contentsline {paragraph}{Three-Stage Training Framework}{1167}{section*.2440}%
\contentsline {paragraph}{Architectural Enhancements and Ablation Insights}{1167}{section*.2441}%
\contentsline {paragraph}{Why Distillation Works}{1167}{section*.2442}%
\contentsline {paragraph}{Quantitative Results and Analysis}{1168}{section*.2443}%
\contentsline {paragraph}{Conclusion}{1169}{section*.2447}%
\contentsline {subsection}{\numberline {22.3.8}ReLIC: Representation Learning via Invariant Causal Mechanisms}{1170}{subsection.22.3.8}%
\contentsline {paragraph}{Motivation and Causal Assumptions}{1170}{section*.2448}%
\contentsline {paragraph}{Learning via Invariant Proxy Prediction}{1170}{section*.2449}%
\contentsline {paragraph}{Summary}{1171}{section*.2451}%
\contentsline {paragraph}{From Proxy Tasks to Instance Discrimination}{1172}{section*.2452}%
\contentsline {paragraph}{ReLIC Architecture and Training Setup}{1172}{section*.2454}%
\contentsline {paragraph}{Contrastive and Distributional Loss Terms}{1173}{section*.2455}%
\contentsline {paragraph}{Loss Term 1: Instance-Level Contrastive Learning}{1174}{section*.2456}%
\contentsline {paragraph}{Loss Term 2: KL Regularization for Distributional Invariance}{1176}{section*.2458}%
\contentsline {paragraph}{From Causal Motivation to Loss Construction}{1177}{section*.2460}%
\contentsline {paragraph}{ReLIC Objective}{1178}{section*.2461}%
\contentsline {paragraph}{Architecture and Implementation Details}{1179}{section*.2462}%
\contentsline {paragraph}{Performance and Evaluation}{1179}{section*.2464}%
\contentsline {paragraph}{Summary and Outlook}{1179}{section*.2465}%
\contentsline {subsection}{\numberline {22.3.9}ReLICv2: Enhanced Invariant Representation Learning}{1180}{subsection.22.3.9}%
\contentsline {subsubsection}{Motivation: From View Invariance to Causal Robustness}{1180}{section*.2466}%
\contentsline {subsubsection}{Foreground Saliency Masking}{1180}{section*.2468}%
\contentsline {subsubsection}{Multi-View Learning with Large and Small Crops}{1181}{section*.2470}%
\contentsline {subsubsection}{ReLICv2 Objective}{1181}{section*.2471}%
\contentsline {paragraph}{Term 1: Contrastive Log-Likelihood (Large-to-Large)}{1182}{section*.2472}%
\contentsline {paragraph}{Term 2: KL Divergence (Large-to-Large)}{1183}{section*.2473}%
\contentsline {paragraph}{Small-to-Large View Consistency Terms}{1184}{section*.2474}%
\contentsline {paragraph}{Training Procedure}{1185}{section*.2475}%
\contentsline {paragraph}{Empirical Evaluation and Robustness Analysis}{1186}{section*.2476}%
\contentsline {paragraph}{Linear Evaluation Performance}{1186}{section*.2477}%
\contentsline {paragraph}{Robustness and Out-of-Distribution Generalization}{1187}{section*.2479}%
\contentsline {paragraph}{Semantic Clarity and Class-wise Consistency}{1187}{section*.2481}%
\contentsline {subsubsection}{Summary}{1188}{section*.2483}%
\contentsline {subsection}{\numberline {22.3.10}Further Contrastive Innovations}{1189}{subsection.22.3.10}%
\contentsline {paragraph}{Nearest-Neighbor Contrastive Learning (NNCLR)}{1189}{section*.2484}%
\contentsline {paragraph}{Adversarial Contrastive Learning (AdCo)}{1190}{section*.2486}%
\contentsline {paragraph}{Contrastive Learning with Stronger Augmentations (CLSA)}{1190}{section*.2487}%
\contentsline {subsubsection}{Enrichment 22.3.10.1: CLSA vs.\ ReLIC: KL Divergence in Perspective}{1191}{section*.2488}%
\contentsline {paragraph}{CLSA: Distributional Distillation Across Augmentation Strength}{1191}{section*.2489}%
\contentsline {paragraph}{ReLICv1: Invariant Prediction Across Augmentations}{1191}{section*.2490}%
\contentsline {paragraph}{Two KL Terms, Two Philosophies}{1191}{section*.2491}%
\contentsline {paragraph}{Summary (CLSA vs. ReLIC)}{1192}{section*.2492}%
\contentsline {paragraph}{Comparative Landscape and Emerging Trends}{1192}{section*.2493}%
\contentsline {paragraph}{A Transition Toward Natural Supervision}{1192}{section*.2495}%
\contentsline {subsection}{\numberline {22.3.11}CLIP: Learning Transferable Visual Models from Natural Language Supervision}{1193}{subsection.22.3.11}%
\contentsline {paragraph}{Motivation: Beyond Fixed Labels}{1193}{section*.2496}%
\contentsline {paragraph}{A NaÃ¯ve Approach: Caption Prediction}{1193}{section*.2498}%
\contentsline {paragraph}{Efficiency Comparison: Contrastive vs.\ Predictive Objectives}{1194}{section*.2499}%
\contentsline {paragraph}{Why Contrastive Learning Wins}{1195}{section*.2501}%
\contentsline {paragraph}{Key Insight}{1195}{section*.2502}%
\contentsline {subsubsection}{CLIPâ€™s Contrastive Training Approach and Loss}{1196}{section*.2503}%
\contentsline {paragraph}{Training Strategy: Paired Alignment at Scale}{1196}{section*.2504}%
\contentsline {paragraph}{Symmetric Contrastive Loss}{1196}{section*.2505}%
\contentsline {paragraph}{Interpretation and Scaling Advantages}{1197}{section*.2507}%
\contentsline {paragraph}{Efficient Large-Scale Training}{1197}{section*.2508}%
\contentsline {subsubsection}{CLIP Loss Pseudo Code \& Further Explanations}{1198}{section*.2509}%
\contentsline {paragraph}{Loss Pseudo Code}{1198}{section*.2510}%
\contentsline {paragraph}{Explanation}{1198}{section*.2511}%
\contentsline {paragraph}{Intuition Behind the BCE Terms}{1199}{section*.2512}%
\contentsline {subsubsection}{CLIP Experiments and Ablations}{1199}{section*.2513}%
\contentsline {paragraph}{Zero-Shot Performance vs.\ Supervised Models}{1199}{section*.2514}%
\contentsline {paragraph}{Robustness to Natural Distribution Shift}{1200}{section*.2516}%
\contentsline {paragraph}{Linear Probe Evaluation Across Models}{1201}{section*.2518}%
\contentsline {paragraph}{Tradeoffs in Dataset-Specific Adaptation}{1202}{section*.2520}%
\contentsline {paragraph}{Summary and Practical Takeaways}{1202}{section*.2522}%
\contentsline {section}{\numberline {22.4}Self-Distillation Methods}{1203}{section.22.4}%
\contentsline {subsection}{\numberline {22.4.1}Limitations of Contrastive Learning}{1203}{subsection.22.4.1}%
\contentsline {subsection}{\numberline {22.4.2}From Contrastive Methods to Self-Distillation}{1203}{subsection.22.4.2}%
\contentsline {paragraph}{Classical Knowledge Distillation}{1203}{section*.2523}%
\contentsline {paragraph}{From Classical KD to Self-Distillation}{1205}{section*.2525}%
\contentsline {paragraph}{Self-Distillation: Teacher-Free Prediction Alignment}{1205}{section*.2526}%
\contentsline {paragraph}{Cold Start and the Bootstrapping Feedback Loop}{1206}{section*.2527}%
\contentsline {paragraph}{Final Representation: What Do We Keep?}{1207}{section*.2529}%
\contentsline {paragraph}{Introduction Summary}{1207}{section*.2530}%
\contentsline {subsection}{\numberline {22.4.3}Bootstrap Your Own Latent (BYOL)}{1208}{subsection.22.4.3}%
\contentsline {paragraph}{Motivation: Learning Without Contrast}{1208}{section*.2531}%
\contentsline {paragraph}{Architectural Overview}{1208}{section*.2532}%
\contentsline {paragraph}{Mathematical Formulation and Training Objective}{1209}{section*.2534}%
\contentsline {paragraph}{Robustness and Empirical Performance}{1210}{section*.2535}%
\contentsline {paragraph}{Linear Evaluation on ImageNet}{1210}{section*.2537}%
\contentsline {paragraph}{Semi-Supervised Evaluation}{1211}{section*.2539}%
\contentsline {paragraph}{Transfer to Downstream Tasks}{1211}{section*.2541}%
\contentsline {paragraph}{Ablation Studies and Collapse Prevention}{1211}{section*.2543}%
\contentsline {paragraph}{Conclusion}{1212}{section*.2544}%
\contentsline {subsection}{\numberline {22.4.4}SimSiam: Self-Supervised Learning Without Negative Pairs or Momentum}{1213}{subsection.22.4.4}%
\contentsline {paragraph}{Motivation: Can Collapse Be Avoided Without Negatives or EMA?}{1213}{section*.2545}%
\contentsline {paragraph}{Architecture and Symmetric Learning Mechanism}{1213}{section*.2546}%
\contentsline {paragraph}{SimSiam Training Pseudocode}{1214}{section*.2548}%
\contentsline {paragraph}{Gradient Formula and Learning Signal}{1215}{section*.2549}%
\contentsline {paragraph}{EM-Like Interpretation of SimSiam Training}{1216}{section*.2550}%
\contentsline {paragraph}{Conclusion: Stop-Gradient as a Structural Inductive Bias}{1217}{section*.2551}%
\contentsline {paragraph}{Empirical Validation of the Stop-Gradient Mechanism}{1217}{section*.2552}%
\contentsline {paragraph}{Ablation Studies and Analysis}{1218}{section*.2554}%
\contentsline {paragraph}{Comparison to Other Self-Supervised Methods}{1220}{section*.2558}%
\contentsline {paragraph}{Paper Summary}{1220}{section*.2561}%
\contentsline {subsection}{\numberline {22.4.5}DINO: Self-Distillation with No Labels}{1221}{subsection.22.4.5}%
\contentsline {paragraph}{Motivation: From Invariance to Semantic Understanding}{1221}{section*.2562}%
\contentsline {paragraph}{Self-Distillation Without Labels}{1221}{section*.2564}%
\contentsline {paragraph}{Multi-Crop Strategy and View Asymmetry}{1222}{section*.2565}%
\contentsline {paragraph}{Architectural Backbone: Why Vision Transformers?}{1224}{section*.2568}%
\contentsline {paragraph}{Preventing Collapse with Centering and Sharpening}{1224}{section*.2569}%
\contentsline {paragraph}{Asymmetric Distillation Objective}{1225}{section*.2570}%
\contentsline {paragraph}{Why Use Softmax Without Labels?}{1226}{section*.2571}%
\contentsline {paragraph}{No Predictor: Functional Asymmetry Instead of Architectural Tricks}{1227}{section*.2572}%
\contentsline {paragraph}{PyTorch-Style Pseudocode and Explanation}{1228}{section*.2573}%
\contentsline {subsubsection}{Experimental Results and Ablations for DINO}{1229}{section*.2574}%
\contentsline {paragraph}{Linear and k-NN Evaluation on ImageNet}{1229}{section*.2575}%
\contentsline {paragraph}{Transfer to Retrieval and Segmentation Tasks}{1229}{section*.2577}%
\contentsline {paragraph}{Ablation: Emergent Object Segmentation via Self-Attention}{1230}{section*.2578}%
\contentsline {paragraph}{Ablation: Semantic Structure from Unlabeled Data}{1231}{section*.2580}%
\contentsline {paragraph}{Ablation: Teacher Update Strategies}{1232}{section*.2582}%
\contentsline {paragraph}{Ablation: Collapse Prevention via Centering and Sharpening}{1233}{section*.2584}%
\contentsline {paragraph}{Ablation: Patch Size and Inference Throughput}{1233}{section*.2586}%
\contentsline {paragraph}{Ablation: Batch Size Effects}{1234}{section*.2588}%
\contentsline {paragraph}{Ablation: Multi-Crop Augmentation and Resource Tradeoffs}{1234}{section*.2590}%
\contentsline {paragraph}{Paper Conclusion}{1234}{section*.2592}%
\contentsline {subsection}{\numberline {22.4.6}DINOv2: Learning Robust Visual Features Without Supervision}{1235}{subsection.22.4.6}%
\contentsline {paragraph}{Background and Motivation}{1235}{section*.2593}%
\contentsline {paragraph}{Emergent Semantic Structure Without Labels}{1235}{section*.2595}%
\contentsline {paragraph}{Scaling Training through Architectural and Data Efficiency}{1236}{section*.2596}%
\contentsline {paragraph}{Data Processing in DINOv2}{1236}{section*.2597}%
\contentsline {subsubsection}{SSCD: A Self-Supervised Descriptor for Image Copy Detection}{1237}{section*.2599}%
\contentsline {paragraph}{Motivation for Copy Detection in DINOv2}{1237}{section*.2600}%
\contentsline {paragraph}{Core Architecture and Augmentations}{1240}{section*.2602}%
\contentsline {paragraph}{Post-Processing via Whitening and Synergy with Training}{1240}{section*.2603}%
\contentsline {paragraph}{Augmentation Pipeline for Real-World Tampering}{1241}{section*.2604}%
\contentsline {paragraph}{Loss Formulation with Entropy and Mixed Positives}{1242}{section*.2605}%
\contentsline {paragraph}{Empirical Results and Impact}{1244}{section*.2607}%
\contentsline {subsubsection}{Masked Autoencoders (MAE): Scalable Vision Learners}{1245}{section*.2608}%
\contentsline {paragraph}{Asymmetric Architecture and High-Ratio Masking}{1246}{section*.2610}%
\contentsline {paragraph}{Empirical Results and Qualitative Analysis}{1248}{section*.2612}%
\contentsline {subsubsection}{iBOT: Masked Image Modeling with Self-Distillation}{1251}{section*.2618}%
\contentsline {paragraph}{iBOT Loss Function and Self-Distillation Objective}{1253}{section*.2620}%
\contentsline {paragraph}{iBOT Training Procedure}{1256}{section*.2621}%
\contentsline {paragraph}{Empirical Results and Evaluation}{1257}{section*.2623}%
\contentsline {paragraph}{Ablation Studies and Component Analysis}{1259}{section*.2628}%
\contentsline {paragraph}{iBOT vs. DINO: Paving the Way for DINOv2}{1260}{section*.2631}%
\contentsline {paragraph}{Sinkhorn--Knopp Centering in DINOv2}{1261}{section*.2632}%
\contentsline {paragraph}{Sinkhorn--Knopp Algorithm (NumPy Pseudocode)}{1263}{section*.2633}%
\contentsline {paragraph}{Explanation and DINOv2 Motivation}{1264}{section*.2634}%
\contentsline {paragraph}{Toy Example: The Fair Project Manager}{1264}{section*.2635}%
\contentsline {paragraph}{Connection to DINOv2}{1266}{section*.2636}%
\contentsline {paragraph}{Linear Evaluation on ImageNet and Comparison to Prior Work}{1267}{section*.2637}%
\contentsline {paragraph}{Ablation of Design Modifications from iBOT to DINOv2}{1268}{section*.2639}%
\contentsline {paragraph}{Ablation of Pretraining Data: LVD-142M vs ImageNet-22k}{1269}{section*.2641}%
\contentsline {paragraph}{Effectiveness of Knowledge Distillation from DINOv2}{1270}{section*.2643}%
\contentsline {paragraph}{Transfer to Diverse Visual Tasks}{1271}{section*.2645}%
\contentsline {paragraph}{From Self-Distillation to Clustering-Based Objectives}{1271}{section*.2646}%
\contentsline {section}{\numberline {22.5}Clustering Methods}{1272}{section.22.5}%
\contentsline {subsection}{\numberline {22.5.1}SwAV: Online Clustering via Swapped Assignments}{1272}{subsection.22.5.1}%
\contentsline {paragraph}{From Contrastive Bottlenecks to Clustering-Based Self-Supervision}{1272}{section*.2647}%
\contentsline {subsubsection}{Architecture and Training Pipeline}{1273}{section*.2649}%
\contentsline {paragraph}{Multi-crop Augmentation and Swapped Prediction}{1273}{section*.2650}%
\contentsline {paragraph}{Training Objective and Prototype Updates}{1274}{section*.2651}%
\contentsline {paragraph}{Summary}{1275}{section*.2653}%
\contentsline {subsubsection}{Empirical Results and Key Findings}{1275}{section*.2654}%
\contentsline {paragraph}{Benchmarking on ImageNet}{1276}{section*.2655}%
\contentsline {paragraph}{Transfer to Downstream Tasks}{1276}{section*.2656}%
\contentsline {paragraph}{Training Efficiency and Accessibility}{1276}{section*.2657}%
\contentsline {paragraph}{Ablation Highlights}{1276}{section*.2658}%
\contentsline {paragraph}{Impact and Legacy}{1276}{section*.2659}%
\contentsline {section}{\numberline {22.6}Feature Decorrelation Methods}{1277}{section.22.6}%
\contentsline {subsection}{\numberline {22.6.1}Barlow Twins: Feature Decorrelation without Negatives}{1277}{subsection.22.6.1}%
\contentsline {paragraph}{Method Overview}{1277}{section*.2661}%
\contentsline {paragraph}{Redundancy Reduction Loss}{1278}{section*.2662}%
\contentsline {paragraph}{Practical Details}{1278}{section*.2664}%
\contentsline {subsubsection}{Empirical Results and Ablation Studies}{1279}{section*.2665}%
\contentsline {paragraph}{Linear Evaluation on ImageNet}{1279}{section*.2666}%
\contentsline {paragraph}{Transfer Learning Performance}{1279}{section*.2668}%
\contentsline {paragraph}{Ablation Studies}{1280}{section*.2670}%
\contentsline {paragraph}{Batch Size Robustness}{1280}{section*.2672}%
\contentsline {paragraph}{Effect of Projector Dimensionality}{1281}{section*.2674}%
\contentsline {paragraph}{Sensitivity to Augmentations}{1281}{section*.2676}%
\contentsline {paragraph}{Hyperparameter Stability}{1282}{section*.2678}%
\contentsline {paragraph}{Summary and Outlook}{1282}{section*.2680}%
\contentsline {subsection}{\numberline {22.6.2}VICReg: Variance-Invariance-Covariance Regularization}{1283}{subsection.22.6.2}%
\contentsline {subsubsection}{Invariance Term: Similarity Loss}{1284}{section*.2682}%
\contentsline {subsubsection}{Variance Term: Spread Preservation}{1285}{section*.2683}%
\contentsline {subsubsection}{Covariance Term: Redundancy Reduction}{1285}{section*.2684}%
\contentsline {subsubsection}{Implementation Details and Empirical Evaluation}{1287}{section*.2685}%
\contentsline {paragraph}{Training Setup}{1287}{section*.2686}%
\contentsline {paragraph}{Linear Evaluation on ImageNet}{1287}{section*.2687}%
\contentsline {paragraph}{Transfer Learning Performance}{1287}{section*.2689}%
\contentsline {paragraph}{Robustness to Batch Size}{1288}{section*.2691}%
\contentsline {paragraph}{Summary of Empirical Results}{1288}{section*.2692}%
\contentsline {subsubsection}{Ablation Studies and Objective Decomposition}{1288}{section*.2693}%
\contentsline {paragraph}{Effect of Removing Loss Terms}{1288}{section*.2694}%
\contentsline {paragraph}{Architectural Robustness}{1289}{section*.2696}%
\contentsline {paragraph}{Comparison with Whitening-Based Methods}{1289}{section*.2697}%
\contentsline {paragraph}{Ablation Summary}{1289}{section*.2698}%
\contentsline {section}{\numberline {22.7}Adapting SSL to Downstream Tasks}{1290}{section.22.7}%
\contentsline {subsection}{\numberline {22.7.1}Aligning Backbone Structure with Task Demands}{1290}{subsection.22.7.1}%
\contentsline {paragraph}{Masked Image Modeling: Prioritizing Spatial Detail}{1290}{section*.2699}%
\contentsline {paragraph}{Contrastive and Clustering Methods: Emphasizing Semantic Structure}{1290}{section*.2700}%
\contentsline {paragraph}{Hybrid Approaches: Balancing Spatial and Semantic Information}{1290}{section*.2701}%
\contentsline {paragraph}{Recommended Usage}{1291}{section*.2702}%
\contentsline {subsection}{\numberline {22.7.2}Data Distribution and Domain Shift Considerations}{1291}{subsection.22.7.2}%
\contentsline {paragraph}{Diagnosing Domain Shift}{1291}{section*.2703}%
\contentsline {paragraph}{Should We Try Multiple Backbones?}{1292}{section*.2704}%
\contentsline {paragraph}{Summary}{1292}{section*.2705}%
\contentsline {section}{\numberline {22.8}Fine-Tuning Self-Supervised Backbones}{1292}{section.22.8}%
\contentsline {subsection}{\numberline {22.8.1}Choosing an Adaptation Strategy: Data, Domain, and Cost}{1292}{subsection.22.8.1}%
\contentsline {subsubsection}{(1) Linear Probing and Lightweight Heads}{1292}{section*.2706}%
\contentsline {subsubsection}{(2) Parameter-Efficient Fine-Tuning (PEFT)}{1293}{section*.2707}%
\contentsline {paragraph}{Why Use PEFT?}{1293}{section*.2708}%
\contentsline {paragraph}{Common PEFT Strategies}{1293}{section*.2709}%
\contentsline {paragraph}{Practical Considerations}{1293}{section*.2711}%
\contentsline {subsubsection}{(3) Progressive Unfreezing and LP-FT}{1294}{section*.2712}%
\contentsline {paragraph}{Progressive Unfreezing}{1294}{section*.2713}%
\contentsline {paragraph}{Linear-Probe-Then-Fine-Tune (LP-FT)}{1294}{section*.2714}%
\contentsline {subsubsection}{(4) Full Fine-Tuning (FFT)}{1294}{section*.2715}%
\contentsline {subsubsection}{(5) Continued Self-Supervised Pretraining (C-SSL)}{1294}{section*.2716}%
\contentsline {paragraph}{Why Curation Beats Raw Scale}{1295}{section*.2717}%
\contentsline {paragraph}{Curation Workflow: Practical Steps}{1295}{section*.2718}%
\contentsline {paragraph}{Illustrative Case Study: Learning Artistic Style}{1296}{section*.2719}%
\contentsline {paragraph}{Challenge: Content-Biased Representations}{1296}{section*.2720}%
\contentsline {paragraph}{C-SSL Solution: Re-centering on Style}{1296}{section*.2721}%
\contentsline {paragraph}{Outcome: Efficient Style Recognition}{1296}{section*.2722}%
\contentsline {paragraph}{Summary: Fine-Tuning Strategies for Self-Supervised Models}{1297}{section*.2723}%
\contentsline {subsection}{\numberline {22.8.2}Linear Probing and MLP Head Adaptation}{1298}{subsection.22.8.2}%
\contentsline {paragraph}{Purpose and Motivation}{1298}{section*.2725}%
\contentsline {paragraph}{Application Procedure}{1298}{section*.2726}%
\contentsline {paragraph}{Hyperparameter Recommendations}{1299}{section*.2727}%
\contentsline {paragraph}{Practical Tips and Diagnostic Insights}{1299}{section*.2728}%
\contentsline {paragraph}{When to Escalate to LoRA or Other PEFT Techniques}{1299}{section*.2729}%
\contentsline {paragraph}{Best Practices}{1300}{section*.2730}%
\contentsline {paragraph}{Empirical Signal for Escalation}{1300}{section*.2731}%
\contentsline {subsection}{\numberline {22.8.3}Low-Rank Adaptation (LoRA) for Efficient Transfer}{1301}{subsection.22.8.3}%
\contentsline {paragraph}{Motivation and Intuition}{1301}{section*.2732}%
\contentsline {paragraph}{Mechanism}{1301}{section*.2733}%
\contentsline {paragraph}{Initialization and Forward Pass}{1301}{section*.2734}%
\contentsline {paragraph}{The Role of the Scaling Factor \( \alpha / r \)}{1301}{section*.2735}%
\contentsline {paragraph}{Tuning \( \alpha \) in Practice}{1301}{section*.2736}%
\contentsline {paragraph}{Empirical Findings and Low-Rank Capacity}{1302}{section*.2737}%
\contentsline {paragraph}{Inference-Time Behavior}{1302}{section*.2738}%
\contentsline {paragraph}{Advantages of LoRA}{1302}{section*.2739}%
\contentsline {paragraph}{Recommended Hyperparameters}{1302}{section*.2740}%
\contentsline {paragraph}{Example: PyTorch-style LoRA Setup}{1303}{section*.2741}%
\contentsline {paragraph}{When LoRA Is Not Enough}{1303}{section*.2742}%
\contentsline {paragraph}{Variants and Extensions}{1303}{section*.2743}%
\contentsline {paragraph}{Why They Matter}{1304}{section*.2744}%
\contentsline {paragraph}{Summary}{1304}{section*.2745}%
\contentsline {subsection}{\numberline {22.8.4}Progressive Unfreezing and LP-FT}{1305}{subsection.22.8.4}%
\contentsline {paragraph}{Motivation}{1305}{section*.2746}%
\contentsline {paragraph}{Progressive Unfreezing: Controlled Backbone Adaptation}{1305}{section*.2747}%
\contentsline {paragraph}{Example Schedule}{1305}{section*.2748}%
\contentsline {paragraph}{LP-FT: Linear Probing Followed by Full Fine-Tuning}{1305}{section*.2749}%
\contentsline {paragraph}{Best Use Cases}{1306}{section*.2750}%
\contentsline {paragraph}{Decision Guidelines}{1306}{section*.2751}%
\contentsline {paragraph}{Summary}{1306}{section*.2752}%
\contentsline {chapter}{\numberline {23}Lecture 23: 3D vision}{1307}{chapter.23}%
\ttl@stoptoc {default@22}
\ttl@starttoc {default@23}
\contentsline {chapter}{\numberline {24}Lecture 24: Videos}{1308}{chapter.24}%
\ttl@stoptoc {default@23}
\ttl@starttoc {default@24}
\contentsfinish 
