\relax 
\providecommand\zref@newlabel[2]{}
\abx@aux@refcontext{nty/global//global/global/global}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\babel@aux{english}{}
\pgfsyspdfmark {pgfid2}{0}{52099153}
\pgfsyspdfmark {pgfid1}{5966969}{45620378}
\BKM@entry{id=1,dest={636861707465722A2E32},srcline={97}}{5C3337365C3337375C303030505C303030725C303030655C303030665C303030615C303030635C30303065}
\BKM@entry{id=2,dest={73656374696F6E2E302E31},srcline={99}}{5C3337365C3337375C303030475C303030655C303030745C303030745C303030695C3030306E5C303030675C3030305C3034305C303030535C303030745C303030615C303030725C303030745C303030655C303030645C3030303A5C3030305C3034305C303030415C303030625C3030306F5C303030755C303030745C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030505C303030725C3030306F5C3030306A5C303030655C303030635C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030485C3030306F5C303030775C3030305C3034305C303030745C3030306F5C3030305C3034305C3030304E5C303030615C303030765C303030695C303030675C303030615C303030745C303030655C3030305C3034305C303030495C30303074}
\BKM@entry{id=3,dest={73756273656374696F6E2E302E312E31},srcline={101}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030545C303030685C303030695C303030735C3030305C3034305C303030445C3030306F5C303030635C303030755C3030306D5C303030655C3030306E5C303030745C3030303F}
\BKM@entry{id=4,dest={73756273656374696F6E2E302E312E32},srcline={108}}{5C3337365C3337375C303030415C303030635C3030306B5C3030306E5C3030306F5C303030775C3030306C5C303030655C303030645C303030675C3030306D5C303030655C3030306E5C303030745C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030745C303030725C303030695C303030625C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=5,dest={73756273656374696F6E2E302E312E33},srcline={111}}{5C3337365C3337375C303030595C3030306F5C303030755C303030725C3030305C3034305C303030465C303030655C303030655C303030645C303030625C303030615C303030635C3030306B5C3030305C3034305C3030304D5C303030615C303030745C303030745C303030655C303030725C30303073}
\pgfsyspdfmark {pgfid4}{0}{52099153}
\pgfsyspdfmark {pgfid3}{5966969}{45620378}
\@writefile{toc}{\contentsline {chapter}{Preface}{18}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Getting Started: About the Project and How to Navigate It}{18}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}Why This Document?}{18}{subsection.0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}Acknowledgments and Contributions}{18}{subsection.0.1.2}\protected@file@percent }
\BKM@entry{id=6,dest={73756273656374696F6E2E302E312E34},srcline={114}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030745C3030306F5C3030305C3034305C3030304E5C303030615C303030765C303030695C303030675C303030615C303030745C303030655C3030305C3034305C303030545C303030685C303030695C303030735C3030305C3034305C303030445C3030306F5C303030635C303030755C3030306D5C303030655C3030306E5C30303074}
\BKM@entry{id=7,dest={73756273656374696F6E2E302E312E35},srcline={122}}{5C3337365C3337375C303030535C303030745C303030615C303030795C303030695C3030306E5C303030675C3030305C3034305C303030555C303030705C303030645C303030615C303030745C303030655C303030645C3030305C3034305C303030695C3030306E5C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030465C303030695C303030655C3030306C5C30303064}
\BKM@entry{id=8,dest={73756273656374696F6E2E302E312E36},srcline={125}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030495C3030306D5C303030705C3030306F5C303030725C303030745C303030615C3030306E5C303030635C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030505C303030725C303030615C303030635C303030745C303030695C303030635C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.3}Your Feedback Matters}{19}{subsection.0.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.4}How to Navigate This Document}{19}{subsection.0.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.5}Staying Updated in the Field}{19}{subsection.0.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.6}The Importance of Practice}{19}{subsection.0.1.6}\protected@file@percent }
\BKM@entry{id=9,dest={636861707465722E31},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C3030303A5C3030305C3034305C303030435C3030306F5C303030755C303030725C303030735C303030655C3030305C3034305C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=10,dest={73656374696F6E2E312E31},srcline={13}}{5C3337365C3337375C303030435C3030306F5C303030725C303030655C3030305C3034305C303030545C303030655C303030725C3030306D5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030465C303030695C303030655C3030306C5C30303064}
\BKM@entry{id=11,dest={73756273656374696F6E2E312E312E31},srcline={17}}{5C3337365C3337375C303030415C303030725C303030745C303030695C303030665C303030695C303030635C303030695C303030615C3030306C5C3030305C3034305C303030495C3030306E5C303030745C303030655C3030306C5C3030306C5C303030695C303030675C303030655C3030306E5C303030635C303030655C3030305C3034305C3030305C3035305C303030415C303030495C3030305C303531}
\BKM@entry{id=12,dest={73756273656374696F6E2E312E312E32},srcline={22}}{5C3337365C3337375C3030304D5C303030615C303030635C303030685C303030695C3030306E5C303030655C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030305C3035305C3030304D5C3030304C5C3030305C303531}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Lecture 1: Course Introduction}{20}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@starttoc{default@1}}
\pgfsyspdfmark {pgfid6}{0}{52099153}
\pgfsyspdfmark {pgfid5}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Core Terms in the Field}{20}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Artificial Intelligence (AI)}{20}{subsection.1.1.1}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-1}{\default{1.1.1}\page{20}\abspage{20}\mdf@pagevalue{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Machine Learning (ML)}{20}{subsection.1.1.2}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-2}{\default{1.1.2}\page{20}\abspage{20}\mdf@pagevalue{20}}
\BKM@entry{id=13,dest={73756273656374696F6E2E312E312E33},srcline={34}}{5C3337365C3337375C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030305C3035305C303030445C3030304C5C3030305C303531}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Deep Learning (DL)}{21}{subsection.1.1.3}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-3}{\default{1.1.3}\page{21}\abspage{21}\mdf@pagevalue{21}}
\BKM@entry{id=14,dest={73756273656374696F6E2E312E312E34},srcline={41}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030435C303030565C3030305C303531}
\BKM@entry{id=15,dest={73756273656374696F6E2E312E312E35},srcline={46}}{5C3337365C3337375C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030445C3030306F5C303030745C30303073}
\BKM@entry{id=16,dest={73656374696F6E2E312E32},srcline={62}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030535C303030745C303030755C303030645C303030795C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E5C3030303F}
\BKM@entry{id=17,dest={73756273656374696F6E2E312E322E31},srcline={65}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Computer Vision (CV)}{22}{subsection.1.1.4}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-4}{\default{1.1.4}\page{22}\abspage{22}\mdf@pagevalue{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.5}Connecting the Dots}{22}{subsection.1.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces In this course, we study 'Deep Learning' for Computer Vision.}}{22}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:chapter1_slide13}{{1.1}{22}{In this course, we study 'Deep Learning' for Computer Vision}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why Study Deep Learning for Computer Vision?}{22}{section.1.2}\protected@file@percent }
\abx@aux@cite{0}{appen_road_annotation}
\abx@aux@segm{0}{0}{appen_road_annotation}
\abx@aux@cite{0}{appen_road_annotation}
\abx@aux@segm{0}{0}{appen_road_annotation}
\BKM@entry{id=18,dest={73656374696F6E2E312E33},srcline={80}}{5C3337365C3337375C303030485C303030695C303030735C303030745C3030306F5C303030725C303030695C303030635C303030615C3030306C5C3030305C3034305C3030304D5C303030695C3030306C5C303030655C303030735C303030745C3030306F5C3030306E5C303030655C30303073}
\BKM@entry{id=19,dest={73756273656374696F6E2E312E332E31},srcline={85}}{5C3337365C3337375C303030485C303030755C303030625C303030655C3030306C5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030575C303030695C303030655C303030735C303030655C3030306C5C3030305C3034305C3030305C3035305C303030315C303030395C303030355C303030395C3030305C3035315C3030303A5C3030305C3034305C303030485C3030306F5C303030775C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C303030575C3030306F5C303030725C3030306B5C303030735C3030303F}
\abx@aux@cite{0}{hubel1959_receptivefields}
\abx@aux@segm{0}{0}{hubel1959_receptivefields}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Motivation for Deep Learning in Computer Vision}{23}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Road annotation for autonomous vehicles. Image credit: Appen \blx@tocontentsinit {0}\cite {appen_road_annotation}.}}{23}{figure.caption.4}\protected@file@percent }
\abx@aux@backref{2}{appen_road_annotation}{0}{23}{23}
\newlabel{fig:road_annotation}{{1.2}{23}{Road annotation for autonomous vehicles. Image credit: Appen \cite {appen_road_annotation}}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Historical Milestones}{23}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Hubel and Wiesel (1959): How Vision Works?}{23}{subsection.1.3.1}\protected@file@percent }
\abx@aux@cite{0}{hubel1959_receptivefields}
\abx@aux@segm{0}{0}{hubel1959_receptivefields}
\abx@aux@cite{0}{hubel1959_receptivefields}
\abx@aux@segm{0}{0}{hubel1959_receptivefields}
\BKM@entry{id=20,dest={73756273656374696F6E2E312E332E32},srcline={95}}{5C3337365C3337375C3030304C5C303030615C303030725C303030725C303030795C3030305C3034305C303030525C3030306F5C303030625C303030655C303030725C303030745C303030735C3030305C3034305C3030305C3035305C303030315C303030395C303030365C303030335C3030305C3035315C3030303A5C3030305C3034305C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030455C303030645C303030675C303030655C303030735C3030305C3034305C303030745C3030306F5C3030305C3034305C3030304B5C303030655C303030795C303030705C3030306F5C303030695C3030306E5C303030745C30303073}
\abx@aux@cite{0}{roberts1963_3dsolids}
\abx@aux@segm{0}{0}{roberts1963_3dsolids}
\abx@aux@cite{0}{roberts1963_3dsolids}
\abx@aux@segm{0}{0}{roberts1963_3dsolids}
\abx@aux@cite{0}{roberts1963_3dsolids}
\abx@aux@segm{0}{0}{roberts1963_3dsolids}
\abx@aux@backref{3}{hubel1959_receptivefields}{0}{24}{24}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Hubel \& Wiesel's study, revolutionizing our understanding of visual processing \blx@tocontentsinit {0}\cite {hubel1959_receptivefields}.}}{24}{figure.caption.5}\protected@file@percent }
\abx@aux@backref{5}{hubel1959_receptivefields}{0}{24}{24}
\newlabel{fig:chapter1_slide16}{{1.3}{24}{Hubel \& Wiesel's study, revolutionizing our understanding of visual processing \cite {hubel1959_receptivefields}}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Larry Roberts (1963): From Edges to Keypoints}{24}{subsection.1.3.2}\protected@file@percent }
\abx@aux@backref{6}{roberts1963_3dsolids}{0}{24}{24}
\BKM@entry{id=21,dest={73756273656374696F6E2E312E332E33},srcline={105}}{5C3337365C3337375C303030445C303030615C303030765C303030695C303030645C3030305C3034305C3030304D5C303030615C303030725C303030725C3030305C3034305C3030305C3035305C303030315C303030395C303030375C303030305C303030735C3030305C3035315C3030303A5C3030305C3034305C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C303030735C3030305C3034305C303030745C3030306F5C3030305C3034305C303030615C3030305C3034305C303030335C303030445C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C}
\abx@aux@cite{0}{marr1982_vision}
\abx@aux@segm{0}{0}{marr1982_vision}
\abx@aux@cite{0}{marr1982_vision}
\abx@aux@segm{0}{0}{marr1982_vision}
\abx@aux@cite{0}{marr1982_vision}
\abx@aux@segm{0}{0}{marr1982_vision}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Larry Roberts' 1963 thesis introduced edge detection as a critical component of early computer vision systems \blx@tocontentsinit {0}\cite {roberts1963_3dsolids}.}}{25}{figure.caption.6}\protected@file@percent }
\abx@aux@backref{8}{roberts1963_3dsolids}{0}{25}{25}
\newlabel{fig:chapter1_roberts}{{1.4}{25}{Larry Roberts' 1963 thesis introduced edge detection as a critical component of early computer vision systems \cite {roberts1963_3dsolids}}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}David Marr (1970s): From Features to a 3D Model}{25}{subsection.1.3.3}\protected@file@percent }
\abx@aux@backref{9}{marr1982_vision}{0}{25}{25}
\BKM@entry{id=22,dest={73756273656374696F6E2E312E332E34},srcline={123}}{5C3337365C3337375C303030525C303030655C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030765C303030695C303030615C3030305C3034305C303030505C303030615C303030725C303030745C303030735C3030305C3034305C3030305C3035305C303030315C303030395C303030375C303030305C303030735C3030305C303531}
\abx@aux@cite{0}{brooks1979_modelbased}
\abx@aux@segm{0}{0}{brooks1979_modelbased}
\abx@aux@cite{0}{fischler1973_pictorialstructures}
\abx@aux@segm{0}{0}{fischler1973_pictorialstructures}
\abx@aux@cite{0}{brooks1979_modelbased}
\abx@aux@segm{0}{0}{brooks1979_modelbased}
\abx@aux@cite{0}{fischler1973_pictorialstructures}
\abx@aux@segm{0}{0}{fischler1973_pictorialstructures}
\abx@aux@cite{0}{brooks1979_modelbased}
\abx@aux@segm{0}{0}{brooks1979_modelbased}
\abx@aux@cite{0}{fischler1973_pictorialstructures}
\abx@aux@segm{0}{0}{fischler1973_pictorialstructures}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces David Marr's theory of multi-stage visual processing \blx@tocontentsinit {0}\cite {marr1982_vision}.}}{26}{figure.caption.7}\protected@file@percent }
\abx@aux@backref{11}{marr1982_vision}{0}{26}{26}
\newlabel{fig:chapter1_marr}{{1.5}{26}{David Marr's theory of multi-stage visual processing \cite {marr1982_vision}}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Recognition via Parts (1970s)}{26}{subsection.1.3.4}\protected@file@percent }
\abx@aux@backref{12}{brooks1979_modelbased}{0}{26}{26}
\abx@aux@backref{13}{fischler1973_pictorialstructures}{0}{26}{26}
\BKM@entry{id=23,dest={73756273656374696F6E2E312E332E35},srcline={138}}{5C3337365C3337375C303030525C303030655C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030765C303030695C303030615C3030305C3034305C303030455C303030645C303030675C303030655C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030315C303030395C303030385C303030305C303030735C3030305C303531}
\abx@aux@cite{0}{canny1986_edgedetection}
\abx@aux@segm{0}{0}{canny1986_edgedetection}
\abx@aux@cite{0}{lowe1987_objectrecognition}
\abx@aux@segm{0}{0}{lowe1987_objectrecognition}
\abx@aux@cite{0}{canny1986_edgedetection}
\abx@aux@segm{0}{0}{canny1986_edgedetection}
\abx@aux@cite{0}{lowe1987_objectrecognition}
\abx@aux@segm{0}{0}{lowe1987_objectrecognition}
\abx@aux@cite{0}{canny1986_edgedetection}
\abx@aux@segm{0}{0}{canny1986_edgedetection}
\abx@aux@cite{0}{lowe1987_objectrecognition}
\abx@aux@segm{0}{0}{lowe1987_objectrecognition}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Recognition via parts: Generalized Cylinders and Pictorial Structures, foundational to modern object recognition \blx@tocontentsinit {0}\cite {brooks1979_modelbased, fischler1973_pictorialstructures}.}}{27}{figure.caption.8}\protected@file@percent }
\abx@aux@backref{16}{brooks1979_modelbased}{0}{27}{27}
\abx@aux@backref{17}{fischler1973_pictorialstructures}{0}{27}{27}
\newlabel{fig:chapter1_parts_recognition}{{1.6}{27}{Recognition via parts: Generalized Cylinders and Pictorial Structures, foundational to modern object recognition \cite {brooks1979_modelbased, fischler1973_pictorialstructures}}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}Recognition via Edge Detection (1980s)}{27}{subsection.1.3.5}\protected@file@percent }
\abx@aux@backref{18}{canny1986_edgedetection}{0}{27}{27}
\abx@aux@backref{19}{lowe1987_objectrecognition}{0}{27}{27}
\BKM@entry{id=24,dest={73756273656374696F6E2E312E332E36},srcline={157}}{5C3337365C3337375C303030525C303030655C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030765C303030695C303030615C3030305C3034305C303030475C303030725C3030306F5C303030755C303030705C303030695C3030306E5C303030675C3030305C3034305C3030305C3035305C303030315C303030395C303030395C303030305C303030735C3030305C303531}
\abx@aux@cite{0}{shi1997_normalizedcuts}
\abx@aux@segm{0}{0}{shi1997_normalizedcuts}
\abx@aux@cite{0}{shi1997_normalizedcuts}
\abx@aux@segm{0}{0}{shi1997_normalizedcuts}
\abx@aux@cite{0}{shi1997_normalizedcuts}
\abx@aux@segm{0}{0}{shi1997_normalizedcuts}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Recognition via edge detection: Canny Edge Detector and template matching by Lowe, foundational to object detection \blx@tocontentsinit {0}\cite {canny1986_edgedetection, lowe1987_objectrecognition}.}}{28}{figure.caption.9}\protected@file@percent }
\abx@aux@backref{22}{canny1986_edgedetection}{0}{28}{28}
\abx@aux@backref{23}{lowe1987_objectrecognition}{0}{28}{28}
\newlabel{fig:chapter1_edge_detection}{{1.7}{28}{Recognition via edge detection: Canny Edge Detector and template matching by Lowe, foundational to object detection \cite {canny1986_edgedetection, lowe1987_objectrecognition}}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.6}Recognition via Grouping (1990s)}{28}{subsection.1.3.6}\protected@file@percent }
\abx@aux@backref{24}{shi1997_normalizedcuts}{0}{28}{28}
\BKM@entry{id=25,dest={73756273656374696F6E2E312E332E37},srcline={178}}{5C3337365C3337375C303030525C303030655C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030765C303030695C303030615C3030305C3034305C3030304D5C303030615C303030745C303030635C303030685C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030425C303030655C3030306E5C303030635C303030685C3030306D5C303030615C303030725C3030306B5C303030695C3030306E5C303030675C3030305C3034305C3030305C3035305C303030325C303030305C303030305C303030305C303030735C3030305C303531}
\abx@aux@cite{0}{lowe1999_sift}
\abx@aux@segm{0}{0}{lowe1999_sift}
\abx@aux@cite{0}{lowe1999_sift}
\abx@aux@segm{0}{0}{lowe1999_sift}
\abx@aux@cite{0}{lowe1999_sift}
\abx@aux@segm{0}{0}{lowe1999_sift}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Recognition via grouping: Normalized Cuts by Shi and Malik, a groundbreaking approach to image segmentation \blx@tocontentsinit {0}\cite {shi1997_normalizedcuts}.}}{29}{figure.caption.10}\protected@file@percent }
\abx@aux@backref{26}{shi1997_normalizedcuts}{0}{29}{29}
\newlabel{fig:chapter1_grouping}{{1.8}{29}{Recognition via grouping: Normalized Cuts by Shi and Malik, a groundbreaking approach to image segmentation \cite {shi1997_normalizedcuts}}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.7}Recognition via Matching and Benchmarking (2000s)}{29}{subsection.1.3.7}\protected@file@percent }
\abx@aux@backref{27}{lowe1999_sift}{0}{29}{29}
\abx@aux@cite{0}{viola2001_boosteddetection}
\abx@aux@segm{0}{0}{viola2001_boosteddetection}
\abx@aux@cite{0}{viola2001_boosteddetection}
\abx@aux@segm{0}{0}{viola2001_boosteddetection}
\abx@aux@cite{0}{viola2001_boosteddetection}
\abx@aux@segm{0}{0}{viola2001_boosteddetection}
\abx@aux@cite{0}{pascal2010_visualchallenge}
\abx@aux@segm{0}{0}{pascal2010_visualchallenge}
\abx@aux@cite{0}{pascal2010_visualchallenge}
\abx@aux@segm{0}{0}{pascal2010_visualchallenge}
\abx@aux@cite{0}{pascal2010_visualchallenge}
\abx@aux@segm{0}{0}{pascal2010_visualchallenge}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces SIFT: A groundbreaking feature matching algorithm introduced by Lowe in 1999 \blx@tocontentsinit {0}\cite {lowe1999_sift}.}}{30}{figure.caption.11}\protected@file@percent }
\abx@aux@backref{29}{lowe1999_sift}{0}{30}{30}
\newlabel{fig:chapter1_sift}{{1.9}{30}{SIFT: A groundbreaking feature matching algorithm introduced by Lowe in 1999 \cite {lowe1999_sift}}{figure.caption.11}{}}
\abx@aux@backref{30}{viola2001_boosteddetection}{0}{30}{30}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Viola-Jones face detection algorithm, a milestone in real-time object detection \blx@tocontentsinit {0}\cite {viola2001_boosteddetection}.}}{30}{figure.caption.12}\protected@file@percent }
\abx@aux@backref{32}{viola2001_boosteddetection}{0}{30}{30}
\newlabel{fig:chapter1_viola_jones}{{1.10}{30}{Viola-Jones face detection algorithm, a milestone in real-time object detection \cite {viola2001_boosteddetection}}{figure.caption.12}{}}
\abx@aux@backref{33}{pascal2010_visualchallenge}{0}{30}{30}
\BKM@entry{id=26,dest={73756273656374696F6E2E312E332E38},srcline={214}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030304E5C303030655C303030745C3030305C3034305C303030445C303030615C303030745C303030615C303030735C303030655C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C30303065}
\abx@aux@cite{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@segm{0}{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\abx@aux@cite{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@segm{0}{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\abx@aux@cite{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@segm{0}{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces PASCAL Visual Object Challenge: A benchmark for object detection \& recognition \blx@tocontentsinit {0}\cite {pascal2010_visualchallenge}.}}{31}{figure.caption.13}\protected@file@percent }
\abx@aux@backref{35}{pascal2010_visualchallenge}{0}{31}{31}
\newlabel{fig:chapter1_pascal}{{1.11}{31}{PASCAL Visual Object Challenge: A benchmark for object detection \& recognition \cite {pascal2010_visualchallenge}}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.8}The ImageNet Dataset and Classification Challenge}{31}{subsection.1.3.8}\protected@file@percent }
\abx@aux@backref{36}{imagenet2009_hierarchicaldatabase}{0}{31}{31}
\abx@aux@backref{37}{krizhevsky2012_alexnet}{0}{31}{31}
\BKM@entry{id=27,dest={73756273656374696F6E2E312E332E39},srcline={231}}{5C3337365C3337375C303030415C3030306C5C303030655C303030785C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030415C3030305C3034305C303030525C303030655C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030325C303030305C303030315C303030325C3030305C303531}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Advances in the ImageNet Classification Challenge \blx@tocontentsinit {0}\cite {imagenet2009_hierarchicaldatabase, krizhevsky2012_alexnet}.}}{32}{figure.caption.14}\protected@file@percent }
\abx@aux@backref{40}{imagenet2009_hierarchicaldatabase}{0}{32}{32}
\abx@aux@backref{41}{krizhevsky2012_alexnet}{0}{32}{32}
\newlabel{fig:chapter1_imagenet_challenge}{{1.12}{32}{Advances in the ImageNet Classification Challenge \cite {imagenet2009_hierarchicaldatabase, krizhevsky2012_alexnet}}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.9}AlexNet: A Revolution in Computer Vision (2012)}{32}{subsection.1.3.9}\protected@file@percent }
\abx@aux@backref{42}{krizhevsky2012_alexnet}{0}{32}{32}
\abx@aux@cite{0}{he2016_resnet}
\abx@aux@segm{0}{0}{he2016_resnet}
\abx@aux@cite{0}{rumelhart1986_backpropagation}
\abx@aux@segm{0}{0}{rumelhart1986_backpropagation}
\abx@aux@cite{0}{hochreiter1997_lstm}
\abx@aux@segm{0}{0}{hochreiter1997_lstm}
\abx@aux@cite{0}{donahue2015_ltrcnn}
\abx@aux@segm{0}{0}{donahue2015_ltrcnn}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces AlexNet’s performance in the 2012 ImageNet Challenge, showcasing its revolutionary impact on deep learning \blx@tocontentsinit {0}\cite {krizhevsky2012_alexnet}.}}{33}{figure.caption.15}\protected@file@percent }
\abx@aux@backref{44}{krizhevsky2012_alexnet}{0}{33}{33}
\newlabel{fig:chapter1_alexnet}{{1.13}{33}{AlexNet’s performance in the 2012 ImageNet Challenge, showcasing its revolutionary impact on deep learning \cite {krizhevsky2012_alexnet}}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Building on AlexNet: Evolution of CNNs and Beyond}{33}{section*.16}\protected@file@percent }
\abx@aux@backref{45}{he2016_resnet}{0}{33}{33}
\abx@aux@backref{46}{rumelhart1986_backpropagation}{0}{33}{33}
\abx@aux@backref{47}{hochreiter1997_lstm}{0}{33}{33}
\abx@aux@cite{0}{vaswani2017_attention}
\abx@aux@segm{0}{0}{vaswani2017_attention}
\abx@aux@cite{0}{vit2020_transformers}
\abx@aux@segm{0}{0}{vit2020_transformers}
\abx@aux@cite{0}{mamba2023_selective}
\abx@aux@segm{0}{0}{mamba2023_selective}
\abx@aux@cite{0}{dino2021_selfsupervised}
\abx@aux@segm{0}{0}{dino2021_selfsupervised}
\abx@aux@cite{0}{clip2021_multimodal}
\abx@aux@segm{0}{0}{clip2021_multimodal}
\abx@aux@backref{48}{donahue2015_ltrcnn}{0}{34}{34}
\abx@aux@backref{49}{vaswani2017_attention}{0}{34}{34}
\abx@aux@backref{50}{vit2020_transformers}{0}{34}{34}
\abx@aux@backref{51}{mamba2023_selective}{0}{34}{34}
\abx@aux@backref{52}{dino2021_selfsupervised}{0}{34}{34}
\abx@aux@cite{0}{sam2023_segmentation}
\abx@aux@segm{0}{0}{sam2023_segmentation}
\abx@aux@cite{0}{flamingo2022_fewshot}
\abx@aux@segm{0}{0}{flamingo2022_fewshot}
\BKM@entry{id=28,dest={73656374696F6E2E312E34},srcline={318}}{5C3337365C3337375C3030304D5C303030695C3030306C5C303030655C303030735C303030745C3030306F5C3030306E5C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030455C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E}
\BKM@entry{id=29,dest={73756273656374696F6E2E312E342E31},srcline={322}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030505C303030655C303030725C303030635C303030655C303030705C303030745C303030725C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030315C303030395C303030355C303030385C3030305C303531}
\abx@aux@cite{0}{rosenblatt1958_perceptron}
\abx@aux@segm{0}{0}{rosenblatt1958_perceptron}
\abx@aux@cite{0}{minsky1969_perceptrons}
\abx@aux@segm{0}{0}{minsky1969_perceptrons}
\abx@aux@cite{0}{rosenblatt1958_perceptron}
\abx@aux@segm{0}{0}{rosenblatt1958_perceptron}
\abx@aux@cite{0}{rosenblatt1958_perceptron}
\abx@aux@segm{0}{0}{rosenblatt1958_perceptron}
\BKM@entry{id=30,dest={73756273656374696F6E2E312E342E32},srcline={332}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030415C303030495C3030305C3034305C303030575C303030695C3030306E5C303030745C303030655C303030725C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030306C5C303030615C303030795C303030655C303030725C3030305C3034305C303030505C303030655C303030725C303030635C303030655C303030705C303030745C303030725C3030306F5C3030306E5C303030735C3030305C3034305C3030305C3035305C303030315C303030395C303030365C303030395C3030305C303531}
\abx@aux@cite{0}{minsky1969_perceptrons}
\abx@aux@segm{0}{0}{minsky1969_perceptrons}
\abx@aux@backref{53}{clip2021_multimodal}{0}{35}{35}
\abx@aux@backref{54}{sam2023_segmentation}{0}{35}{35}
\abx@aux@backref{55}{flamingo2022_fewshot}{0}{35}{35}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Milestones in the Evolution of Learning in Computer Vision}{35}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}The Perceptron (1958)}{35}{subsection.1.4.1}\protected@file@percent }
\abx@aux@backref{56}{minsky1969_perceptrons}{0}{35}{35}
\abx@aux@backref{57}{rosenblatt1958_perceptron}{0}{35}{35}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Frank Rosenblatt’s Perceptron, foundational to neural network research \blx@tocontentsinit {0}\cite {rosenblatt1958_perceptron}.}}{35}{figure.caption.17}\protected@file@percent }
\abx@aux@backref{59}{rosenblatt1958_perceptron}{0}{35}{35}
\newlabel{fig:chapter1_perceptron}{{1.14}{35}{Frank Rosenblatt’s Perceptron, foundational to neural network research \cite {rosenblatt1958_perceptron}}{figure.caption.17}{}}
\abx@aux@cite{0}{minsky1969_perceptrons}
\abx@aux@segm{0}{0}{minsky1969_perceptrons}
\abx@aux@cite{0}{minsky1969_perceptrons}
\abx@aux@segm{0}{0}{minsky1969_perceptrons}
\BKM@entry{id=31,dest={73756273656374696F6E2E312E342E33},srcline={342}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C3030304E5C303030655C3030306F5C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030725C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030315C303030395C303030385C303030305C3030305C303531}
\abx@aux@cite{0}{fukushima1980_neocognitron}
\abx@aux@segm{0}{0}{fukushima1980_neocognitron}
\abx@aux@cite{0}{fukushima1980_neocognitron}
\abx@aux@segm{0}{0}{fukushima1980_neocognitron}
\abx@aux@cite{0}{fukushima1980_neocognitron}
\abx@aux@segm{0}{0}{fukushima1980_neocognitron}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}The AI Winter and Multilayer Perceptrons (1969)}{36}{subsection.1.4.2}\protected@file@percent }
\abx@aux@backref{60}{minsky1969_perceptrons}{0}{36}{36}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Minsky and Papert’s seminal book "Perceptrons," critiquing single-layer networks \blx@tocontentsinit {0}\cite {minsky1969_perceptrons}.}}{36}{figure.caption.18}\protected@file@percent }
\abx@aux@backref{62}{minsky1969_perceptrons}{0}{36}{36}
\newlabel{fig:chapter1_perceptrons_book}{{1.15}{36}{Minsky and Papert’s seminal book "Perceptrons," critiquing single-layer networks \cite {minsky1969_perceptrons}}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}The Neocognitron (1980)}{36}{subsection.1.4.3}\protected@file@percent }
\abx@aux@backref{63}{fukushima1980_neocognitron}{0}{36}{36}
\BKM@entry{id=32,dest={73756273656374696F6E2E312E342E34},srcline={352}}{5C3337365C3337375C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030525C303030655C303030765C303030695C303030765C303030615C3030306C5C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030315C303030395C303030385C303030365C3030305C303531}
\abx@aux@cite{0}{rumelhart1986_backpropagation}
\abx@aux@segm{0}{0}{rumelhart1986_backpropagation}
\abx@aux@cite{0}{rumelhart1986_backpropagation}
\abx@aux@segm{0}{0}{rumelhart1986_backpropagation}
\abx@aux@cite{0}{rumelhart1986_backpropagation}
\abx@aux@segm{0}{0}{rumelhart1986_backpropagation}
\BKM@entry{id=33,dest={73756273656374696F6E2E312E342E35},srcline={362}}{5C3337365C3337375C3030304C5C303030655C3030304E5C303030655C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030455C3030306D5C303030655C303030725C303030675C303030655C3030306E5C303030635C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030315C303030395C303030395C303030385C3030305C303531}
\abx@aux@cite{0}{lecun1998_lenet}
\abx@aux@segm{0}{0}{lecun1998_lenet}
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces Kunihiko Fukushima’s Neocognitron: A precursor to modern CNNs \blx@tocontentsinit {0}\cite {fukushima1980_neocognitron}.}}{37}{figure.caption.19}\protected@file@percent }
\abx@aux@backref{65}{fukushima1980_neocognitron}{0}{37}{37}
\newlabel{fig:chapter1_neocognitron}{{1.16}{37}{Kunihiko Fukushima’s Neocognitron: A precursor to modern CNNs \cite {fukushima1980_neocognitron}}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Backpropagation and the Revival of Neural Networks (1986)}{37}{subsection.1.4.4}\protected@file@percent }
\abx@aux@backref{66}{rumelhart1986_backpropagation}{0}{37}{37}
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces Backpropagation algorithm by Rumelhart et al., pivotal for training deep networks \blx@tocontentsinit {0}\cite {rumelhart1986_backpropagation}.}}{37}{figure.caption.20}\protected@file@percent }
\abx@aux@backref{68}{rumelhart1986_backpropagation}{0}{37}{37}
\newlabel{fig:chapter1_backprop}{{1.17}{37}{Backpropagation algorithm by Rumelhart et al., pivotal for training deep networks \cite {rumelhart1986_backpropagation}}{figure.caption.20}{}}
\abx@aux@cite{0}{lecun1998_lenet}
\abx@aux@segm{0}{0}{lecun1998_lenet}
\abx@aux@cite{0}{lecun1998_lenet}
\abx@aux@segm{0}{0}{lecun1998_lenet}
\BKM@entry{id=34,dest={73756273656374696F6E2E312E342E36},srcline={372}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030325C303030305C303030305C303030305C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030455C303030725C303030615C3030305C3034305C3030306F5C303030665C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}LeNet and the Emergence of Convolutional Networks (1998)}{38}{subsection.1.4.5}\protected@file@percent }
\abx@aux@backref{69}{lecun1998_lenet}{0}{38}{38}
\@writefile{lof}{\contentsline {figure}{\numberline {1.18}{\ignorespaces Yann LeCun’s LeNet-5: The first practical convolutional network \blx@tocontentsinit {0}\cite {lecun1998_lenet}.}}{38}{figure.caption.21}\protected@file@percent }
\abx@aux@backref{71}{lecun1998_lenet}{0}{38}{38}
\newlabel{fig:chapter1_lenet}{{1.18}{38}{Yann LeCun’s LeNet-5: The first practical convolutional network \cite {lecun1998_lenet}}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}The 2000s: The Era of Deep Learning}{38}{subsection.1.4.6}\protected@file@percent }
\BKM@entry{id=35,dest={73756273656374696F6E2E312E342E37},srcline={382}}{5C3337365C3337375C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030455C303030785C303030705C3030306C5C3030306F5C303030735C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030325C303030305C303030305C303030375C3030302D5C303030325C303030305C303030325C303030305C3030305C303531}
\abx@aux@cite{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@segm{0}{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\BKM@entry{id=36,dest={73756273656374696F6E2E312E342E38},srcline={393}}{5C3337365C3337375C303030325C303030305C303030315C303030325C3030305C3034305C303030745C3030306F5C3030305C3034305C303030505C303030725C303030655C303030735C303030655C3030306E5C303030745C3030303A5C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030695C303030735C3030305C3034305C303030455C303030765C303030655C303030725C303030795C303030775C303030685C303030655C303030725C30303065}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\abx@aux@cite{0}{he2016_resnet}
\abx@aux@segm{0}{0}{he2016_resnet}
\@writefile{lof}{\contentsline {figure}{\numberline {1.19}{\ignorespaces The 2000s: Advances in hardware and algorithms enabling deep learning.}}{39}{figure.caption.22}\protected@file@percent }
\newlabel{fig:chapter1_dl_2000s}{{1.19}{39}{The 2000s: Advances in hardware and algorithms enabling deep learning}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.7}Deep Learning Explosion (2007-2020)}{39}{subsection.1.4.7}\protected@file@percent }
\abx@aux@backref{72}{imagenet2009_hierarchicaldatabase}{0}{39}{39}
\abx@aux@backref{73}{krizhevsky2012_alexnet}{0}{39}{39}
\@writefile{lof}{\contentsline {figure}{\numberline {1.20}{\ignorespaces Exponential growth in deep learning research, from 2007 to 2020.}}{39}{figure.caption.23}\protected@file@percent }
\newlabel{fig:chapter1_dl_explosion}{{1.20}{39}{Exponential growth in deep learning research, from 2007 to 2020}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.8}2012 to Present: Deep Learning is Everywhere}{39}{subsection.1.4.8}\protected@file@percent }
\abx@aux@cite{0}{ren2015_fasterrcnn}
\abx@aux@segm{0}{0}{ren2015_fasterrcnn}
\abx@aux@cite{0}{chen2017_deeplab}
\abx@aux@segm{0}{0}{chen2017_deeplab}
\abx@aux@cite{0}{he2017_maskrcnn}
\abx@aux@segm{0}{0}{he2017_maskrcnn}
\abx@aux@cite{0}{simonyan2014_twostream}
\abx@aux@segm{0}{0}{simonyan2014_twostream}
\abx@aux@cite{0}{toshev2014pose_estimation}
\abx@aux@segm{0}{0}{toshev2014pose_estimation}
\abx@aux@cite{0}{guo2014_atari}
\abx@aux@segm{0}{0}{guo2014_atari}
\abx@aux@cite{0}{vinyals2015_captioning}
\abx@aux@segm{0}{0}{vinyals2015_captioning}
\abx@aux@cite{0}{karpathy2015_visualsemantic}
\abx@aux@segm{0}{0}{karpathy2015_visualsemantic}
\abx@aux@cite{0}{dalle2021_texttoimage}
\abx@aux@segm{0}{0}{dalle2021_texttoimage}
\abx@aux@cite{0}{clip2021_multimodal}
\abx@aux@segm{0}{0}{clip2021_multimodal}
\abx@aux@cite{0}{flamingo2022_fewshot}
\abx@aux@segm{0}{0}{flamingo2022_fewshot}
\abx@aux@cite{0}{levy2016_medicalimaging}
\abx@aux@segm{0}{0}{levy2016_medicalimaging}
\abx@aux@cite{0}{dieleman2014_galaxycnn}
\abx@aux@segm{0}{0}{dieleman2014_galaxycnn}
\abx@aux@cite{0}{sam2023_segmentation}
\abx@aux@segm{0}{0}{sam2023_segmentation}
\abx@aux@cite{0}{dino2021_selfsupervised}
\abx@aux@segm{0}{0}{dino2021_selfsupervised}
\abx@aux@cite{0}{mamba2023_selective}
\abx@aux@segm{0}{0}{mamba2023_selective}
\@writefile{toc}{\contentsline {subsubsection}{Core Vision Tasks}{40}{section*.24}\protected@file@percent }
\abx@aux@backref{74}{krizhevsky2012_alexnet}{0}{40}{40}
\abx@aux@backref{75}{he2016_resnet}{0}{40}{40}
\abx@aux@backref{76}{ren2015_fasterrcnn}{0}{40}{40}
\abx@aux@backref{77}{chen2017_deeplab}{0}{40}{40}
\abx@aux@backref{78}{he2017_maskrcnn}{0}{40}{40}
\@writefile{toc}{\contentsline {subsubsection}{Video and Temporal Analysis}{40}{section*.25}\protected@file@percent }
\abx@aux@backref{79}{simonyan2014_twostream}{0}{40}{40}
\abx@aux@backref{80}{toshev2014pose_estimation}{0}{40}{40}
\abx@aux@backref{81}{guo2014_atari}{0}{40}{40}
\@writefile{toc}{\contentsline {subsubsection}{Generative and Multimodal Models}{40}{section*.26}\protected@file@percent }
\abx@aux@backref{82}{vinyals2015_captioning}{0}{40}{40}
\abx@aux@backref{83}{karpathy2015_visualsemantic}{0}{40}{40}
\abx@aux@backref{84}{dalle2021_texttoimage}{0}{40}{40}
\abx@aux@backref{85}{clip2021_multimodal}{0}{40}{40}
\abx@aux@backref{86}{flamingo2022_fewshot}{0}{40}{40}
\@writefile{toc}{\contentsline {subsubsection}{Specialized Domains}{40}{section*.27}\protected@file@percent }
\abx@aux@backref{87}{levy2016_medicalimaging}{0}{40}{40}
\abx@aux@backref{88}{dieleman2014_galaxycnn}{0}{40}{40}
\@writefile{toc}{\contentsline {subsubsection}{State-of-the-Art Foundation Models}{40}{section*.28}\protected@file@percent }
\abx@aux@backref{89}{sam2023_segmentation}{0}{40}{40}
\abx@aux@backref{90}{dino2021_selfsupervised}{0}{40}{40}
\abx@aux@backref{91}{mamba2023_selective}{0}{40}{40}
\abx@aux@cite{0}{dalle2021_texttoimage}
\abx@aux@segm{0}{0}{dalle2021_texttoimage}
\abx@aux@cite{0}{dalle2021_texttoimage}
\abx@aux@segm{0}{0}{dalle2021_texttoimage}
\abx@aux@cite{0}{dalle2021_texttoimage}
\abx@aux@segm{0}{0}{dalle2021_texttoimage}
\abx@aux@cite{0}{dalle2021_texttoimage}
\abx@aux@segm{0}{0}{dalle2021_texttoimage}
\@writefile{lof}{\contentsline {figure}{\numberline {1.21}{\ignorespaces The iconic avocado-shaped armchair, generated by DALL-E, exemplifies the creative potential of generative models \blx@tocontentsinit {0}\cite {dalle2021_texttoimage}.}}{41}{figure.caption.29}\protected@file@percent }
\abx@aux@backref{93}{dalle2021_texttoimage}{0}{41}{41}
\newlabel{fig:dalle_avocado}{{1.21}{41}{The iconic avocado-shaped armchair, generated by DALL-E, exemplifies the creative potential of generative models \cite {dalle2021_texttoimage}}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.22}{\ignorespaces Another example for a peach-shaped armchair, generated by DALL-E \blx@tocontentsinit {0}\cite {dalle2021_texttoimage}.}}{41}{figure.caption.30}\protected@file@percent }
\abx@aux@backref{95}{dalle2021_texttoimage}{0}{41}{41}
\newlabel{fig:dalle_peach}{{1.22}{41}{Another example for a peach-shaped armchair, generated by DALL-E \cite {dalle2021_texttoimage}}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{Computation is Cheaper: More GFLOPs per Dollar}{41}{section*.31}\protected@file@percent }
\BKM@entry{id=37,dest={73656374696F6E2E312E35},srcline={470}}{5C3337365C3337375C3030304B5C303030655C303030795C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C303030565C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030465C303030755C303030745C303030755C303030725C303030655C3030305C3034305C303030445C303030695C303030725C303030655C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\abx@aux@cite{0}{buolamwini2018_gendershades}
\abx@aux@segm{0}{0}{buolamwini2018_gendershades}
\@writefile{lof}{\contentsline {figure}{\numberline {1.23}{\ignorespaces The dramatic drop in GFLOPs cost over time, enabling more accessible deep learning applications.}}{42}{figure.caption.32}\protected@file@percent }
\newlabel{fig:gflops_cost}{{1.23}{42}{The dramatic drop in GFLOPs cost over time, enabling more accessible deep learning applications}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.24}{\ignorespaces Advances in GPUs, including tensor cores, greatly enhancing GFLOPs per dollar.}}{42}{figure.caption.33}\protected@file@percent }
\newlabel{fig:gpu_tensor_cores}{{1.24}{42}{Advances in GPUs, including tensor cores, greatly enhancing GFLOPs per dollar}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Key Challenges in CV and Future Directions}{42}{section.1.5}\protected@file@percent }
\abx@aux@cite{0}{buolamwini2018_gendershades}
\abx@aux@segm{0}{0}{buolamwini2018_gendershades}
\abx@aux@cite{0}{buolamwini2018_gendershades}
\abx@aux@segm{0}{0}{buolamwini2018_gendershades}
\abx@aux@cite{0}{goodfellow2014_adversarial}
\abx@aux@segm{0}{0}{goodfellow2014_adversarial}
\abx@aux@cite{0}{goodfellow2014_adversarial}
\abx@aux@segm{0}{0}{goodfellow2014_adversarial}
\abx@aux@cite{0}{goodfellow2014_adversarial}
\abx@aux@segm{0}{0}{goodfellow2014_adversarial}
\abx@aux@backref{96}{buolamwini2018_gendershades}{0}{43}{43}
\@writefile{lof}{\contentsline {figure}{\numberline {1.25}{\ignorespaces Ethical concerns: CV systems can amplify biases or cause harm, such as misidentifications \blx@tocontentsinit {0}\cite {buolamwini2018_gendershades}.}}{43}{figure.caption.34}\protected@file@percent }
\abx@aux@backref{98}{buolamwini2018_gendershades}{0}{43}{43}
\newlabel{fig:chapter1_ethics}{{1.25}{43}{Ethical concerns: CV systems can amplify biases or cause harm, such as misidentifications \cite {buolamwini2018_gendershades}}{figure.caption.34}{}}
\abx@aux@backref{99}{goodfellow2014_adversarial}{0}{43}{43}
\@writefile{lof}{\contentsline {figure}{\numberline {1.26}{\ignorespaces Adversarial examples: Adding imperceptible noise to a panda image causes the model to misclassify it \blx@tocontentsinit {0}\cite {goodfellow2014_adversarial}.}}{43}{figure.caption.35}\protected@file@percent }
\abx@aux@backref{101}{goodfellow2014_adversarial}{0}{43}{43}
\newlabel{fig:chapter1_adversarial}{{1.26}{43}{Adversarial examples: Adding imperceptible noise to a panda image causes the model to misclassify it \cite {goodfellow2014_adversarial}}{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.27}{\ignorespaces Complex scene understanding: AI struggles with nuanced contexts like social interactions.}}{44}{figure.caption.36}\protected@file@percent }
\newlabel{fig:chapter1_context}{{1.27}{44}{Complex scene understanding: AI struggles with nuanced contexts like social interactions}{figure.caption.36}{}}
\BKM@entry{id=38,dest={636861707465722E32},srcline={3}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030325C3030303A5C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=39,dest={73656374696F6E2E322E31},srcline={9}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Lecture 2: Image Classification}{45}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@1}}
\ttl@writefile{ptc}{\ttl@starttoc{default@2}}
\pgfsyspdfmark {pgfid8}{0}{52099153}
\pgfsyspdfmark {pgfid7}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction to Image Classification}{45}{section.2.1}\protected@file@percent }
\BKM@entry{id=40,dest={73656374696F6E2E322E32},srcline={23}}{5C3337365C3337375C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C30303073}
\BKM@entry{id=41,dest={73756273656374696F6E2E322E322E31},srcline={27}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030535C303030655C3030306D5C303030615C3030306E5C303030745C303030695C303030635C3030305C3034305C303030475C303030615C30303070}
\BKM@entry{id=42,dest={73756273656374696F6E2E322E322E32},srcline={37}}{5C3337365C3337375C303030525C3030306F5C303030625C303030755C303030735C303030745C3030306E5C303030655C303030735C303030735C3030305C3034305C303030745C3030306F5C3030305C3034305C303030435C303030615C3030306D5C303030655C303030725C303030615C3030305C3034305C3030304D5C3030306F5C303030765C303030655C3030306D5C303030655C3030306E5C30303074}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Image Classification Challenges}{46}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}The Semantic Gap}{46}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Images are represented as grids of pixel values, lacking inherent semantic meaning.}}{46}{figure.caption.37}\protected@file@percent }
\newlabel{fig:chapter2_semantic_gap}{{2.1}{46}{Images are represented as grids of pixel values, lacking inherent semantic meaning}{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Robustness to Camera Movement}{46}{subsection.2.2.2}\protected@file@percent }
\BKM@entry{id=43,dest={73756273656374696F6E2E322E322E33},srcline={47}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C303030615C3030302D5C303030435C3030306C5C303030615C303030735C303030735C3030305C3034305C303030565C303030615C303030725C303030695C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=44,dest={73756273656374696F6E2E322E322E34},srcline={57}}{5C3337365C3337375C303030465C303030695C3030306E5C303030655C3030302D5C303030475C303030725C303030615C303030695C3030306E5C303030655C303030645C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Changes in camera position or angle result in varying pixel grids, complicating classification.}}{47}{figure.caption.38}\protected@file@percent }
\newlabel{fig:chapter2_camera_movement}{{2.2}{47}{Changes in camera position or angle result in varying pixel grids, complicating classification}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Intra-Class Variation}{47}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Cats of different breeds show significant visual differences, a phenomenon known as intra-class variation.}}{47}{figure.caption.39}\protected@file@percent }
\newlabel{fig:chapter2_intra_class_variation}{{2.3}{47}{Cats of different breeds show significant visual differences, a phenomenon known as intra-class variation}{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Fine-Grained Classification}{47}{subsection.2.2.4}\protected@file@percent }
\BKM@entry{id=45,dest={73756273656374696F6E2E322E322E35},srcline={67}}{5C3337365C3337375C303030425C303030615C303030635C3030306B5C303030675C303030725C3030306F5C303030755C3030306E5C303030645C3030305C3034305C303030435C3030306C5C303030755C303030745C303030745C303030655C30303072}
\BKM@entry{id=46,dest={73756273656374696F6E2E322E322E36},srcline={77}}{5C3337365C3337375C303030495C3030306C5C3030306C5C303030755C3030306D5C303030695C3030306E5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030435C303030685C303030615C3030306E5C303030675C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Fine-grained classification requires distinguishing subtle differences within visually similar categories.}}{48}{figure.caption.40}\protected@file@percent }
\newlabel{fig:chapter2_fine_grained}{{2.4}{48}{Fine-grained classification requires distinguishing subtle differences within visually similar categories}{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Background Clutter}{48}{subsection.2.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Background clutter can obscure target objects, complicating image classification.}}{48}{figure.caption.41}\protected@file@percent }
\newlabel{fig:chapter2_background_clutter}{{2.5}{48}{Background clutter can obscure target objects, complicating image classification}{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Illumination Changes}{48}{subsection.2.2.6}\protected@file@percent }
\BKM@entry{id=47,dest={73756273656374696F6E2E322E322E37},srcline={87}}{5C3337365C3337375C303030445C303030655C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030535C303030635C303030615C3030306C5C30303065}
\BKM@entry{id=48,dest={73756273656374696F6E2E322E322E38},srcline={97}}{5C3337365C3337375C3030304F5C303030635C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Variations in illumination conditions affect object appearance, requiring robust algorithms.}}{49}{figure.caption.42}\protected@file@percent }
\newlabel{fig:chapter2_illumination}{{2.6}{49}{Variations in illumination conditions affect object appearance, requiring robust algorithms}{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Deformation and Object Scale}{49}{subsection.2.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Objects can deform and appear at varying scales, posing challenges for classification.}}{49}{figure.caption.43}\protected@file@percent }
\newlabel{fig:chapter2_deformation_scale}{{2.7}{49}{Objects can deform and appear at varying scales, posing challenges for classification}{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.8}Occlusions}{49}{subsection.2.2.8}\protected@file@percent }
\BKM@entry{id=49,dest={73756273656374696F6E2E322E322E39},srcline={107}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C30303073}
\BKM@entry{id=50,dest={73656374696F6E2E322E33},srcline={117}}{5C3337365C3337375C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C303030735C3030305C3034305C303030615C3030305C3034305C303030425C303030755C303030695C3030306C5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304F5C303030745C303030685C303030655C303030725C3030305C3034305C303030545C303030615C303030735C3030306B5C30303073}
\BKM@entry{id=51,dest={73756273656374696F6E2E322E332E31},srcline={121}}{5C3337365C3337375C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Occlusions, such as partial visibility of objects, obscure critical features and hinder classification.}}{50}{figure.caption.44}\protected@file@percent }
\newlabel{fig:chapter2_occlusions}{{2.8}{50}{Occlusions, such as partial visibility of objects, obscure critical features and hinder classification}{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.9}Summary of Challenges}{50}{subsection.2.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Image Classification as a Building Block for Other Tasks}{50}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Object Detection}{51}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Using sliding windows for object detection: classifying regions as background or containing an object.}}{51}{figure.caption.45}\protected@file@percent }
\newlabel{fig:chapter2_sliding_window_bg}{{2.9}{51}{Using sliding windows for object detection: classifying regions as background or containing an object}{figure.caption.45}{}}
\BKM@entry{id=52,dest={73756273656374696F6E2E322E332E32},srcline={141}}{5C3337365C3337375C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C303030615C303030705C303030745C303030695C3030306F5C3030306E5C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Using sliding windows for object detection: classifying regions containing objects (e.g., person).}}{52}{figure.caption.46}\protected@file@percent }
\newlabel{fig:chapter2_sliding_window_person}{{2.10}{52}{Using sliding windows for object detection: classifying regions containing objects (e.g., person)}{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Image Captioning}{52}{subsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Image captioning as sequential classification: determining the first word (e.g., "man").}}{52}{figure.caption.47}\protected@file@percent }
\newlabel{fig:chapter2_caption_man}{{2.11}{52}{Image captioning as sequential classification: determining the first word (e.g., "man")}{figure.caption.47}{}}
\BKM@entry{id=53,dest={73756273656374696F6E2E322E332E33},srcline={168}}{5C3337365C3337375C303030445C303030655C303030635C303030695C303030735C303030695C3030306F5C3030306E5C3030302D5C3030304D5C303030615C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030695C3030306E5C3030305C3034305C303030425C3030306F5C303030615C303030725C303030645C3030305C3034305C303030475C303030615C3030306D5C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Image captioning as sequential classification: determining the next word (e.g., "riding").}}{53}{figure.caption.48}\protected@file@percent }
\newlabel{fig:chapter2_caption_riding}{{2.12}{53}{Image captioning as sequential classification: determining the next word (e.g., "riding")}{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Image captioning: determining the end of the sentence with a "STOP" token.}}{53}{figure.caption.49}\protected@file@percent }
\newlabel{fig:chapter2_caption_stop}{{2.13}{53}{Image captioning: determining the end of the sentence with a "STOP" token}{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Decision-Making in Board Games}{53}{subsection.2.3.3}\protected@file@percent }
\BKM@entry{id=54,dest={73756273656374696F6E2E322E332E34},srcline={179}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030303A5C3030305C3034305C3030304C5C303030655C303030765C303030655C303030725C303030615C303030675C303030695C3030306E5C303030675C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=55,dest={73656374696F6E2E322E34},srcline={183}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030735C303030745C303030725C303030755C303030635C303030745C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C30303072}
\BKM@entry{id=56,dest={73756273656374696F6E2E322E342E31},srcline={187}}{5C3337365C3337375C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030302D5C303030425C303030615C303030735C303030655C303030645C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030635C303030615C3030306C5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C30303068}
\abx@aux@cite{0}{canny1986_edgedetection}
\abx@aux@segm{0}{0}{canny1986_edgedetection}
\abx@aux@cite{0}{harris1988_combined}
\abx@aux@segm{0}{0}{harris1988_combined}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Board games like Go framed as classification problems: determining the optimal next move.}}{54}{figure.caption.50}\protected@file@percent }
\newlabel{fig:chapter2_board_games}{{2.14}{54}{Board games like Go framed as classification problems: determining the optimal next move}{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Summary: Leveraging Image Classification}{54}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Constructing an Image Classifier}{54}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Feature-Based Image Classification: The Classical Approach}{54}{subsection.2.4.1}\protected@file@percent }
\abx@aux@backref{102}{canny1986_edgedetection}{0}{54}{54}
\abx@aux@backref{103}{harris1988_combined}{0}{54}{54}
\BKM@entry{id=57,dest={73756273656374696F6E2E322E342E32},srcline={218}}{5C3337365C3337375C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030485C303030615C3030306E5C303030645C3030302D5C303030435C303030725C303030615C303030665C303030745C303030655C303030645C3030305C3034305C303030525C303030755C3030306C5C303030655C303030735C3030305C3034305C303030745C3030306F5C3030305C3034305C303030445C303030615C303030745C303030615C3030302D5C303030445C303030725C303030695C303030765C303030655C3030306E5C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Attempting to classify images using hard-coded features is highly challenging.}}{55}{figure.caption.51}\protected@file@percent }
\newlabel{fig:chapter2_classification_attempt}{{2.15}{55}{Attempting to classify images using hard-coded features is highly challenging}{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Edges and corners as features for classification: an incomplete solution.}}{55}{figure.caption.52}\protected@file@percent }
\newlabel{fig:chapter2_edge_corners}{{2.16}{55}{Edges and corners as features for classification: an incomplete solution}{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}From Hand-Crafted Rules to Data-Driven Learning}{55}{subsection.2.4.2}\protected@file@percent }
\BKM@entry{id=58,dest={73756273656374696F6E2E322E342E33},srcline={237}}{5C3337365C3337375C303030505C303030725C3030306F5C303030675C303030725C303030615C3030306D5C3030306D5C303030695C3030306E5C303030675C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030445C303030615C303030745C303030615C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C3030304D5C3030306F5C303030645C303030655C303030725C3030306E5C3030305C3034305C303030505C303030615C303030725C303030615C303030645C303030695C303030675C3030306D}
\BKM@entry{id=59,dest={73756273656374696F6E2E322E342E34},srcline={249}}{5C3337365C3337375C303030445C303030615C303030745C303030615C3030302D5C303030445C303030725C303030695C303030765C303030655C3030306E5C3030305C3034305C3030304D5C303030615C303030635C303030685C303030695C3030306E5C303030655C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C3030304E5C303030655C303030775C3030305C3034305C303030465C303030725C3030306F5C3030306E5C303030745C303030695C303030655C30303072}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces A data-driven pipeline for training and evaluating machine learning-based image classifiers.}}{56}{figure.caption.53}\protected@file@percent }
\newlabel{fig:chapter2_data_driven}{{2.17}{56}{A data-driven pipeline for training and evaluating machine learning-based image classifiers}{figure.caption.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Programming with Data: The Modern Paradigm}{56}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Data-Driven Machine Learning: The New Frontier}{56}{subsection.2.4.4}\protected@file@percent }
\BKM@entry{id=60,dest={73656374696F6E2E322E35},srcline={264}}{5C3337365C3337375C303030445C303030615C303030745C303030615C303030735C303030655C303030745C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=61,dest={73756273656374696F6E2E322E352E31},srcline={268}}{5C3337365C3337375C3030304D5C3030304E5C303030495C303030535C303030545C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030545C3030306F5C303030795C3030305C3034305C303030445C303030615C303030745C303030615C303030735C303030655C30303074}
\abx@aux@cite{0}{lecun1998_lenet}
\abx@aux@segm{0}{0}{lecun1998_lenet}
\BKM@entry{id=62,dest={73756273656374696F6E2E322E352E32},srcline={281}}{5C3337365C3337375C303030435C303030495C303030465C303030415C303030525C3030303A5C3030305C3034305C303030525C303030655C303030615C3030306C5C3030302D5C303030575C3030306F5C303030725C3030306C5C303030645C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030525C303030655C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{krizhevsky2009_learning}
\abx@aux@segm{0}{0}{krizhevsky2009_learning}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Datasets in Image Classification}{57}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}MNIST: The Toy Dataset}{57}{subsection.2.5.1}\protected@file@percent }
\abx@aux@backref{104}{lecun1998_lenet}{0}{57}{57}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces MNIST: A dataset of handwritten digits, often used as a toy benchmark.}}{57}{figure.caption.54}\protected@file@percent }
\newlabel{fig:chapter2_mnist}{{2.18}{57}{MNIST: A dataset of handwritten digits, often used as a toy benchmark}{figure.caption.54}{}}
\BKM@entry{id=63,dest={73756273656374696F6E2E322E352E33},srcline={301}}{5C3337365C3337375C303030495C3030306D5C303030615C303030675C303030655C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030475C3030306F5C3030306C5C303030645C3030305C3034305C303030535C303030745C303030615C3030306E5C303030645C303030615C303030725C30303064}
\abx@aux@cite{0}{imagenet2009_hierarchicaldatabase}
\abx@aux@segm{0}{0}{imagenet2009_hierarchicaldatabase}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}CIFAR: Real-World Object Recognition}{58}{subsection.2.5.2}\protected@file@percent }
\abx@aux@backref{105}{krizhevsky2009_learning}{0}{58}{58}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces CIFAR-10: A dataset for object classification with 10 categories.}}{58}{figure.caption.55}\protected@file@percent }
\newlabel{fig:chapter2_cifar10}{{2.19}{58}{CIFAR-10: A dataset for object classification with 10 categories}{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces CIFAR-100: An extension of CIFAR-10 with 100 categories.}}{58}{figure.caption.56}\protected@file@percent }
\newlabel{fig:chapter2_cifar100}{{2.20}{58}{CIFAR-100: An extension of CIFAR-10 with 100 categories}{figure.caption.56}{}}
\BKM@entry{id=64,dest={73756273656374696F6E2E322E352E34},srcline={324}}{5C3337365C3337375C3030304D5C303030495C303030545C3030305C3034305C303030505C3030306C5C303030615C303030635C303030655C303030735C3030303A5C3030305C3034305C303030535C303030635C303030655C3030306E5C303030655C3030305C3034305C303030525C303030655C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{zhou2017_places}
\abx@aux@segm{0}{0}{zhou2017_places}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}ImageNet: The Gold Standard}{59}{subsection.2.5.3}\protected@file@percent }
\abx@aux@backref{106}{imagenet2009_hierarchicaldatabase}{0}{59}{59}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces ImageNet: A dataset of 1,000 categories pivotal to computer vision progress.}}{59}{figure.caption.57}\protected@file@percent }
\newlabel{fig:chapter2_imagenet}{{2.21}{59}{ImageNet: A dataset of 1,000 categories pivotal to computer vision progress}{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces ImageNet top-5 accuracy: A widely adopted evaluation metric.}}{59}{figure.caption.58}\protected@file@percent }
\newlabel{fig:chapter2_imagenet_top5}{{2.22}{59}{ImageNet top-5 accuracy: A widely adopted evaluation metric}{figure.caption.58}{}}
\BKM@entry{id=65,dest={73756273656374696F6E2E322E352E35},srcline={335}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C3030306E5C303030675C3030305C3034305C303030445C303030615C303030745C303030615C303030735C303030655C303030745C3030305C3034305C303030535C303030695C3030307A5C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}MIT Places: Scene Recognition}{60}{subsection.2.5.4}\protected@file@percent }
\abx@aux@backref{107}{zhou2017_places}{0}{60}{60}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces MIT Places: A dataset for scene classification, focusing on diverse environmental contexts.}}{60}{figure.caption.59}\protected@file@percent }
\newlabel{fig:chapter2_places}{{2.23}{60}{MIT Places: A dataset for scene classification, focusing on diverse environmental contexts}{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Comparing Dataset Sizes}{60}{subsection.2.5.5}\protected@file@percent }
\BKM@entry{id=66,dest={73756273656374696F6E2E322E352E36},srcline={354}}{5C3337365C3337375C3030304F5C3030306D5C3030306E5C303030695C303030675C3030306C5C3030306F5C303030745C3030303A5C3030305C3034305C303030465C303030655C303030775C3030302D5C303030535C303030685C3030306F5C303030745C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\abx@aux@cite{0}{lake2015_human}
\abx@aux@segm{0}{0}{lake2015_human}
\BKM@entry{id=67,dest={73756273656374696F6E2E322E352E37},srcline={365}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030445C303030615C303030745C303030615C303030735C303030655C303030745C303030735C3030305C3034305C303030445C303030725C303030695C303030765C303030695C3030306E5C303030675C3030305C3034305C303030505C303030725C3030306F5C303030675C303030725C303030655C303030735C30303073}
\BKM@entry{id=68,dest={73656374696F6E2E322E36},srcline={369}}{5C3337365C3337375C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C3030303A5C3030305C3034305C303030415C3030305C3034305C303030475C303030615C303030745C303030655C303030775C303030615C303030795C3030305C3034305C303030745C3030306F5C3030305C3034305C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces Comparing dataset sizes: MNIST, CIFAR, ImageNet, and MIT Places.}}{61}{figure.caption.60}\protected@file@percent }
\newlabel{fig:chapter2_dataset_sizes}{{2.24}{61}{Comparing dataset sizes: MNIST, CIFAR, ImageNet, and MIT Places}{figure.caption.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.6}Omniglot: Few-Shot Learning}{61}{subsection.2.5.6}\protected@file@percent }
\abx@aux@backref{108}{lake2015_human}{0}{61}{61}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces Omniglot: A dataset for few-shot learning, with minimal examples per category.}}{61}{figure.caption.61}\protected@file@percent }
\newlabel{fig:chapter2_omniglot}{{2.25}{61}{Omniglot: A dataset for few-shot learning, with minimal examples per category}{figure.caption.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.7}Conclusion: Datasets Driving Progress}{61}{subsection.2.5.7}\protected@file@percent }
\BKM@entry{id=69,dest={73756273656374696F6E2E322E362E31},srcline={373}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030425C303030655C303030675C303030695C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C3030303F}
\BKM@entry{id=70,dest={73756273656374696F6E2E322E362E32},srcline={385}}{5C3337365C3337375C303030535C303030655C303030745C303030745C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030535C303030745C303030615C303030675C303030655C3030303A5C3030305C3034305C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030505C303030695C303030785C303030655C3030306C5C303030735C3030305C3034305C303030745C3030306F5C3030305C3034305C303030505C303030725C303030655C303030645C303030695C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=71,dest={73756273656374696F6E2E322E362E33},srcline={394}}{5C3337365C3337375C303030415C3030306C5C303030675C3030306F5C303030725C303030695C303030745C303030685C3030306D5C3030305C3034305C303030445C303030655C303030735C303030635C303030725C303030695C303030705C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Nearest Neighbor Classifier: A Gateway to Understanding Classification}{62}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Why Begin with Nearest Neighbor?}{62}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Setting the Stage: From Pixels to Predictions}{62}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Algorithm Description}{62}{subsection.2.6.3}\protected@file@percent }
\BKM@entry{id=72,dest={73756273656374696F6E2E322E362E34},srcline={409}}{5C3337365C3337375C303030445C303030695C303030735C303030745C303030615C3030306E5C303030635C303030655C3030305C3034305C3030304D5C303030655C303030745C303030725C303030695C303030635C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030435C3030306F5C303030725C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C30303072}
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Nearest Neighbor classifier: memorize training data and predict based on the closest match.}}{63}{figure.caption.62}\protected@file@percent }
\newlabel{fig:chapter2_nn_description}{{2.26}{63}{Nearest Neighbor classifier: memorize training data and predict based on the closest match}{figure.caption.62}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Distance Metrics: The Core of Nearest Neighbor}{63}{subsection.2.6.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces L1 distance example: a simple and interpretable metric.}}{63}{figure.caption.63}\protected@file@percent }
\newlabel{fig:chapter2_l1_distance}{{2.27}{63}{L1 distance example: a simple and interpretable metric}{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces Comparison of L1 and L2 distance metrics: points with the same distance from the origin $(0,0)$ according to each metric (left:L1, right: L2).}}{64}{figure.caption.64}\protected@file@percent }
\newlabel{fig:chapter2_l1_l2_comparison}{{2.28}{64}{Comparison of L1 and L2 distance metrics: points with the same distance from the origin $(0,0)$ according to each metric (left:L1, right: L2)}{figure.caption.64}{}}
\newlabel{fig:chapter2_l1_l2_comparison}{{2.29}{64}{}{figure.caption.65}{}}
\BKM@entry{id=73,dest={73756273656374696F6E2E322E362E35},srcline={462}}{5C3337365C3337375C303030455C303030785C303030745C303030655C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C3030303A5C3030305C3034305C303030415C303030705C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces Limitations of L1 distance: visually dissimilar objects with similar colors may be incorrectly classified.}}{65}{figure.caption.66}\protected@file@percent }
\newlabel{fig:chapter2_l1_poor_performance}{{2.30}{65}{Limitations of L1 distance: visually dissimilar objects with similar colors may be incorrectly classified}{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Extending Nearest Neighbor: Applications Beyond Images}{65}{subsection.2.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Using Nearest Neighbor for Non-Image Data}{65}{section*.67}\protected@file@percent }
\BKM@entry{id=74,dest={73756273656374696F6E2E322E362E36},srcline={501}}{5C3337365C3337375C303030485C303030795C303030705C303030655C303030725C303030705C303030615C303030725C303030615C3030306D5C303030655C303030745C303030655C303030725C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C30303072}
\@writefile{toc}{\contentsline {subsubsection}{Academic Paper Recommendation Example}{66}{section*.68}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces Nearest Neighbor using TF-IDF similarity for academic paper recommendations.}}{66}{figure.caption.69}\protected@file@percent }
\newlabel{fig:chapter2_nn_tfidf}{{2.31}{66}{Nearest Neighbor using TF-IDF similarity for academic paper recommendations}{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsubsection}{Key Insights}{66}{section*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.6}Hyperparameters in Nearest Neighbor}{66}{subsection.2.6.6}\protected@file@percent }
\BKM@entry{id=75,dest={73756273656374696F6E2E322E362E37},srcline={531}}{5C3337365C3337375C303030435C303030725C3030306F5C303030735C303030735C3030302D5C303030565C303030615C3030306C5C303030695C303030645C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.32}{\ignorespaces Train-validation-test split for robust evaluation.}}{67}{figure.caption.71}\protected@file@percent }
\newlabel{fig:chapter2_train_val_test}{{2.32}{67}{Train-validation-test split for robust evaluation}{figure.caption.71}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.7}Cross-Validation}{67}{subsection.2.6.7}\protected@file@percent }
\BKM@entry{id=76,dest={73756273656374696F6E2E322E362E38},srcline={544}}{5C3337365C3337375C303030495C3030306D5C303030705C3030306C5C303030655C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306D5C303030705C3030306C5C303030655C303030785C303030695C303030745C30303079}
\@writefile{lof}{\contentsline {figure}{\numberline {2.33}{\ignorespaces Cross-validation accuracy for different values of \(k\). Each dot represents a trial, and the mean is represented by the line. Here we pick $k=7$ as the mean is the highest in this case.}}{68}{figure.caption.72}\protected@file@percent }
\newlabel{fig:chapter2_cross_validation}{{2.33}{68}{Cross-validation accuracy for different values of \(k\). Each dot represents a trial, and the mean is represented by the line. Here we pick $k=7$ as the mean is the highest in this case}{figure.caption.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.8}Implementation and Complexity}{68}{subsection.2.6.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.34}{\ignorespaces \texttt  {train} method: Memorizing training data.}}{68}{figure.caption.73}\protected@file@percent }
\newlabel{fig:chapter2_train}{{2.34}{68}{\texttt {train} method: Memorizing training data}{figure.caption.73}{}}
\BKM@entry{id=77,dest={73756273656374696F6E2E322E362E39},srcline={570}}{5C3337365C3337375C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030445C303030655C303030635C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C303030425C3030306F5C303030755C3030306E5C303030645C303030615C303030725C303030695C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {2.35}{\ignorespaces \texttt  {predict} method: Computing similarity and predicting the closest label.}}{69}{figure.caption.74}\protected@file@percent }
\newlabel{fig:chapter2_predict}{{2.35}{69}{\texttt {predict} method: Computing similarity and predicting the closest label}{figure.caption.74}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.9}Visualization of Decision Boundaries}{69}{subsection.2.6.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.36}{\ignorespaces Decision boundaries for Nearest Neighbor on a 2D dataset.}}{69}{figure.caption.75}\protected@file@percent }
\newlabel{fig:chapter2_decision_boundaries_start}{{2.36}{69}{Decision boundaries for Nearest Neighbor on a 2D dataset}{figure.caption.75}{}}
\BKM@entry{id=78,dest={73756273656374696F6E2E322E362E3130},srcline={590}}{5C3337365C3337375C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C3030306D5C303030655C3030306E5C303030745C303030735C3030303A5C3030305C3034305C3030306B5C3030302D5C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C30303073}
\BKM@entry{id=79,dest={73756273656374696F6E2E322E362E3131},srcline={603}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030555C3030306E5C303030695C303030765C303030655C303030725C303030735C303030615C3030306C5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030785C303030695C3030306D5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.37}{\ignorespaces Outliers disrupting decision boundaries in Nearest Neighbor classification.}}{70}{figure.caption.76}\protected@file@percent }
\newlabel{fig:chapter2_outlier_effect}{{2.37}{70}{Outliers disrupting decision boundaries in Nearest Neighbor classification}{figure.caption.76}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.10}Improvements: k-Nearest Neighbors}{70}{subsection.2.6.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.38}{\ignorespaces k-Nearest Neighbors ($k=3$): Smoother decision boundaries and reduced outlier influence.}}{70}{figure.caption.77}\protected@file@percent }
\newlabel{fig:chapter2_knn_smoothing}{{2.38}{70}{k-Nearest Neighbors ($k=3$): Smoother decision boundaries and reduced outlier influence}{figure.caption.77}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.11}Limitations and Universal Approximation}{71}{subsection.2.6.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.39}{\ignorespaces A step towards a dense coverage with Nearest Neighbor.}}{71}{figure.caption.78}\protected@file@percent }
\newlabel{fig:chapter2_dense_coverage}{{2.39}{71}{A step towards a dense coverage with Nearest Neighbor}{figure.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.40}{\ignorespaces The curse of dimensionality: limitations of KNN in high-dimensional spaces.}}{71}{figure.caption.79}\protected@file@percent }
\newlabel{fig:chapter2_curse_dimensionality}{{2.40}{71}{The curse of dimensionality: limitations of KNN in high-dimensional spaces}{figure.caption.79}{}}
\BKM@entry{id=80,dest={73756273656374696F6E2E322E362E3132},srcline={630}}{5C3337365C3337375C303030555C303030735C303030695C3030306E5C303030675C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{devlin2015_imagetocaption}
\abx@aux@segm{0}{0}{devlin2015_imagetocaption}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.12}Using CNN Features for Nearest Neighbor Classification}{72}{subsection.2.6.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.41}{\ignorespaces Nearest Neighbor with CNN features: improved semantic similarity.}}{72}{figure.caption.80}\protected@file@percent }
\newlabel{fig:chapter2_nn_cnn}{{2.41}{72}{Nearest Neighbor with CNN features: improved semantic similarity}{figure.caption.80}{}}
\abx@aux@backref{109}{devlin2015_imagetocaption}{0}{72}{72}
\BKM@entry{id=81,dest={73756273656374696F6E2E322E362E3133},srcline={656}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030465C303030725C3030306F5C3030306D5C3030305C3034305C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030305C3034305C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C3030305C3034305C303030745C3030306F5C3030305C3034305C303030415C303030645C303030765C303030615C3030306E5C303030635C303030655C303030645C3030305C3034305C3030304D5C3030304C5C3030305C3034305C303030465C303030725C3030306F5C3030306E5C303030745C303030695C303030655C303030725C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {2.42}{\ignorespaces Nearest Neighbor captioning: retrieving captions from the closest matching image.}}{73}{figure.caption.81}\protected@file@percent }
\newlabel{fig:chapter2_nn_captioning}{{2.42}{73}{Nearest Neighbor captioning: retrieving captions from the closest matching image}{figure.caption.81}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.13}Conclusion: From Nearest Neighbor to Advanced ML Frontiers}{73}{subsection.2.6.13}\protected@file@percent }
\BKM@entry{id=82,dest={636861707465722E33},srcline={3}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030335C3030303A5C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\BKM@entry{id=83,dest={73656374696F6E2E332E31},srcline={9}}{5C3337365C3337375C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C303030735C3030303A5C3030305C3034305C303030415C3030305C3034305C303030465C3030306F5C303030755C3030306E5C303030645C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Lecture 3: Linear Classifiers}{74}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@2}}
\ttl@writefile{ptc}{\ttl@starttoc{default@3}}
\pgfsyspdfmark {pgfid10}{0}{52099153}
\pgfsyspdfmark {pgfid9}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Linear Classifiers: A Foundation for Neural Networks}{74}{section.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Neural networks are constructed from stacked building blocks, much like Lego blocks. Linear classifiers are one of these foundational components.}}{74}{figure.caption.82}\protected@file@percent }
\newlabel{fig:chapter3_lego_blocks}{{3.1}{74}{Neural networks are constructed from stacked building blocks, much like Lego blocks. Linear classifiers are one of these foundational components}{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Parametric linear classifier pipeline: The input image is flattened into a vector, multiplied with weights, and added to a bias vector to produce class scores.}}{75}{figure.caption.83}\protected@file@percent }
\newlabel{fig:chapter3_parametric_classifier}{{3.2}{75}{Parametric linear classifier pipeline: The input image is flattened into a vector, multiplied with weights, and added to a bias vector to produce class scores}{figure.caption.83}{}}
\BKM@entry{id=84,dest={73656374696F6E2A2E3834},srcline={64}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030335C3030302E5C303030315C3030302E5C303030315C3030303A5C3030305C3034305C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030525C3030306F5C3030306C5C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030425C303030695C303030615C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {subsection}{Enrichment 3.1.1: Understanding the Role of Bias in Linear Classifiers}{77}{section*.84}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Without Bias (\(b=0\)):}{77}{section*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{With Bias (\(b = 3\)):}{77}{section*.86}\protected@file@percent }
\BKM@entry{id=85,dest={73756273656374696F6E2E332E312E32},srcline={133}}{5C3337365C3337375C303030415C3030305C3034305C303030545C3030306F5C303030795C3030305C3034305C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030475C303030725C303030615C303030795C303030735C303030635C303030615C3030306C5C303030655C3030305C3034305C303030435C303030615C303030745C3030305C3034305C303030495C3030306D5C303030615C303030675C30303065}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Bias shifts the decision boundary (orange line), enabling correct classification of the two points. Without bias (e.g., green line for the chosen $W$), no line passing through the origin can separate the points.}}{78}{figure.caption.87}\protected@file@percent }
\newlabel{fig:chapter3_bias_example}{{3.3}{78}{Bias shifts the decision boundary (orange line), enabling correct classification of the two points. Without bias (e.g., green line for the chosen $W$), no line passing through the origin can separate the points}{figure.caption.87}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}A Toy Example: Grayscale Cat Image}{78}{subsection.3.1.2}\protected@file@percent }
\BKM@entry{id=86,dest={73756273656374696F6E2E332E312E33},srcline={162}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030425C303030695C303030615C303030735C3030305C3034305C303030545C303030725C303030695C303030635C3030306B}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A toy example of a grayscale \(2 \times 2\) cat image (Slide 14), stretched into a vector and passed through a linear classifier.}}{79}{figure.caption.88}\protected@file@percent }
\newlabel{fig:chapter3_slide14_toy_example}{{3.4}{79}{A toy example of a grayscale \(2 \times 2\) cat image (Slide 14), stretched into a vector and passed through a linear classifier}{figure.caption.88}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}The Bias Trick}{79}{subsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The bias trick applied to the toy cat example: augmenting the image vector with a constant 1 and extending the weight matrix to incorporate the bias.}}{80}{figure.caption.89}\protected@file@percent }
\newlabel{fig:chapter3_bias_trick}{{3.5}{80}{The bias trick applied to the toy cat example: augmenting the image vector with a constant 1 and extending the weight matrix to incorporate the bias}{figure.caption.89}{}}
\BKM@entry{id=87,dest={73656374696F6E2E332E32},srcline={219}}{5C3337365C3337375C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030415C3030306C5C303030675C303030655C303030625C303030725C303030615C303030695C303030635C3030305C3034305C303030565C303030695C303030655C303030775C303030705C3030306F5C303030695C3030306E5C30303074}
\BKM@entry{id=88,dest={73756273656374696F6E2E332E322E31},srcline={223}}{5C3337365C3337375C303030535C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030505C303030725C3030306F5C303030705C303030655C303030725C303030745C303030695C303030655C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030495C3030306E5C303030735C303030695C303030675C303030685C303030745C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Linear Classifiers: The Algebraic Viewpoint}{81}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Scaling Properties and Insights}{81}{subsection.3.2.1}\protected@file@percent }
\BKM@entry{id=89,dest={73756273656374696F6E2E332E322E32},srcline={248}}{5C3337365C3337375C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030415C3030306C5C303030675C303030655C303030625C303030725C303030615C3030305C3034305C303030745C3030306F5C3030305C3034305C303030565C303030695C303030735C303030755C303030615C3030306C5C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030705C303030725C303030655C303030745C303030615C303030625C303030695C3030306C5C303030695C303030745C30303079}
\BKM@entry{id=90,dest={73656374696F6E2E332E33},srcline={261}}{5C3337365C3337375C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030565C303030695C303030735C303030755C303030615C3030306C5C3030305C3034305C303030565C303030695C303030655C303030775C303030705C3030306F5C303030695C3030306E5C30303074}
\BKM@entry{id=91,dest={73756273656374696F6E2E332E332E31},srcline={265}}{5C3337365C3337375C303030545C303030655C3030306D5C303030705C3030306C5C303030615C303030745C303030655C3030305C3034305C3030304D5C303030615C303030745C303030635C303030685C303030695C3030306E5C303030675C3030305C3034305C303030505C303030655C303030725C303030735C303030705C303030655C303030635C303030745C303030695C303030765C30303065}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Scaling effect in linear classifiers: uniform scaling of inputs leads to proportional scaling of output scores, as shown in this cat image example.}}{82}{figure.caption.90}\protected@file@percent }
\newlabel{fig:chapter3_scaling_bias_trick}{{3.6}{82}{Scaling effect in linear classifiers: uniform scaling of inputs leads to proportional scaling of output scores, as shown in this cat image example}{figure.caption.90}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}From Algebra to Visual Interpretability}{82}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Linear Classifiers: The Visual Viewpoint}{82}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Template Matching Perspective}{83}{subsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Visualizing the rows of the weight matrix \(\mathbf  {W}\) as learned templates for each class.}}{83}{figure.caption.91}\protected@file@percent }
\newlabel{fig:chapter3_template_matching}{{3.7}{83}{Visualizing the rows of the weight matrix \(\mathbf {W}\) as learned templates for each class}{figure.caption.91}{}}
\BKM@entry{id=92,dest={73756273656374696F6E2E332E332E32},srcline={286}}{5C3337365C3337375C303030495C3030306E5C303030745C303030655C303030725C303030705C303030725C303030655C303030745C303030695C3030306E5C303030675C3030305C3034305C303030545C303030655C3030306D5C303030705C3030306C5C303030615C303030745C303030655C30303073}
\BKM@entry{id=93,dest={73756273656374696F6E2E332E332E33},srcline={297}}{5C3337365C3337375C303030505C303030795C303030745C303030685C3030306F5C3030306E5C3030305C3034305C303030435C3030306F5C303030645C303030655C3030305C3034305C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030655C303030645C3030305C3034305C303030545C303030655C3030306D5C303030705C3030306C5C303030615C303030745C303030655C30303073}
\BKM@entry{id=94,dest={73756273656374696F6E2E332E332E34},srcline={326}}{5C3337365C3337375C303030545C303030655C3030306D5C303030705C3030306C5C303030615C303030745C303030655C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030303A5C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030655C3030305C3034305C3030304D5C3030306F5C303030645C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Interpreting Templates}{84}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Python Code Example: Visualizing Learned Templates}{84}{subsection.3.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The output of the code (building upon NumPy and Matplotlib) visualizes the rows of the weight matrix reshaped into the input image format, enabling inspection of the learned templates.}}{84}{figure.caption.92}\protected@file@percent }
\newlabel{fig:chapter3_visualize_class_templates}{{3.8}{84}{The output of the code (building upon NumPy and Matplotlib) visualizes the rows of the weight matrix reshaped into the input image format, enabling inspection of the learned templates}{figure.caption.92}{}}
\BKM@entry{id=95,dest={73756273656374696F6E2E332E332E35},srcline={340}}{5C3337365C3337375C3030304C5C3030306F5C3030306F5C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030415C303030685C303030655C303030615C30303064}
\BKM@entry{id=96,dest={73656374696F6E2E332E34},srcline={344}}{5C3337365C3337375C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030475C303030655C3030306F5C3030306D5C303030655C303030745C303030725C303030695C303030635C3030305C3034305C303030565C303030695C303030655C303030775C303030705C3030306F5C303030695C3030306E5C30303074}
\BKM@entry{id=97,dest={73756273656374696F6E2E332E342E31},srcline={348}}{5C3337365C3337375C303030495C3030306D5C303030615C303030675C303030655C303030735C3030305C3034305C303030615C303030735C3030305C3034305C303030485C303030695C303030675C303030685C3030302D5C303030445C303030695C3030306D5C303030655C3030306E5C303030735C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030505C3030306F5C303030695C3030306E5C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Template Limitations: Multiple Modes}{85}{subsection.3.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The horse class template demonstrates the limitation of learning a single template for a category with multiple modes.}}{85}{figure.caption.93}\protected@file@percent }
\newlabel{fig:chapter3_multiple_modes}{{3.9}{85}{The horse class template demonstrates the limitation of learning a single template for a category with multiple modes}{figure.caption.93}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}Looking Ahead}{85}{subsection.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Linear Classifiers: The Geometric Viewpoint}{85}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Images as High-Dimensional Points}{85}{subsection.3.4.1}\protected@file@percent }
\BKM@entry{id=98,dest={73756273656374696F6E2E332E342E32},srcline={363}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Left: Dimensionality-reduced visualization of a dataset. Right: Hyperplanes partitioning a higher-dimensional space into regions for classification.}}{86}{figure.caption.94}\protected@file@percent }
\newlabel{fig:chapter3_geometric_hyperplanes}{{3.10}{86}{Left: Dimensionality-reduced visualization of a dataset. Right: Hyperplanes partitioning a higher-dimensional space into regions for classification}{figure.caption.94}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Limitations of Linear Classifiers}{86}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Examples of classification problems that linear classifiers cannot solve.}}{86}{figure.caption.95}\protected@file@percent }
\newlabel{fig:chapter3_viewpoint_failures}{{3.11}{86}{Examples of classification problems that linear classifiers cannot solve}{figure.caption.95}{}}
\BKM@entry{id=99,dest={73756273656374696F6E2E332E342E33},srcline={383}}{5C3337365C3337375C303030485C303030695C303030735C303030745C3030306F5C303030725C303030695C303030635C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306E5C303030745C303030655C303030785C303030745C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030505C303030655C303030725C303030635C303030655C303030705C303030745C303030725C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030585C3030304F5C303030525C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=100,dest={73756273656374696F6E2E332E342E34},srcline={396}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030485C303030695C303030675C303030685C3030302D5C303030445C303030695C3030306D5C303030655C3030306E5C303030735C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030655C3030306F5C3030306D5C303030655C303030745C303030725C30303079}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Historical Context: The Perceptron and XOR Limitation}{87}{subsection.3.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces XOR Function: The perceptron can't separate blue \& green regions with a single line.}}{87}{figure.caption.96}\protected@file@percent }
\newlabel{fig:chapter3_xor_limitations}{{3.12}{87}{XOR Function: The perceptron can't separate blue \& green regions with a single line}{figure.caption.96}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Challenges of High-Dimensional Geometry}{87}{subsection.3.4.4}\protected@file@percent }
\BKM@entry{id=101,dest={73656374696F6E2E332E35},srcline={407}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030303A5C3030305C3034305C303030535C303030685C3030306F5C303030725C303030745C303030635C3030306F5C3030306D5C303030695C3030306E5C303030675C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\BKM@entry{id=102,dest={73756273656374696F6E2E332E352E31},srcline={411}}{5C3337365C3337375C303030415C3030306C5C303030675C303030655C303030625C303030725C303030615C303030695C303030635C3030305C3034305C303030565C303030695C303030655C303030775C303030705C3030306F5C303030695C3030306E5C30303074}
\BKM@entry{id=103,dest={73756273656374696F6E2E332E352E32},srcline={418}}{5C3337365C3337375C303030565C303030695C303030735C303030755C303030615C3030306C5C3030305C3034305C303030565C303030695C303030655C303030775C303030705C3030306F5C303030695C3030306E5C30303074}
\BKM@entry{id=104,dest={73756273656374696F6E2E332E352E33},srcline={425}}{5C3337365C3337375C303030475C303030655C3030306F5C3030306D5C303030655C303030745C303030725C303030695C303030635C3030305C3034305C303030565C303030695C303030655C303030775C303030705C3030306F5C303030695C3030306E5C30303074}
\BKM@entry{id=105,dest={73756273656374696F6E2E332E352E34},srcline={432}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C303030735C3030305C3034305C303030415C303030725C303030655C3030306E5C303030275C303030745C3030305C3034305C303030455C3030306E5C3030306F5C303030755C303030675C30303068}
\BKM@entry{id=106,dest={73656374696F6E2E332E36},srcline={435}}{5C3337365C3337375C303030435C303030685C3030306F5C3030306F5C303030735C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\BKM@entry{id=107,dest={73656374696F6E2E332E37},srcline={445}}{5C3337365C3337375C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=108,dest={73756273656374696F6E2E332E372E31},srcline={453}}{5C3337365C3337375C303030435C303030725C3030306F5C303030735C303030735C3030302D5C303030455C3030306E5C303030745C303030725C3030306F5C303030705C303030795C3030305C3034305C3030304C5C3030306F5C303030735C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Summary: Shortcomings of Linear Classifiers}{88}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Algebraic Viewpoint}{88}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Visual Viewpoint}{88}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Geometric Viewpoint}{88}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Conclusion: Linear Classifiers Aren't Enough}{88}{subsection.3.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Choosing the Weights for Linear Classifiers}{88}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Loss Functions}{88}{section.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Cross-Entropy Loss}{89}{subsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Softmax Function}{89}{section*.97}\protected@file@percent }
\newlabel{subsec:softmax}{{3.7.1}{89}{Softmax Function}{section*.97}{}}
\@writefile{toc}{\contentsline {paragraph}{Advanced Note: Boltzmann Perspective.}{89}{section*.98}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Loss Computation}{89}{section*.99}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Example: CIFAR-10 Image Classification}{89}{section*.100}\protected@file@percent }
\BKM@entry{id=109,dest={73756273656374696F6E2E332E372E32},srcline={527}}{5C3337365C3337375C3030304D5C303030755C3030306C5C303030745C303030695C303030635C3030306C5C303030615C303030735C303030735C3030305C3034305C303030535C303030565C3030304D5C3030305C3034305C3030304C5C3030306F5C303030735C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Cross-entropy loss computation for a cat image. Softmax normalizes raw scores into probabilities, and the loss is computed by comparing with the ground truth.}}{90}{figure.caption.101}\protected@file@percent }
\newlabel{fig:chapter3_ce_loss_example}{{3.13}{90}{Cross-entropy loss computation for a cat image. Softmax normalizes raw scores into probabilities, and the loss is computed by comparing with the ground truth}{figure.caption.101}{}}
\@writefile{toc}{\contentsline {paragraph}{Properties of Cross-Entropy Loss}{90}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why "Cross-Entropy"?}{90}{section*.103}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Multiclass SVM Loss}{90}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Loss Definition}{91}{section*.104}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example Computation}{91}{section*.105}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Loss for the Cat Image}{91}{section*.106}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces SVM loss computation for the cat image. Each term corresponds to a margin violation for an incorrect class.}}{91}{figure.caption.107}\protected@file@percent }
\newlabel{fig:chapter3_svm_loss_cat}{{3.14}{91}{SVM loss computation for the cat image. Each term corresponds to a margin violation for an incorrect class}{figure.caption.107}{}}
\@writefile{toc}{\contentsline {paragraph}{Loss for the Car Image}{92}{section*.108}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces SVM loss computation for the car image. As the car score exceeds the rest by more than the margin, the loss is 0.}}{92}{figure.caption.109}\protected@file@percent }
\newlabel{fig:chapter3_svm_loss_car}{{3.15}{92}{SVM loss computation for the car image. As the car score exceeds the rest by more than the margin, the loss is 0}{figure.caption.109}{}}
\@writefile{toc}{\contentsline {paragraph}{Loss for the Frog Image}{92}{section*.110}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces SVM loss computation for the frog image. With the correct class score being the lowest, the loss is the largest.}}{93}{figure.caption.111}\protected@file@percent }
\newlabel{fig:chapter3_svm_loss_frog}{{3.16}{93}{SVM loss computation for the frog image. With the correct class score being the lowest, the loss is the largest}{figure.caption.111}{}}
\@writefile{toc}{\contentsline {paragraph}{Total Loss}{93}{section*.112}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Total loss computed as the average of losses over the three images.}}{93}{figure.caption.113}\protected@file@percent }
\newlabel{fig:chapter3_svm_total_loss}{{3.17}{93}{Total loss computed as the average of losses over the three images}{figure.caption.113}{}}
\@writefile{toc}{\contentsline {subsubsection}{Key Questions and Insights}{93}{section*.114}\protected@file@percent }
\BKM@entry{id=110,dest={73756273656374696F6E2E332E372E33},srcline={637}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C303030725C3030306F5C303030735C303030735C3030302D5C303030455C3030306E5C303030745C303030725C3030306F5C303030705C303030795C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030635C3030306C5C303030615C303030735C303030735C3030305C3034305C303030535C303030565C3030304D5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Comparison of Cross-Entropy and Multiclass SVM Losses}{94}{subsection.3.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Impact of scaling on SVM and cross-entropy loss. The CE loss decreases, while the SVM loss remains unchanged.}}{94}{figure.caption.115}\protected@file@percent }
\newlabel{fig:chapter3_loss_comparison_scaling}{{3.18}{94}{Impact of scaling on SVM and cross-entropy loss. The CE loss decreases, while the SVM loss remains unchanged}{figure.caption.115}{}}
\@writefile{toc}{\contentsline {subsubsection}{Conclusion: SVM, Cross Entropy, and the Evolving Landscape of Loss Functions}{94}{section*.116}\protected@file@percent }
\BKM@entry{id=111,dest={636861707465722E34},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030345C3030303A5C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3034365C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=112,dest={73656374696F6E2E342E31},srcline={9}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{yenigun_overfitting}
\abx@aux@segm{0}{0}{yenigun_overfitting}
\abx@aux@cite{0}{yenigun_overfitting}
\abx@aux@segm{0}{0}{yenigun_overfitting}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Lecture 4: Regularization \& Optimization}{95}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@3}}
\ttl@writefile{ptc}{\ttl@starttoc{default@4}}
\pgfsyspdfmark {pgfid13}{0}{52099153}
\pgfsyspdfmark {pgfid12}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction to Regularization}{95}{section.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Illustration of underfitting, good fitting, and overfitting in classification and regression tasks \blx@tocontentsinit {0}\cite {yenigun_overfitting}. Good regularization aims to strike the balance between underfitting and overfitting.}}{95}{figure.caption.117}\protected@file@percent }
\abx@aux@backref{111}{yenigun_overfitting}{0}{95}{95}
\newlabel{fig:chapter4_overfitting_underfitting}{{4.1}{95}{Illustration of underfitting, good fitting, and overfitting in classification and regression tasks \cite {yenigun_overfitting}. Good regularization aims to strike the balance between underfitting and overfitting}{figure.caption.117}{}}
\BKM@entry{id=113,dest={73756273656374696F6E2E342E312E31},srcline={30}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030695C303030735C3030305C3034305C303030555C303030735C303030655C303030645C3030303F}
\BKM@entry{id=114,dest={73756273656374696F6E2E342E312E32},srcline={44}}{5C3337365C3337375C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030535C303030695C3030306D5C303030705C3030306C5C303030655C303030725C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C303030415C303030725C303030655C3030305C3034305C303030505C303030725C303030655C303030665C303030655C303030725C303030725C303030655C30303064}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}How Regularization is Used?}{96}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Regularization: Simpler Models Are Preferred}{96}{subsection.4.1.2}\protected@file@percent }
\BKM@entry{id=115,dest={73656374696F6E2E342E32},srcline={50}}{5C3337365C3337375C303030545C303030795C303030705C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C3030304C5C303030315C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C30303032}
\BKM@entry{id=116,dest={73756273656374696F6E2E342E322E31},srcline={52}}{5C3337365C3337375C3030304C5C303030315C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C3030304C5C303030615C303030735C303030735C3030306F5C3030305C303531}
\BKM@entry{id=117,dest={73756273656374696F6E2E342E322E32},srcline={77}}{5C3337365C3337375C3030304C5C303030325C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030525C303030695C303030645C303030675C303030655C3030305C303531}
\BKM@entry{id=118,dest={73756273656374696F6E2E342E322E33},srcline={105}}{5C3337365C3337375C303030435C303030685C3030306F5C3030306F5C303030735C303030695C3030306E5C303030675C3030305C3034305C303030425C303030655C303030745C303030775C303030655C303030655C3030306E5C3030305C3034305C3030304C5C303030315C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030325C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=119,dest={73656374696F6E2A2E313138},srcline={121}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030345C3030302E5C303030325C3030302E5C303030345C3030303A5C3030305C3034305C303030435C303030615C3030306E5C3030305C3034305C303030575C303030655C3030305C3034305C303030435C3030306F5C3030306D5C303030625C303030695C3030306E5C303030655C3030305C3034305C3030304C5C303030315C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030325C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030303F}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Types of Regularization: L1 and L2}{97}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}L1 Regularization (Lasso)}{97}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}L2 Regularization (Ridge)}{97}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Choosing Between L1 and L2 Regularization}{97}{subsection.4.2.3}\protected@file@percent }
\BKM@entry{id=120,dest={73756273656374696F6E2E342E322E35},srcline={144}}{5C3337365C3337375C303030455C303030785C303030705C303030725C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C303030505C303030725C303030655C303030665C303030655C303030725C303030655C3030306E5C303030635C303030655C303030735C3030305C3034305C303030545C303030685C303030725C3030306F5C303030755C303030675C303030685C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=121,dest={73656374696F6E2E342E33},srcline={156}}{5C3337365C3337375C303030495C3030306D5C303030705C303030615C303030635C303030745C3030305C3034305C3030306F5C303030665C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030535C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C3030306F5C3030306E5C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{Enrichment 4.2.4: Can We Combine L1 and L2 Regularization?}{98}{section*.118}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{When to Use Elastic Net?}{98}{section*.119}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary:}{98}{section*.120}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Expressing Preferences Through Regularization}{98}{subsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Impact of Feature Scaling on Regularization}{98}{section.4.3}\protected@file@percent }
\BKM@entry{id=122,dest={73756273656374696F6E2E342E332E31},srcline={167}}{5C3337365C3337375C303030505C303030725C303030615C303030635C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C303030495C3030306D5C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=123,dest={73756273656374696F6E2E342E332E32},srcline={170}}{5C3337365C3337375C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030525C303030655C303030735C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030615C303030735C303030735C3030306F5C3030305C3034305C303030525C303030655C303030675C303030725C303030655C303030735C303030735C303030695C3030306F5C3030306E5C3030302E}
\BKM@entry{id=124,dest={73656374696F6E2E342E34},srcline={173}}{5C3337365C3337375C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C303030735C3030305C3034305C303030615C3030305C3034305C303030435C303030615C303030745C303030615C3030306C5C303030795C303030735C303030745C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030425C303030655C303030745C303030745C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=125,dest={73756273656374696F6E2E342E342E31},srcline={177}}{5C3337365C3337375C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C303030735C3030305C3034305C303030505C303030615C303030725C303030745C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=126,dest={73756273656374696F6E2E342E342E32},srcline={191}}{5C3337365C3337375C303030415C303030755C303030675C3030306D5C303030655C3030306E5C303030745C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030535C303030755C303030725C303030665C303030615C303030635C303030655C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030435C303030755C303030725C303030765C303030615C303030745C303030755C303030725C30303065}
\BKM@entry{id=127,dest={73756273656374696F6E2E342E342E33},srcline={202}}{5C3337365C3337375C3030304D5C303030695C303030745C303030695C303030675C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030495C3030306E5C303030735C303030745C303030615C303030625C303030695C3030306C5C303030695C303030745C303030795C3030305C3034305C303030695C3030306E5C3030305C3034305C303030485C303030695C303030675C303030685C3030305C3034305C303030445C303030695C3030306D5C303030655C3030306E5C303030735C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Practical Implication}{99}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Example: Rescaling and Lasso Regression.}{99}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Regularization as a Catalyst for Better Optimization}{99}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Regularization as Part of Optimization}{99}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Augmenting the Loss Surface with Curvature}{99}{subsection.4.4.2}\protected@file@percent }
\BKM@entry{id=128,dest={73756273656374696F6E2E342E342E34},srcline={205}}{5C3337365C3337375C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030645C303030695C303030745C303030695C3030306F5C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030465C303030615C303030735C303030745C303030655C303030725C3030305C3034305C303030435C3030306F5C3030306E5C303030765C303030655C303030725C303030675C303030655C3030306E5C303030635C30303065}
\BKM@entry{id=129,dest={73656374696F6E2E342E35},srcline={212}}{5C3337365C3337375C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030545C303030725C303030615C303030765C303030655C303030725C303030735C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C3030304C5C303030615C3030306E5C303030645C303030735C303030635C303030615C303030705C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Mitigating Instability in High Dimensions}{100}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Improving Conditioning for Faster Convergence}{100}{subsection.4.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Optimization: Traversing the Loss Landscape}{100}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The loss landscape. Each point corresponds to a weight matrix, and the height represents its corresponding loss value.}}{100}{figure.caption.121}\protected@file@percent }
\newlabel{fig:chapter4_landscape}{{4.2}{100}{The loss landscape. Each point corresponds to a weight matrix, and the height represents its corresponding loss value}{figure.caption.121}{}}
\BKM@entry{id=130,dest={73756273656374696F6E2E342E352E31},srcline={228}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C3030304C5C303030615C3030306E5C303030645C303030735C303030635C303030615C303030705C303030655C3030305C3034305C303030495C3030306E5C303030745C303030755C303030695C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=131,dest={73656374696F6E2A2E313233},srcline={244}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030345C3030302E5C303030355C3030302E5C303030325C3030303A5C3030305C3034305C303030575C303030685C303030795C3030305C3034305C303030455C303030785C303030705C3030306C5C303030695C303030635C303030695C303030745C3030305C3034305C303030415C3030306E5C303030615C3030306C5C303030795C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C303030535C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030415C303030725C303030655C3030305C3034305C3030304F5C303030665C303030745C303030655C3030306E5C3030305C3034305C303030495C3030306D5C303030705C303030725C303030615C303030635C303030745C303030695C303030635C303030615C3030306C}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}The Loss Landscape Intuition}{101}{subsection.4.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Traversing the loss landscape toward the minimum. The person starts at a random point and follows a path downwards.}}{101}{figure.caption.122}\protected@file@percent }
\newlabel{fig:chapter4_traversal}{{4.3}{101}{Traversing the loss landscape toward the minimum. The person starts at a random point and follows a path downwards}{figure.caption.122}{}}
\@writefile{toc}{\contentsline {subsection}{Enrichment 4.5.2: Why Explicit Analytical Solutions Are Often Impractical}{101}{section*.123}\protected@file@percent }
\newlabel{enrichment:why_analytical_impractical}{{4.5.2}{101}{\color {ocre}Enrichment \thesubsection : Why Explicit Analytical Solutions Are Often Impractical}{section*.123}{}}
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 4.5.2.1: High Dimensionality}{101}{section*.124}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 4.5.2.2: Non-Convexity of the Loss Landscape}{101}{section*.125}\protected@file@percent }
\BKM@entry{id=132,dest={73756273656374696F6E2E342E352E33},srcline={273}}{5C3337365C3337375C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030495C303030645C303030655C303030615C3030305C3034305C3030305C3034335C303030315C3030303A5C3030305C3034305C303030525C303030615C3030306E5C303030645C3030306F5C3030306D5C3030305C3034305C303030535C303030655C303030615C303030725C303030635C30303068}
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 4.5.2.3: Complexity of Regularization Terms}{102}{section*.126}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 4.5.2.4: Lack of Generalizability and Flexibility}{102}{section*.127}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 4.5.2.5: Memory and Computational Cost}{102}{section*.128}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Optimization Idea \#1: Random Search}{102}{subsection.4.5.3}\protected@file@percent }
\BKM@entry{id=133,dest={73756273656374696F6E2E342E352E34},srcline={285}}{5C3337365C3337375C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030495C303030645C303030655C303030615C3030305C3034305C3030305C3034335C303030325C3030303A5C3030305C3034305C303030465C3030306F5C3030306C5C3030306C5C3030306F5C303030775C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030535C3030306C5C3030306F5C303030705C30303065}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Random search: A naive optimization approach.}}{103}{figure.caption.129}\protected@file@percent }
\newlabel{fig:chapter4_random_search}{{4.4}{103}{Random search: A naive optimization approach}{figure.caption.129}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Optimization Idea \#2: Following the Slope}{103}{subsection.4.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Following the slope to descend the landscape.}}{103}{figure.caption.130}\protected@file@percent }
\newlabel{fig:chapter4_following_slope}{{4.5}{103}{Following the slope to descend the landscape}{figure.caption.130}{}}
\BKM@entry{id=134,dest={73756273656374696F6E2E342E352E35},srcline={299}}{5C3337365C3337375C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C3030304D5C303030615C303030745C303030685C303030655C3030306D5C303030615C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C303030425C303030615C303030735C303030695C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}Gradients: The Mathematical Basis}{104}{subsection.4.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why Does the Gradient Point to the Steepest Ascent?}{104}{section*.131}\protected@file@percent }
\BKM@entry{id=135,dest={73656374696F6E2E342E36},srcline={377}}{5C3337365C3337375C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\@writefile{toc}{\contentsline {subsubsection}{Why Does the Negative Gradient Indicate the Steepest Descent?}{105}{section*.132}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The gradient \( \nabla L(w) \) points to the steepest ascent, while \( -\nabla L(w) \) leads to the steepest descent.}}{105}{figure.caption.133}\protected@file@percent }
\newlabel{fig:chapter4_gradient_steepest_directions}{{4.6}{105}{The gradient \( \nabla L(w) \) points to the steepest ascent, while \( -\nabla L(w) \) leads to the steepest descent}{figure.caption.133}{}}
\BKM@entry{id=136,dest={73756273656374696F6E2E342E362E31},srcline={381}}{5C3337365C3337375C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}From Gradient Computation to Gradient Descent}{106}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Gradient Computation Methods}{106}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Numerical Gradient: Approximating Gradients via Finite Differences}{106}{section*.134}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Process:}{106}{section*.135}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Numerical Gradient: Computing the slope of \( L(W) \) with respect to a perturbed element of \( W \).}}{106}{figure.caption.136}\protected@file@percent }
\newlabel{fig:chapter4_numeric_gradient}{{4.7}{106}{Numerical Gradient: Computing the slope of \( L(W) \) with respect to a perturbed element of \( W \)}{figure.caption.136}{}}
\BKM@entry{id=137,dest={73756273656374696F6E2E342E362E32},srcline={441}}{5C3337365C3337375C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C303030745C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030495C303030745C303030655C303030725C303030615C303030745C303030695C303030765C303030655C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030415C3030306C5C303030675C3030306F5C303030725C303030695C303030745C303030685C3030306D}
\@writefile{toc}{\contentsline {paragraph}{Advantages:}{107}{section*.137}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Disadvantages:}{107}{section*.138}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Analytical Gradient: Exact Gradients via Calculus}{107}{section*.139}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Analytical Gradient: Exact computation of gradients via calculus.}}{107}{figure.caption.140}\protected@file@percent }
\newlabel{fig:chapter4_analytical_gradient}{{4.8}{107}{Analytical Gradient: Exact computation of gradients via calculus}{figure.caption.140}{}}
\@writefile{toc}{\contentsline {paragraph}{Advantages:}{107}{section*.141}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Relation to Gradient Descent:}{107}{section*.142}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Gradient Descent: The Iterative Optimization Algorithm}{108}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Motivation and Concept}{108}{section*.143}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Steps of Gradient Descent:}{108}{section*.144}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Gradient Descent: Iterative optimization using gradient updates.}}{108}{figure.caption.145}\protected@file@percent }
\newlabel{fig:chapter4_gradient_descent}{{4.9}{108}{Gradient Descent: Iterative optimization using gradient updates}{figure.caption.145}{}}
\@writefile{toc}{\contentsline {subsubsection}{Hyperparameters of Gradient Descent}{108}{section*.146}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Learning Rate (\( \eta \)):}{108}{section*.147}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Weight Initialization:}{108}{section*.148}\protected@file@percent }
\BKM@entry{id=138,dest={73656374696F6E2E342E37},srcline={488}}{5C3337365C3337375C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\BKM@entry{id=139,dest={73756273656374696F6E2E342E372E31},srcline={490}}{5C3337365C3337375C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C303030745C3030305C3034305C303030545C303030685C303030725C3030306F5C303030755C303030675C303030685C3030305C3034305C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=140,dest={73756273656374696F6E2E342E372E32},srcline={505}}{5C3337365C3337375C303030505C303030725C3030306F5C303030705C303030655C303030725C303030745C303030695C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\@writefile{toc}{\contentsline {paragraph}{3. Stopping Criterion:}{109}{section*.149}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Visualizing Gradient Descent}{109}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}Understanding Gradient Descent Through Visualization}{109}{subsection.4.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Visualization of Gradient Descent Using a Contour Plot. The path starts at a high-loss region (blue) and iteratively moves toward a lower-loss region (red).}}{109}{figure.caption.150}\protected@file@percent }
\newlabel{fig:chapter4_gradient_descent_contour}{{4.10}{109}{Visualization of Gradient Descent Using a Contour Plot. The path starts at a high-loss region (blue) and iteratively moves toward a lower-loss region (red)}{figure.caption.150}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}Properties of Gradient Descent}{109}{subsection.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Curved Paths Toward the Minimum}{109}{section*.151}\protected@file@percent }
\BKM@entry{id=141,dest={73756273656374696F6E2E342E372E33},srcline={527}}{5C3337365C3337375C303030425C303030615C303030745C303030635C303030685C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\BKM@entry{id=142,dest={73656374696F6E2E342E38},srcline={538}}{5C3337365C3337375C303030535C303030745C3030306F5C303030635C303030685C303030615C303030735C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C303030745C3030305C3034305C3030305C3035305C303030535C303030475C303030445C3030305C303531}
\BKM@entry{id=143,dest={73756273656374696F6E2E342E382E31},srcline={540}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030535C303030745C3030306F5C303030635C303030685C303030615C303030735C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\@writefile{toc}{\contentsline {subsubsection}{Slowing Down Near the Minimum}{110}{section*.152}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.3}Batch Gradient Descent}{110}{subsection.4.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Stochastic Gradient Descent (SGD)}{110}{section.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}Introduction to Stochastic Gradient Descent}{110}{subsection.4.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Minibatch Gradient Computation}{110}{section*.153}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Stochastic Gradient Descent: Leveraging minibatches to approximate loss and gradients.}}{111}{figure.caption.154}\protected@file@percent }
\newlabel{fig:chapter4_sgd_intro}{{4.11}{111}{Stochastic Gradient Descent: Leveraging minibatches to approximate loss and gradients}{figure.caption.154}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Sampling and Epochs}{111}{section*.155}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why "Stochastic"?}{111}{section*.156}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces SGD approximates the expectation over all possible samples via minibatch sampling.}}{111}{figure.caption.157}\protected@file@percent }
\newlabel{fig:chapter4_sgd_sampling}{{4.12}{111}{SGD approximates the expectation over all possible samples via minibatch sampling}{figure.caption.157}{}}
\BKM@entry{id=144,dest={73756273656374696F6E2E342E382E32},srcline={578}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030535C303030475C30303044}
\abx@aux@cite{0}{alger2019_data}
\abx@aux@segm{0}{0}{alger2019_data}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}Advantages and Challenges of SGD}{112}{subsection.4.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Advantages}{112}{section*.158}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Challenges of SGD}{112}{section*.159}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{High Condition Numbers}{112}{section*.160}\protected@file@percent }
\abx@aux@backref{112}{alger2019_data}{0}{112}{112}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Visualization of oscillations in SGD caused by high condition numbers.}}{112}{figure.caption.161}\protected@file@percent }
\newlabel{fig:chapter4_high_condition_number}{{4.13}{112}{Visualization of oscillations in SGD caused by high condition numbers}{figure.caption.161}{}}
\@writefile{toc}{\contentsline {paragraph}{Saddle Points and Local Minima}{112}{section*.162}\protected@file@percent }
\BKM@entry{id=145,dest={73756273656374696F6E2E342E382E33},srcline={632}}{5C3337365C3337375C3030304C5C3030306F5C3030306F5C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030415C303030685C303030655C303030615C303030645C3030303A5C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030695C3030306E5C303030675C3030305C3034305C303030535C303030475C30303044}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Examples of saddle points and local minima in loss landscapes.}}{113}{figure.caption.163}\protected@file@percent }
\newlabel{fig:chapter4_saddle_point}{{4.14}{113}{Examples of saddle points and local minima in loss landscapes}{figure.caption.163}{}}
\@writefile{toc}{\contentsline {paragraph}{Noisy Gradients}{113}{section*.164}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Noisy gradient updates in SGD resulting in slower convergence.}}{113}{figure.caption.165}\protected@file@percent }
\newlabel{fig:chapter4_noisy_gradients}{{4.15}{113}{Noisy gradient updates in SGD resulting in slower convergence}{figure.caption.165}{}}
\BKM@entry{id=146,dest={73656374696F6E2E342E39},srcline={635}}{5C3337365C3337375C303030535C303030475C303030445C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D}
\BKM@entry{id=147,dest={73756273656374696F6E2E342E392E31},srcline={636}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=148,dest={73756273656374696F6E2E342E392E32},srcline={639}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030535C303030475C303030445C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D5C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=149,dest={73756273656374696F6E2E342E392E33},srcline={662}}{5C3337365C3337375C303030495C3030306E5C303030745C303030755C303030695C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030425C303030655C303030685C303030695C3030306E5C303030645C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.3}Looking Ahead: Improving SGD}{114}{subsection.4.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.9}SGD with Momentum}{114}{section.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}Motivation}{114}{subsection.4.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.2}How SGD with Momentum Works}{114}{subsection.4.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Update Equations}{114}{section*.166}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces SGD with Momentum: Implementation in PyTorch.}}{114}{figure.caption.167}\protected@file@percent }
\newlabel{fig:chapter4_sgd_momentum}{{4.16}{114}{SGD with Momentum: Implementation in PyTorch}{figure.caption.167}{}}
\BKM@entry{id=150,dest={73756273656374696F6E2E342E392E34},srcline={678}}{5C3337365C3337375C303030425C303030655C3030306E5C303030655C303030665C303030695C303030745C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.3}Intuition Behind Momentum}{115}{subsection.4.9.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Alternative formulation of SGD with Momentum.}}{115}{figure.caption.168}\protected@file@percent }
\newlabel{fig:chapter4_momentum_alternative}{{4.17}{115}{Alternative formulation of SGD with Momentum}{figure.caption.168}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.4}Benefits of Momentum}{115}{subsection.4.9.4}\protected@file@percent }
\BKM@entry{id=151,dest={73756273656374696F6E2E342E392E35},srcline={693}}{5C3337365C3337375C303030445C3030306F5C303030775C3030306E5C303030735C303030695C303030645C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D}
\BKM@entry{id=152,dest={73756273656374696F6E2E342E392E36},srcline={703}}{5C3337365C3337375C3030304E5C303030655C303030735C303030745C303030655C303030725C3030306F5C303030765C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D5C3030303A5C3030305C3034305C303030415C3030305C3034305C3030304C5C3030306F5C3030306F5C3030306B5C3030302D5C303030415C303030685C303030655C303030615C303030645C3030305C3034305C303030535C303030745C303030725C303030615C303030745C303030655C303030675C30303079}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces Momentum accelerates convergence by smoothing oscillations and reducing noise.}}{116}{figure.caption.169}\protected@file@percent }
\newlabel{fig:chapter4_momentum_benefits}{{4.18}{116}{Momentum accelerates convergence by smoothing oscillations and reducing noise}{figure.caption.169}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.5}Downsides of Momentum}{116}{subsection.4.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.6}Nesterov Momentum: A Look-Ahead Strategy}{116}{subsection.4.9.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Overview}{116}{section*.170}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mathematical Formulation}{116}{section*.171}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces Nesterov Momentum: Look-ahead Gradient Update.}}{117}{figure.caption.172}\protected@file@percent }
\newlabel{fig:chapter4_nesterov_momentum}{{4.19}{117}{Nesterov Momentum: Look-ahead Gradient Update}{figure.caption.172}{}}
\@writefile{toc}{\contentsline {subsubsection}{Motivation and Advantages}{117}{section*.173}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reformulation for Practical Implementation}{118}{section*.174}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Comparison with SGD and SGD+Momentum}{118}{section*.175}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Limitations of Nesterov Momentum and the Need for Adaptivity}{118}{section*.176}\protected@file@percent }
\BKM@entry{id=153,dest={73656374696F6E2E342E3130},srcline={810}}{5C3337365C3337375C303030415C303030645C303030615C303030475C303030725C303030615C303030645C3030303A5C3030305C3034305C303030415C303030645C303030615C303030705C303030745C303030695C303030765C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030415C3030306C5C303030675C3030306F5C303030725C303030695C303030745C303030685C3030306D}
\BKM@entry{id=154,dest={73756273656374696F6E2E342E31302E31},srcline={821}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030415C303030645C303030615C303030475C303030725C303030615C303030645C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Motivation for a Better Optimizer: AdaGrad}{119}{section*.177}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.10}AdaGrad: Adaptive Gradient Algorithm}{119}{section.4.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces AdaGrad Implementation in PyTorch. Each parameter is updated individually, with learning rates adjusted based on the historical squared gradients.}}{119}{figure.caption.178}\protected@file@percent }
\newlabel{fig:chapter4_adagrad_impl}{{4.20}{119}{AdaGrad Implementation in PyTorch. Each parameter is updated individually, with learning rates adjusted based on the historical squared gradients}{figure.caption.178}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10.1}How AdaGrad Works}{119}{subsection.4.10.1}\protected@file@percent }
\BKM@entry{id=155,dest={73756273656374696F6E2E342E31302E32},srcline={849}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030415C303030645C303030615C303030475C303030725C303030615C30303064}
\BKM@entry{id=156,dest={73756273656374696F6E2E342E31302E33},srcline={861}}{5C3337365C3337375C303030445C303030695C303030735C303030615C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030415C303030645C303030615C303030475C303030725C303030615C30303064}
\@writefile{toc}{\contentsline {paragraph}{Updating the Weight Matrix Components}{120}{section*.179}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Does This Work?}{120}{section*.180}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10.2}Advantages of AdaGrad}{120}{subsection.4.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10.3}Disadvantages of AdaGrad}{120}{subsection.4.10.3}\protected@file@percent }
\BKM@entry{id=157,dest={73656374696F6E2E342E3131},srcline={879}}{5C3337365C3337375C303030525C3030304D5C303030535C303030505C303030725C3030306F5C303030705C3030303A5C3030305C3034305C303030525C3030306F5C3030306F5C303030745C3030305C3034305C3030304D5C303030655C303030615C3030306E5C3030305C3034305C303030535C303030715C303030755C303030615C303030725C303030655C3030305C3034305C303030505C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=158,dest={73756273656374696F6E2E342E31312E31},srcline={881}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030525C3030304D5C303030535C303030505C303030725C3030306F5C30303070}
\BKM@entry{id=159,dest={73756273656374696F6E2E342E31312E32},srcline={886}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030525C3030304D5C303030535C303030505C303030725C3030306F5C303030705C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=160,dest={73756273656374696F6E2E342E31312E33},srcline={908}}{5C3337365C3337375C303030555C303030705C303030645C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C3030304D5C303030615C303030745C303030725C303030695C303030785C3030305C3034305C303030435C3030306F5C3030306D5C303030705C3030306F5C3030306E5C303030655C3030306E5C303030745C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4.11}RMSProp: Root Mean Square Propagation}{121}{section.4.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.1}Motivation for RMSProp}{121}{subsection.4.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.2}How RMSProp Works}{121}{subsection.4.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.3}Updating the Weight Matrix Components}{121}{subsection.4.11.3}\protected@file@percent }
\BKM@entry{id=161,dest={73756273656374696F6E2E342E31312E34},srcline={932}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C3030304D5C303030535C303030505C303030725C3030306F5C30303070}
\BKM@entry{id=162,dest={73756273656374696F6E2E342E31312E35},srcline={948}}{5C3337365C3337375C303030445C3030306F5C303030775C3030306E5C303030735C303030695C303030645C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C3030304D5C303030535C303030505C303030725C3030306F5C30303070}
\@writefile{lof}{\contentsline {figure}{\numberline {4.21}{\ignorespaces The transformation from AdaGrad to RMSProp using a decay rate (\( \rho \)). RMSProp ensures better progress over the course of training by forgetting older squared gradients.}}{122}{figure.caption.181}\protected@file@percent }
\newlabel{fig:chapter4_rmsprop_conversion}{{4.21}{122}{The transformation from AdaGrad to RMSProp using a decay rate (\( \rho \)). RMSProp ensures better progress over the course of training by forgetting older squared gradients}{figure.caption.181}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.4}Advantages of RMSProp}{122}{subsection.4.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.5}Downsides of RMSProp}{122}{subsection.4.11.5}\protected@file@percent }
\newlabel{sec:downsides-rmsprop}{{4.11.5}{122}{Downsides of RMSProp}{subsection.4.11.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{No Momentum Carry-Over}{122}{section*.182}\protected@file@percent }
\newlabel{subsubsec:no-momentum-carry-over}{{4.11.5}{122}{No Momentum Carry-Over}{section*.182}{}}
\BKM@entry{id=163,dest={73756273656374696F6E2E342E31312E36},srcline={993}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030415C303030645C303030615C3030306D5C3030302C5C3030305C3034305C303030615C3030305C3034305C303030535C3030304F5C303030545C303030415C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030655C30303072}
\BKM@entry{id=164,dest={73656374696F6E2E342E3132},srcline={1007}}{5C3337365C3337375C303030415C303030645C303030615C3030306D5C3030303A5C3030305C3034305C303030415C303030645C303030615C303030705C303030745C303030695C303030765C303030655C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030455C303030735C303030745C303030695C3030306D5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=165,dest={73756273656374696F6E2E342E31322E31},srcline={1009}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030415C303030645C303030615C3030306D}
\@writefile{toc}{\contentsline {subsubsection}{Bias in Early Updates}{123}{section*.183}\protected@file@percent }
\newlabel{subsubsec:bias-early-updates}{{4.11.5}{123}{Bias in Early Updates}{section*.183}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to Hyperparameters}{123}{section*.184}\protected@file@percent }
\newlabel{subsubsec:sensitivity-hparams}{{4.11.5}{123}{Sensitivity to Hyperparameters}{section*.184}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.6}Motivation for Adam, a SOTA Optimizer}{123}{subsection.4.11.6}\protected@file@percent }
\newlabel{subsec:motivation-adam}{{4.11.6}{123}{Motivation for Adam, a SOTA Optimizer}{subsection.4.11.6}{}}
\BKM@entry{id=166,dest={73756273656374696F6E2E342E31322E32},srcline={1025}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030415C303030645C303030615C3030306D5C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4.12}Adam: Adaptive Moment Estimation}{124}{section.4.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.1}Motivation for Adam}{124}{subsection.4.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.2}How Adam Works}{124}{subsection.4.12.2}\protected@file@percent }
\BKM@entry{id=167,dest={73756273656374696F6E2E342E31322E33},srcline={1055}}{5C3337365C3337375C303030425C303030695C303030615C303030735C3030305C3034305C303030435C3030306F5C303030725C303030725C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {4.22}{\ignorespaces Adam implementation without bias correction, as shown in PyTorch.}}{125}{figure.caption.185}\protected@file@percent }
\newlabel{fig:chapter4_adam_basic}{{4.22}{125}{Adam implementation without bias correction, as shown in PyTorch}{figure.caption.185}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.3}Bias Correction}{125}{subsection.4.12.3}\protected@file@percent }
\BKM@entry{id=168,dest={73756273656374696F6E2E342E31322E34},srcline={1077}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030415C303030645C303030615C3030306D5C3030305C3034305C303030575C3030306F5C303030725C3030306B5C303030735C3030305C3034305C303030575C303030655C3030306C5C3030306C5C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C303030725C303030615C303030635C303030745C303030695C303030635C30303065}
\BKM@entry{id=169,dest={73756273656374696F6E2E342E31322E35},srcline={1089}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304F5C303030745C303030685C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030655C303030725C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {4.23}{\ignorespaces Complete Adam implementation with bias correction as shown in PyTorch.}}{126}{figure.caption.186}\protected@file@percent }
\newlabel{fig:chapter4_adam_bias_correction}{{4.23}{126}{Complete Adam implementation with bias correction as shown in PyTorch}{figure.caption.186}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.4}Why Adam Works Well in Practice}{126}{subsection.4.12.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.24}{\ignorespaces Examples of Adam's hyperparameter usage in various deep learning papers.}}{126}{figure.caption.187}\protected@file@percent }
\newlabel{fig:chapter4_adam_hyperparams}{{4.24}{126}{Examples of Adam's hyperparameter usage in various deep learning papers}{figure.caption.187}{}}
\BKM@entry{id=170,dest={73756273656374696F6E2E342E31322E36},srcline={1099}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030415C303030645C303030615C3030306D}
\BKM@entry{id=171,dest={73756273656374696F6E2E342E31322E37},srcline={1107}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030415C303030645C303030615C3030306D}
\BKM@entry{id=172,dest={73656374696F6E2E342E3133},srcline={1117}}{5C3337365C3337375C303030415C303030645C303030615C3030306D5C303030575C3030303A5C3030305C3034305C303030445C303030655C303030635C3030306F5C303030755C303030705C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C303030445C303030655C303030635C303030615C303030795C3030305C3034305C303030665C303030725C3030306F5C3030306D5C3030305C3034305C3030304C5C303030325C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=173,dest={73756273656374696F6E2E342E31332E31},srcline={1119}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030415C303030645C303030615C3030306D5C30303057}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.5}Comparison with Other Optimizers}{127}{subsection.4.12.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.25}{\ignorespaces Comparison of optimizers: SGD, SGD+Momentum, RMSProp, and Adam. Adam converges faster with fewer oscillations.}}{127}{figure.caption.188}\protected@file@percent }
\newlabel{fig:chapter4_adam_comparison}{{4.25}{127}{Comparison of optimizers: SGD, SGD+Momentum, RMSProp, and Adam. Adam converges faster with fewer oscillations}{figure.caption.188}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.6}Advantages of Adam}{127}{subsection.4.12.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.7}Limitations of Adam}{127}{subsection.4.12.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Looking Ahead}{127}{section*.189}\protected@file@percent }
\BKM@entry{id=174,dest={73756273656374696F6E2E342E31332E32},srcline={1135}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030415C303030645C303030615C3030306D5C303030575C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4.13}AdamW: Decoupling Weight Decay from L2 Regularization}{128}{section.4.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.1}Motivation for AdamW}{128}{subsection.4.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.26}{\ignorespaces Integration of L2 regularization and weight decay in AdamW. Decoupling these ensures consistent penalization of parameter magnitudes.}}{128}{figure.caption.190}\protected@file@percent }
\newlabel{fig:chapter4_adamw_weight_decay}{{4.26}{128}{Integration of L2 regularization and weight decay in AdamW. Decoupling these ensures consistent penalization of parameter magnitudes}{figure.caption.190}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.2}How AdamW Works}{128}{subsection.4.13.2}\protected@file@percent }
\BKM@entry{id=175,dest={73756273656374696F6E2E342E31332E33},srcline={1159}}{5C3337365C3337375C3030304E5C3030306F5C303030745C303030655C3030305C3034305C3030306F5C3030306E5C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C303030445C303030655C303030635C303030615C303030795C3030305C3034305C303030695C3030306E5C3030305C3034305C303030415C303030645C303030615C3030306D5C30303057}
\BKM@entry{id=176,dest={73756273656374696F6E2E342E31332E34},srcline={1174}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030415C303030645C303030615C3030306D5C303030575C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C3030306D5C303030655C3030306E5C30303074}
\@writefile{lof}{\contentsline {figure}{\numberline {4.27}{\ignorespaces Pseudo-code for AdamW, illustrating the decoupling of weight decay from L2 regularization.}}{129}{figure.caption.191}\protected@file@percent }
\newlabel{fig:chapter4_adamw_pseudocode}{{4.27}{129}{Pseudo-code for AdamW, illustrating the decoupling of weight decay from L2 regularization}{figure.caption.191}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.3}Note on Weight Decay in AdamW}{129}{subsection.4.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.4}The AdamW Improvement}{129}{subsection.4.13.4}\protected@file@percent }
\BKM@entry{id=177,dest={73756273656374696F6E2E342E31332E35},srcline={1187}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030415C303030645C303030615C3030306D5C30303057}
\BKM@entry{id=178,dest={73756273656374696F6E2E342E31332E36},srcline={1198}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030415C303030645C303030615C3030306D5C303030575C3030305C3034305C303030695C303030735C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030445C303030655C303030665C303030615C303030755C3030306C5C303030745C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030655C30303072}
\BKM@entry{id=179,dest={73756273656374696F6E2E342E31332E37},srcline={1206}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030415C303030645C303030615C3030306D5C30303057}
\BKM@entry{id=180,dest={73656374696F6E2E342E3134},srcline={1213}}{5C3337365C3337375C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=181,dest={73756273656374696F6E2E342E31342E31},srcline={1215}}{5C3337365C3337375C3030304F5C303030765C303030655C303030725C303030765C303030695C303030655C303030775C3030305C3034305C3030306F5C303030665C3030305C3034305C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.5}Advantages of AdamW}{130}{subsection.4.13.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.6}Why AdamW is the Default Optimizer}{130}{subsection.4.13.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.7}Limitations of AdamW}{130}{subsection.4.13.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.14}Second-Order Optimization}{130}{section.4.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.1}Overview of Second-Order Optimization}{130}{subsection.4.14.1}\protected@file@percent }
\BKM@entry{id=182,dest={73756273656374696F6E2E342E31342E32},srcline={1235}}{5C3337365C3337375C303030515C303030755C303030615C303030645C303030725C303030615C303030745C303030695C303030635C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030785C303030695C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030555C303030735C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030485C303030655C303030735C303030735C303030695C303030615C3030306E}
\BKM@entry{id=183,dest={73756273656374696F6E2E342E31342E33},srcline={1251}}{5C3337365C3337375C303030505C303030725C303030615C303030635C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {4.28}{\ignorespaces Second-order optimization forms a quadratic surface to approximate the objective function and adaptively determines step size.}}{131}{figure.caption.192}\protected@file@percent }
\newlabel{fig:chapter4_second_order_quadratic}{{4.28}{131}{Second-order optimization forms a quadratic surface to approximate the objective function and adaptively determines step size}{figure.caption.192}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.2}Quadratic Approximation Using the Hessian}{131}{subsection.4.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.3}Practical Challenges of Second-Order Methods}{131}{subsection.4.14.3}\protected@file@percent }
\BKM@entry{id=184,dest={73756273656374696F6E2E342E31342E34},srcline={1268}}{5C3337365C3337375C303030465C303030695C303030725C303030735C303030745C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C303030735C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030785C303030695C3030306D5C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C303030425C303030655C303030685C303030615C303030765C303030695C3030306F5C30303072}
\BKM@entry{id=185,dest={73756273656374696F6E2E342E31342E35},srcline={1276}}{5C3337365C3337375C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030695C3030306E5C303030675C3030305C3034305C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030425C303030465C303030475C303030535C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C3030302D5C303030425C303030465C303030475C30303053}
\@writefile{lof}{\contentsline {figure}{\numberline {4.29}{\ignorespaces Challenges of second-order optimization in high-dimensional spaces, including storage and computational costs.}}{132}{figure.caption.193}\protected@file@percent }
\newlabel{fig:chapter4_second_order_limitations}{{4.29}{132}{Challenges of second-order optimization in high-dimensional spaces, including storage and computational costs}{figure.caption.193}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.4}First-Order Methods Approximating Second-Order Behavior}{132}{subsection.4.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.5}Improving Second-Order Optimization: BFGS and L-BFGS}{132}{subsection.4.14.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.30}{\ignorespaces BFGS and L-BFGS use approximations to reduce the computational and memory demands of second-order optimization.}}{133}{figure.caption.194}\protected@file@percent }
\newlabel{fig:chapter4_bfgs_lbfgs}{{4.30}{133}{BFGS and L-BFGS use approximations to reduce the computational and memory demands of second-order optimization}{figure.caption.194}{}}
\@writefile{toc}{\contentsline {subsubsection}{BFGS: An Approximation of the Hessian Matrix}{133}{section*.195}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{L-BFGS: Reducing Memory Requirements}{133}{section*.196}\protected@file@percent }
\BKM@entry{id=186,dest={73756273656374696F6E2E342E31342E36},srcline={1329}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030305C3034305C3030306F5C303030665C3030305C3034305C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C303030685C303030655C30303073}
\@writefile{toc}{\contentsline {subsubsection}{Advantages and Limitations of BFGS and L-BFGS}{134}{section*.197}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages:}{134}{section*.198}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Limitations:}{134}{section*.199}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Applications of L-BFGS}{134}{section*.200}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.6}Summary of Second-Order Optimization Approaches}{134}{subsection.4.14.6}\protected@file@percent }
\BKM@entry{id=187,dest={636861707465722E35},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030355C3030303A5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=188,dest={73656374696F6E2E352E31},srcline={10}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=189,dest={73756273656374696F6E2E352E312E31},srcline={13}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\BKM@entry{id=190,dest={73756273656374696F6E2E352E312E32},srcline={22}}{5C3337365C3337375C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030735C3030305C3034305C303030615C303030735C3030305C3034305C303030615C3030305C3034305C303030535C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Lecture 5: Neural Networks}{135}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@4}}
\ttl@writefile{ptc}{\ttl@starttoc{default@5}}
\pgfsyspdfmark {pgfid15}{0}{52099153}
\pgfsyspdfmark {pgfid14}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction to Neural Networks}{135}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Limitations of Linear Classifiers}{135}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Feature Transforms as a Solution}{135}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Transforms in Action}{135}{section*.201}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Cartesian to polar transformation enabling linear separability in the feature space.}}{136}{figure.caption.202}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Color histogram as a feature representation for images.}}{136}{figure.caption.203}\protected@file@percent }
\newlabel{fig:chapter5_color_histogram}{{5.2}{136}{Color histogram as a feature representation for images}{figure.caption.203}{}}
\BKM@entry{id=191,dest={73756273656374696F6E2E352E312E33},srcline={60}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C3030304D5C303030615C3030306E5C303030755C303030615C3030306C5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=192,dest={73756273656374696F6E2E352E312E34},srcline={67}}{5C3337365C3337375C303030445C303030615C303030745C303030615C3030302D5C303030445C303030725C303030695C303030765C303030655C3030306E5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Histogram of Oriented Gradients (HoG) as a feature representation for images.}}{137}{figure.caption.204}\protected@file@percent }
\newlabel{fig:chapter5_hog}{{5.3}{137}{Histogram of Oriented Gradients (HoG) as a feature representation for images}{figure.caption.204}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Challenges in Manual Feature Transformations}{137}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Data-Driven Feature Transformations}{137}{subsection.5.1.4}\protected@file@percent }
\BKM@entry{id=193,dest={73756273656374696F6E2E352E312E35},srcline={85}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030625C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030655C3030305C3034305C303030525C303030655C303030705C303030725C303030655C303030735C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=194,dest={73756273656374696F6E2E352E312E36},srcline={95}}{5C3337365C3337375C303030525C303030655C303030615C3030306C5C3030302D5C303030575C3030306F5C303030725C3030306C5C303030645C3030305C3034305C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030325C303030305C303030315C303030315C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030304E5C303030655C303030745C3030305C3034305C303030575C303030695C3030306E5C3030306E5C303030655C30303072}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Bag of Words approach for feature transformation.}}{138}{figure.caption.205}\protected@file@percent }
\newlabel{fig:chapter5_bag_of_words}{{5.4}{138}{Bag of Words approach for feature transformation}{figure.caption.205}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Combining Multiple Representations}{138}{subsection.5.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Combining multiple feature representations into a single feature vector.}}{138}{figure.caption.206}\protected@file@percent }
\newlabel{fig:chapter5_combined_features}{{5.5}{138}{Combining multiple feature representations into a single feature vector}{figure.caption.206}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.6}Real-World Example: 2011 ImageNet Winner}{138}{subsection.5.1.6}\protected@file@percent }
\BKM@entry{id=195,dest={73656374696F6E2E352E32},srcline={115}}{5C3337365C3337375C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030425C303030615C303030735C303030695C303030635C30303073}
\BKM@entry{id=196,dest={73756273656374696F6E2E352E322E31},srcline={117}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Feature extraction pipeline of the 2011 ImageNet winner.}}{139}{figure.caption.207}\protected@file@percent }
\newlabel{fig:chapter5_imagenet_pipeline}{{5.6}{139}{Feature extraction pipeline of the 2011 ImageNet winner}{figure.caption.207}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Neural Networks: The Basics}{139}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Motivation for Neural Networks}{139}{subsection.5.2.1}\protected@file@percent }
\BKM@entry{id=197,dest={73756273656374696F6E2E352E322E32},srcline={137}}{5C3337365C3337375C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030655C303030645C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Comparison between the classic feature extraction pipeline and the neural network-based pipeline. The neural network pipeline is fully tunable end-to-end based on training data.}}{140}{figure.caption.208}\protected@file@percent }
\newlabel{fig:chapter5_classic_vs_nn_pipeline}{{5.7}{140}{Comparison between the classic feature extraction pipeline and the neural network-based pipeline. The neural network pipeline is fully tunable end-to-end based on training data}{figure.caption.208}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Mathematical/functional notation of linear classifiers compared to small neural networks.}}{140}{figure.caption.209}\protected@file@percent }
\newlabel{fig:chapter5_nn_functional_notation}{{5.8}{140}{Mathematical/functional notation of linear classifiers compared to small neural networks}{figure.caption.209}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Fully Connected Networks}{140}{subsection.5.2.2}\protected@file@percent }
\BKM@entry{id=198,dest={73756273656374696F6E2E352E322E33},srcline={147}}{5C3337365C3337375C303030495C3030306E5C303030745C303030655C303030725C303030705C303030725C303030655C303030745C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces A visual representation of a fully connected neural network with a single hidden layer, an input layer, and an output layer.}}{141}{figure.caption.210}\protected@file@percent }
\newlabel{fig:chapter5_fc_network}{{5.9}{141}{A visual representation of a fully connected neural network with a single hidden layer, an input layer, and an output layer}{figure.caption.210}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Interpreting Neural Networks}{141}{subsection.5.2.3}\protected@file@percent }
\BKM@entry{id=199,dest={73656374696F6E2E352E33},srcline={164}}{5C3337365C3337375C303030425C303030755C303030695C3030306C5C303030645C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=200,dest={73756273656374696F6E2E352E332E31},srcline={174}}{5C3337365C3337375C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C303030735C3030303A5C3030305C3034305C3030304E5C3030306F5C3030306E5C3030302D5C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030425C303030725C303030695C303030645C303030675C303030655C303030735C3030305C3034305C303030425C303030655C303030745C303030775C303030655C303030655C3030306E5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Visualization of learned templates in the first layer of a neural network, including a left-facing and a right-facing horse.}}{142}{figure.caption.211}\protected@file@percent }
\newlabel{fig:chapter5_learned_templates}{{5.10}{142}{Visualization of learned templates in the first layer of a neural network, including a left-facing and a right-facing horse}{figure.caption.211}{}}
\@writefile{toc}{\contentsline {paragraph}{Network Pruning: Pruning Redundant Representations}{142}{section*.212}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Building Neural Networks}{142}{section.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces A visual representation of a deep neural network.}}{142}{figure.caption.213}\protected@file@percent }
\newlabel{fig:chapter5_deep_nn}{{5.11}{142}{A visual representation of a deep neural network}{figure.caption.213}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Activation Functions: Non-Linear Bridges Between Layers}{143}{subsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Collapsing multiple linear layers reduces the network to a linear classifier.}}{143}{figure.caption.214}\protected@file@percent }
\newlabel{fig:chapter5_linear_collapse}{{5.12}{143}{Collapsing multiple linear layers reduces the network to a linear classifier}{figure.caption.214}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Non-Linearity Matters.}{143}{section*.215}\protected@file@percent }
\BKM@entry{id=201,dest={73756273656374696F6E2E352E332E32},srcline={207}}{5C3337365C3337375C303030415C3030305C3034305C303030535C303030695C3030306D5C303030705C3030306C5C303030655C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C3030305C3034305C303030695C3030306E5C3030305C3034305C303030325C303030305C3030305C3034305C3030304C5C303030695C3030306E5C303030655C30303073}
\BKM@entry{id=202,dest={73656374696F6E2E352E34},srcline={224}}{5C3337365C3337375C303030425C303030695C3030306F5C3030306C5C3030306F5C303030675C303030695C303030635C303030615C3030306C5C3030305C3034305C303030495C3030306E5C303030735C303030705C303030695C303030725C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Examples of common activation functions.}}{144}{figure.caption.216}\protected@file@percent }
\newlabel{fig:chapter5_activation_functions}{{5.13}{144}{Examples of common activation functions}{figure.caption.216}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}A Simple Neural Network in 20 Lines}{144}{subsection.5.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Minimal implementation of a neural network in under 20 lines of code.}}{144}{figure.caption.217}\protected@file@percent }
\newlabel{fig:chapter5_simple_nn}{{5.14}{144}{Minimal implementation of a neural network in under 20 lines of code}{figure.caption.217}{}}
\BKM@entry{id=203,dest={73756273656374696F6E2E352E342E31},srcline={249}}{5C3337365C3337375C303030425C303030695C3030306F5C3030306C5C3030306F5C303030675C303030695C303030635C303030615C3030306C5C3030305C3034305C303030415C3030306E5C303030615C3030306C5C3030306F5C303030675C303030795C3030303A5C3030305C3034305C303030615C3030305C3034305C3030304C5C3030306F5C3030306F5C303030735C303030655C3030305C3034305C303030415C3030306E5C303030615C3030306C5C3030306F5C303030675C30303079}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Biological Inspiration}{145}{section.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Biological inspiration: flow of impulses in neurons.}}{145}{figure.caption.218}\protected@file@percent }
\newlabel{fig:chapter5_biological_inspiration}{{5.15}{145}{Biological inspiration: flow of impulses in neurons}{figure.caption.218}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Comparison of biological neurons and artificial neurons.}}{145}{figure.caption.219}\protected@file@percent }
\newlabel{fig:chapter5_artificial_neurons}{{5.16}{145}{Comparison of biological neurons and artificial neurons}{figure.caption.219}{}}
\BKM@entry{id=204,dest={73656374696F6E2E352E35},srcline={257}}{5C3337365C3337375C303030535C303030705C303030615C303030635C303030655C3030305C3034305C303030575C303030615C303030725C303030705C303030695C3030306E5C303030675C3030303A5C3030305C3034305C303030415C3030306E5C3030306F5C303030745C303030685C303030655C303030725C3030305C3034305C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030415C303030725C303030745C303030695C303030665C303030695C303030635C303030695C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=205,dest={73756273656374696F6E2E352E352E31},srcline={271}}{5C3337365C3337375C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030545C303030685C303030655C303030695C303030725C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Biological Analogy: a Loose Analogy}{146}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Space Warping: Another Motivation for Artificial Neural Networks}{146}{section.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Transforming input features \( x_1, x_2 \) into a new feature space \( h \) via \( h = \mathbf  {W} \mathbf  {x} \).}}{146}{figure.caption.220}\protected@file@percent }
\newlabel{fig:chapter5_linear_transformation}{{5.17}{146}{Transforming input features \( x_1, x_2 \) into a new feature space \( h \) via \( h = \mathbf {W} \mathbf {x} \)}{figure.caption.220}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Linear Transformations and Their Limitations}{146}{subsection.5.5.1}\protected@file@percent }
\BKM@entry{id=206,dest={73756273656374696F6E2E352E352E32},srcline={283}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030695C3030306E5C303030675C3030305C3034305C3030304E5C3030306F5C3030306E5C3030302D5C3030304C5C303030695C3030306E5C303030655C303030615C303030725C303030695C303030745C303030795C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030525C303030655C3030304C5C30303055}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Regions in the input space divided by linear decision boundaries.}}{147}{figure.caption.221}\protected@file@percent }
\newlabel{fig:chapter5_input_regions}{{5.18}{147}{Regions in the input space divided by linear decision boundaries}{figure.caption.221}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Introducing Non-Linearity with ReLU}{147}{subsection.5.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Transformation of quadrants using ReLU, collapsing regions onto specific axes.}}{147}{figure.caption.222}\protected@file@percent }
\newlabel{fig:chapter5_relu_quadrants}{{5.19}{147}{Transformation of quadrants using ReLU, collapsing regions onto specific axes}{figure.caption.222}{}}
\BKM@entry{id=207,dest={73756273656374696F6E2E352E352E33},srcline={305}}{5C3337365C3337375C3030304D5C303030615C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030445C303030615C303030745C303030615C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030306C5C303030795C3030305C3034305C303030535C303030655C303030705C303030615C303030725C303030615C303030625C3030306C5C30303065}
\BKM@entry{id=208,dest={73756273656374696F6E2E352E352E34},srcline={313}}{5C3337365C3337375C303030535C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030555C303030705C3030303A5C3030305C3034305C303030495C3030306E5C303030635C303030725C303030655C303030615C303030735C303030695C3030306E5C303030675C3030305C3034305C303030525C303030655C303030705C303030725C303030655C303030735C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030505C3030306F5C303030775C303030655C30303072}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Making Data Linearly Separable}{148}{subsection.5.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Non-linearity (e.g., ReLU) enables linear separability in the transformed feature space.}}{148}{figure.caption.223}\protected@file@percent }
\newlabel{fig:chapter5_relu_separability}{{5.20}{148}{Non-linearity (e.g., ReLU) enables linear separability in the transformed feature space}{figure.caption.223}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Scaling Up: Increasing Representation Power}{148}{subsection.5.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces Adding hidden units increases the complexity of decision boundaries in the input space.}}{148}{figure.caption.224}\protected@file@percent }
\newlabel{fig:chapter5_complex_boundaries}{{5.21}{148}{Adding hidden units increases the complexity of decision boundaries in the input space}{figure.caption.224}{}}
\BKM@entry{id=209,dest={73756273656374696F6E2E352E352E35},srcline={323}}{5C3337365C3337375C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=210,dest={73656374696F6E2E352E36},srcline={333}}{5C3337365C3337375C303030555C3030306E5C303030695C303030765C303030655C303030725C303030735C303030615C3030306C5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030785C303030695C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030685C303030655C3030306F5C303030725C303030655C3030306D}
\BKM@entry{id=211,dest={73756273656374696F6E2E352E362E31},srcline={344}}{5C3337365C3337375C303030505C303030725C303030615C303030635C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306E5C303030745C303030655C303030785C303030745C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030425C303030755C3030306D5C303030705C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.5}Regularizing Neural Networks}{149}{subsection.5.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Using stronger L2 regularization to simplify decision boundaries and reduce overfitting.}}{149}{figure.caption.225}\protected@file@percent }
\newlabel{fig:chapter5_regularization}{{5.22}{149}{Using stronger L2 regularization to simplify decision boundaries and reduce overfitting}{figure.caption.225}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Universal Approximation Theorem}{149}{section.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Practical Context: The Bump Function}{149}{subsection.5.6.1}\protected@file@percent }
\BKM@entry{id=212,dest={73756273656374696F6E2E352E362E32},srcline={361}}{5C3337365C3337375C303030515C303030755C303030655C303030735C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030465C303030755C303030725C303030745C303030685C303030655C303030725C3030305C3034305C303030455C303030785C303030705C3030306C5C3030306F5C303030725C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=213,dest={73756273656374696F6E2E352E362E33},srcline={370}}{5C3337365C3337375C303030525C303030655C303030615C3030306C5C303030695C303030745C303030795C3030305C3034305C303030435C303030685C303030655C303030635C3030306B5C3030303A5C3030305C3034305C303030555C3030306E5C303030695C303030765C303030655C303030725C303030735C303030615C3030306C5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030785C303030695C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030695C303030735C3030305C3034305C3030304E5C3030306F5C303030745C3030305C3034305C303030455C3030306E5C3030306F5C303030755C303030675C30303068}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces A bump function constructed using four hidden units, demonstrating the capacity of neural networks to approximate complex functions.}}{150}{figure.caption.226}\protected@file@percent }
\newlabel{fig:chapter5_bump_function}{{5.23}{150}{A bump function constructed using four hidden units, demonstrating the capacity of neural networks to approximate complex functions}{figure.caption.226}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}Questions for Further Exploration}{150}{subsection.5.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}Reality Check: Universal Approximation is Not Enough}{150}{subsection.5.6.3}\protected@file@percent }
\BKM@entry{id=214,dest={73656374696F6E2E352E37},srcline={389}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030765C303030655C303030785C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C303030735C3030303A5C3030305C3034305C303030415C3030305C3034305C303030535C303030705C303030655C303030635C303030695C303030615C3030306C5C3030305C3034305C303030435C303030615C303030735C30303065}
\@writefile{lof}{\contentsline {figure}{\numberline {5.24}{\ignorespaces Reality check: Neural networks can approximate complex functions, but universal approximation does not guarantee practical learnability.}}{151}{figure.caption.227}\protected@file@percent }
\newlabel{fig:chapter5_reality_check}{{5.24}{151}{Reality check: Neural networks can approximate complex functions, but universal approximation does not guarantee practical learnability}{figure.caption.227}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Convex Functions: A Special Case}{151}{section.5.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.25}{\ignorespaces The parabola \( f(x) = x^2 \) is an example of a convex function.}}{151}{figure.caption.228}\protected@file@percent }
\newlabel{fig:chapter5_convex_function}{{5.25}{151}{The parabola \( f(x) = x^2 \) is an example of a convex function}{figure.caption.228}{}}
\BKM@entry{id=215,dest={73756273656374696F6E2E352E372E31},srcline={410}}{5C3337365C3337375C3030304E5C3030306F5C3030306E5C3030302D5C303030435C3030306F5C3030306E5C303030765C303030655C303030785C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=216,dest={73756273656374696F6E2E352E372E32},srcline={420}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030765C303030655C303030785C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030695C3030306E5C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.1}Non-Convex Functions}{152}{subsection.5.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.26}{\ignorespaces \( f(x) = \cos (x) \) is an example of a non-convex function.}}{152}{figure.caption.229}\protected@file@percent }
\newlabel{fig:chapter5_nonconvex_function}{{5.26}{152}{\( f(x) = \cos (x) \) is an example of a non-convex function}{figure.caption.229}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.2}Convex Optimization in Linear Classifiers}{152}{subsection.5.7.2}\protected@file@percent }
\BKM@entry{id=217,dest={73756273656374696F6E2E352E372E33},srcline={442}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=218,dest={73756273656374696F6E2E352E372E34},srcline={451}}{5C3337365C3337375C303030425C303030725C303030695C303030645C303030675C303030695C3030306E5C303030675C3030305C3034305C303030745C3030306F5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {5.27}{\ignorespaces Optimization problems for linear classifiers are convex.}}{153}{figure.caption.230}\protected@file@percent }
\newlabel{fig:chapter5_linear_convex_optimization}{{5.27}{153}{Optimization problems for linear classifiers are convex}{figure.caption.230}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.3}Challenges with Neural Networks}{153}{subsection.5.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.4}Bridging to Backpropagation: Efficient Gradient Computation}{153}{subsection.5.7.4}\protected@file@percent }
\BKM@entry{id=219,dest={636861707465722E36},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030365C3030303A5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=220,dest={73656374696F6E2E362E31},srcline={10}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C30303073}
\BKM@entry{id=221,dest={73756273656374696F6E2E362E312E31},srcline={25}}{5C3337365C3337375C303030415C3030305C3034305C303030425C303030615C303030645C3030305C3034305C303030495C303030645C303030655C303030615C3030303A5C3030305C3034305C3030304D5C303030615C3030306E5C303030755C303030615C3030306C5C3030306C5C303030795C3030305C3034305C303030445C303030655C303030725C303030695C303030765C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Lecture 6: Backpropagation}{154}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@5}}
\ttl@writefile{ptc}{\ttl@starttoc{default@6}}
\pgfsyspdfmark {pgfid17}{0}{52099153}
\pgfsyspdfmark {pgfid16}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction: The Challenge of Computing Gradients}{154}{section.6.1}\protected@file@percent }
\newlabel{sec:introduction}{{6.1}{154}{Introduction: The Challenge of Computing Gradients}{section.6.1}{}}
\BKM@entry{id=222,dest={73756273656374696F6E2E362E312E32},srcline={36}}{5C3337365C3337375C303030415C3030305C3034305C303030425C303030655C303030745C303030745C303030655C303030725C3030305C3034305C303030495C303030645C303030655C303030615C3030303A5C3030305C3034305C303030555C303030745C303030695C3030306C5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C3030305C3035305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C303531}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}A Bad Idea: Manually Deriving Gradients}{155}{subsection.6.1.1}\protected@file@percent }
\newlabel{sec:manual-gradients}{{6.1.1}{155}{A Bad Idea: Manually Deriving Gradients}{subsection.6.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Manually deriving gradients for a simple linear classifier using the SVM loss. This process becomes infeasible for deep networks.}}{155}{figure.caption.231}\protected@file@percent }
\newlabel{fig:chapter6_manual_gradients}{{6.1}{155}{Manually deriving gradients for a simple linear classifier using the SVM loss. This process becomes infeasible for deep networks}{figure.caption.231}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}A Better Idea: Utilizing Computational Graphs (Backpropagation)}{155}{subsection.6.1.2}\protected@file@percent }
\newlabel{sec:comp-graphs}{{6.1.2}{155}{A Better Idea: Utilizing Computational Graphs (Backpropagation)}{subsection.6.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Computational graphs provide a structured, automatic approach to computing gradients.}}{155}{figure.caption.232}\protected@file@percent }
\newlabel{fig:chapter6_comp_graphs}{{6.2}{155}{Computational graphs provide a structured, automatic approach to computing gradients}{figure.caption.232}{}}
\BKM@entry{id=223,dest={73656374696F6E2E362E32},srcline={61}}{5C3337365C3337375C303030545C3030306F5C303030795C3030305C3034305C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030665C3030305C3035305C303030785C3030302C5C303030795C3030302C5C3030307A5C3030305C3035315C3030303D5C3030305C3035305C303030785C3030302B5C303030795C3030305C3035315C3030307A}
\@writefile{toc}{\contentsline {paragraph}{Why Use Computational Graphs?}{156}{section*.233}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Toy Example of Backpropagation: $f(x,y,z) = (x + y)\,z$}{156}{section.6.2}\protected@file@percent }
\newlabel{sec:toy-example}{{6.2}{156}{Toy Example of Backpropagation: \texorpdfstring {$f(x,y,z) = (x + y)\,z$}{f(x,y,z)=(x+y)z}}{section.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Computational graph representation of \(f(x,y,z) = (x + y)z\), showing forward and backward passes. Intermediate values of the forward pass are presented in green on-top of the graph edges, while the corresponding backpropagation values are presented in red below the edges.}}{156}{figure.caption.234}\protected@file@percent }
\newlabel{fig:chapter6_example_fxyz}{{6.3}{156}{Computational graph representation of \(f(x,y,z) = (x + y)z\), showing forward and backward passes. Intermediate values of the forward pass are presented in green on-top of the graph edges, while the corresponding backpropagation values are presented in red below the edges}{figure.caption.234}{}}
\BKM@entry{id=224,dest={73756273656374696F6E2E362E322E31},srcline={78}}{5C3337365C3337375C303030465C3030306F5C303030725C303030775C303030615C303030725C303030645C3030305C3034305C303030505C303030615C303030735C30303073}
\BKM@entry{id=225,dest={73756273656374696F6E2E362E322E32},srcline={85}}{5C3337365C3337375C303030425C303030615C303030635C3030306B5C303030775C303030615C303030725C303030645C3030305C3034305C303030505C303030615C303030735C303030735C3030303A5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C30303073}
\BKM@entry{id=226,dest={73656374696F6E2E362E33},srcline={94}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030303F}
\BKM@entry{id=227,dest={73756273656374696F6E2E362E332E31},srcline={95}}{5C3337365C3337375C3030304C5C3030306F5C303030635C303030615C3030306C5C3030305C3034305C3030305C3034365C3030305C3034305C303030535C303030635C303030615C3030306C5C303030615C303030625C3030306C5C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C303030735C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Forward Pass}{157}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Backward Pass: Computing Gradients}{157}{subsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Why Backpropagation?}{157}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Local \& Scalable Gradients Computation}{157}{subsection.6.3.1}\protected@file@percent }
\newlabel{subsec:local-upstream}{{6.3.1}{157}{Local \& Scalable Gradients Computation}{subsection.6.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces During backpropagation, each node in the computational graph computes its downstream gradients using the local gradient (computed based on the local operation over the input. For instance, if we denote the input to the node as x and the node computes $\frac  {1}{x}$, then the local gradient is $\frac  {\partial }{\partial x}{[\frac  {1}{x}]}=-\frac  {1}{x^2}$) and the upstream gradient that is simply given as input from subsequent nodes.}}{157}{figure.caption.235}\protected@file@percent }
\newlabel{fig:chapter6_local_upstream}{{6.4}{157}{During backpropagation, each node in the computational graph computes its downstream gradients using the local gradient (computed based on the local operation over the input. For instance, if we denote the input to the node as x and the node computes $\frac {1}{x}$, then the local gradient is $\frac {\partial }{\partial x}{[\frac {1}{x}]}=-\frac {1}{x^2}$) and the upstream gradient that is simply given as input from subsequent nodes}{figure.caption.235}{}}
\BKM@entry{id=228,dest={73756273656374696F6E2E362E332E32},srcline={128}}{5C3337365C3337375C303030505C303030615C303030695C303030725C303030695C3030306E5C303030675C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C303030735C3030305C3034305C3030305C3034365C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030655C303030725C303030735C3030305C3034305C303030695C303030735C3030305C3034305C303030455C303030615C303030735C30303079}
\BKM@entry{id=229,dest={73756273656374696F6E2E362E332E33},srcline={131}}{5C3337365C3337375C3030304D5C3030306F5C303030645C303030755C3030306C5C303030615C303030725C303030695C303030745C303030795C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C303030755C303030735C303030745C3030306F5C3030306D5C3030305C3034305C3030304E5C3030306F5C303030645C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Visualizing the backpropagation process for a node f that is given as inputs x, y and outputs z. As can be seen, the backpropagation gives us the upstream gradient from subsequent node in the graph, and we are only left with the local gradients computation: $\frac  {\partial z}{\partial x}, \frac  {\partial z}{\partial y}$ in order to compute the downstream gradients: $\frac  {\partial L}{\partial x}, \frac  {\partial L}{\partial y}$ allowing us to continue the graph traversal in the backpropagation process.}}{158}{figure.caption.236}\protected@file@percent }
\newlabel{fig:chapter6_indpendent_node}{{6.5}{158}{Visualizing the backpropagation process for a node f that is given as inputs x, y and outputs z. As can be seen, the backpropagation gives us the upstream gradient from subsequent node in the graph, and we are only left with the local gradients computation: $\frac {\partial z}{\partial x}, \frac {\partial z}{\partial y}$ in order to compute the downstream gradients: $\frac {\partial L}{\partial x}, \frac {\partial L}{\partial y}$ allowing us to continue the graph traversal in the backpropagation process}{figure.caption.236}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Pairing Backpropagation Gradients \& Optimizers is Easy}{158}{subsection.6.3.2}\protected@file@percent }
\BKM@entry{id=230,dest={73756273656374696F6E2E362E332E34},srcline={150}}{5C3337365C3337375C303030555C303030745C303030695C3030306C5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030505C303030615C303030745C303030745C303030655C303030725C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030465C3030306C5C3030306F5C30303077}
\BKM@entry{id=231,dest={73756273656374696F6E2E362E332E35},srcline={155}}{5C3337365C3337375C303030415C303030645C303030645C303030695C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030475C303030615C303030745C303030655C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030695C303030735C303030745C303030725C303030695C303030625C303030755C303030745C3030306F5C30303072}
\BKM@entry{id=232,dest={73756273656374696F6E2E362E332E36},srcline={160}}{5C3337365C3337375C303030435C3030306F5C303030705C303030795C3030305C3034305C303030475C303030615C303030745C303030655C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030415C303030645C303030645C303030655C30303072}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Modularity and Custom Nodes}{159}{subsection.6.3.3}\protected@file@percent }
\newlabel{sec:modularity-custom-nodes}{{6.3.3}{159}{Modularity and Custom Nodes}{subsection.6.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces A ``sigmoid node'' (in the blue rectangle) can replace multiple low-level operations (the intermediate nodes encapsulated within). Its known derivative simplifies backpropagation.}}{159}{figure.caption.237}\protected@file@percent }
\newlabel{fig:chapter6_sigmoid_node}{{6.6}{159}{A ``sigmoid node'' (in the blue rectangle) can replace multiple low-level operations (the intermediate nodes encapsulated within). Its known derivative simplifies backpropagation}{figure.caption.237}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Utilizing Patterns in Gradient Flow}{159}{subsection.6.3.4}\protected@file@percent }
\newlabel{sec:gradient-flow-patterns}{{6.3.4}{159}{Utilizing Patterns in Gradient Flow}{subsection.6.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}Addition Gate: The Gradient Distributor}{159}{subsection.6.3.5}\protected@file@percent }
\BKM@entry{id=233,dest={73756273656374696F6E2E362E332E37},srcline={176}}{5C3337365C3337375C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030475C303030615C303030745C303030655C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030535C303030775C303030615C303030705C303030705C303030655C30303072}
\BKM@entry{id=234,dest={73756273656374696F6E2E362E332E38},srcline={197}}{5C3337365C3337375C3030304D5C303030615C303030785C3030305C3034305C303030475C303030615C303030745C303030655C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030525C3030306F5C303030755C303030745C303030655C30303072}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.6}Copy Gate: The Gradient Adder}{160}{subsection.6.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.7}Multiplication Gate: The Gradient Swapper}{160}{subsection.6.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.8}Max Gate: The Gradient Router}{160}{subsection.6.3.8}\protected@file@percent }
\BKM@entry{id=235,dest={73656374696F6E2E362E34},srcline={208}}{5C3337365C3337375C303030495C3030306D5C303030705C3030306C5C303030655C3030306D5C303030655C3030306E5C303030745C303030695C3030306E5C303030675C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C303030645C30303065}
\BKM@entry{id=236,dest={73756273656374696F6E2E362E342E31},srcline={220}}{5C3337365C3337375C303030465C3030306C5C303030615C303030745C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030415C3030305C3034305C303030445C303030695C303030725C303030655C303030635C303030745C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C30303068}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Visualization of gradient flow patterns: (1) Add gate—gradient distributor, (2) Copy gate—gradient adder, (3) Multiplication gate—gradient swapper, and (4) Max gate—gradient router.}}{161}{figure.caption.238}\protected@file@percent }
\newlabel{fig:chapter6_gradient_patterns}{{6.7}{161}{Visualization of gradient flow patterns: (1) Add gate—gradient distributor, (2) Copy gate—gradient adder, (3) Multiplication gate—gradient swapper, and (4) Max gate—gradient router}{figure.caption.238}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Implementing Backpropagation in Code}{161}{section.6.4}\protected@file@percent }
\newlabel{sec:implementing-backprop}{{6.4}{161}{Implementing Backpropagation in Code}{section.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces A pseudo-implementation of forward and backward passes in a flat gradient backpropagation implementation.}}{161}{figure.caption.239}\protected@file@percent }
\newlabel{fig:chapter6_flat_backprop}{{6.8}{161}{A pseudo-implementation of forward and backward passes in a flat gradient backpropagation implementation}{figure.caption.239}{}}
\BKM@entry{id=237,dest={73656374696F6E2E362E35},srcline={250}}{5C3337365C3337375C303030415C3030305C3034305C3030304D5C3030306F5C303030725C303030655C3030305C3034305C3030304D5C3030306F5C303030645C303030755C3030306C5C303030615C303030725C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C303030685C3030303A5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C303030725C303030615C303030635C303030745C303030695C303030635C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Flat Backpropagation: A Direct Approach}{162}{subsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Flat Backpropagation Works Well.}{162}{section*.240}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}A More Modular Approach: Computational Graphs in Practice}{162}{section.6.5}\protected@file@percent }
\newlabel{sec:modular-backprop}{{6.5}{162}{A More Modular Approach: Computational Graphs in Practice}{section.6.5}{}}
\BKM@entry{id=238,dest={73756273656374696F6E2E362E352E31},srcline={267}}{5C3337365C3337375C303030545C3030306F5C303030705C3030306F5C3030306C5C3030306F5C303030675C303030695C303030635C303030615C3030306C5C3030305C3034305C3030304F5C303030725C303030645C303030655C303030725C303030695C3030306E5C303030675C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C30303073}
\BKM@entry{id=239,dest={73756273656374696F6E2E362E352E32},srcline={275}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030415C303030505C303030495C3030303A5C3030305C3034305C303030465C3030306F5C303030725C303030775C303030615C303030725C303030645C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030425C303030615C303030635C3030306B5C303030775C303030615C303030725C303030645C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\BKM@entry{id=240,dest={73756273656374696F6E2E362E352E33},srcline={284}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030615C3030305C3034305C3030304D5C3030306F5C303030645C303030755C3030306C5C303030615C303030725C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C30303068}
\BKM@entry{id=241,dest={73656374696F6E2E362E36},srcline={294}}{5C3337365C3337375C303030495C3030306D5C303030705C3030306C5C303030655C3030306D5C303030655C3030306E5C303030745C303030695C3030306E5C303030675C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030505C303030795C303030545C3030306F5C303030725C303030635C303030685C3030305C3034305C303030415C303030755C303030745C3030306F5C303030675C303030725C303030615C30303064}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces API for a computational graph, requiring an implementation of both the forward and backward methods.}}{163}{figure.caption.241}\protected@file@percent }
\newlabel{fig:chapter6_computational_graph_api}{{6.9}{163}{API for a computational graph, requiring an implementation of both the forward and backward methods}{figure.caption.241}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Topological Ordering in Computational Graphs}{163}{subsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.2}The API: Forward and Backward Methods}{163}{subsection.6.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.3}Advantages of a Modular Computational Graph}{163}{subsection.6.5.3}\protected@file@percent }
\BKM@entry{id=242,dest={73756273656374696F6E2E362E362E31},srcline={310}}{5C3337365C3337375C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030475C303030615C303030745C303030655C3030305C3034305C303030695C3030306E5C3030305C3034305C303030415C303030755C303030745C3030306F5C303030675C303030725C303030615C30303064}
\BKM@entry{id=243,dest={73756273656374696F6E2E362E362E32},srcline={322}}{5C3337365C3337375C303030455C303030785C303030745C303030655C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030415C303030755C303030745C3030306F5C303030675C303030725C303030615C303030645C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030435C303030755C303030735C303030745C3030306F5C3030306D5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Implementing Backpropagation with PyTorch Autograd}{164}{section.6.6}\protected@file@percent }
\newlabel{sec:pytorch-autograd}{{6.6}{164}{Implementing Backpropagation with PyTorch Autograd}{section.6.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Example of PyTorch Autograd implementation for a multiplication gate (\( z = x \cdot y \)).}}{164}{figure.caption.242}\protected@file@percent }
\newlabel{fig:chapter6_autograd_multiplication}{{6.10}{164}{Example of PyTorch Autograd implementation for a multiplication gate (\( z = x \cdot y \))}{figure.caption.242}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Example: Multiplication Gate in Autograd}{164}{subsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Extending Autograd for Custom Functions}{164}{subsection.6.6.2}\protected@file@percent }
\BKM@entry{id=244,dest={73656374696F6E2E362E37},srcline={338}}{5C3337365C3337375C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030535C303030635C303030615C3030306C5C303030615C303030725C303030735C3030303A5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030565C303030655C303030635C303030745C3030306F5C303030725C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030545C303030655C3030306E5C303030735C3030306F5C303030725C30303073}
\BKM@entry{id=245,dest={73756273656374696F6E2E362E372E31},srcline={350}}{5C3337365C3337375C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C303030735C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C3030304A5C303030615C303030635C3030306F5C303030625C303030695C303030615C3030306E5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Example of PyTorch's \texttt  {sigmoid} layer implementation with automatic differentiation.}}{165}{figure.caption.243}\protected@file@percent }
\newlabel{fig:chapter6_autograd_sigmoid}{{6.11}{165}{Example of PyTorch's \texttt {sigmoid} layer implementation with automatic differentiation}{figure.caption.243}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Beyond Scalars: Backpropagation for Vectors and Tensors}{165}{section.6.7}\protected@file@percent }
\newlabel{sec:vector-backprop}{{6.7}{165}{Beyond Scalars: Backpropagation for Vectors and Tensors}{section.6.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Recap of scalar derivatives, gradients, and Jacobians.}}{165}{figure.caption.244}\protected@file@percent }
\newlabel{fig:chapter6_jacobians}{{6.12}{165}{Recap of scalar derivatives, gradients, and Jacobians}{figure.caption.244}{}}
\BKM@entry{id=246,dest={73756273656374696F6E2E362E372E32},srcline={374}}{5C3337365C3337375C303030455C303030785C303030745C303030655C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030565C303030655C303030635C303030745C3030306F5C303030725C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.1}Gradients vs.\ Jacobians}{166}{subsection.6.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.2}Extending Backpropagation to Vectors}{166}{subsection.6.7.2}\protected@file@percent }
\newlabel{sec:vector_backprop}{{6.7.2}{166}{Extending Backpropagation to Vectors}{subsection.6.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces A node \( f \) receiving two vectors \(\mathbf  {x}\in \mathbb  {R}^{D_x}\) and \(\mathbf  {y}\in \mathbb  {R}^{D_y}\) and producing \(\mathbf  {z}\in \mathbb  {R}^{D_z}\). We extend backpropagation to handle vector inputs and outputs.}}{166}{figure.caption.245}\protected@file@percent }
\newlabel{fig:chapter6_vector_backprop}{{6.13}{166}{A node \( f \) receiving two vectors \(\mathbf {x}\in \mathbb {R}^{D_x}\) and \(\mathbf {y}\in \mathbb {R}^{D_y}\) and producing \(\mathbf {z}\in \mathbb {R}^{D_z}\). We extend backpropagation to handle vector inputs and outputs}{figure.caption.245}{}}
\BKM@entry{id=247,dest={73756273656374696F6E2E362E372E33},srcline={418}}{5C3337365C3337375C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030455C3030306C5C303030655C3030306D5C303030655C3030306E5C303030745C303030775C303030695C303030735C303030655C3030305C3034305C303030525C303030655C3030304C5C30303055}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.3}Example: Backpropagation for Elementwise ReLU}{167}{subsection.6.7.3}\protected@file@percent }
\newlabel{sec:relu_vector_backprop}{{6.7.3}{167}{Example: Backpropagation for Elementwise ReLU}{subsection.6.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Backprop through an elementwise ReLU node. Negative inputs produce zeros in the output (and zero gradients), while positive inputs pass gradients through.}}{167}{figure.caption.246}\protected@file@percent }
\newlabel{fig:chapter6_relu_backprop}{{6.14}{167}{Backprop through an elementwise ReLU node. Negative inputs produce zeros in the output (and zero gradients), while positive inputs pass gradients through}{figure.caption.246}{}}
\BKM@entry{id=248,dest={73756273656374696F6E2E362E372E34},srcline={469}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030765C303030695C303030615C3030305C3034305C3030304C5C3030306F5C303030635C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030535C3030306C5C303030695C303030635C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces A more memory-efficient approach: do not form \(\tfrac  {\partial \mathbf  {y}}{\partial \mathbf  {x}}\) explicitly. Instead, reuse the input mask (i.e., which elements of \(\mathbf  {x}\) are positive).}}{168}{figure.caption.247}\protected@file@percent }
\newlabel{fig:chapter6_relu_implicit}{{6.15}{168}{A more memory-efficient approach: do not form \(\tfrac {\partial \mathbf {y}}{\partial \mathbf {x}}\) explicitly. Instead, reuse the input mask (i.e., which elements of \(\mathbf {x}\) are positive)}{figure.caption.247}{}}
\BKM@entry{id=249,dest={73756273656374696F6E2E362E372E35},srcline={474}}{5C3337365C3337375C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304D5C303030615C303030745C303030725C303030695C303030635C303030655C303030735C3030303A5C3030305C3034305C303030415C3030305C3034305C303030435C3030306F5C3030306E5C303030635C303030725C303030655C303030745C303030655C3030305C3034305C303030455C303030785C303030615C3030306D5C303030705C3030306C5C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.4}Efficient Computation via Local Gradient Slices}{169}{subsection.6.7.4}\protected@file@percent }
\newlabel{sec:implicit_jacobian}{{6.7.4}{169}{Efficient Computation via Local Gradient Slices}{subsection.6.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.5}Backpropagation with Matrices: A Concrete Example}{169}{subsection.6.7.5}\protected@file@percent }
\newlabel{sec:gradient_slices}{{6.7.5}{169}{Backpropagation with Matrices: A Concrete Example}{subsection.6.7.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Numerical Setup.}{169}{section*.248}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces Computing a ``gradient slice'' for a single element \(\mathbf  {X}_{i,j}\). Rather than storing the entire local Jacobian, we only determine how \(\mathbf  {X}_{i,j}\) influences each output element of \(\mathbf  {Y}\), then combine that slice with the relevant elements of \(\tfrac  {\partial L}{\partial \mathbf  {Y}}\). }}{169}{figure.caption.249}\protected@file@percent }
\newlabel{fig:chapter6_gradient_slice}{{6.16}{169}{Computing a ``gradient slice'' for a single element \(\mathbf {X}_{i,j}\). Rather than storing the entire local Jacobian, we only determine how \(\mathbf {X}_{i,j}\) influences each output element of \(\mathbf {Y}\), then combine that slice with the relevant elements of \(\tfrac {\partial L}{\partial \mathbf {Y}}\)}{figure.caption.249}{}}
\@writefile{toc}{\contentsline {paragraph}{Slice Logic for One Input Element.}{170}{section*.250}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces Another view of the slice approach for \(\mathbf  {X}_{1,1}\). Only the first row of \(\mathbf  {Y}\) receives a nonzero local gradient from this input element. }}{170}{figure.caption.251}\protected@file@percent }
\newlabel{fig:chapter6_gradient_first}{{6.17}{170}{Another view of the slice approach for \(\mathbf {X}_{1,1}\). Only the first row of \(\mathbf {Y}\) receives a nonzero local gradient from this input element}{figure.caption.251}{}}
\@writefile{toc}{\contentsline {paragraph}{Another Example: \(\mathbf  {X}_{2,3}\).}{170}{section*.252}\protected@file@percent }
\BKM@entry{id=250,dest={73756273656374696F6E2E362E372E36},srcline={601}}{5C3337365C3337375C303030495C3030306D5C303030705C3030306C5C303030695C303030635C303030695C303030745C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030455C3030306E5C303030745C303030695C303030725C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C30303074}
\@writefile{lof}{\contentsline {figure}{\numberline {6.18}{\ignorespaces Similarly, \(\mathbf  {X}_{2,3}\) affects only the second row of \(\mathbf  {Y}\). By repeating this logic for all elements, we derive the standard matrix-multiplication backprop formulas. }}{171}{figure.caption.253}\protected@file@percent }
\newlabel{fig:chapter6_gradient_last}{{6.18}{171}{Similarly, \(\mathbf {X}_{2,3}\) affects only the second row of \(\mathbf {Y}\). By repeating this logic for all elements, we derive the standard matrix-multiplication backprop formulas}{figure.caption.253}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.6}Implicit Multiplication for the Entire Gradient}{171}{subsection.6.7.6}\protected@file@percent }
\newlabel{sec:implicit_mult}{{6.7.6}{171}{Implicit Multiplication for the Entire Gradient}{subsection.6.7.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.19}{\ignorespaces By using vector/matrix multiplications and slicing logic, we avoid forming massive Jacobians in memory. }}{171}{figure.caption.254}\protected@file@percent }
\newlabel{fig:chapter6_matrix_implicit}{{6.19}{171}{By using vector/matrix multiplications and slicing logic, we avoid forming massive Jacobians in memory}{figure.caption.254}{}}
\BKM@entry{id=251,dest={73756273656374696F6E2E362E372E37},srcline={640}}{5C3337365C3337375C303030415C3030305C3034305C303030435C303030685C303030615C303030695C3030306E5C3030305C3034305C303030565C303030695C303030655C303030775C3030305C3034305C3030306F5C303030665C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {paragraph}{Why Slices Are the Solution.}{172}{section*.255}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.7}A Chain View of Backpropagation}{172}{subsection.6.7.7}\protected@file@percent }
\newlabel{sec:chain_view_backprop}{{6.7.7}{172}{A Chain View of Backpropagation}{subsection.6.7.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Reverse-Mode Automatic Differentiation}{172}{section*.256}\protected@file@percent }
\newlabel{sec:reverse_mode_ad}{{6.7.7}{172}{Reverse-Mode Automatic Differentiation}{section*.256}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.20}{\ignorespaces Reverse-mode automatic differentiation can exploit the associativity of matrix multiplication to replace potentially expensive matrix-matrix products with matrix-vector products, moving from right to left. }}{172}{figure.caption.257}\protected@file@percent }
\newlabel{fig:chapter6_reverse_mode}{{6.20}{172}{Reverse-mode automatic differentiation can exploit the associativity of matrix multiplication to replace potentially expensive matrix-matrix products with matrix-vector products, moving from right to left}{figure.caption.257}{}}
\BKM@entry{id=252,dest={73756273656374696F6E2E362E372E38},srcline={697}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030695C3030306E5C303030675C3030305C3034305C303030485C303030695C303030675C303030685C303030655C303030725C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C303030445C303030655C303030725C303030695C303030765C303030615C303030745C303030695C303030765C303030655C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsubsection}{Forward-Mode Automatic Differentiation}{173}{section*.258}\protected@file@percent }
\newlabel{sec:forward_mode_ad}{{6.7.7}{173}{Forward-Mode Automatic Differentiation}{section*.258}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.21}{\ignorespaces Forward-mode automatic differentiation is useful for computing the derivatives of scalar inputs with respect to multiple outputs. While not commonly used in deep learning, it is widely applied in physics simulations and sensitivity analysis. }}{173}{figure.caption.259}\protected@file@percent }
\newlabel{fig:chapter6_forward_mode}{{6.21}{173}{Forward-mode automatic differentiation is useful for computing the derivatives of scalar inputs with respect to multiple outputs. While not commonly used in deep learning, it is widely applied in physics simulations and sensitivity analysis}{figure.caption.259}{}}
\@writefile{toc}{\contentsline {paragraph}{When Is Forward-Mode Automatic Differentiation is Useful?}{173}{section*.260}\protected@file@percent }
\BKM@entry{id=253,dest={73756273656374696F6E2E362E372E39},srcline={726}}{5C3337365C3337375C303030415C303030705C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030302D5C3030304E5C3030306F5C303030725C3030306D5C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.8}Computing Higher-Order Derivatives with Backpropagation}{174}{subsection.6.7.8}\protected@file@percent }
\newlabel{sec:higher_order_backprop}{{6.7.8}{174}{Computing Higher-Order Derivatives with Backpropagation}{subsection.6.7.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.22}{\ignorespaces Using backpropagation to compute Hessian-vector products as an efficient way to obtain second-order derivatives. }}{174}{figure.caption.261}\protected@file@percent }
\newlabel{fig:chapter6_hessian_backprop}{{6.22}{174}{Using backpropagation to compute Hessian-vector products as an efficient way to obtain second-order derivatives}{figure.caption.261}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Compute Hessians?}{174}{section*.262}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Efficient Hessian Computation: Hessian-Vector Products}{174}{section*.263}\protected@file@percent }
\BKM@entry{id=254,dest={73756273656374696F6E2E362E372E3130},srcline={744}}{5C3337365C3337375C303030415C303030755C303030745C3030306F5C3030306D5C303030615C303030745C303030695C303030635C3030305C3034305C303030445C303030695C303030665C303030665C303030655C303030725C303030655C3030306E5C303030745C303030695C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304B5C303030655C303030795C3030305C3034305C303030495C3030306E5C303030735C303030695C303030675C303030685C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.9}Application: Gradient-Norm Regularization}{175}{subsection.6.7.9}\protected@file@percent }
\newlabel{sec:higher_order_regularization}{{6.7.9}{175}{Application: Gradient-Norm Regularization}{subsection.6.7.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.23}{\ignorespaces An example of using second-order derivatives: Regularizing the gradient norm to improve optimization stability. }}{175}{figure.caption.264}\protected@file@percent }
\newlabel{fig:chapter6_gradient_norm_reg}{{6.23}{175}{An example of using second-order derivatives: Regularizing the gradient norm to improve optimization stability}{figure.caption.264}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.10}Automatic Differentiation: Summary of Key Insights}{175}{subsection.6.7.10}\protected@file@percent }
\BKM@entry{id=255,dest={636861707465722E37},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030375C3030303A5C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=256,dest={73656374696F6E2E372E31},srcline={10}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030465C303030755C3030306C5C3030306C5C303030795C3030302D5C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030655C303030645C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=257,dest={73656374696F6E2E372E32},srcline={26}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C3030306F5C3030306E5C303030655C3030306E5C303030745C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Lecture 7: Convolutional Networks}{176}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@6}}
\ttl@writefile{ptc}{\ttl@starttoc{default@7}}
\pgfsyspdfmark {pgfid19}{0}{52099153}
\pgfsyspdfmark {pgfid18}{5966969}{45620378}
\newlabel{chap:cnn}{{7}{176}{Lecture 7: Convolutional Networks}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Introduction: The Limitations of Fully-Connected Networks}{176}{section.7.1}\protected@file@percent }
\newlabel{sec:cnn_intro}{{7.1}{176}{Introduction: The Limitations of Fully-Connected Networks}{section.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Fully-connected networks and linear classifiers do not respect the 2D spatial structure of images, requiring us to flatten image pixels into a single vector.}}{176}{figure.caption.265}\protected@file@percent }
\newlabel{fig:chapter7_flattening_problem}{{7.1}{176}{Fully-connected networks and linear classifiers do not respect the 2D spatial structure of images, requiring us to flatten image pixels into a single vector}{figure.caption.265}{}}
\BKM@entry{id=258,dest={73656374696F6E2E372E33},srcline={45}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C303030735C3030303A5C3030305C3034305C303030505C303030725C303030655C303030735C303030655C303030725C303030765C303030695C3030306E5C303030675C3030305C3034305C303030535C303030705C303030615C303030745C303030695C303030615C3030306C5C3030305C3034305C303030535C303030745C303030725C303030755C303030635C303030745C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Components of Convolutional Neural Networks}{177}{section.7.2}\protected@file@percent }
\newlabel{sec:cnn_components}{{7.2}{177}{Components of Convolutional Neural Networks}{section.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Key components of Convolutional Neural Networks (CNNs). In addition to fully-connected layers and activation functions, CNNs introduce convolutional layers, pooling layers, and normalization layers.}}{177}{figure.caption.266}\protected@file@percent }
\newlabel{fig:chapter7_cnn_components}{{7.2}{177}{Key components of Convolutional Neural Networks (CNNs). In addition to fully-connected layers and activation functions, CNNs introduce convolutional layers, pooling layers, and normalization layers}{figure.caption.266}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Convolutional Layers: Preserving Spatial Structure}{177}{section.7.3}\protected@file@percent }
\newlabel{sec:conv_layers_intro}{{7.3}{177}{Convolutional Layers: Preserving Spatial Structure}{section.7.3}{}}
\BKM@entry{id=259,dest={73756273656374696F6E2E372E332E31},srcline={57}}{5C3337365C3337375C303030495C3030306E5C303030705C303030755C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030445C303030695C3030306D5C303030655C3030306E5C303030735C303030695C3030306F5C3030306E5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces A filter is applied to a local region of the input tensor, producing a single number at each spatial position.}}{178}{figure.caption.267}\protected@file@percent }
\newlabel{fig:chapter7_filter_application}{{7.3}{178}{A filter is applied to a local region of the input tensor, producing a single number at each spatial position}{figure.caption.267}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Input and Output Dimensions}{178}{subsection.7.3.1}\protected@file@percent }
\newlabel{subsec:conv_input_output}{{7.3.1}{178}{Input and Output Dimensions}{subsection.7.3.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Common Filter Sizes}{178}{section*.268}\protected@file@percent }
\BKM@entry{id=260,dest={73756273656374696F6E2E372E332E32},srcline={96}}{5C3337365C3337375C303030465C303030695C3030306C5C303030745C303030655C303030725C3030305C3034305C303030415C303030705C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030435C303030615C3030306C5C303030635C303030755C3030306C5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=261,dest={73656374696F6E2A2E323731},srcline={121}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030335C3030302E5C303030335C3030303A5C3030305C3034305C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030685C303030725C3030306F5C303030755C303030675C303030685C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030535C3030306F5C303030625C303030655C3030306C5C3030305C3034305C3030304F5C303030705C303030655C303030725C303030615C303030745C3030306F5C30303072}
\@writefile{toc}{\contentsline {paragraph}{Why Are Kernel Sizes Typically Odd?}{179}{section*.269}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Filter Application and Output Calculation}{179}{subsection.7.3.2}\protected@file@percent }
\newlabel{subsec:conv_filter_output}{{7.3.2}{179}{Filter Application and Output Calculation}{subsection.7.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Applying two convolutional filters to a \(3 \times 32 \times 32\) input image produces two activation maps of shape \(1 \times 28 \times 28\) (no padding applied).}}{179}{figure.caption.270}\protected@file@percent }
\newlabel{fig:chapter7_two_filters}{{7.4}{179}{Applying two convolutional filters to a \(3 \times 32 \times 32\) input image produces two activation maps of shape \(1 \times 28 \times 28\) (no padding applied)}{figure.caption.270}{}}
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.3.3: Understanding Convolution Through the Sobel Operator}{180}{section*.271}\protected@file@percent }
\newlabel{enr:conv_sobel}{{7.3.3}{180}{\color {ocre}Enrichment \thesubsection : Understanding Convolution Through the Sobel Operator}{section*.271}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces A zoomed-in section of a grayscale image, used for demonstrating convolution.}}{180}{figure.caption.272}\protected@file@percent }
\newlabel{fig:chapter7_grayscale_zoom}{{7.5}{180}{A zoomed-in section of a grayscale image, used for demonstrating convolution}{figure.caption.272}{}}
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 7.3.3.1: Using the Sobel Kernel for Edge Detection}{180}{section*.273}\protected@file@percent }
\newlabel{subsubsec:sobel_kernel}{{7.3.3.1}{180}{\color {ocre}Enrichment \thesubsubsection : Using the Sobel Kernel for Edge Detection}{section*.273}{}}
\@writefile{toc}{\contentsline {paragraph}{Approximating Image Gradients with the Sobel Operator}{180}{section*.274}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Basic Difference Operators}{181}{section*.275}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The Sobel Filters: Adding Robustness}{181}{section*.276}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 7.3.3.2: Why Does the Sobel Filter Use These Weights?}{181}{section*.277}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Enrichment 7.3.3.3: Computing the Gradient Magnitude}{181}{section*.278}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Computation of the first two cells of the image patch convolved with \(\text  {Sobel}_x\).}}{182}{figure.caption.279}\protected@file@percent }
\newlabel{fig:chapter7_convolve_x_1}{{7.6}{182}{Computation of the first two cells of the image patch convolved with \(\text {Sobel}_x\)}{figure.caption.279}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Computation of the third and fourth cells of the image patch convolved with \(\text  {Sobel}_x\). As we can see, after sliding the 2D kernel over the first row, we move to the beginning of the second row and continue from there.}}{182}{figure.caption.280}\protected@file@percent }
\newlabel{fig:chapter7_convolve_x_2}{{7.7}{182}{Computation of the third and fourth cells of the image patch convolved with \(\text {Sobel}_x\). As we can see, after sliding the 2D kernel over the first row, we move to the beginning of the second row and continue from there}{figure.caption.280}{}}
\BKM@entry{id=262,dest={73656374696F6E2A2E323834},srcline={275}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030345C3030303A5C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C303030435C303030685C303030615C3030306E5C3030306E5C303030655C3030306C5C3030305C3034305C303030465C303030695C3030306C5C303030745C303030655C303030725C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces The Sobel example resulting in $G_x, G_y$ after applying the 2D sobel kernels.}}{183}{figure.caption.281}\protected@file@percent }
\newlabel{fig:chapter7_gx_gy}{{7.8}{183}{The Sobel example resulting in $G_x, G_y$ after applying the 2D sobel kernels}{figure.caption.281}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces The Sobel edge image $G$ resultant from combining $G_x, G_y$.}}{183}{figure.caption.282}\protected@file@percent }
\newlabel{fig:chapter7_sobel_end}{{7.9}{183}{The Sobel edge image $G$ resultant from combining $G_x, G_y$}{figure.caption.282}{}}
\@writefile{toc}{\contentsline {paragraph}{Hands-On Exploration}{183}{section*.283}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Enrichment 7.4: Convolutional Layers with Multi-Channel Filters}{184}{section*.284}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces The separate color channels (R, G, B) of the Lotus image. Each filter in a convolutional layer operates across all these channels simultaneously.}}{184}{figure.caption.285}\protected@file@percent }
\newlabel{fig:chapter7_lotus_ch}{{7.10}{184}{The separate color channels (R, G, B) of the Lotus image. Each filter in a convolutional layer operates across all these channels simultaneously}{figure.caption.285}{}}
\BKM@entry{id=263,dest={73656374696F6E2A2E323836},srcline={289}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030345C3030302E5C303030315C3030303A5C3030305C3034305C303030455C303030785C303030745C303030655C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C303030435C303030685C303030615C3030306E5C3030306E5C303030655C3030306C5C3030305C3034305C303030495C3030306E5C303030705C303030755C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.4.1: Extending Convolution to Multi-Channel Inputs}{185}{section*.286}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces A \(5 \times 5\) patch of the Lotus image (visualized with a bold yellow box on one of the left leafs), displayed across three color channels (R, G, B).}}{185}{figure.caption.287}\protected@file@percent }
\newlabel{fig:chapter7_lotus_patch}{{7.11}{185}{A \(5 \times 5\) patch of the Lotus image (visualized with a bold yellow box on one of the left leafs), displayed across three color channels (R, G, B)}{figure.caption.287}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.12}{\ignorespaces The sample image patch over the different channels (R, G, B), along with a corresponding filter. Each filter channel operates on exactly one input channel.}}{185}{figure.caption.288}\protected@file@percent }
\newlabel{fig:chapter7_filter_and_patch}{{7.12}{185}{The sample image patch over the different channels (R, G, B), along with a corresponding filter. Each filter channel operates on exactly one input channel}{figure.caption.288}{}}
\@writefile{toc}{\contentsline {paragraph}{Multi-Channel Convolution Process}{186}{section*.289}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.13}{\ignorespaces Each filter channel performs a separate 2D convolution on its corresponding input channel. The results are then summed along with the bias to produce a single output pixel value.}}{186}{figure.caption.290}\protected@file@percent }
\newlabel{fig:chapter7_multi_dim_filter1}{{7.13}{186}{Each filter channel performs a separate 2D convolution on its corresponding input channel. The results are then summed along with the bias to produce a single output pixel value}{figure.caption.290}{}}
\@writefile{toc}{\contentsline {paragraph}{Sliding the Filter Across the Image}{186}{section*.291}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.14}{\ignorespaces The filter shifts spatially by one step, computing the next output pixel. This process continues across the entire image.}}{186}{figure.caption.292}\protected@file@percent }
\newlabel{fig:chapter7_multi_dim_filter2}{{7.14}{186}{The filter shifts spatially by one step, computing the next output pixel. This process continues across the entire image}{figure.caption.292}{}}
\@writefile{toc}{\contentsline {paragraph}{From Single Filters to Complete Convolutional Layers}{187}{section*.293}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What Our Example Missed: Padding and Stride}{187}{section*.294}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Are Kernel Values Restricted?}{187}{section*.295}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Negative and Large Output Values}{187}{section*.296}\protected@file@percent }
\BKM@entry{id=264,dest={73756273656374696F6E2E372E342E32},srcline={358}}{5C3337365C3337375C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030655C3030305C3034305C303030465C303030695C3030306C5C303030745C303030655C303030725C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030435C303030685C303030615C3030306E5C3030306E5C303030655C3030306C5C30303073}
\BKM@entry{id=265,dest={73756273656374696F6E2E372E342E33},srcline={374}}{5C3337365C3337375C303030545C303030775C3030306F5C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030705C303030725C303030655C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304F5C303030755C303030745C303030705C303030755C303030745C30303073}
\BKM@entry{id=266,dest={73756273656374696F6E2E372E342E34},srcline={383}}{5C3337365C3337375C303030425C303030615C303030745C303030635C303030685C3030305C3034305C303030505C303030725C3030306F5C303030635C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Multiple Filters and Output Channels}{188}{subsection.7.4.2}\protected@file@percent }
\newlabel{subsec:conv_multiple_filters}{{7.4.2}{188}{Multiple Filters and Output Channels}{subsection.7.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.15}{\ignorespaces A convolutional layer with 6 filters, each of size \(3 \times 5 \times 5\), applied to an input image of shape \(3 \times 32 \times 32\), producing 6 activation maps of shape \(1 \times 28 \times 28\). Each filter has an associated bias term.}}{188}{figure.caption.297}\protected@file@percent }
\newlabel{fig:chapter7_multiple_filters}{{7.15}{188}{A convolutional layer with 6 filters, each of size \(3 \times 5 \times 5\), applied to an input image of shape \(3 \times 32 \times 32\), producing 6 activation maps of shape \(1 \times 28 \times 28\). Each filter has an associated bias term}{figure.caption.297}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.3}Two Interpretations of Convolutional Outputs}{188}{subsection.7.4.3}\protected@file@percent }
\newlabel{subsec:conv_output_interpretation}{{7.4.3}{188}{Two Interpretations of Convolutional Outputs}{subsection.7.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.4}Batch Processing with Convolutional Layers}{188}{subsection.7.4.4}\protected@file@percent }
\newlabel{subsec:conv_batch_processing}{{7.4.4}{188}{Batch Processing with Convolutional Layers}{subsection.7.4.4}{}}
\BKM@entry{id=267,dest={73656374696F6E2E372E35},srcline={402}}{5C3337365C3337375C303030425C303030755C303030695C3030306C5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=268,dest={73756273656374696F6E2E372E352E31},srcline={405}}{5C3337365C3337375C303030535C303030745C303030615C303030635C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {7.16}{\ignorespaces The general form of a convolutional layer applied to a batch of images, producing a batch of feature maps.}}{189}{figure.caption.298}\protected@file@percent }
\newlabel{fig:chapter7_general_conv}{{7.16}{189}{The general form of a convolutional layer applied to a batch of images, producing a batch of feature maps}{figure.caption.298}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Building Convolutional Neural Networks}{189}{section.7.5}\protected@file@percent }
\newlabel{sec:conv_nets}{{7.5}{189}{Building Convolutional Neural Networks}{section.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Stacking Convolutional Layers}{189}{subsection.7.5.1}\protected@file@percent }
\newlabel{subsec:stacking_convs}{{7.5.1}{189}{Stacking Convolutional Layers}{subsection.7.5.1}{}}
\BKM@entry{id=269,dest={73756273656374696F6E2E372E352E32},srcline={430}}{5C3337365C3337375C303030415C303030645C303030645C303030695C3030306E5C303030675C3030305C3034305C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030655C303030645C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=270,dest={73756273656374696F6E2E372E352E33},srcline={442}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C3030304E5C303030655C303030655C303030645C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304E5C3030306F5C3030306E5C3030302D5C3030304C5C303030695C3030306E5C303030655C303030615C303030725C303030695C303030745C30303079}
\@writefile{lof}{\contentsline {figure}{\numberline {7.17}{\ignorespaces A simple convolutional neural network with three stacked convolutional layers. Each layer extracts progressively higher-level features.}}{190}{figure.caption.299}\protected@file@percent }
\newlabel{fig:convnet_stack}{{7.17}{190}{A simple convolutional neural network with three stacked convolutional layers. Each layer extracts progressively higher-level features}{figure.caption.299}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Adding Fully Connected Layers for Classification}{190}{subsection.7.5.2}\protected@file@percent }
\newlabel{subsec:flatten_fc}{{7.5.2}{190}{Adding Fully Connected Layers for Classification}{subsection.7.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}The Need for Non-Linearity}{190}{subsection.7.5.3}\protected@file@percent }
\newlabel{subsec:conv_non_linearity}{{7.5.3}{190}{The Need for Non-Linearity}{subsection.7.5.3}{}}
\BKM@entry{id=271,dest={73756273656374696F6E2E372E352E34},srcline={466}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C30303079}
\BKM@entry{id=272,dest={73656374696F6E2E372E36},srcline={477}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030745C303030725C3030306F5C3030306C5C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030705C303030615C303030745C303030695C303030615C3030306C5C3030305C3034305C303030445C303030695C3030306D5C303030655C3030306E5C303030735C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\BKM@entry{id=273,dest={73756273656374696F6E2E372E362E31},srcline={480}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030415C303030665C303030665C303030655C303030635C303030745C303030735C3030305C3034305C303030535C303030705C303030615C303030745C303030695C303030615C3030306C5C3030305C3034305C303030535C303030695C3030307A5C30303065}
\BKM@entry{id=274,dest={73756273656374696F6E2E372E362E32},srcline={491}}{5C3337365C3337375C3030304D5C303030695C303030745C303030695C303030675C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030535C303030685C303030725C303030695C3030306E5C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C3030304D5C303030615C303030705C303030735C3030303A5C3030305C3034305C303030505C303030615C303030645C303030645C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {7.18}{\ignorespaces A convolutional network with three layers, now incorporating non-linear activations (ReLU) between them. This introduces non-linearity, enhancing the model’s expressive power.}}{191}{figure.caption.300}\protected@file@percent }
\newlabel{fig:convnet_relu_stack}{{7.18}{191}{A convolutional network with three layers, now incorporating non-linear activations (ReLU) between them. This introduces non-linearity, enhancing the model’s expressive power}{figure.caption.300}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.4}Summary}{191}{subsection.7.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Controlling Spatial Dimensions in Convolutional Layers}{191}{section.7.6}\protected@file@percent }
\newlabel{sec:conv_dimensions}{{7.6}{191}{Controlling Spatial Dimensions in Convolutional Layers}{section.7.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}How Convolution Affects Spatial Size}{191}{subsection.7.6.1}\protected@file@percent }
\BKM@entry{id=275,dest={73756273656374696F6E2E372E362E33},srcline={512}}{5C3337365C3337375C303030525C303030655C303030635C303030655C303030705C303030745C303030695C303030765C303030655C3030305C3034305C303030465C303030695C303030655C3030306C5C303030645C303030735C3030303A5C3030305C3034305C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030575C303030685C303030615C303030745C3030305C3034305C303030455C303030615C303030635C303030685C3030305C3034305C303030505C303030695C303030785C303030655C3030306C5C3030305C3034305C303030535C303030655C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}Mitigating Shrinking Feature Maps: Padding}{192}{subsection.7.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.19}{\ignorespaces Zero-padding around an image to maintain spatial dimensions during convolution.}}{192}{figure.caption.301}\protected@file@percent }
\newlabel{fig:padding_visualization}{{7.19}{192}{Zero-padding around an image to maintain spatial dimensions during convolution}{figure.caption.301}{}}
\@writefile{toc}{\contentsline {paragraph}{Choosing the Padding Size}{192}{section*.302}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.3}Receptive Fields: Understanding What Each Pixel Sees}{193}{subsection.7.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.20}{\ignorespaces Receptive field of an output pixel for a single convolution operation.}}{193}{figure.caption.303}\protected@file@percent }
\newlabel{fig:receptive_field_single_layer}{{7.20}{193}{Receptive field of an output pixel for a single convolution operation}{figure.caption.303}{}}
\@writefile{toc}{\contentsline {paragraph}{The Problem of Limited Receptive Field Growth}{193}{section*.304}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.21}{\ignorespaces Receptive field expansion across multiple layers. Deeper layers see a larger portion of the input image.}}{193}{figure.caption.305}\protected@file@percent }
\newlabel{fig:receptive_field_multi_layers}{{7.21}{193}{Receptive field expansion across multiple layers. Deeper layers see a larger portion of the input image}{figure.caption.305}{}}
\BKM@entry{id=276,dest={73756273656374696F6E2E372E362E34},srcline={541}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030745C303030725C3030306F5C3030306C5C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030705C303030615C303030745C303030695C303030615C3030306C5C3030305C3034305C303030525C303030655C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030535C303030745C303030725C303030695C303030645C303030655C30303073}
\BKM@entry{id=277,dest={73656374696F6E2E372E37},srcline={553}}{5C3337365C3337375C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030575C303030685C303030615C303030745C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030465C303030695C3030306C5C303030745C303030655C303030725C303030735C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E}
\BKM@entry{id=278,dest={73756273656374696F6E2E372E372E31},srcline={556}}{5C3337365C3337375C3030304D5C3030304C5C303030505C303030735C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C303030435C3030304E5C3030304E5C303030735C3030303A5C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030705C303030615C303030745C303030695C303030615C3030306C5C3030305C3034305C303030535C303030745C303030725C303030755C303030635C303030745C303030755C303030725C30303065}
\BKM@entry{id=279,dest={73756273656374696F6E2E372E372E32},srcline={561}}{5C3337365C3337375C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304C5C3030306F5C303030635C303030615C3030306C5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030465C303030695C303030725C303030735C303030745C3030305C3034305C3030304C5C303030615C303030795C303030655C30303072}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.4}Controlling Spatial Reduction with Strides}{194}{subsection.7.6.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.22}{\ignorespaces Effect of stride on convolution. A stride of 2 moves the filter by 2 pixels, reducing spatial dimensions.}}{194}{figure.caption.306}\protected@file@percent }
\newlabel{fig:stride_visualization}{{7.22}{194}{Effect of stride on convolution. A stride of 2 moves the filter by 2 pixels, reducing spatial dimensions}{figure.caption.306}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Understanding What Convolutional Filters Learn}{194}{section.7.7}\protected@file@percent }
\newlabel{sec:cnn_feature_learning}{{7.7}{194}{Understanding What Convolutional Filters Learn}{section.7.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}MLPs vs. CNNs: Learning Spatial Structure}{194}{subsection.7.7.1}\protected@file@percent }
\newlabel{subsec:mlp_vs_cnn}{{7.7.1}{194}{MLPs vs. CNNs: Learning Spatial Structure}{subsection.7.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.2}Learning Local Features: The First Layer}{194}{subsection.7.7.2}\protected@file@percent }
\newlabel{subsec:learning_local_features}{{7.7.2}{194}{Learning Local Features: The First Layer}{subsection.7.7.2}{}}
\BKM@entry{id=280,dest={73756273656374696F6E2E372E372E33},srcline={578}}{5C3337365C3337375C303030425C303030755C303030695C3030306C5C303030645C303030695C3030306E5C303030675C3030305C3034305C3030304D5C3030306F5C303030725C303030655C3030305C3034305C303030435C3030306F5C3030306D5C303030705C3030306C5C303030655C303030785C3030305C3034305C303030505C303030615C303030745C303030745C303030655C303030725C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030445C303030655C303030655C303030705C303030655C303030725C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\BKM@entry{id=281,dest={73656374696F6E2E372E38},srcline={592}}{5C3337365C3337375C303030505C303030615C303030725C303030615C3030306D5C303030655C303030745C303030655C303030725C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C3030306C5C303030655C303030785C303030695C303030745C303030795C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=282,dest={73756273656374696F6E2E372E382E31},srcline={597}}{5C3337365C3337375C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C3030305C3034305C303030535C303030655C303030745C303030755C30303070}
\@writefile{lof}{\contentsline {figure}{\numberline {7.23}{\ignorespaces Visualization of first-layer filters from AlexNet. Filters specialize in detecting edge orientations, color contrasts, and simple patterns.}}{195}{figure.caption.307}\protected@file@percent }
\newlabel{fig:alexnet_first_layer}{{7.23}{195}{Visualization of first-layer filters from AlexNet. Filters specialize in detecting edge orientations, color contrasts, and simple patterns}{figure.caption.307}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.3}Building More Complex Patterns in Deeper Layers}{195}{subsection.7.7.3}\protected@file@percent }
\newlabel{subsec:deeper_features}{{7.7.3}{195}{Building More Complex Patterns in Deeper Layers}{subsection.7.7.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical Learning via Composition}{195}{section*.308}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Parameters and Computational Complexity in Convolutional Networks}{195}{section.7.8}\protected@file@percent }
\newlabel{sec:conv_params}{{7.8}{195}{Parameters and Computational Complexity in Convolutional Networks}{section.7.8}{}}
\BKM@entry{id=283,dest={73756273656374696F6E2E372E382E32},srcline={607}}{5C3337365C3337375C3030304F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030565C3030306F5C3030306C5C303030755C3030306D5C303030655C3030305C3034305C303030435C303030615C3030306C5C303030635C303030755C3030306C5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=284,dest={73756273656374696F6E2E372E382E33},srcline={617}}{5C3337365C3337375C3030304E5C303030755C3030306D5C303030625C303030655C303030725C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030615C303030625C3030306C5C303030655C3030305C3034305C303030505C303030615C303030725C303030615C3030306D5C303030655C303030745C303030655C303030725C30303073}
\BKM@entry{id=285,dest={73756273656374696F6E2E372E382E34},srcline={635}}{5C3337365C3337375C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030795C3030302D5C303030415C303030635C303030635C303030755C3030306D5C303030755C3030306C5C303030615C303030745C303030655C3030305C3034305C3030304F5C303030705C303030655C303030725C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030305C3035305C3030304D5C303030415C303030435C303030735C3030305C303531}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.1}Example: Convolutional Layer Setup}{196}{subsection.7.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.2}Output Volume Calculation}{196}{subsection.7.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.3}Number of Learnable Parameters}{196}{subsection.7.8.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.24}{\ignorespaces The number of learnable parameters in a convolutional layer, with 76 parameters per filter and 760 total.}}{196}{figure.caption.309}\protected@file@percent }
\newlabel{fig:chapter7_params}{{7.24}{196}{The number of learnable parameters in a convolutional layer, with 76 parameters per filter and 760 total}{figure.caption.309}{}}
\BKM@entry{id=286,dest={73756273656374696F6E2E372E382E35},srcline={652}}{5C3337365C3337375C3030304D5C303030415C303030435C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030465C3030304C5C3030304F5C303030505C30303073}
\BKM@entry{id=287,dest={73756273656374696F6E2E372E382E36},srcline={664}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030795C3030302D5C303030415C303030645C303030645C3030305C3034305C3030304F5C303030705C303030655C303030725C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030305C3035305C3030304D5C303030415C303030435C303030735C3030305C3035315C3030305C3034305C3030304D5C303030615C303030745C303030745C303030655C30303072}
\BKM@entry{id=288,dest={73656374696F6E2A2E333131},srcline={673}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030385C3030302E5C303030375C3030303A5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\abx@aux@cite{0}{solai2023_backpropconv}
\abx@aux@segm{0}{0}{solai2023_backpropconv}
\abx@aux@cite{0}{solai2023_backpropconv}
\abx@aux@segm{0}{0}{solai2023_backpropconv}
\abx@aux@cite{0}{solai2023_backpropconv}
\abx@aux@segm{0}{0}{solai2023_backpropconv}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.4}Multiply-Accumulate Operations (MACs)}{197}{subsection.7.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{MACs Calculation:}{197}{section*.310}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.5}MACs and FLOPs}{197}{subsection.7.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.6}Why Multiply-Add Operations (MACs) Matter}{197}{subsection.7.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.8.7: Backpropagation for Convolutional Neural Networks}{197}{section*.311}\protected@file@percent }
\abx@aux@backref{113}{solai2023_backpropconv}{0}{197}{197}
\@writefile{toc}{\contentsline {paragraph}{Key Idea: Convolution as a Graph Node}{197}{section*.312}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.25}{\ignorespaces Backpropagation in a convolution: A computational graph demonstrates convolving input tensor \(X\) and filter \(F\), then propagating gradients \(\frac  {dL}{dO}\). Source: \blx@tocontentsinit {0}\cite {solai2023_backpropconv}.}}{198}{figure.caption.313}\protected@file@percent }
\abx@aux@backref{115}{solai2023_backpropconv}{0}{198}{198}
\newlabel{fig:chapter7_backprop_conv}{{7.25}{198}{Backpropagation in a convolution: A computational graph demonstrates convolving input tensor \(X\) and filter \(F\), then propagating gradients \(\frac {dL}{dO}\). Source: \cite {solai2023_backpropconv}}{figure.caption.313}{}}
\@writefile{toc}{\contentsline {paragraph}{Computing \(\tfrac  {dO}{dF}\)}{198}{section*.314}\protected@file@percent }
\abx@aux@cite{0}{solai2023_backpropconv}
\abx@aux@segm{0}{0}{solai2023_backpropconv}
\abx@aux@cite{0}{solai2023_backpropconv}
\abx@aux@segm{0}{0}{solai2023_backpropconv}
\abx@aux@cite{0}{solai2023_backpropconv}
\abx@aux@segm{0}{0}{solai2023_backpropconv}
\@writefile{toc}{\contentsline {paragraph}{Computing \(\tfrac  {dL}{dX}\)}{199}{section*.315}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.26}{\ignorespaces Backpropagation through convolutions: The gradient computation involves convolution between the input \(X\) (or a rotated version of \(F\)) and the upstream gradient \(\tfrac  {dL}{dO}\). Source: \blx@tocontentsinit {0}\cite {solai2023_backpropconv}.}}{199}{figure.caption.316}\protected@file@percent }
\abx@aux@backref{117}{solai2023_backpropconv}{0}{199}{199}
\newlabel{fig:chapter7_backprop_through_conv}{{7.26}{199}{Backpropagation through convolutions: The gradient computation involves convolution between the input \(X\) (or a rotated version of \(F\)) and the upstream gradient \(\tfrac {dL}{dO}\). Source: \cite {solai2023_backpropconv}}{figure.caption.316}{}}
\abx@aux@backref{118}{solai2023_backpropconv}{0}{199}{199}
\BKM@entry{id=289,dest={73656374696F6E2E372E39},srcline={761}}{5C3337365C3337375C303030535C303030705C303030655C303030635C303030695C303030615C3030306C5C3030305C3034305C303030545C303030795C303030705C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030735C3030303A5C3030305C3034305C303030315C303030785C303030315C3030302C5C3030305C3034305C303030315C303030445C3030302C5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030335C303030445C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=290,dest={73756273656374696F6E2E372E392E31},srcline={766}}{5C3337365C3337375C303030315C303030785C303030315C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}Special Types of Convolutions: 1x1, 1D, and 3D Convolutions}{200}{section.7.9}\protected@file@percent }
\newlabel{sec:special_convs}{{7.9}{200}{Special Types of Convolutions: 1x1, 1D, and 3D Convolutions}{section.7.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.1}1x1 Convolutions}{200}{subsection.7.9.1}\protected@file@percent }
\newlabel{subsec:1x1_convs}{{7.9.1}{200}{1x1 Convolutions}{subsection.7.9.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dimensionality Reduction and Feature Selection}{200}{section*.317}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.27}{\ignorespaces A visualization of a 1x1 convolution. The input tensor is of volume \(56 \times 56 \times 64\) and the convolutional layer has 32 \emph  {1x1} filters, resulting in an output volume of \(56 \times 56 \times 32\).}}{200}{figure.caption.318}\protected@file@percent }
\newlabel{fig:chapter7_1x1_conv}{{7.27}{200}{A visualization of a 1x1 convolution. The input tensor is of volume \(56 \times 56 \times 64\) and the convolutional layer has 32 \emph {1x1} filters, resulting in an output volume of \(56 \times 56 \times 32\)}{figure.caption.318}{}}
\@writefile{toc}{\contentsline {subsubsection}{Efficiency of 1x1 Convolutions as a Bottleneck}{200}{section*.319}\protected@file@percent }
\newlabel{subsubsec:conv_efficiency_1x1}{{7.9.1}{200}{Efficiency of 1x1 Convolutions as a Bottleneck}{section*.319}{}}
\BKM@entry{id=291,dest={73756273656374696F6E2E372E392E32},srcline={841}}{5C3337365C3337375C303030315C303030445C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Example: Transforming 256 Channels to 256 Channels with a 3x3 Kernel.}{201}{section*.320}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Parameter and FLOP Savings.}{201}{section*.321}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.2}1D Convolutions}{201}{subsection.7.9.2}\protected@file@percent }
\newlabel{subsec:1D_convs}{{7.9.2}{201}{1D Convolutions}{subsection.7.9.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Numerical Example: 1D Convolution on Multichannel Time Series Data}{201}{section*.322}\protected@file@percent }
\BKM@entry{id=292,dest={73756273656374696F6E2E372E392E33},srcline={914}}{5C3337365C3337375C303030335C303030445C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Computing the Output}{202}{section*.323}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applications of 1D Convolutions}{202}{section*.324}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.3}3D Convolutions}{203}{subsection.7.9.3}\protected@file@percent }
\newlabel{subsec:3D_convs}{{7.9.3}{203}{3D Convolutions}{subsection.7.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.28}{\ignorespaces Visualization of \emph  {3D convolution}, where a \emph  {3D kernel} moves through a volumetric input to capture spatial-temporal relationships.}}{203}{figure.caption.325}\protected@file@percent }
\newlabel{fig:chapter7_3D_conv}{{7.28}{203}{Visualization of \emph {3D convolution}, where a \emph {3D kernel} moves through a volumetric input to capture spatial-temporal relationships}{figure.caption.325}{}}
\@writefile{toc}{\contentsline {paragraph}{Numerical Example: 3D Convolution on Volumetric Data}{203}{section*.326}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3D Convolution Formula}{204}{section*.327}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Computing the Output}{204}{section*.328}\protected@file@percent }
\BKM@entry{id=293,dest={73756273656374696F6E2E372E392E34},srcline={1079}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304D5C3030306F5C303030625C303030695C3030306C5C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030455C3030306D5C303030625C303030655C303030645C303030645C303030655C303030645C3030305C3034305C303030535C303030795C303030735C303030745C303030655C3030306D5C30303073}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\abx@aux@cite{0}{sandler2018_mobilenetv2}
\abx@aux@segm{0}{0}{sandler2018_mobilenetv2}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{howard2017_mobilenets}
\abx@aux@segm{0}{0}{howard2017_mobilenets}
\abx@aux@cite{0}{zhang2018_shufflenet}
\abx@aux@segm{0}{0}{zhang2018_shufflenet}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\BKM@entry{id=294,dest={73756273656374696F6E2E372E392E35},srcline={1084}}{5C3337365C3337375C303030535C303030705C303030615C303030745C303030695C303030615C3030306C5C3030305C3034305C303030535C303030655C303030705C303030615C303030725C303030615C303030625C3030306C5C303030655C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Final Output Tensor}{205}{section*.329}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applications of 3D Convolutions}{205}{section*.330}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages of 3D Convolutions}{205}{section*.331}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Challenges of 3D Convolutions}{205}{section*.332}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.4}Efficient Convolutions for Mobile and Embedded Systems}{205}{subsection.7.9.4}\protected@file@percent }
\newlabel{subsec:efficient_convs}{{7.9.4}{205}{Efficient Convolutions for Mobile and Embedded Systems}{subsection.7.9.4}{}}
\abx@aux@backref{119}{krizhevsky2012_alexnet}{0}{205}{205}
\abx@aux@backref{120}{sandler2018_mobilenetv2}{0}{205}{205}
\abx@aux@backref{121}{tan2019_efficientnet}{0}{205}{205}
\abx@aux@backref{122}{howard2017_mobilenets}{0}{205}{205}
\abx@aux@backref{123}{zhang2018_shufflenet}{0}{205}{205}
\abx@aux@backref{124}{tan2019_efficientnet}{0}{205}{205}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.5}Spatial Separable Convolutions}{205}{subsection.7.9.5}\protected@file@percent }
\newlabel{subsec:spatial_separable_convs}{{7.9.5}{205}{Spatial Separable Convolutions}{subsection.7.9.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Concept and Intuition}{205}{section*.333}\protected@file@percent }
\abx@aux@cite{0}{lecun1998_lenet}
\abx@aux@segm{0}{0}{lecun1998_lenet}
\BKM@entry{id=295,dest={73756273656374696F6E2E372E392E36},srcline={1131}}{5C3337365C3337375C303030445C303030655C303030705C303030745C303030685C303030775C303030695C303030735C303030655C3030305C3034305C303030535C303030655C303030705C303030615C303030725C303030615C303030625C3030306C5C303030655C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\abx@aux@cite{0}{chollet2017_xception}
\abx@aux@segm{0}{0}{chollet2017_xception}
\abx@aux@cite{0}{howard2017_mobilenets}
\abx@aux@segm{0}{0}{howard2017_mobilenets}
\@writefile{toc}{\contentsline {paragraph}{Limitations and Transition to Depthwise Separable Convolutions}{206}{section*.334}\protected@file@percent }
\abx@aux@backref{125}{lecun1998_lenet}{0}{206}{206}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.6}Depthwise Separable Convolutions}{206}{subsection.7.9.6}\protected@file@percent }
\newlabel{subsec:depthwise_separable_convs}{{7.9.6}{206}{Depthwise Separable Convolutions}{subsection.7.9.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Concept and Motivation}{206}{section*.335}\protected@file@percent }
\abx@aux@backref{126}{chollet2017_xception}{0}{206}{206}
\abx@aux@backref{127}{howard2017_mobilenets}{0}{206}{206}
\@writefile{toc}{\contentsline {paragraph}{Computational Efficiency}{207}{section*.336}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Standard \((K \times K)\) Convolution}{207}{section*.337}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Depthwise Separable Convolution}{207}{section*.338}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example: \((K=3,\tmspace  +\thickmuskip {.2777em}C_{\mathrm  {in}}=128,\tmspace  +\thickmuskip {.2777em}C_{\mathrm  {out}}=256,\tmspace  +\thickmuskip {.2777em}H=W=32)\)}{207}{section*.339}\protected@file@percent }
\newlabel{subsubsec:depthwise_separable_example}{{7.9.6}{207}{Example: \((K=3,\;C_{\mathrm {in}}=128,\;C_{\mathrm {out}}=256,\;H=W=32)\)}{section*.339}{}}
\abx@aux@cite{0}{blog2023_separable_convolutions}
\abx@aux@segm{0}{0}{blog2023_separable_convolutions}
\abx@aux@cite{0}{blog2023_separable_convolutions}
\abx@aux@segm{0}{0}{blog2023_separable_convolutions}
\@writefile{lof}{\contentsline {figure}{\numberline {7.29}{\ignorespaces Illustration of a \emph  {depthwise separable convolution}. \textbf  {Step 1 (Depthwise)}: Each of the \(C_{\text  {in}}\) input channels is convolved separately by a \(k \times k\) filter, preserving the spatial dimensions but not mixing channels. \textbf  {Step 2 (Pointwise)}: To produce the desired \(C_{\text  {out}}\) channels, a series of \(1 \times 1 \times C_{\text  {in}}\) filters (kernels) is applied—one for each output channel—resulting in a stack of 2D feature maps with the same spatial size. Source: \blx@tocontentsinit {0}\cite {blog2023_separable_convolutions}. }}{208}{figure.caption.340}\protected@file@percent }
\abx@aux@backref{129}{blog2023_separable_convolutions}{0}{208}{208}
\newlabel{fig:chapter7_depthwise_conv}{{7.29}{208}{Illustration of a \emph {depthwise separable convolution}. \textbf {Step 1 (Depthwise)}: Each of the \(C_{\text {in}}\) input channels is convolved separately by a \(k \times k\) filter, preserving the spatial dimensions but not mixing channels. \textbf {Step 2 (Pointwise)}: To produce the desired \(C_{\text {out}}\) channels, a series of \(1 \times 1 \times C_{\text {in}}\) filters (kernels) is applied—one for each output channel—resulting in a stack of 2D feature maps with the same spatial size. Source: \cite {blog2023_separable_convolutions}}{figure.caption.340}{}}
\abx@aux@cite{0}{howard2017_mobilenets}
\abx@aux@segm{0}{0}{howard2017_mobilenets}
\abx@aux@cite{0}{zhang2018_shufflenet}
\abx@aux@segm{0}{0}{zhang2018_shufflenet}
\abx@aux@cite{0}{chollet2017_xception}
\abx@aux@segm{0}{0}{chollet2017_xception}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{chollet2017_xception}
\abx@aux@segm{0}{0}{chollet2017_xception}
\BKM@entry{id=296,dest={73756273656374696F6E2E372E392E37},srcline={1292}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030305C3034305C3030306F5C303030665C3030305C3034305C303030535C303030705C303030655C303030635C303030695C303030615C3030306C5C303030695C3030307A5C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Reduction Factor}{209}{section*.341}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Usage and Examples}{209}{section*.342}\protected@file@percent }
\abx@aux@backref{130}{howard2017_mobilenets}{0}{209}{209}
\abx@aux@backref{131}{zhang2018_shufflenet}{0}{209}{209}
\abx@aux@backref{132}{chollet2017_xception}{0}{209}{209}
\abx@aux@backref{133}{tan2019_efficientnet}{0}{209}{209}
\@writefile{toc}{\contentsline {paragraph}{Trade-Offs}{209}{section*.343}\protected@file@percent }
\abx@aux@backref{134}{chollet2017_xception}{0}{209}{209}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.7}Summary of Specialized Convolutions}{209}{subsection.7.9.7}\protected@file@percent }
\newlabel{subsec:conv_summary}{{7.9.7}{209}{Summary of Specialized Convolutions}{subsection.7.9.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.30}{\ignorespaces Illustration of \texttt  {torch.nn.Conv2d} and its parameters. The attached paragraph shows how the convolution operation applies filters to input data, computing feature maps based on the hyper-parameters of stride, padding, and kernel size.}}{210}{figure.caption.344}\protected@file@percent }
\newlabel{fig:chapter7_pytorch_conv2d}{{7.30}{210}{Illustration of \texttt {torch.nn.Conv2d} and its parameters. The attached paragraph shows how the convolution operation applies filters to input data, computing feature maps based on the hyper-parameters of stride, padding, and kernel size}{figure.caption.344}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.31}{\ignorespaces Comparison of PyTorch convolution layers: \texttt  {Conv1d}, \texttt  {Conv2d}, and \texttt  {Conv3d}. The figure highlights their function signatures and input parameter definitions in the PyTorch library.}}{210}{figure.caption.345}\protected@file@percent }
\newlabel{fig:chapter7_pytorch_conv_layers}{{7.31}{210}{Comparison of PyTorch convolution layers: \texttt {Conv1d}, \texttt {Conv2d}, and \texttt {Conv3d}. The figure highlights their function signatures and input parameter definitions in the PyTorch library}{figure.caption.345}{}}
\BKM@entry{id=297,dest={73656374696F6E2E372E3130},srcline={1320}}{5C3337365C3337375C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C303030675C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\BKM@entry{id=298,dest={73756273656374696F6E2E372E31302E31},srcline={1325}}{5C3337365C3337375C303030545C303030795C303030705C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\BKM@entry{id=299,dest={73756273656374696F6E2E372E31302E32},srcline={1342}}{5C3337365C3337375C303030455C303030665C303030665C303030655C303030635C303030745C3030305C3034305C3030306F5C303030665C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {section}{\numberline {7.10}Pooling Layers}{211}{section.7.10}\protected@file@percent }
\newlabel{subsec:pooling_layers}{{7.10}{211}{Pooling Layers}{section.7.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10.1}Types of Pooling}{211}{subsection.7.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.32}{\ignorespaces Example of \emph  {max pooling} with a \( 2 \times 2 \) kernel and stride of 2. The operation introduces slight spatial invariance, helping retain dominant features.}}{211}{figure.caption.346}\protected@file@percent }
\newlabel{fig:chapter7_max_pooling}{{7.32}{211}{Example of \emph {max pooling} with a \( 2 \times 2 \) kernel and stride of 2. The operation introduces slight spatial invariance, helping retain dominant features}{figure.caption.346}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10.2}Effect of Pooling}{211}{subsection.7.10.2}\protected@file@percent }
\BKM@entry{id=300,dest={73656374696F6E2A2E333438},srcline={1358}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030315C303030305C3030302E5C303030335C3030303A5C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C303030675C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {7.33}{\ignorespaces Summary of pooling layers: input size, hyperparameters (kernel size, stride, pooling function), output size, and common pooling configurations.}}{212}{figure.caption.347}\protected@file@percent }
\newlabel{fig:chapter7_pooling_summary}{{7.33}{212}{Summary of pooling layers: input size, hyperparameters (kernel size, stride, pooling function), output size, and common pooling configurations}{figure.caption.347}{}}
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.10.3: Pooling Layers in Backpropagation}{212}{section*.348}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Forward Pass of Pooling Layers}{212}{section*.349}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Example of Forward Pass}{212}{section*.350}\protected@file@percent }
\BKM@entry{id=301,dest={73756273656374696F6E2E372E31302E34},srcline={1459}}{5C3337365C3337375C303030475C3030306C5C3030306F5C303030625C303030615C3030306C5C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C303030675C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {subsubsection}{Backpropagation Through Pooling Layers}{213}{section*.351}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Max Pooling Backpropagation}{213}{section*.352}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Average Pooling Backpropagation}{213}{section*.353}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generalization of Backpropagation for Pooling}{213}{section*.354}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10.4}Global Pooling Layers}{213}{subsection.7.10.4}\protected@file@percent }
\newlabel{subsec:global_pooling}{{7.10.4}{213}{Global Pooling Layers}{subsection.7.10.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{General Advantages}{214}{section*.355}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Global Average Pooling (GAP)}{214}{section*.356}\protected@file@percent }
\newlabel{subsubsec:gap}{{7.10.4}{214}{Global Average Pooling (GAP)}{section*.356}{}}
\@writefile{toc}{\contentsline {paragraph}{Operation.}{214}{section*.357}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Upsides.}{214}{section*.358}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Downsides.}{214}{section*.359}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Backpropagation.}{214}{section*.360}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Global Max Pooling (GMP)}{214}{section*.361}\protected@file@percent }
\newlabel{subsubsec:gmp}{{7.10.4}{214}{Global Max Pooling (GMP)}{section*.361}{}}
\@writefile{toc}{\contentsline {paragraph}{Operation.}{214}{section*.362}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Upsides.}{214}{section*.363}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Downsides.}{215}{section*.364}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Backpropagation.}{215}{section*.365}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Comparison of GAP and GMP}{215}{section*.366}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Contrasting with Regular Pooling}{215}{section*.367}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Window Size.}{215}{section*.368}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{When to Use Global Pooling.}{215}{section*.369}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{When to Use Regular Pooling.}{215}{section*.370}\protected@file@percent }
\BKM@entry{id=302,dest={73656374696F6E2E372E3131},srcline={1565}}{5C3337365C3337375C303030435C3030306C5C303030615C303030735C303030735C303030695C303030635C303030615C3030306C5C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C30303073}
\abx@aux@cite{0}{lecun1998_lenet}
\abx@aux@segm{0}{0}{lecun1998_lenet}
\BKM@entry{id=303,dest={73756273656374696F6E2E372E31312E31},srcline={1570}}{5C3337365C3337375C3030304C5C303030655C3030304E5C303030655C303030745C3030302D5C303030355C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {section}{\numberline {7.11}Classical CNN Architectures}{216}{section.7.11}\protected@file@percent }
\newlabel{subsec:lenet5}{{7.11}{216}{Classical CNN Architectures}{section.7.11}{}}
\abx@aux@backref{135}{lecun1998_lenet}{0}{216}{216}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.1}LeNet-5 Architecture}{216}{subsection.7.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.34}{\ignorespaces LeNet-5 architecture following the classical \([ \text  {Conv}, \text  {ReLU}, \text  {Pool} ] \times N\), Flatten, \([ \text  {FC}, \text  {ReLU} ] \times M\), FC design. The network reduces spatial dimensions while increasing the number of feature channels, a pattern common in CNNs.}}{216}{figure.caption.371}\protected@file@percent }
\newlabel{fig:lenet5_architecture}{{7.34}{216}{LeNet-5 architecture following the classical \([ \text {Conv}, \text {ReLU}, \text {Pool} ] \times N\), Flatten, \([ \text {FC}, \text {ReLU} ] \times M\), FC design. The network reduces spatial dimensions while increasing the number of feature channels, a pattern common in CNNs}{figure.caption.371}{}}
\@writefile{toc}{\contentsline {subsubsection}{Detailed Layer Breakdown}{217}{section*.372}\protected@file@percent }
\BKM@entry{id=304,dest={73756273656374696F6E2E372E31312E32},srcline={1686}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030415C303030725C303030655C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C303030735C3030305C3034305C303030445C303030655C303030735C303030695C303030675C3030306E5C303030655C303030645C3030303F}
\@writefile{toc}{\contentsline {subsubsection}{Summary of LeNet-5}{218}{section*.373}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Key Architectural Trends in CNNs, Illustrated by LeNet-5}{218}{section*.374}\protected@file@percent }
\newlabel{subsubsec:lenet_trends}{{7.11.1}{218}{Key Architectural Trends in CNNs, Illustrated by LeNet-5}{section*.374}{}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical Feature Learning.}{218}{section*.375}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Alternating Convolution and Pooling.}{218}{section*.376}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transition to Fully Connected (FC) Layers.}{218}{section*.377}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.2}How Are CNN Architectures Designed?}{218}{subsection.7.11.2}\protected@file@percent }
\newlabel{subsec:cnn_design}{{7.11.2}{218}{How Are CNN Architectures Designed?}{subsection.7.11.2}{}}
\BKM@entry{id=305,dest={73656374696F6E2A2E333738},srcline={1703}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030315C303030325C3030303A5C3030305C3034305C303030565C303030615C3030306E5C303030695C303030735C303030685C303030695C3030306E5C303030675C3030305C3034305C3030305C3034365C3030305C3034305C303030455C303030785C303030705C3030306C5C3030306F5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C303030735C3030303A5C3030305C3034305C303030415C3030305C3034305C303030425C303030615C303030725C303030725C303030695C303030655C303030725C3030305C3034305C303030745C3030306F5C3030305C3034305C303030445C3030304C}
\BKM@entry{id=306,dest={73656374696F6E2A2E333830},srcline={1711}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030315C303030325C3030302E5C303030315C3030303A5C3030305C3034305C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030505C303030725C3030306F5C303030625C3030306C5C303030655C3030306D}
\@writefile{toc}{\contentsline {section}{Enrichment 7.12: Vanishing \& Exploding Gradients: A Barrier to DL}{219}{section*.378}\protected@file@percent }
\newlabel{enrichment:vanishing_exploding_gradients}{{7.12}{219}{\color {ocre}Enrichment \thesection : Vanishing \& Exploding Gradients: A Barrier to DL}{section*.378}{}}
\@writefile{toc}{\contentsline {paragraph}{Context}{219}{section*.379}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.12.1: Understanding the Problem}{219}{section*.380}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Role of Gradients in Deep Networks}{219}{section*.381}\protected@file@percent }
\newlabel{subsubsec:gradient_flow}{{7.12.1}{219}{The Role of Gradients in Deep Networks}{section*.381}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gradient Computation in Deep Networks}{219}{section*.382}\protected@file@percent }
\newlabel{eq:gradient_general}{{7.1}{219}{Gradient Computation in Deep Networks}{equation.7.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Components of Gradient Propagation}{219}{section*.383}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Impact of Depth in Neural Networks}{220}{section*.384}\protected@file@percent }
\newlabel{subsubsec:impact_of_depth}{{7.12.1}{220}{Impact of Depth in Neural Networks}{section*.384}{}}
\@writefile{toc}{\contentsline {subsubsection}{Practical Example: Vanishing Gradients with Sigmoid Activation}{222}{section*.385}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.35}{\ignorespaces Shows the sigmoid function and its derivative. As we can see, the \emph  {area of significance} is quite small, spanning between $-4 to 4$, and even in it, the derivative value is at most $0.25$}}{222}{figure.caption.386}\protected@file@percent }
\newlabel{fig:chapter7_sigmoid_derivative}{{7.35}{222}{Shows the sigmoid function and its derivative. As we can see, the \emph {area of significance} is quite small, spanning between $-4 to 4$, and even in it, the derivative value is at most $0.25$}{figure.caption.386}{}}
\newlabel{eq:gradient_first_layer_example}{{7.2}{222}{Practical Example: Vanishing Gradients with Sigmoid Activation}{equation.7.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Effect of Activation Gradients}{223}{section*.387}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Effect of Weight Multiplications}{223}{section*.388}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Conclusion: Vanishing Gradients}{223}{section*.389}\protected@file@percent }
\BKM@entry{id=307,dest={73656374696F6E2E372E3133},srcline={1932}}{5C3337365C3337375C303030425C303030615C303030745C303030635C303030685C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{ioffe2015_batchnorm}
\abx@aux@segm{0}{0}{ioffe2015_batchnorm}
\BKM@entry{id=308,dest={73756273656374696F6E2E372E31332E31},srcline={1937}}{5C3337365C3337375C303030555C3030306E5C303030645C303030655C303030725C303030735C303030745C303030615C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C3030304D5C303030655C303030615C3030306E5C3030302C5C3030305C3034305C303030565C303030615C303030725C303030695C303030615C3030306E5C303030635C303030655C3030302C5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=309,dest={73756273656374696F6E2E372E31332E32},srcline={1974}}{5C3337365C3337375C303030495C3030306E5C303030745C303030655C303030725C3030306E5C303030615C3030306C5C3030305C3034305C303030435C3030306F5C303030765C303030615C303030725C303030695C303030615C303030745C303030655C3030305C3034305C303030535C303030685C303030695C303030665C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030425C303030615C303030745C303030635C303030685C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3034305C3033315C303030735C3030305C3034305C303030525C3030306F5C3030306C5C30303065}
\@writefile{toc}{\contentsline {section}{\numberline {7.13}Batch Normalization}{225}{section.7.13}\protected@file@percent }
\newlabel{sec:batchnorm}{{7.13}{225}{Batch Normalization}{section.7.13}{}}
\abx@aux@backref{136}{ioffe2015_batchnorm}{0}{225}{225}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.13.1}Understanding Mean, Variance, and Normalization}{225}{subsection.7.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mean:}{225}{section*.390}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Variance:}{225}{section*.391}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Standard Deviation:}{225}{section*.392}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Effect of Normalization:}{225}{section*.393}\protected@file@percent }
\BKM@entry{id=310,dest={73756273656374696F6E2E372E31332E33},srcline={1988}}{5C3337365C3337375C303030425C303030615C303030745C303030635C303030685C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030505C303030725C3030306F5C303030635C303030655C303030735C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.13.2}Internal Covariate Shift and Batch Normalization’s Role}{226}{subsection.7.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What is Covariate Shift?}{226}{section*.394}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What is Internal Covariate Shift?}{226}{section*.395}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.13.3}Batch Normalization Process}{226}{subsection.7.13.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.36}{\ignorespaces Summary of shapes and formulas of the 'Batch Normalization' process: normalization followed by learnable scaling and shifting (de-normalization).}}{227}{figure.caption.396}\protected@file@percent }
\newlabel{fig:chapter7_batchnorm_process}{{7.36}{227}{Summary of shapes and formulas of the 'Batch Normalization' process: normalization followed by learnable scaling and shifting (de-normalization)}{figure.caption.396}{}}
\@writefile{toc}{\contentsline {subsubsection}{Batch Normalization for Convolutional Neural Networks (CNNs)}{227}{section*.397}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.37}{\ignorespaces Extending Batch Normalization to CNNs by computing batch statistics across spatial dimensions (H, W) in addition to batch samples (N). Each feature map is normalized independently.}}{228}{figure.caption.398}\protected@file@percent }
\newlabel{fig:chapter7_batchnorm_cnn}{{7.37}{228}{Extending Batch Normalization to CNNs by computing batch statistics across spatial dimensions (H, W) in addition to batch samples (N). Each feature map is normalized independently}{figure.caption.398}{}}
\BKM@entry{id=311,dest={73756273656374696F6E2E372E31332E34},srcline={2064}}{5C3337365C3337375C303030425C303030615C303030745C303030635C303030685C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{santurkar2018_howdoesbatchnormhelp}
\abx@aux@segm{0}{0}{santurkar2018_howdoesbatchnormhelp}
\abx@aux@cite{0}{ioffe2015_batchnorm}
\abx@aux@segm{0}{0}{ioffe2015_batchnorm}
\abx@aux@cite{0}{ioffe2015_batchnorm}
\abx@aux@segm{0}{0}{ioffe2015_batchnorm}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.13.4}Batch Normalization and Optimization}{229}{subsection.7.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Beyond Covariate Shift: Why Does BatchNorm Improve Training?}{229}{section*.399}\protected@file@percent }
\abx@aux@backref{137}{santurkar2018_howdoesbatchnormhelp}{0}{229}{229}
\@writefile{lof}{\contentsline {figure}{\numberline {7.38}{\ignorespaces Training accuracy across different conditions (no BN, with BN, BN with artificially induced covariate shift). Performance differences indicate that covariate shift is not the key issue affecting training efficiency.}}{229}{figure.caption.400}\protected@file@percent }
\newlabel{fig:chapter7_batchnorm_training_stability}{{7.38}{229}{Training accuracy across different conditions (no BN, with BN, BN with artificially induced covariate shift). Performance differences indicate that covariate shift is not the key issue affecting training efficiency}{figure.caption.400}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.39}{\ignorespaces Impact of Batch Normalization on optimization: smoother loss landscape (left), more stable gradients (middle), and overall training stability (right) \blx@tocontentsinit {0}\cite {ioffe2015_batchnorm}.}}{230}{figure.caption.401}\protected@file@percent }
\abx@aux@backref{139}{ioffe2015_batchnorm}{0}{230}{230}
\newlabel{fig:batchnorm_loss_smooth}{{7.39}{230}{Impact of Batch Normalization on optimization: smoother loss landscape (left), more stable gradients (middle), and overall training stability (right) \cite {ioffe2015_batchnorm}}{figure.caption.401}{}}
\@writefile{toc}{\contentsline {subsubsection}{Why Does BatchNorm Smooth the Loss Surface?}{230}{section*.402}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Hessian Eigenvalues and Loss Surface Curvature}{230}{section*.403}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Computing Eigenvalues}{230}{section*.404}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Interpretation of Eigenvalues}{230}{section*.405}\protected@file@percent }
\abx@aux@cite{0}{santurkar2018_howdoesbatchnormhelp}
\abx@aux@segm{0}{0}{santurkar2018_howdoesbatchnormhelp}
\abx@aux@backref{140}{santurkar2018_howdoesbatchnormhelp}{0}{231}{231}
\@writefile{toc}{\contentsline {paragraph}{2. Reducing the Lipschitz Constant}{231}{section*.406}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Implicit Regularization via Mini-Batch Noise}{231}{section*.407}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{BN Helps Decoupling Weight Magnitude from Activation Scale}{232}{section*.408}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mini Example: ReLU Dead Zone Prevention}{232}{section*.409}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Conclusion: The Real Reason BatchNorm Works}{232}{section*.410}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Normalization in Test Time}{233}{section*.411}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.40}{\ignorespaces Batch Normalization in test time: mean and variance are fixed, computed using a running average during training.}}{233}{figure.caption.412}\protected@file@percent }
\newlabel{fig:chapter7_batchnorm_test}{{7.40}{233}{Batch Normalization in test time: mean and variance are fixed, computed using a running average during training}{figure.caption.412}{}}
\@writefile{toc}{\contentsline {subsubsection}{Limitations of BatchNorm}{233}{section*.413}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Alternative Normalization Methods}{234}{section*.414}\protected@file@percent }
\newlabel{subsubsec:alt_norms}{{7.13.4}{234}{Alternative Normalization Methods}{section*.414}{}}
\@writefile{toc}{\contentsline {subsubsection}{Layer Normalization (LN)}{234}{section*.415}\protected@file@percent }
\newlabel{subsubsec:layer_norm}{{7.13.4}{234}{Layer Normalization (LN)}{section*.415}{}}
\@writefile{toc}{\contentsline {paragraph}{Core Idea}{234}{section*.416}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.41}{\ignorespaces Layer Normalization in a fully connected layer: each sample’s hidden activations are normalized independently.}}{234}{figure.caption.417}\protected@file@percent }
\newlabel{fig:chapter7_layernorm_fc}{{7.41}{234}{Layer Normalization in a fully connected layer: each sample’s hidden activations are normalized independently}{figure.caption.417}{}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{235}{section*.418}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Layer Normalization (LN)}{235}{section*.419}\protected@file@percent }
\newlabel{subsubsec:layer_norm}{{7.13.4}{235}{Layer Normalization (LN)}{section*.419}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.42}{\ignorespaces Layer Normalization in a fully connected layer: each sample’s hidden activations are normalized independently.}}{235}{figure.caption.420}\protected@file@percent }
\newlabel{fig:chapter7_layernorm_fc}{{7.42}{235}{Layer Normalization in a fully connected layer: each sample’s hidden activations are normalized independently}{figure.caption.420}{}}
\@writefile{toc}{\contentsline {paragraph}{Definition (Fully Connected Layers).}{235}{section*.421}\protected@file@percent }
\abx@aux@cite{0}{becominghuman2018_allaboutnorm}
\abx@aux@segm{0}{0}{becominghuman2018_allaboutnorm}
\abx@aux@cite{0}{becominghuman2018_allaboutnorm}
\abx@aux@segm{0}{0}{becominghuman2018_allaboutnorm}
\@writefile{toc}{\contentsline {paragraph}{Extension to Convolutional Layers}{236}{section*.422}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.43}{\ignorespaces Visualization of Layer Normalization operation, indicating how it is applied to each input image in the batch, with its own corresponding mean and std values \blx@tocontentsinit {0}\cite {becominghuman2018_allaboutnorm}.}}{236}{figure.caption.423}\protected@file@percent }
\abx@aux@backref{142}{becominghuman2018_allaboutnorm}{0}{236}{236}
\newlabel{fig:chapter7_layernorm_visual}{{7.43}{236}{Visualization of Layer Normalization operation, indicating how it is applied to each input image in the batch, with its own corresponding mean and std values \cite {becominghuman2018_allaboutnorm}}{figure.caption.423}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation}{236}{section*.424}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages of LN}{236}{section*.425}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Instance Normalization (IN)}{236}{section*.426}\protected@file@percent }
\abx@aux@cite{0}{becominghuman2018_allaboutnorm}
\abx@aux@segm{0}{0}{becominghuman2018_allaboutnorm}
\abx@aux@cite{0}{becominghuman2018_allaboutnorm}
\abx@aux@segm{0}{0}{becominghuman2018_allaboutnorm}
\@writefile{lof}{\contentsline {figure}{\numberline {7.44}{\ignorespaces Visualization of Instance Normalization operation \blx@tocontentsinit {0}\cite {becominghuman2018_allaboutnorm}.}}{237}{figure.caption.427}\protected@file@percent }
\abx@aux@backref{144}{becominghuman2018_allaboutnorm}{0}{237}{237}
\newlabel{fig:chapter7_instancenorm_visual}{{7.44}{237}{Visualization of Instance Normalization operation \cite {becominghuman2018_allaboutnorm}}{figure.caption.427}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation}{237}{section*.428}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages of Instance Normalization}{237}{section*.429}\protected@file@percent }
\abx@aux@cite{0}{sh-tsang2018_groupnorm}
\abx@aux@segm{0}{0}{sh-tsang2018_groupnorm}
\abx@aux@cite{0}{sh-tsang2018_groupnorm}
\abx@aux@segm{0}{0}{sh-tsang2018_groupnorm}
\@writefile{toc}{\contentsline {subsubsection}{Group Normalization (GN)}{238}{section*.430}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.45}{\ignorespaces Visualization of Group Normalization operation compared to the rest of normalization methods (BN, LN, and IN) \blx@tocontentsinit {0}\cite {sh-tsang2018_groupnorm}.}}{238}{figure.caption.431}\protected@file@percent }
\abx@aux@backref{146}{sh-tsang2018_groupnorm}{0}{238}{238}
\newlabel{fig:chpater7_groupnorm_visual}{{7.45}{238}{Visualization of Group Normalization operation compared to the rest of normalization methods (BN, LN, and IN) \cite {sh-tsang2018_groupnorm}}{figure.caption.431}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation}{238}{section*.432}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages of Group Normalization}{238}{section*.433}\protected@file@percent }
\BKM@entry{id=312,dest={73656374696F6E2A2E343337},srcline={2456}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030315C303030335C3030302E5C303030355C3030303A5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030425C303030615C303030745C303030635C303030685C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsubsection}{Why Do IN, LN, and GN Improve Optimization?}{239}{section*.434}\protected@file@percent }
\newlabel{subsubsec:why_alt_norm}{{7.13.4}{239}{Why Do IN, LN, and GN Improve Optimization?}{section*.434}{}}
\@writefile{toc}{\contentsline {paragraph}{Common Benefits Across IN, LN, and GN}{239}{section*.435}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary: How These Methods Enhance Training}{239}{section*.436}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.13.5: Backpropagation for Batch Normalization}{239}{section*.437}\protected@file@percent }
\newlabel{enrichment:bn_backprop_node}{{7.13.5}{239}{\color {ocre}Enrichment \thesubsection : Backpropagation for Batch Normalization}{section*.437}{}}
\@writefile{toc}{\contentsline {paragraph}{Chain Rule in the Graph}{240}{section*.438}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Gradients w.r.t.\ \(\gamma \) and \(\beta \)}{240}{subparagraph*.439}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Gradient w.r.t.\ \(\hat  {x}_i\)}{240}{subparagraph*.440}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradients Involving \(\mu \) and \(\sigma ^2\)}{240}{section*.441}\protected@file@percent }
\abx@aux@cite{0}{zakka2016_batchnorm}
\abx@aux@segm{0}{0}{zakka2016_batchnorm}
\@writefile{toc}{\contentsline {paragraph}{Final: Gradients w.r.t.\ Each \(x_i\)}{241}{section*.442}\protected@file@percent }
\abx@aux@backref{147}{zakka2016_batchnorm}{0}{241}{241}
\@writefile{toc}{\contentsline {paragraph}{Computational Efficiency}{241}{section*.443}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Extension to LN, IN, GN}{241}{section*.444}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{241}{section*.445}\protected@file@percent }
\BKM@entry{id=313,dest={73656374696F6E2A2E343436},srcline={2626}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030375C3030302E5C303030315C303030335C3030302E5C303030365C3030303A5C3030305C3034305C303030425C303030615C303030745C303030635C303030685C3030304E5C3030306F5C303030725C3030306D5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030325C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{Enrichment 7.13.6: BatchNorm and \(L_2\) Regularization}{242}{section*.446}\protected@file@percent }
\newlabel{enrichment:bn_l2_regularization}{{7.13.6}{242}{\color {ocre}Enrichment \thesubsection : BatchNorm and \(L_2\) Regularization}{section*.446}{}}
\@writefile{toc}{\contentsline {paragraph}{Context and Motivation}{242}{section*.447}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Combine Them?}{242}{section*.448}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Key Interaction: BN Masks the Scale of Weights}{242}{section*.449}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Invariance to Weight Scaling}{242}{subparagraph*.450}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Shifting Role of \(L_2\)}{242}{subparagraph*.451}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Pitfalls}{242}{section*.452}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{(1) Excluding \(\gamma ,\beta \) from Decay}{242}{subparagraph*.453}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{(2) Small Batches}{242}{subparagraph*.454}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Recommendations}{242}{section*.455}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary}{243}{section*.456}\protected@file@percent }
\BKM@entry{id=314,dest={636861707465722E38},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030385C3030303A5C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C303030735C3030305C3034305C30303049}
\BKM@entry{id=315,dest={73656374696F6E2E382E31},srcline={10}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030425C303030755C303030695C3030306C5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B5C303030735C3030305C3034305C303030745C3030306F5C3030305C3034305C303030535C3030304F5C303030545C303030415C3030305C3034305C303030435C3030304E5C3030304E5C30303073}
\BKM@entry{id=316,dest={73656374696F6E2E382E32},srcline={16}}{5C3337365C3337375C303030415C3030306C5C303030655C303030785C3030304E5C303030655C30303074}
\abx@aux@cite{0}{krizhevsky2012_alexnet}
\abx@aux@segm{0}{0}{krizhevsky2012_alexnet}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Lecture 8: CNN Architectures I}{244}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@7}}
\ttl@writefile{ptc}{\ttl@starttoc{default@8}}
\pgfsyspdfmark {pgfid21}{0}{52099153}
\pgfsyspdfmark {pgfid20}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Introduction: From Building Blocks to SOTA CNNs}{244}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}AlexNet}{244}{section.8.2}\protected@file@percent }
\abx@aux@backref{148}{krizhevsky2012_alexnet}{0}{244}{244}
\BKM@entry{id=317,dest={73756273656374696F6E2E382E322E31},srcline={32}}{5C3337365C3337375C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030445C303030655C303030745C303030615C303030695C3030306C5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Architecture Details}{245}{subsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{First Convolutional Layer (Conv1)}{245}{section*.457}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Memory Requirements}{245}{section*.458}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Number of Learnable Parameters}{245}{section*.459}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Computational Cost}{245}{section*.460}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Max Pooling Layer}{245}{section*.461}\protected@file@percent }
\BKM@entry{id=318,dest={73756273656374696F6E2E382E322E32},srcline={93}}{5C3337365C3337375C303030465C303030695C3030306E5C303030615C3030306C5C3030305C3034305C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030655C303030645C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\BKM@entry{id=319,dest={73756273656374696F6E2E382E322E33},srcline={127}}{5C3337365C3337375C3030304B5C303030655C303030795C3030305C3034305C303030545C303030615C3030306B5C303030655C303030615C303030775C303030615C303030795C303030735C3030305C3034305C303030665C303030725C3030306F5C3030306D5C3030305C3034305C303030415C3030306C5C303030655C303030785C3030304E5C303030655C30303074}
\@writefile{toc}{\contentsline {paragraph}{Memory and Computational Cost}{246}{section*.462}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Final Fully Connected Layers}{246}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Computational Cost}{246}{section*.463}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces The AlexNet architecture, including a table summarizing memory, parameters, and FLOPs per layer.}}{246}{figure.caption.464}\protected@file@percent }
\newlabel{fig:chapter8_alexnet_architecture}{{8.1}{246}{The AlexNet architecture, including a table summarizing memory, parameters, and FLOPs per layer}{figure.caption.464}{}}
\BKM@entry{id=320,dest={73756273656374696F6E2E382E322E34},srcline={141}}{5C3337365C3337375C3030305A5C303030465C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030415C3030306E5C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C3030306D5C303030655C3030306E5C303030745C3030305C3034305C3030306F5C3030306E5C3030305C3034305C303030415C3030306C5C303030655C303030785C3030304E5C303030655C30303074}
\abx@aux@cite{0}{zeiler2014_visualizing}
\abx@aux@segm{0}{0}{zeiler2014_visualizing}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Key Takeaways from AlexNet}{247}{subsection.8.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Trends in AlexNet: memory usage in early conv layers, parameter-heavy FC layers, and computational cost concentrated in convolutions.}}{247}{figure.caption.465}\protected@file@percent }
\newlabel{fig:chapter8_alexnet_trends}{{8.2}{247}{Trends in AlexNet: memory usage in early conv layers, parameter-heavy FC layers, and computational cost concentrated in convolutions}{figure.caption.465}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}ZFNet: An Improvement on AlexNet}{247}{subsection.8.2.4}\protected@file@percent }
\abx@aux@backref{149}{zeiler2014_visualizing}{0}{247}{247}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces The ZFNet architecture and its improvements over AlexNet.}}{247}{figure.caption.466}\protected@file@percent }
\newlabel{fig:chapter8_zfnet_architecture}{{8.3}{247}{The ZFNet architecture and its improvements over AlexNet}{figure.caption.466}{}}
\BKM@entry{id=321,dest={73656374696F6E2E382E33},srcline={160}}{5C3337365C3337375C303030565C303030475C303030475C3030303A5C3030305C3034305C303030415C3030305C3034305C303030505C303030725C303030695C3030306E5C303030635C303030695C303030705C3030306C5C303030655C303030645C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\abx@aux@cite{0}{simonyan2014_vgg}
\abx@aux@segm{0}{0}{simonyan2014_vgg}
\BKM@entry{id=322,dest={73756273656374696F6E2E382E332E31},srcline={182}}{5C3337365C3337375C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C3030305C3034305C303030535C303030745C303030725C303030755C303030635C303030745C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {subsubsection}{Key Modifications in ZFNet}{248}{section*.467}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}VGG: A Principled CNN Architecture}{248}{section.8.3}\protected@file@percent }
\newlabel{sec:vgg_architecture}{{8.3}{248}{VGG: A Principled CNN Architecture}{section.8.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Historical Context.}{248}{section*.468}\protected@file@percent }
\abx@aux@backref{150}{simonyan2014_vgg}{0}{248}{248}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces Comparison of AlexNet vs.\ VGG: model size, parameter count, and FLOPs.}}{248}{figure.caption.469}\protected@file@percent }
\newlabel{fig:chapter7_vgg_alexnet}{{8.4}{248}{Comparison of AlexNet vs.\ VGG: model size, parameter count, and FLOPs}{figure.caption.469}{}}
\@writefile{toc}{\contentsline {paragraph}{Core Design Principles.}{248}{section*.470}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Network Structure}{248}{subsection.8.3.1}\protected@file@percent }
\BKM@entry{id=323,dest={73756273656374696F6E2E382E332E32},srcline={201}}{5C3337365C3337375C3030304B5C303030655C303030795C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030615C3030306C5C3030305C3034305C303030495C3030306E5C303030735C303030695C303030675C303030685C303030745C30303073}
\BKM@entry{id=324,dest={73756273656374696F6E2E382E332E33},srcline={227}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030545C303030685C303030695C303030735C3030305C3034305C303030535C303030745C303030725C303030615C303030745C303030655C303030675C303030795C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces AlexNet vs.\ VGG-16 and VGG-19, highlighting VGG’s deeper, more uniform design. (Slide~\ref {fig:chapter7_vgg_alexnet})}}{249}{figure.caption.471}\protected@file@percent }
\newlabel{fig:chapter7_vgg_alexnet_compare}{{8.5}{249}{AlexNet vs.\ VGG-16 and VGG-19, highlighting VGG’s deeper, more uniform design. (Slide~\ref {fig:chapter7_vgg_alexnet})}{figure.caption.471}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.2}Key Architectural Insights}{249}{subsection.8.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Small-Kernel Convolutions (\(3\times 3\))}{249}{section*.472}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pooling \(\,2\times 2\), Stride=2, No Padding}{249}{section*.473}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Doubling Channels After Each Pool}{249}{section*.474}\protected@file@percent }
\BKM@entry{id=325,dest={73756273656374696F6E2E382E332E34},srcline={234}}{5C3337365C3337375C303030505C303030725C303030615C303030635C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C3030304F5C303030625C303030735C303030655C303030725C303030765C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=326,dest={73756273656374696F6E2E382E332E35},srcline={244}}{5C3337365C3337375C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030565C303030655C303030725C303030795C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030565C303030475C303030475C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C30303068}
\abx@aux@cite{0}{simonyan2014_vgg}
\abx@aux@segm{0}{0}{simonyan2014_vgg}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.3}Why This Strategy Works}{250}{subsection.8.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Balanced Computation.}{250}{section*.475}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Influence on Later Architectures.}{250}{section*.476}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.4}Practical Observations}{250}{subsection.8.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.5}Training Very Deep Networks: The VGG Approach}{250}{subsection.8.3.5}\protected@file@percent }
\newlabel{subsec:vgg_training}{{8.3.5}{250}{Training Very Deep Networks: The VGG Approach}{subsection.8.3.5}{}}
\abx@aux@backref{151}{simonyan2014_vgg}{0}{250}{250}
\@writefile{toc}{\contentsline {subsubsection}{Incremental Training Strategy}{250}{section*.477}\protected@file@percent }
\BKM@entry{id=327,dest={73656374696F6E2E382E34},srcline={279}}{5C3337365C3337375C303030475C3030306F5C3030306F5C303030675C3030304C5C303030655C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030635C303030795C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030505C303030615C303030725C303030615C3030306C5C3030306C5C303030655C3030306C5C303030695C303030735C3030306D}
\abx@aux@cite{0}{szegedy2015_googlenet}
\abx@aux@segm{0}{0}{szegedy2015_googlenet}
\@writefile{toc}{\contentsline {subsubsection}{Optimization and Training Details}{251}{section*.478}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Effectiveness of the Approach}{251}{section*.479}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.4}GoogLeNet: Efficiency and Parallelism}{251}{section.8.4}\protected@file@percent }
\newlabel{sec:googlenet}{{8.4}{251}{GoogLeNet: Efficiency and Parallelism}{section.8.4}{}}
\abx@aux@backref{152}{szegedy2015_googlenet}{0}{251}{251}
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces Comparison of AlexNet, VGG, and GoogLeNet, highlighting the architectural evolution toward efficiency.}}{251}{figure.caption.480}\protected@file@percent }
\newlabel{fig:chpater8_googlenet_vgg_comparison}{{8.6}{251}{Comparison of AlexNet, VGG, and GoogLeNet, highlighting the architectural evolution toward efficiency}{figure.caption.480}{}}
\BKM@entry{id=328,dest={73756273656374696F6E2E382E342E31},srcline={294}}{5C3337365C3337375C303030535C303030745C303030655C3030306D5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C3030303A5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030455C303030615C303030725C3030306C5C303030795C3030305C3034305C303030445C3030306F5C303030775C3030306E5C303030735C303030615C3030306D5C303030705C3030306C5C303030695C3030306E5C30303067}
\BKM@entry{id=329,dest={73756273656374696F6E2E382E342E32},srcline={316}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030495C3030306E5C303030635C303030655C303030705C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304D5C3030306F5C303030645C303030755C3030306C5C303030655C3030303A5C3030305C3034305C303030505C303030615C303030725C303030615C3030306C5C3030306C5C303030655C3030306C5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030455C303030785C303030745C303030725C303030615C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.1}Stem Network: Efficient Early Downsampling}{252}{subsection.8.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces The stem network in GoogLeNet, highlighting its efficient early downsampling.}}{252}{figure.caption.481}\protected@file@percent }
\newlabel{fig:chpater8_googlenet_stem}{{8.7}{252}{The stem network in GoogLeNet, highlighting its efficient early downsampling}{figure.caption.481}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.2}The Inception Module: Parallel Feature Extraction}{252}{subsection.8.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces The Inception module visualized, with the first occurrence in the network highlighted.}}{253}{figure.caption.482}\protected@file@percent }
\newlabel{fig:chapter8_inception_module}{{8.8}{253}{The Inception module visualized, with the first occurrence in the network highlighted}{figure.caption.482}{}}
\@writefile{toc}{\contentsline {subsubsection}{Why Does the Inception Module Improve Gradient Flow?}{253}{section*.483}\protected@file@percent }
\BKM@entry{id=330,dest={73756273656374696F6E2E382E342E33},srcline={361}}{5C3337365C3337375C303030475C3030306C5C3030306F5C303030625C303030615C3030306C5C3030305C3034305C303030415C303030765C303030655C303030725C303030615C303030675C303030655C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C303030675C3030305C3034305C3030305C3035305C303030475C303030415C303030505C3030305C303531}
\@writefile{toc}{\contentsline {paragraph}{Structure of the Inception Module}{254}{section*.484}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.3}Global Average Pooling (GAP)}{254}{subsection.8.4.3}\protected@file@percent }
\BKM@entry{id=331,dest={73756273656374696F6E2E382E342E34},srcline={378}}{5C3337365C3337375C303030415C303030755C303030785C303030695C3030306C5C303030695C303030615C303030725C303030795C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030655C303030725C303030735C3030303A5C3030305C3034305C303030415C3030305C3034305C303030575C3030306F5C303030725C3030306B5C303030615C303030725C3030306F5C303030755C3030306E5C303030645C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030565C303030615C3030306E5C303030695C303030735C303030685C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {8.9}{\ignorespaces GoogLeNet replaces fully connected layers with Global Average Pooling (GAP), drastically reducing parameters and FLOPs.}}{255}{figure.caption.485}\protected@file@percent }
\newlabel{fig:chapter8_googlenet_gap}{{8.9}{255}{GoogLeNet replaces fully connected layers with Global Average Pooling (GAP), drastically reducing parameters and FLOPs}{figure.caption.485}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.4}Auxiliary Classifiers: A Workaround for Vanishing Gradients}{255}{subsection.8.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Were Auxiliary Classifiers Needed?}{255}{section*.486}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{How Do They Help?}{255}{section*.487}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Auxiliary Classifier Design}{255}{section*.488}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.10}{\ignorespaces Auxiliary classifiers in GoogLeNet, placed at intermediate layers to aid gradient flow.}}{256}{figure.caption.489}\protected@file@percent }
\newlabel{fig:chapter8_googlenet_auxiliary}{{8.10}{256}{Auxiliary classifiers in GoogLeNet, placed at intermediate layers to aid gradient flow}{figure.caption.489}{}}
\@writefile{toc}{\contentsline {paragraph}{Gradient Flow and Regularization}{256}{section*.490}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Relevance Today}{256}{section*.491}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{256}{section*.492}\protected@file@percent }
\BKM@entry{id=332,dest={73656374696F6E2E382E35},srcline={433}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030525C303030695C303030735C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C303030655C303030735C303030695C303030645C303030755C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030525C303030655C303030735C3030304E5C303030655C303030745C303030735C3030305C303531}
\BKM@entry{id=333,dest={73756273656374696F6E2E382E352E31},srcline={435}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\abx@aux@cite{0}{he2016_resnet}
\abx@aux@segm{0}{0}{he2016_resnet}
\BKM@entry{id=334,dest={73756273656374696F6E2E382E352E32},srcline={448}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C3030304E5C303030655C303030655C303030645C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030525C303030655C303030735C303030695C303030645C303030755C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}The Rise of Residual Networks (ResNets)}{257}{section.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.1}Challenges in Training Deep Neural Networks}{257}{subsection.8.5.1}\protected@file@percent }
\abx@aux@backref{153}{he2016_resnet}{0}{257}{257}
\@writefile{lof}{\contentsline {figure}{\numberline {8.11}{\ignorespaces ResNets in 2015 compared to previous top-performing models in the ImageNet classification challenge. The error rate dropped significantly ( $\approx 0.5$ error of previous year) while the number of layers increased (x $7$).}}{257}{figure.caption.493}\protected@file@percent }
\newlabel{fig:chapter8_resnet_performance}{{8.11}{257}{ResNets in 2015 compared to previous top-performing models in the ImageNet classification challenge. The error rate dropped significantly ( $\approx 0.5$ error of previous year) while the number of layers increased (x $7$)}{figure.caption.493}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.2}The Need for Residual Connections}{257}{subsection.8.5.2}\protected@file@percent }
\BKM@entry{id=335,dest={73756273656374696F6E2E382E352E33},srcline={463}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030695C3030306E5C303030675C3030305C3034305C303030525C303030655C303030735C303030695C303030645C303030755C303030615C3030306C5C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {8.12}{\ignorespaces A comparison of a 56-layer network and a 20-layer network. The 20-layer model performs better on the test set, while the 56-layer model underfits on the training set, indicating optimization difficulties.}}{258}{figure.caption.494}\protected@file@percent }
\newlabel{fig:chapter8_deeper_networks_underfit}{{8.12}{258}{A comparison of a 56-layer network and a 20-layer network. The 20-layer model performs better on the test set, while the 56-layer model underfits on the training set, indicating optimization difficulties}{figure.caption.494}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.3}Introducing Residual Blocks}{258}{subsection.8.5.3}\protected@file@percent }
\newlabel{sec:residual_blocks}{{8.5.3}{258}{Introducing Residual Blocks}{subsection.8.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.13}{\ignorespaces A comparison between a plain block (left) and a residual block (right). The shortcut connection enables direct gradient flow and allows layers to learn an identity mapping if needed.}}{258}{figure.caption.495}\protected@file@percent }
\newlabel{fig:chapter8_residual_block}{{8.13}{258}{A comparison between a plain block (left) and a residual block (right). The shortcut connection enables direct gradient flow and allows layers to learn an identity mapping if needed}{figure.caption.495}{}}
\BKM@entry{id=336,dest={73756273656374696F6E2E382E352E34},srcline={489}}{5C3337365C3337375C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030615C3030306C5C3030305C3034305C303030445C303030655C303030735C303030695C303030675C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030745C30303073}
\BKM@entry{id=337,dest={73756273656374696F6E2E382E352E35},srcline={506}}{5C3337365C3337375C303030425C3030306F5C303030745C303030745C3030306C5C303030655C3030306E5C303030655C303030635C3030306B5C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B5C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030445C303030655C303030655C303030705C303030655C303030725C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Intuition Behind Residual Connections}{259}{section*.496}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.4}Architectural Design of ResNets}{259}{subsection.8.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.14}{\ignorespaces ResNet structure: A stack of residual blocks, where each block consists of two 3x3 convolutional layers with a shortcut connection.}}{259}{figure.caption.497}\protected@file@percent }
\newlabel{fig:chapter8_resnet_structure}{{8.14}{259}{ResNet structure: A stack of residual blocks, where each block consists of two 3x3 convolutional layers with a shortcut connection}{figure.caption.497}{}}
\BKM@entry{id=338,dest={73756273656374696F6E2E382E352E36},srcline={532}}{5C3337365C3337375C303030525C303030655C303030735C3030304E5C303030655C303030745C3030305C3034305C303030575C303030695C3030306E5C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030745C303030725C303030655C303030615C3030306B5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030745C303030695C3030306E5C303030755C303030655C303030645C3030305C3034305C303030495C3030306E5C303030665C3030306C5C303030755C303030655C3030306E5C303030635C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.5}Bottleneck Blocks for Deeper Networks}{260}{subsection.8.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.15}{\ignorespaces Bottleneck residual block: Using 1x1 convolutions before and after the main 3x3 convolution reduces computational costs while increasing depth.}}{260}{figure.caption.498}\protected@file@percent }
\newlabel{fig:chapter8_bottleneck_block}{{8.15}{260}{Bottleneck residual block: Using 1x1 convolutions before and after the main 3x3 convolution reduces computational costs while increasing depth}{figure.caption.498}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.16}{\ignorespaces Switching to bottleneck blocks allowed a smooth transition from ResNet-34 to deeper models like ResNet-50, ResNet-101, and ResNet-152, while improving efficiency.}}{260}{figure.caption.499}\protected@file@percent }
\newlabel{fig:chapter8_resnet_deeper_models}{{8.16}{260}{Switching to bottleneck blocks allowed a smooth transition from ResNet-34 to deeper models like ResNet-50, ResNet-101, and ResNet-152, while improving efficiency}{figure.caption.499}{}}
\abx@aux@cite{0}{lin2014microsoft}
\abx@aux@segm{0}{0}{lin2014microsoft}
\BKM@entry{id=339,dest={73756273656374696F6E2E382E352E37},srcline={542}}{5C3337365C3337375C303030465C303030755C303030725C303030745C303030685C303030655C303030725C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C3030306D5C303030655C3030306E5C303030745C303030735C3030303A5C3030305C3034305C303030505C303030725C303030655C3030302D5C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B5C30303073}
\abx@aux@cite{0}{he2016identity}
\abx@aux@segm{0}{0}{he2016identity}
\BKM@entry{id=340,dest={73756273656374696F6E2E382E352E38},srcline={553}}{5C3337365C3337375C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030455C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C30303074}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.6}ResNet Winning Streak and Continued Influence}{261}{subsection.8.5.6}\protected@file@percent }
\abx@aux@backref{154}{lin2014microsoft}{0}{261}{261}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.7}Further Improvements: Pre-Activation Blocks}{261}{subsection.8.5.7}\protected@file@percent }
\abx@aux@backref{155}{he2016identity}{0}{261}{261}
\@writefile{lof}{\contentsline {figure}{\numberline {8.17}{\ignorespaces Pre-activation residual block, which improves accuracy by reordering the batch normalization and activation functions.}}{261}{figure.caption.500}\protected@file@percent }
\newlabel{fig:chapter8_pre_activation_resnet}{{8.17}{261}{Pre-activation residual block, which improves accuracy by reordering the batch normalization and activation functions}{figure.caption.500}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.8}Architectural Comparisons and Evolution Beyond ResNet}{262}{subsection.8.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The 2016 ImageNet Challenge: Lack of Novelty}{262}{section*.501}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Comparing Model Complexity and Efficiency}{262}{section*.502}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.18}{\ignorespaces Comparison of ResNets with other architectures such as VGG, GoogLeNet, Inception, and others in terms of accuracy, model complexity, and computational cost.}}{262}{figure.caption.503}\protected@file@percent }
\newlabel{fig:chapter8_architecture_comparison}{{8.18}{262}{Comparison of ResNets with other architectures such as VGG, GoogLeNet, Inception, and others in terms of accuracy, model complexity, and computational cost}{figure.caption.503}{}}
\@writefile{toc}{\contentsline {subsubsection}{Beyond ResNets: Refinements and Lightweight Models}{263}{section*.504}\protected@file@percent }
\BKM@entry{id=341,dest={636861707465722E39},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030395C3030303A5C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C30303049}
\BKM@entry{id=342,dest={73656374696F6E2E392E31},srcline={10}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=343,dest={73756273656374696F6E2E392E312E31},srcline={15}}{5C3337365C3337375C303030435C303030615C303030745C303030655C303030675C3030306F5C303030725C303030695C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030505C303030725C303030615C303030635C303030745C303030695C303030635C303030615C3030306C5C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030755C303030625C3030306A5C303030655C303030635C303030745C30303073}
\BKM@entry{id=344,dest={73656374696F6E2E392E32},srcline={45}}{5C3337365C3337375C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Lecture 9: Training Neural Networks I}{264}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@8}}
\ttl@writefile{ptc}{\ttl@starttoc{default@9}}
\pgfsyspdfmark {pgfid23}{0}{52099153}
\pgfsyspdfmark {pgfid22}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Introduction to Training Neural Networks}{264}{section.9.1}\protected@file@percent }
\newlabel{sec:chapter9_intro}{{9.1}{264}{Introduction to Training Neural Networks}{section.9.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Categories of Practical Training Subjects}{264}{subsection.9.1.1}\protected@file@percent }
\newlabel{subsec:chapter9_training_categories}{{9.1.1}{264}{Categories of Practical Training Subjects}{subsection.9.1.1}{}}
\BKM@entry{id=345,dest={73756273656374696F6E2E392E322E31},srcline={50}}{5C3337365C3337375C303030535C303030695C303030675C3030306D5C3030306F5C303030695C303030645C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Activation Functions}{265}{section.9.2}\protected@file@percent }
\newlabel{sec:chapter9_activation_functions}{{9.2}{265}{Activation Functions}{section.9.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Sigmoid Activation Function}{265}{subsection.9.2.1}\protected@file@percent }
\newlabel{subsec:chapter9_sigmoid}{{9.2.1}{265}{Sigmoid Activation Function}{subsection.9.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Issues with the Sigmoid Function}{265}{section*.505}\protected@file@percent }
\newlabel{subsubsec:chapter9_sigmoid_issues}{{9.2.1}{265}{Issues with the Sigmoid Function}{section*.505}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Sigmoid function visualization, highlighting gradient behavior at \( x = -10, 0, 10 \). Gradients are near zero at extreme values, causing vanishing gradients.}}{265}{figure.caption.506}\protected@file@percent }
\newlabel{fig:chapter9_sigmoid_gradients}{{9.1}{265}{Sigmoid function visualization, highlighting gradient behavior at \( x = -10, 0, 10 \). Gradients are near zero at extreme values, causing vanishing gradients}{figure.caption.506}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces Gradient updates when using sigmoid activation: all gradients with respect to the weights have the same sign, leading to inefficient learning dynamics and potential oscillations.}}{266}{figure.caption.507}\protected@file@percent }
\newlabel{fig:chapter9_sigmoid_grad_dynamics}{{9.2}{266}{Gradient updates when using sigmoid activation: all gradients with respect to the weights have the same sign, leading to inefficient learning dynamics and potential oscillations}{figure.caption.507}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Tanh Activation Function}{267}{section*.508}\protected@file@percent }
\newlabel{subsubsec:chapter9_tanh}{{9.2.1}{267}{The Tanh Activation Function}{section*.508}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces The \(\tanh \) activation function compared to sigmoid. While \(\tanh \) is zero-centered, it still suffers from vanishing gradients in saturation regions.}}{267}{figure.caption.509}\protected@file@percent }
\newlabel{fig:chapter9_tanh}{{9.3}{267}{The \(\tanh \) activation function compared to sigmoid. While \(\tanh \) is zero-centered, it still suffers from vanishing gradients in saturation regions}{figure.caption.509}{}}
\BKM@entry{id=346,dest={73756273656374696F6E2E392E322E32},srcline={163}}{5C3337365C3337375C303030525C303030655C303030635C303030745C303030695C303030665C303030695C303030655C303030645C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030555C3030306E5C303030695C303030745C303030735C3030305C3034305C3030305C3035305C303030525C303030655C3030304C5C303030555C3030305C3035315C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030495C303030745C303030735C3030305C3034305C303030565C303030615C303030725C303030695C303030615C3030306E5C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Rectified Linear Units (ReLU) and Its Variants}{268}{subsection.9.2.2}\protected@file@percent }
\newlabel{sec:chapter9_relu}{{9.2.2}{268}{Rectified Linear Units (ReLU) and Its Variants}{subsection.9.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Issues with ReLU}{268}{section*.510}\protected@file@percent }
\newlabel{subsubsec:chapter9_relu_issues}{{9.2.2}{268}{Issues with ReLU}{section*.510}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces ReLU activation function and its failure cases. When inputs are negative, ReLU neurons become inactive, leading to dead ReLUs.}}{269}{figure.caption.511}\protected@file@percent }
\newlabel{fig:chapter9_dead_relu}{{9.4}{269}{ReLU activation function and its failure cases. When inputs are negative, ReLU neurons become inactive, leading to dead ReLUs}{figure.caption.511}{}}
\@writefile{toc}{\contentsline {subsubsection}{Leaky ReLU and Parametric ReLU (PReLU)}{269}{section*.512}\protected@file@percent }
\newlabel{subsubsec:chapter9_leaky_prelu}{{9.2.2}{269}{Leaky ReLU and Parametric ReLU (PReLU)}{section*.512}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces Parametric ReLU (PReLU) and Leaky ReLU. PReLU generalizes Leaky ReLU by making \(\alpha \) a learnable parameter.}}{269}{figure.caption.513}\protected@file@percent }
\newlabel{fig:chapter9_prelu}{{9.5}{269}{Parametric ReLU (PReLU) and Leaky ReLU. PReLU generalizes Leaky ReLU by making \(\alpha \) a learnable parameter}{figure.caption.513}{}}
\abx@aux@cite{0}{he2015_delving}
\abx@aux@segm{0}{0}{he2015_delving}
\abx@aux@cite{0}{clevert2015_fast}
\abx@aux@segm{0}{0}{clevert2015_fast}
\abx@aux@backref{156}{he2015_delving}{0}{270}{270}
\@writefile{toc}{\contentsline {subsubsection}{Exponential Linear Unit (ELU)}{270}{section*.514}\protected@file@percent }
\newlabel{subsubsec:chapter9_elu}{{9.2.2}{270}{Exponential Linear Unit (ELU)}{section*.514}{}}
\abx@aux@backref{157}{clevert2015_fast}{0}{270}{270}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces ELU activation function. Unlike ReLU, ELU allows small negative values for negative inputs, which improves learning stability.}}{270}{figure.caption.515}\protected@file@percent }
\newlabel{fig:chapter9_elu}{{9.6}{270}{ELU activation function. Unlike ReLU, ELU allows small negative values for negative inputs, which improves learning stability}{figure.caption.515}{}}
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\@writefile{toc}{\contentsline {subsubsection}{Scaled Exponential Linear Unit (SELU)}{271}{section*.516}\protected@file@percent }
\newlabel{subsubsec:chapter9_selu}{{9.2.2}{271}{Scaled Exponential Linear Unit (SELU)}{section*.516}{}}
\abx@aux@backref{158}{klambauer2017_selu}{0}{271}{271}
\@writefile{toc}{\contentsline {paragraph}{Definition and Self-Normalization Properties}{271}{section*.517}\protected@file@percent }
\abx@aux@backref{159}{klambauer2017_selu}{0}{271}{271}
\@writefile{toc}{\contentsline {paragraph}{Derivation of \(\alpha \) and \(\lambda \)}{271}{section*.518}\protected@file@percent }
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\abx@aux@cite{0}{klambauer2017_selu}
\abx@aux@segm{0}{0}{klambauer2017_selu}
\abx@aux@backref{160}{klambauer2017_selu}{0}{272}{272}
\@writefile{toc}{\contentsline {paragraph}{Weight Initialization and Network Architecture Considerations}{272}{section*.519}\protected@file@percent }
\abx@aux@backref{161}{klambauer2017_selu}{0}{272}{272}
\abx@aux@backref{162}{klambauer2017_selu}{0}{272}{272}
\abx@aux@backref{163}{klambauer2017_selu}{0}{272}{272}
\@writefile{toc}{\contentsline {paragraph}{Practical Considerations and Limitations}{272}{section*.520}\protected@file@percent }
\abx@aux@backref{164}{klambauer2017_selu}{0}{272}{272}
\abx@aux@cite{0}{hendrycks2016_gelu}
\abx@aux@segm{0}{0}{hendrycks2016_gelu}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces SELU activation function. Unlike ELU, SELU has predefined $\alpha , \lambda $ values that ensure self-normalizing properties under certain conditions.}}{273}{figure.caption.521}\protected@file@percent }
\newlabel{fig:chapter9_selu}{{9.7}{273}{SELU activation function. Unlike ELU, SELU has predefined $\alpha , \lambda $ values that ensure self-normalizing properties under certain conditions}{figure.caption.521}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gaussian Error Linear Unit (GELU)}{273}{section*.522}\protected@file@percent }
\newlabel{subsubsec:chapter9_gelu}{{9.2.2}{273}{Gaussian Error Linear Unit (GELU)}{section*.522}{}}
\abx@aux@backref{165}{hendrycks2016_gelu}{0}{273}{273}
\@writefile{toc}{\contentsline {paragraph}{Definition}{273}{section*.523}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces Visualization of GELU activation, highlighting its smoother transition compared to ReLU and its probabilistic activation mechanism.}}{274}{figure.caption.524}\protected@file@percent }
\newlabel{fig:chapter9_gelu}{{9.8}{274}{Visualization of GELU activation, highlighting its smoother transition compared to ReLU and its probabilistic activation mechanism}{figure.caption.524}{}}
\@writefile{toc}{\contentsline {paragraph}{Advantages of GELU}{274}{section*.525}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Comparisons with ReLU and ELU}{274}{section*.526}\protected@file@percent }
\BKM@entry{id=347,dest={73656374696F6E2A2E353238},srcline={390}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030395C3030302E5C303030325C3030302E5C303030335C3030303A5C3030305C3034305C303030535C303030775C303030695C303030735C303030685C3030303A5C3030305C3034305C303030415C3030305C3034305C303030535C303030655C3030306C5C303030665C3030302D5C303030475C303030615C303030745C303030655C303030645C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{ramachandran2017_swish}
\abx@aux@segm{0}{0}{ramachandran2017_swish}
\@writefile{toc}{\contentsline {paragraph}{Computational Considerations}{275}{section*.527}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 9.2.3: Swish: A Self-Gated Activation Function}{275}{section*.528}\protected@file@percent }
\newlabel{enr:chapter9_swish}{{9.2.3}{275}{\color {ocre}Enrichment \thesubsection : Swish: A Self-Gated Activation Function}{section*.528}{}}
\abx@aux@backref{166}{ramachandran2017_swish}{0}{275}{275}
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Visualization of the Swish activation function for different values of \(\beta \). When \(\beta =0\), the sigmoid component is constant at 0.5, making \(f(x)=x\cdot 0.5\) a linear function. For high values of \(\beta \) (e.g., \(\beta =10\)), the sigmoid approximates a binary step function (yielding near 0 for \(x<0\) and near 1 for \(x>0\)), so \(f(x)\) behaves like ReLU. With the standard choice \(\beta =1\), Swish smoothly interpolates between these two extremes, balancing linearity and nonlinearity for improved gradient flow and model performance.}}{275}{figure.caption.529}\protected@file@percent }
\newlabel{fig:chapter9_swish}{{9.9}{275}{Visualization of the Swish activation function for different values of \(\beta \). When \(\beta =0\), the sigmoid component is constant at 0.5, making \(f(x)=x\cdot 0.5\) a linear function. For high values of \(\beta \) (e.g., \(\beta =10\)), the sigmoid approximates a binary step function (yielding near 0 for \(x<0\) and near 1 for \(x>0\)), so \(f(x)\) behaves like ReLU. With the standard choice \(\beta =1\), Swish smoothly interpolates between these two extremes, balancing linearity and nonlinearity for improved gradient flow and model performance}{figure.caption.529}{}}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\@writefile{toc}{\contentsline {subsubsection}{Advantages of Swish}{276}{section*.530}\protected@file@percent }
\newlabel{subsec:chapter9_swish_advantages}{{9.2.3}{276}{Advantages of Swish}{section*.530}{}}
\abx@aux@backref{167}{tan2019_efficientnet}{0}{276}{276}
\@writefile{toc}{\contentsline {subsubsection}{Disadvantages of Swish}{276}{section*.531}\protected@file@percent }
\newlabel{subsec:chapter9_swish_disadvantages}{{9.2.3}{276}{Disadvantages of Swish}{section*.531}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison to Other Top-Tier Activations}{276}{section*.532}\protected@file@percent }
\newlabel{subsec:chapter9_swish_comparison}{{9.2.3}{276}{Comparison to Other Top-Tier Activations}{section*.532}{}}
\BKM@entry{id=348,dest={73756273656374696F6E2E392E322E34},srcline={454}}{5C3337365C3337375C303030435C303030685C3030306F5C3030306F5C303030735C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030525C303030695C303030675C303030685C303030745C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{ramachandran2017_searching}
\abx@aux@segm{0}{0}{ramachandran2017_searching}
\abx@aux@cite{0}{ramachandran2017_searching}
\abx@aux@segm{0}{0}{ramachandran2017_searching}
\@writefile{toc}{\contentsline {subsubsection}{Conclusion}{277}{section*.533}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.4}Choosing the Right Activation Function}{277}{subsection.9.2.4}\protected@file@percent }
\newlabel{subsec:chapter9_activation_choice}{{9.2.4}{277}{Choosing the Right Activation Function}{subsection.9.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Performance comparison of different activation functions. Most modern activations, such as Swish, GELU, ELU, and SELU, perform similarly to ReLU in practice \blx@tocontentsinit {0}\cite {ramachandran2017_searching}.}}{277}{figure.caption.534}\protected@file@percent }
\abx@aux@backref{169}{ramachandran2017_searching}{0}{277}{277}
\newlabel{fig:chapter9_activation_comparison}{{9.10}{277}{Performance comparison of different activation functions. Most modern activations, such as Swish, GELU, ELU, and SELU, perform similarly to ReLU in practice \cite {ramachandran2017_searching}}{figure.caption.534}{}}
\@writefile{toc}{\contentsline {subsubsection}{General Guidelines for Choosing an Activation Function}{277}{section*.535}\protected@file@percent }
\newlabel{subsubsec:chapter9_activation_guidelines}{{9.2.4}{277}{General Guidelines for Choosing an Activation Function}{section*.535}{}}
\BKM@entry{id=349,dest={73656374696F6E2E392E33},srcline={478}}{5C3337365C3337375C303030445C303030615C303030745C303030615C3030305C3034305C303030505C303030725C303030655C3030302D5C303030505C303030725C3030306F5C303030635C303030655C303030735C303030735C303030695C3030306E5C30303067}
\BKM@entry{id=350,dest={73756273656374696F6E2E392E332E31},srcline={483}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030505C303030725C303030655C3030302D5C303030505C303030725C3030306F5C303030635C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C3030304D5C303030615C303030745C303030745C303030655C303030725C30303073}
\BKM@entry{id=351,dest={73756273656374696F6E2E392E332E32},srcline={502}}{5C3337365C3337375C303030415C303030765C3030306F5C303030695C303030645C303030695C3030306E5C303030675C3030305C3034305C303030505C3030306F5C3030306F5C303030725C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030445C303030795C3030306E5C303030615C3030306D5C303030695C303030635C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Data Pre-Processing}{278}{section.9.3}\protected@file@percent }
\newlabel{sec:chapter9_data_preprocessing}{{9.3}{278}{Data Pre-Processing}{section.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.1}Why Pre-Processing Matters}{278}{subsection.9.3.1}\protected@file@percent }
\newlabel{subsec:chapter9_why_preprocessing}{{9.3.1}{278}{Why Pre-Processing Matters}{subsection.9.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.11}{\ignorespaces Visualization of data pre-processing. The red cloud represents raw input data, the green cloud shows the effect of mean subtraction, and the blue cloud demonstrates the effect of feature rescaling.}}{278}{figure.caption.536}\protected@file@percent }
\newlabel{fig:chapter9_data_preprocessing}{{9.11}{278}{Visualization of data pre-processing. The red cloud represents raw input data, the green cloud shows the effect of mean subtraction, and the blue cloud demonstrates the effect of feature rescaling}{figure.caption.536}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.2}Avoiding Poor Training Dynamics}{278}{subsection.9.3.2}\protected@file@percent }
\newlabel{subsec:chapter9_avoid_poor_dynamics}{{9.3.2}{278}{Avoiding Poor Training Dynamics}{subsection.9.3.2}{}}
\BKM@entry{id=352,dest={73756273656374696F6E2E392E332E33},srcline={514}}{5C3337365C3337375C303030435C3030306F5C3030306D5C3030306D5C3030306F5C3030306E5C3030305C3034305C303030505C303030725C303030655C3030302D5C303030505C303030725C3030306F5C303030635C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C303030545C303030655C303030635C303030685C3030306E5C303030695C303030715C303030755C303030655C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {9.12}{\ignorespaces Unnormalized data can lead to unstable training dynamics: inefficient gradient updates.}}{279}{figure.caption.537}\protected@file@percent }
\newlabel{fig:chapter9_inefficient_gradients}{{9.12}{279}{Unnormalized data can lead to unstable training dynamics: inefficient gradient updates}{figure.caption.537}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.3}Common Pre-Processing Techniques}{279}{subsection.9.3.3}\protected@file@percent }
\newlabel{subsec:chapter9_common_preprocessing}{{9.3.3}{279}{Common Pre-Processing Techniques}{subsection.9.3.3}{}}
\BKM@entry{id=353,dest={73756273656374696F6E2E392E332E34},srcline={534}}{5C3337365C3337375C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030525C3030306F5C303030625C303030755C303030735C303030745C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=354,dest={73756273656374696F6E2E392E332E35},srcline={557}}{5C3337365C3337375C3030304D5C303030615C303030695C3030306E5C303030745C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030735C303030695C303030735C303030745C303030655C3030306E5C303030635C303030795C3030305C3034305C303030445C303030755C303030725C303030695C3030306E5C303030675C3030305C3034305C303030495C3030306E5C303030665C303030655C303030725C303030655C3030306E5C303030635C30303065}
\BKM@entry{id=355,dest={73756273656374696F6E2E392E332E36},srcline={562}}{5C3337365C3337375C303030505C303030725C303030655C3030302D5C303030505C303030725C3030306F5C303030635C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C303030695C3030306E5C3030305C3034305C303030575C303030655C3030306C5C3030306C5C3030302D5C3030304B5C3030306E5C3030306F5C303030775C3030306E5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C30303073}
\BKM@entry{id=356,dest={73656374696F6E2E392E34},srcline={573}}{5C3337365C3337375C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.4}Normalization for Robust Optimization}{280}{subsection.9.3.4}\protected@file@percent }
\newlabel{subsec:chapter9_normalization_impact}{{9.3.4}{280}{Normalization for Robust Optimization}{subsection.9.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.13}{\ignorespaces Visualizing the impact of normalization on optimization.}}{280}{figure.caption.538}\protected@file@percent }
\newlabel{fig:chapter9_optimization_stability}{{9.13}{280}{Visualizing the impact of normalization on optimization}{figure.caption.538}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.5}Maintaining Consistency During Inference}{280}{subsection.9.3.5}\protected@file@percent }
\newlabel{subsec:chapter9_inference_consistency}{{9.3.5}{280}{Maintaining Consistency During Inference}{subsection.9.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.6}Pre-Processing in Well-Known Architectures}{280}{subsection.9.3.6}\protected@file@percent }
\newlabel{subsec:chapter9_preprocessing_architectures}{{9.3.6}{280}{Pre-Processing in Well-Known Architectures}{subsection.9.3.6}{}}
\BKM@entry{id=357,dest={73756273656374696F6E2E392E342E31},srcline={578}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030735C303030745C303030615C3030306E5C303030745C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Weight Initialization}{281}{section.9.4}\protected@file@percent }
\newlabel{sec:weight_initialization}{{9.4}{281}{Weight Initialization}{section.9.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Constant Initialization}{281}{subsection.9.4.1}\protected@file@percent }
\newlabel{subsec:constant_init}{{9.4.1}{281}{Constant Initialization}{subsection.9.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Zero Initialization}{281}{section*.539}\protected@file@percent }
\newlabel{subsubsec:zero_init}{{9.4.1}{281}{Zero Initialization}{section*.539}{}}
\@writefile{toc}{\contentsline {subsubsection}{Nonzero Constant Initialization}{282}{section*.540}\protected@file@percent }
\newlabel{subsubsec:constant_nonzero_init}{{9.4.1}{282}{Nonzero Constant Initialization}{section*.540}{}}
\@writefile{toc}{\contentsline {paragraph}{Forward Pass Analysis}{282}{section*.541}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Backpropagation and Gradient Symmetry}{282}{section*.542}\protected@file@percent }
\BKM@entry{id=358,dest={73756273656374696F6E2E392E342E32},srcline={692}}{5C3337365C3337375C303030425C303030725C303030655C303030615C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030795C3030306D5C3030306D5C303030655C303030745C303030725C303030795C3030303A5C3030305C3034305C303030525C303030615C3030306E5C303030645C3030306F5C3030306D5C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=359,dest={73756273656374696F6E2E392E342E33},srcline={713}}{5C3337365C3337375C303030565C303030615C303030725C303030695C303030615C3030306E5C303030635C303030655C3030302D5C303030425C303030615C303030735C303030655C303030645C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030455C3030306E5C303030735C303030755C303030725C303030695C3030306E5C303030675C3030305C3034305C303030535C303030745C303030615C303030625C3030306C5C303030655C3030305C3034305C303030495C3030306E5C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C3030306C5C3030306F5C30303077}
\@writefile{toc}{\contentsline {paragraph}{Implications and Conclusion}{283}{section*.543}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.2}Breaking Symmetry: Random Initialization}{283}{subsection.9.4.2}\protected@file@percent }
\newlabel{subsec:random_init}{{9.4.2}{283}{Breaking Symmetry: Random Initialization}{subsection.9.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.3}Variance-Based Initialization: Ensuring Stable Information Flow}{283}{subsection.9.4.3}\protected@file@percent }
\newlabel{subsec:variance_init}{{9.4.3}{283}{Variance-Based Initialization: Ensuring Stable Information Flow}{subsection.9.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Requirements for Stable Propagation}{284}{section*.544}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Forward Pass Analysis}{284}{section*.545}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Is This Important?}{284}{section*.546}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Does Forward Signal Variance Also Matter?}{284}{section*.547}\protected@file@percent }
\BKM@entry{id=360,dest={73756273656374696F6E2E392E342E34},srcline={783}}{5C3337365C3337375C303030585C303030615C303030765C303030695C303030655C303030725C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{glorot2010_understanding}
\abx@aux@segm{0}{0}{glorot2010_understanding}
\@writefile{toc}{\contentsline {paragraph}{Challenges in Achieving Stable Variance}{285}{section*.548}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.4}Xavier Initialization}{285}{subsection.9.4.4}\protected@file@percent }
\newlabel{sec:xavier_init}{{9.4.4}{285}{Xavier Initialization}{subsection.9.4.4}{}}
\abx@aux@backref{170}{glorot2010_understanding}{0}{285}{285}
\@writefile{toc}{\contentsline {subsubsection}{Motivation}{285}{section*.549}\protected@file@percent }
\newlabel{subsec:xavier_motivation}{{9.4.4}{285}{Motivation}{section*.549}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.14}{\ignorespaces Xavier initialization: activations are nicely scaled for all the layers.}}{286}{figure.caption.550}\protected@file@percent }
\newlabel{fig:chapter9_xavier_init}{{9.14}{286}{Xavier initialization: activations are nicely scaled for all the layers}{figure.caption.550}{}}
\@writefile{toc}{\contentsline {subsubsection}{Mathematical Formulation}{286}{section*.551}\protected@file@percent }
\newlabel{subsec:xavier_math}{{9.4.4}{286}{Mathematical Formulation}{section*.551}{}}
\@writefile{toc}{\contentsline {subsubsection}{Assumptions}{286}{section*.552}\protected@file@percent }
\newlabel{subsec:xavier_assumptions}{{9.4.4}{286}{Assumptions}{section*.552}{}}
\abx@aux@cite{0}{hlav2023_xavier}
\abx@aux@segm{0}{0}{hlav2023_xavier}
\@writefile{toc}{\contentsline {subsubsection}{Derivation of Xavier Initialization}{287}{section*.553}\protected@file@percent }
\newlabel{subsec:xavier_derivation}{{9.4.4}{287}{Derivation of Xavier Initialization}{section*.553}{}}
\abx@aux@backref{171}{hlav2023_xavier}{0}{287}{287}
\@writefile{toc}{\contentsline {paragraph}{Forward Pass: Maintaining Activation Variance}{287}{section*.554}\protected@file@percent }
\newlabel{subsubsec:xavier_forward}{{9.4.4}{287}{Forward Pass: Maintaining Activation Variance}{section*.554}{}}
\@writefile{toc}{\contentsline {paragraph}{Backward Pass: Maintaining Gradient Variance}{287}{section*.555}\protected@file@percent }
\newlabel{subsubsec:xavier_backward}{{9.4.4}{287}{Backward Pass: Maintaining Gradient Variance}{section*.555}{}}
\@writefile{toc}{\contentsline {paragraph}{Balancing Forward and Backward Variance}{288}{section*.556}\protected@file@percent }
\newlabel{subsubsec:xavier_balancing}{{9.4.4}{288}{Balancing Forward and Backward Variance}{section*.556}{}}
\abx@aux@cite{0}{he2015_delving}
\abx@aux@segm{0}{0}{he2015_delving}
\@writefile{toc}{\contentsline {subsubsection}{Final Xavier Initialization Formulation}{289}{section*.557}\protected@file@percent }
\newlabel{subsubsec:xavier_final}{{9.4.4}{289}{Final Xavier Initialization Formulation}{section*.557}{}}
\@writefile{toc}{\contentsline {subsubsection}{Limitations of Xavier Initialization}{289}{section*.558}\protected@file@percent }
\newlabel{subsec:xavier_limitations}{{9.4.4}{289}{Limitations of Xavier Initialization}{section*.558}{}}
\abx@aux@backref{172}{he2015_delving}{0}{289}{289}
\BKM@entry{id=361,dest={73756273656374696F6E2E392E342E35},srcline={975}}{5C3337365C3337375C3030304B5C303030615C303030695C3030306D5C303030695C3030306E5C303030675C3030305C3034305C303030485C303030655C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{he2015_delving}
\abx@aux@segm{0}{0}{he2015_delving}
\abx@aux@cite{0}{hlav2023_kaiming}
\abx@aux@segm{0}{0}{hlav2023_kaiming}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.5}Kaiming He Initialization}{290}{subsection.9.4.5}\protected@file@percent }
\newlabel{subsec:kaiming_init}{{9.4.5}{290}{Kaiming He Initialization}{subsection.9.4.5}{}}
\abx@aux@backref{173}{he2015_delving}{0}{290}{290}
\abx@aux@backref{174}{hlav2023_kaiming}{0}{290}{290}
\@writefile{toc}{\contentsline {subsubsection}{Motivation}{290}{section*.559}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.15}{\ignorespaces Xavier initialization applied with ReLU: activations collapse to zero due to the mismatch between the initialization assumptions and the activation function properties. This prevents effective learning.}}{290}{figure.caption.560}\protected@file@percent }
\newlabel{fig:chapter9_xavier_relu_fail}{{9.15}{290}{Xavier initialization applied with ReLU: activations collapse to zero due to the mismatch between the initialization assumptions and the activation function properties. This prevents effective learning}{figure.caption.560}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.16}{\ignorespaces Kaiming initialization: activations are well-scaled across layers, preserving variance and enabling stable learning with ReLU.}}{291}{figure.caption.561}\protected@file@percent }
\newlabel{fig:chapter9_kaiming_init}{{9.16}{291}{Kaiming initialization: activations are well-scaled across layers, preserving variance and enabling stable learning with ReLU}{figure.caption.561}{}}
\@writefile{toc}{\contentsline {paragraph}{Mathematical Notation}{291}{section*.562}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Assumptions}{291}{section*.563}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Forward and Backward Pass Derivation}{292}{section*.564}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Forward Pass Analysis}{292}{section*.565}\protected@file@percent }
\abx@aux@cite{0}{he2015_delving}
\abx@aux@segm{0}{0}{he2015_delving}
\@writefile{toc}{\contentsline {paragraph}{Backward Pass Analysis}{293}{section*.566}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Final Kaiming Initialization Formulation}{293}{section*.567}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Implementation in Deep Learning Frameworks}{293}{section*.568}\protected@file@percent }
\abx@aux@cite{0}{zhang2019_fixup}
\abx@aux@segm{0}{0}{zhang2019_fixup}
\@writefile{toc}{\contentsline {subsubsection}{Initialization in Residual Networks (ResNets)}{294}{section*.569}\protected@file@percent }
\newlabel{subsubsec:resnet_init}{{9.4.5}{294}{Initialization in Residual Networks (ResNets)}{section*.569}{}}
\abx@aux@backref{175}{he2015_delving}{0}{294}{294}
\@writefile{toc}{\contentsline {paragraph}{Why Doesn't Kaiming Initialization Work for ResNets?}{294}{section*.570}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Fixup Initialization}{294}{section*.571}\protected@file@percent }
\abx@aux@backref{176}{zhang2019_fixup}{0}{294}{294}
\@writefile{lof}{\contentsline {figure}{\numberline {9.17}{\ignorespaces Fixup Initialization: The first convolution is initialized using Kaiming, while the second convolution is initialized to zero, ensuring stable variance across layers in ResNets.}}{294}{figure.caption.572}\protected@file@percent }
\newlabel{fig:chapter9_fixup_init}{{9.17}{294}{Fixup Initialization: The first convolution is initialized using Kaiming, while the second convolution is initialized to zero, ensuring stable variance across layers in ResNets}{figure.caption.572}{}}
\BKM@entry{id=362,dest={73756273656374696F6E2E392E342E36},srcline={1202}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030435C303030685C3030306F5C3030306F5C303030735C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030525C303030695C303030675C303030685C303030745C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030535C303030745C303030725C303030615C303030745C303030655C303030675C30303079}
\abx@aux@cite{0}{glorot2010_understanding}
\abx@aux@segm{0}{0}{glorot2010_understanding}
\abx@aux@cite{0}{he2015_delving}
\abx@aux@segm{0}{0}{he2015_delving}
\abx@aux@cite{0}{zhang2019_fixup}
\abx@aux@segm{0}{0}{zhang2019_fixup}
\abx@aux@cite{0}{huang2020_tfixup}
\abx@aux@segm{0}{0}{huang2020_tfixup}
\abx@aux@cite{0}{brock2021_highperformance}
\abx@aux@segm{0}{0}{brock2021_highperformance}
\BKM@entry{id=363,dest={73656374696F6E2E392E35},srcline={1233}}{5C3337365C3337375C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030655C303030635C303030685C3030306E5C303030695C303030715C303030755C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.6}Conclusion: Choosing the Right Initialization Strategy}{295}{subsection.9.4.6}\protected@file@percent }
\newlabel{subsec:initialization_conclusion}{{9.4.6}{295}{Conclusion: Choosing the Right Initialization Strategy}{subsection.9.4.6}{}}
\abx@aux@backref{177}{glorot2010_understanding}{0}{295}{295}
\abx@aux@backref{178}{he2015_delving}{0}{295}{295}
\abx@aux@backref{179}{zhang2019_fixup}{0}{295}{295}
\abx@aux@backref{180}{huang2020_tfixup}{0}{295}{295}
\@writefile{toc}{\contentsline {subsubsection}{Ongoing Research and Open Questions}{295}{section*.573}\protected@file@percent }
\abx@aux@backref{181}{brock2021_highperformance}{0}{295}{295}
\BKM@entry{id=364,dest={73756273656374696F6E2E392E352E31},srcline={1238}}{5C3337365C3337375C303030445C303030725C3030306F5C303030705C3030306F5C303030755C30303074}
\abx@aux@cite{0}{srivastava2014_dropout}
\abx@aux@segm{0}{0}{srivastava2014_dropout}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Regularization Techniques}{296}{section.9.5}\protected@file@percent }
\newlabel{sec:regularization}{{9.5}{296}{Regularization Techniques}{section.9.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Dropout}{296}{subsection.9.5.1}\protected@file@percent }
\newlabel{subsec:dropout}{{9.5.1}{296}{Dropout}{subsection.9.5.1}{}}
\abx@aux@backref{182}{srivastava2014_dropout}{0}{296}{296}
\@writefile{lof}{\contentsline {figure}{\numberline {9.18}{\ignorespaces Visualization of dropout: neurons are randomly dropped during training.}}{296}{figure.caption.574}\protected@file@percent }
\newlabel{fig:chapter9_dropout}{{9.18}{296}{Visualization of dropout: neurons are randomly dropped during training}{figure.caption.574}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.19}{\ignorespaces Python implementation of dropout in a few lines of code.}}{297}{figure.caption.575}\protected@file@percent }
\newlabel{fig:chapter9_dropout_code}{{9.19}{297}{Python implementation of dropout in a few lines of code}{figure.caption.575}{}}
\@writefile{toc}{\contentsline {subsubsection}{Why Does Dropout Work?}{297}{section*.576}\protected@file@percent }
\newlabel{subsubsec:dropout_interpretation}{{9.5.1}{297}{Why Does Dropout Work?}{section*.576}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.20}{\ignorespaces Dropout prevents co-adaptation by enforcing redundant feature representations.}}{297}{figure.caption.577}\protected@file@percent }
\newlabel{fig:chapter9_dropout_coadaptation}{{9.20}{297}{Dropout prevents co-adaptation by enforcing redundant feature representations}{figure.caption.577}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dropout at Test Time}{298}{section*.578}\protected@file@percent }
\newlabel{subsubsec:dropout_test}{{9.5.1}{298}{Dropout at Test Time}{section*.578}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.21}{\ignorespaces Mathematical formulation of dropout and the difficulty of marginalizing out the random variable.}}{299}{figure.caption.579}\protected@file@percent }
\newlabel{fig:chapter9_dropout_expectation}{{9.21}{299}{Mathematical formulation of dropout and the difficulty of marginalizing out the random variable}{figure.caption.579}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.22}{\ignorespaces Approximation of the expected activation for a single neuron, motivating test-time scaling.}}{299}{figure.caption.580}\protected@file@percent }
\newlabel{fig:chapter9_dropout_scaling}{{9.22}{299}{Approximation of the expected activation for a single neuron, motivating test-time scaling}{figure.caption.580}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.23}{\ignorespaces Test-time dropout implementation: scaling activations by the dropout probability.}}{300}{figure.caption.581}\protected@file@percent }
\newlabel{fig:chapter9_dropout_testtime}{{9.23}{300}{Test-time dropout implementation: scaling activations by the dropout probability}{figure.caption.581}{}}
\@writefile{toc}{\contentsline {subsubsection}{Inverted Dropout}{300}{section*.582}\protected@file@percent }
\newlabel{subsubsec:inverted_dropout}{{9.5.1}{300}{Inverted Dropout}{section*.582}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.24}{\ignorespaces Python implementation of inverted dropout, where scaling occurs during training.}}{300}{figure.caption.583}\protected@file@percent }
\newlabel{fig:chapter9_inverted_dropout}{{9.24}{300}{Python implementation of inverted dropout, where scaling occurs during training}{figure.caption.583}{}}
\BKM@entry{id=365,dest={73756273656374696F6E2E392E352E32},srcline={1370}}{5C3337365C3337375C3030304F5C303030745C303030685C303030655C303030725C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030655C303030635C303030685C3030306E5C303030695C303030715C303030755C303030655C30303073}
\@writefile{toc}{\contentsline {subsubsection}{Where is Dropout Used in CNNs?}{301}{section*.584}\protected@file@percent }
\newlabel{subsubsec:dropout_cnn_usage}{{9.5.1}{301}{Where is Dropout Used in CNNs?}{section*.584}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.25}{\ignorespaces Dropout usage in AlexNet and VGG16: applied to fully connected layers at the end of the architecture.}}{301}{figure.caption.585}\protected@file@percent }
\newlabel{fig:chapter9_dropout_cnn}{{9.25}{301}{Dropout usage in AlexNet and VGG16: applied to fully connected layers at the end of the architecture}{figure.caption.585}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}Other Regularization Techniques}{301}{subsection.9.5.2}\protected@file@percent }
\newlabel{subsec:other_regularization}{{9.5.2}{301}{Other Regularization Techniques}{subsection.9.5.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Augmentation as Implicit Regularization}{302}{section*.586}\protected@file@percent }
\newlabel{subsubsec:data_augmentation}{{9.5.2}{302}{Data Augmentation as Implicit Regularization}{section*.586}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.26}{\ignorespaces Data augmentation: random transformations applied before training.}}{302}{figure.caption.587}\protected@file@percent }
\newlabel{fig:chapter9_data_augmentation}{{9.26}{302}{Data augmentation: random transformations applied before training}{figure.caption.587}{}}
\abx@aux@cite{0}{wan2013_dropconnect}
\abx@aux@segm{0}{0}{wan2013_dropconnect}
\@writefile{lof}{\contentsline {figure}{\numberline {9.27}{\ignorespaces Test-time augmentation in ResNet: multiple fixed crops and scales are used to marginalize out randomness.}}{303}{figure.caption.588}\protected@file@percent }
\newlabel{fig:chapter9_test_time_augmentation}{{9.27}{303}{Test-time augmentation in ResNet: multiple fixed crops and scales are used to marginalize out randomness}{figure.caption.588}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.28}{\ignorespaces Color jittering as an example of augmentation used in AlexNet and ResNet.}}{303}{figure.caption.589}\protected@file@percent }
\newlabel{fig:chapter9_color_jitter}{{9.28}{303}{Color jittering as an example of augmentation used in AlexNet and ResNet}{figure.caption.589}{}}
\@writefile{toc}{\contentsline {subsubsection}{DropConnect}{304}{section*.590}\protected@file@percent }
\newlabel{subsubsec:dropconnect}{{9.5.2}{304}{DropConnect}{section*.590}{}}
\abx@aux@backref{183}{wan2013_dropconnect}{0}{304}{304}
\@writefile{lof}{\contentsline {figure}{\numberline {9.29}{\ignorespaces DropConnect: Instead of zeroing out neurons like in Dropout, DropConnect randomly removes weights.}}{304}{figure.caption.591}\protected@file@percent }
\newlabel{fig:chapter9_dropconnect}{{9.29}{304}{DropConnect: Instead of zeroing out neurons like in Dropout, DropConnect randomly removes weights}{figure.caption.591}{}}
\@writefile{toc}{\contentsline {paragraph}{Comparison Between Dropout and DropConnect}{304}{section*.592}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Effectiveness and Use Cases}{304}{section*.593}\protected@file@percent }
\abx@aux@cite{0}{graham2015_fractionalmaxpool}
\abx@aux@segm{0}{0}{graham2015_fractionalmaxpool}
\@writefile{toc}{\contentsline {paragraph}{Summary}{305}{section*.594}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Fractional Max Pooling}{305}{section*.595}\protected@file@percent }
\newlabel{subsubsec:fractional_max_pooling}{{9.5.2}{305}{Fractional Max Pooling}{section*.595}{}}
\abx@aux@backref{184}{graham2015_fractionalmaxpool}{0}{305}{305}
\@writefile{lof}{\contentsline {figure}{\numberline {9.30}{\ignorespaces Fractional Max Pooling: randomized pooling regions varying in size across forward passes.}}{305}{figure.caption.596}\protected@file@percent }
\newlabel{fig:chapter9_fractional_max_pooling}{{9.30}{305}{Fractional Max Pooling: randomized pooling regions varying in size across forward passes}{figure.caption.596}{}}
\abx@aux@cite{0}{huang2016_stochasticdepth}
\abx@aux@segm{0}{0}{huang2016_stochasticdepth}
\abx@aux@cite{0}{devries2017_cutout}
\abx@aux@segm{0}{0}{devries2017_cutout}
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Depth}{306}{section*.597}\protected@file@percent }
\newlabel{subsubsec:stochastic_depth}{{9.5.2}{306}{Stochastic Depth}{section*.597}{}}
\abx@aux@backref{185}{huang2016_stochasticdepth}{0}{306}{306}
\@writefile{lof}{\contentsline {figure}{\numberline {9.31}{\ignorespaces Stochastic Depth: at each forward pass, only a subset of layers is used. At test time, all layers are utilized.}}{306}{figure.caption.598}\protected@file@percent }
\newlabel{fig:chapter9_stochastic_depth}{{9.31}{306}{Stochastic Depth: at each forward pass, only a subset of layers is used. At test time, all layers are utilized}{figure.caption.598}{}}
\@writefile{toc}{\contentsline {subsubsection}{CutOut}{306}{section*.599}\protected@file@percent }
\newlabel{subsubsec:cutout}{{9.5.2}{306}{CutOut}{section*.599}{}}
\abx@aux@backref{186}{devries2017_cutout}{0}{306}{306}
\abx@aux@cite{0}{zhang2018_mixup}
\abx@aux@segm{0}{0}{zhang2018_mixup}
\@writefile{lof}{\contentsline {figure}{\numberline {9.32}{\ignorespaces CutOut: parts of the image are occluded to prevent over-reliance on specific features.}}{307}{figure.caption.600}\protected@file@percent }
\newlabel{fig:chapter9_cutout}{{9.32}{307}{CutOut: parts of the image are occluded to prevent over-reliance on specific features}{figure.caption.600}{}}
\@writefile{toc}{\contentsline {subsubsection}{MixUp}{307}{section*.601}\protected@file@percent }
\newlabel{subsubsec:mixup}{{9.5.2}{307}{MixUp}{section*.601}{}}
\abx@aux@backref{187}{zhang2018_mixup}{0}{307}{307}
\@writefile{lof}{\contentsline {figure}{\numberline {9.33}{\ignorespaces MixUp: blending two images and their labels to create intermediate samples.}}{307}{figure.caption.602}\protected@file@percent }
\newlabel{fig:chapter9_mixup}{{9.33}{307}{MixUp: blending two images and their labels to create intermediate samples}{figure.caption.602}{}}
\@writefile{toc}{\contentsline {subsubsection}{Summary and Regularization Guidelines}{308}{section*.603}\protected@file@percent }
\newlabel{subsubsec:regularization_guidelines}{{9.5.2}{308}{Summary and Regularization Guidelines}{section*.603}{}}
\BKM@entry{id=366,dest={636861707465722E3130},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030305C3030303A5C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C303030495C30303049}
\BKM@entry{id=367,dest={73656374696F6E2E31302E31},srcline={10}}{5C3337365C3337375C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C303030655C3030305C3034305C303030535C303030635C303030685C303030655C303030645C303030755C3030306C5C303030655C30303073}
\BKM@entry{id=368,dest={73756273656374696F6E2E31302E312E31},srcline={15}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030495C3030306D5C303030705C3030306F5C303030725C303030745C303030615C3030306E5C303030635C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C303030655C3030305C3034305C303030535C303030655C3030306C5C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Lecture 10: Training Neural Networks II}{309}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@9}}
\ttl@writefile{ptc}{\ttl@starttoc{default@10}}
\pgfsyspdfmark {pgfid25}{0}{52099153}
\pgfsyspdfmark {pgfid24}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Learning Rate Schedules}{309}{section.10.1}\protected@file@percent }
\newlabel{sec:learning_rate_schedules}{{10.1}{309}{Learning Rate Schedules}{section.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.1}The Importance of Learning Rate Selection}{309}{subsection.10.1.1}\protected@file@percent }
\newlabel{subsec:learning_rate_selection}{{10.1.1}{309}{The Importance of Learning Rate Selection}{subsection.10.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Effect of different learning rates on training. Yellow: too high, leading to divergence; Blue: too low, resulting in slow progress; Green: somewhat high, converging suboptimally; Red: well-chosen learning rate, ensuring efficient training.}}{309}{figure.caption.604}\protected@file@percent }
\newlabel{fig:chapter10_lr_selection}{{10.1}{309}{Effect of different learning rates on training. Yellow: too high, leading to divergence; Blue: too low, resulting in slow progress; Green: somewhat high, converging suboptimally; Red: well-chosen learning rate, ensuring efficient training}{figure.caption.604}{}}
\BKM@entry{id=369,dest={73756273656374696F6E2E31302E312E32},srcline={38}}{5C3337365C3337375C303030535C303030745C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C303030655C3030305C3034305C303030535C303030635C303030685C303030655C303030645C303030755C3030306C5C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.2}Step Learning Rate Schedule}{310}{subsection.10.1.2}\protected@file@percent }
\newlabel{subsec:step_lr}{{10.1.2}{310}{Step Learning Rate Schedule}{subsection.10.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Step Learning Rate Decay: The learning rate is reduced by a factor of $0.1$ at epochs 30, 60, and 90, indicated by the dashed vertical lines. The red curve represents the noisy per-iteration loss, highlighting the inherent variance in training. The light blue curve shows the Exponential Moving Average (EMA) of the loss, providing a smoother trajectory of the loss progression. The EMA helps visualize the overall trend despite the noise, demonstrating the impact of learning rate drops on loss reduction over time.}}{310}{figure.caption.605}\protected@file@percent }
\newlabel{fig:chapter10_step_lr}{{10.2}{310}{Step Learning Rate Decay: The learning rate is reduced by a factor of $0.1$ at epochs 30, 60, and 90, indicated by the dashed vertical lines. The red curve represents the noisy per-iteration loss, highlighting the inherent variance in training. The light blue curve shows the Exponential Moving Average (EMA) of the loss, providing a smoother trajectory of the loss progression. The EMA helps visualize the overall trend despite the noise, demonstrating the impact of learning rate drops on loss reduction over time}{figure.caption.605}{}}
\BKM@entry{id=370,dest={73756273656374696F6E2E31302E312E33},srcline={69}}{5C3337365C3337375C303030435C3030306F5C303030735C303030695C3030306E5C303030655C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C303030655C3030305C3034305C303030445C303030655C303030635C303030615C30303079}
\@writefile{toc}{\contentsline {subsubsection}{Practical Considerations}{311}{section*.606}\protected@file@percent }
\newlabel{subsec:step_lr_practical}{{10.1.2}{311}{Practical Considerations}{section*.606}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.3}Cosine Learning Rate Decay}{311}{subsection.10.1.3}\protected@file@percent }
\newlabel{subsubsec:cosine_lr}{{10.1.3}{311}{Cosine Learning Rate Decay}{subsection.10.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Cosine learning rate decay: smoothly reducing the learning rate following a cosine wave shape.}}{311}{figure.caption.607}\protected@file@percent }
\newlabel{fig:chapter10_cosine_lr}{{10.3}{311}{Cosine learning rate decay: smoothly reducing the learning rate following a cosine wave shape}{figure.caption.607}{}}
\BKM@entry{id=371,dest={73756273656374696F6E2E31302E312E34},srcline={106}}{5C3337365C3337375C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C303030655C3030305C3034305C303030445C303030655C303030635C303030615C30303079}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.4}Linear Learning Rate Decay}{312}{subsection.10.1.4}\protected@file@percent }
\newlabel{subsubsec:linear_lr}{{10.1.4}{312}{Linear Learning Rate Decay}{subsection.10.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Linear learning rate decay: a simple alternative to cosine decay, reducing the learning rate linearly over time.}}{312}{figure.caption.608}\protected@file@percent }
\newlabel{fig:chapter10_linear_lr}{{10.4}{312}{Linear learning rate decay: a simple alternative to cosine decay, reducing the learning rate linearly over time}{figure.caption.608}{}}
\abx@aux@cite{0}{devlin2019_bert}
\abx@aux@segm{0}{0}{devlin2019_bert}
\abx@aux@cite{0}{liu2019_roberta}
\abx@aux@segm{0}{0}{liu2019_roberta}
\BKM@entry{id=372,dest={73756273656374696F6E2E31302E312E35},srcline={133}}{5C3337365C3337375C303030495C3030306E5C303030765C303030655C303030725C303030735C303030655C3030305C3034305C303030535C303030715C303030755C303030615C303030725C303030655C3030305C3034305C303030525C3030306F5C3030306F5C303030745C3030305C3034305C303030445C303030655C303030635C303030615C30303079}
\abx@aux@cite{0}{vaswani2017_attention}
\abx@aux@segm{0}{0}{vaswani2017_attention}
\BKM@entry{id=373,dest={73756273656374696F6E2E31302E312E36},srcline={151}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030735C303030745C303030615C3030306E5C303030745C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C30303065}
\abx@aux@backref{188}{devlin2019_bert}{0}{313}{313}
\abx@aux@backref{189}{liu2019_roberta}{0}{313}{313}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.5}Inverse Square Root Decay}{313}{subsection.10.1.5}\protected@file@percent }
\newlabel{subsec:inverse_sqrt_decay}{{10.1.5}{313}{Inverse Square Root Decay}{subsection.10.1.5}{}}
\abx@aux@backref{190}{vaswani2017_attention}{0}{313}{313}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Inverse Square Root learning rate decay.}}{313}{figure.caption.609}\protected@file@percent }
\newlabel{fig:chapter10_inverse_sqrt}{{10.5}{313}{Inverse Square Root learning rate decay}{figure.caption.609}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.6}Constant Learning Rate}{314}{subsection.10.1.6}\protected@file@percent }
\newlabel{subsec:constant_lr}{{10.1.6}{314}{Constant Learning Rate}{subsection.10.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Constant learning rate decay.}}{314}{figure.caption.610}\protected@file@percent }
\newlabel{fig:chapter10_constant_lr}{{10.6}{314}{Constant learning rate decay}{figure.caption.610}{}}
\BKM@entry{id=374,dest={73756273656374696F6E2E31302E312E37},srcline={179}}{5C3337365C3337375C303030415C303030645C303030615C303030705C303030745C303030695C303030765C303030655C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C303030655C3030305C3034305C3030304D5C303030655C303030635C303030685C303030615C3030306E5C303030695C303030735C3030306D5C30303073}
\BKM@entry{id=375,dest={73756273656374696F6E2E31302E312E38},srcline={192}}{5C3337365C3337375C303030455C303030615C303030725C3030306C5C303030795C3030305C3034305C303030535C303030745C3030306F5C303030705C303030705C303030695C3030306E5C30303067}
\BKM@entry{id=376,dest={73656374696F6E2E31302E32},srcline={211}}{5C3337365C3337375C303030485C303030795C303030705C303030655C303030725C303030705C303030615C303030725C303030615C3030306D5C303030655C303030745C303030655C303030725C3030305C3034305C303030535C303030655C3030306C5C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.7}Adaptive Learning Rate Mechanisms}{315}{subsection.10.1.7}\protected@file@percent }
\newlabel{subsec:adaptive_lr}{{10.1.7}{315}{Adaptive Learning Rate Mechanisms}{subsection.10.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.8}Early Stopping}{315}{subsection.10.1.8}\protected@file@percent }
\newlabel{subsec:early_stopping}{{10.1.8}{315}{Early Stopping}{subsection.10.1.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Early stopping mechanism: monitoring loss and accuracy trends to determine the best checkpoint.}}{315}{figure.caption.611}\protected@file@percent }
\newlabel{fig:chapter10_early_stopping}{{10.7}{315}{Early stopping mechanism: monitoring loss and accuracy trends to determine the best checkpoint}{figure.caption.611}{}}
\BKM@entry{id=377,dest={73756273656374696F6E2E31302E322E31},srcline={216}}{5C3337365C3337375C303030475C303030725C303030695C303030645C3030305C3034305C303030535C303030655C303030615C303030725C303030635C30303068}
\BKM@entry{id=378,dest={73756273656374696F6E2E31302E322E32},srcline={235}}{5C3337365C3337375C303030525C303030615C3030306E5C303030645C3030306F5C3030306D5C3030305C3034305C303030535C303030655C303030615C303030725C303030635C30303068}
\abx@aux@cite{0}{bergstra2012_randomsearch}
\abx@aux@segm{0}{0}{bergstra2012_randomsearch}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Hyperparameter Selection}{316}{section.10.2}\protected@file@percent }
\newlabel{sec:hyperparameter_selection}{{10.2}{316}{Hyperparameter Selection}{section.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Grid Search}{316}{subsection.10.2.1}\protected@file@percent }
\newlabel{subsec:grid_search}{{10.2.1}{316}{Grid Search}{subsection.10.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Grid search mechanism for hyperparameter tuning.}}{316}{figure.caption.612}\protected@file@percent }
\newlabel{fig:chapter10_grid_search}{{10.8}{316}{Grid search mechanism for hyperparameter tuning}{figure.caption.612}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Random Search}{316}{subsection.10.2.2}\protected@file@percent }
\newlabel{subsec:random_search}{{10.2.2}{316}{Random Search}{subsection.10.2.2}{}}
\abx@aux@backref{191}{bergstra2012_randomsearch}{0}{316}{316}
\BKM@entry{id=379,dest={73756273656374696F6E2E31302E322E33},srcline={265}}{5C3337365C3337375C303030535C303030745C303030655C303030705C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030485C303030795C303030705C303030655C303030725C303030705C303030615C303030725C303030615C3030306D5C303030655C303030745C303030655C303030725C3030305C3034305C303030545C303030755C3030306E5C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Comparison of grid search and random search strategies. The green distribution over the horizontal axis represents the model performance based on the values of the important hyperparameter, while the orange distribution over the vertical axis represents the performance of the model based on the values of the unimportant one. As we can see, the yellow distribution is rather flat, while the green one has a clear pick, corresponding to a parameter value that maximizes the model's performance. Random search provides better coverage of the important hyperparameters (as it allows us to sample more values for each parameter in a fixed number of tries), and with it we manage to sample the distribution near the pick, as we would like.}}{317}{figure.caption.613}\protected@file@percent }
\newlabel{fig:chapter10_random_vs_grid}{{10.9}{317}{Comparison of grid search and random search strategies. The green distribution over the horizontal axis represents the model performance based on the values of the important hyperparameter, while the orange distribution over the vertical axis represents the performance of the model based on the values of the unimportant one. As we can see, the yellow distribution is rather flat, while the green one has a clear pick, corresponding to a parameter value that maximizes the model's performance. Random search provides better coverage of the important hyperparameters (as it allows us to sample more values for each parameter in a fixed number of tries), and with it we manage to sample the distribution near the pick, as we would like}{figure.caption.613}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.3}Steps for Hyperparameter Tuning}{317}{subsection.10.2.3}\protected@file@percent }
\newlabel{subsec:steps_hyperparam_tuning}{{10.2.3}{317}{Steps for Hyperparameter Tuning}{subsection.10.2.3}{}}
\BKM@entry{id=380,dest={73756273656374696F6E2E31302E322E34},srcline={334}}{5C3337365C3337375C303030495C3030306E5C303030745C303030655C303030725C303030705C303030725C303030655C303030745C303030695C3030306E5C303030675C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030435C303030755C303030725C303030765C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.4}Interpreting Learning Curves}{319}{subsection.10.2.4}\protected@file@percent }
\newlabel{subsec:learning_curves}{{10.2.4}{319}{Interpreting Learning Curves}{subsection.10.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces A learning curve that is very flat at the beginning and then drops sharply, indicating poor initialization.}}{319}{figure.caption.614}\protected@file@percent }
\newlabel{fig:chapter10_bad_init}{{10.10}{319}{A learning curve that is very flat at the beginning and then drops sharply, indicating poor initialization}{figure.caption.614}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.11}{\ignorespaces Learning curve plateauing, indicating the need for learning rate decay or weight decay tuning.}}{320}{figure.caption.615}\protected@file@percent }
\newlabel{fig:chapter10_plateau}{{10.11}{320}{Learning curve plateauing, indicating the need for learning rate decay or weight decay tuning}{figure.caption.615}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.12}{\ignorespaces Step decay applied too early, leading to stagnation. Adjusting the decay timing may help.}}{320}{figure.caption.616}\protected@file@percent }
\newlabel{fig:chapter10_step_decay}{{10.12}{320}{Step decay applied too early, leading to stagnation. Adjusting the decay timing may help}{figure.caption.616}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.13}{\ignorespaces Accuracy still increasing, suggesting longer training is needed.}}{321}{figure.caption.617}\protected@file@percent }
\newlabel{fig:chapter10_longer_training}{{10.13}{321}{Accuracy still increasing, suggesting longer training is needed}{figure.caption.617}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.14}{\ignorespaces Train-validation accuracy gap, indicating overfitting. Regularization techniques may help.}}{321}{figure.caption.618}\protected@file@percent }
\newlabel{fig:chapter10_overfitting}{{10.14}{321}{Train-validation accuracy gap, indicating overfitting. Regularization techniques may help}{figure.caption.618}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.15}{\ignorespaces Underfitting: train and validation accuracy increasing together but at a low level. Model capacity should be increased.}}{322}{figure.caption.619}\protected@file@percent }
\newlabel{fig:chapter10_underfitting}{{10.15}{322}{Underfitting: train and validation accuracy increasing together but at a low level. Model capacity should be increased}{figure.caption.619}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.16}{\ignorespaces Monitoring weight update to weight magnitude ratio, an important stability metric during training.}}{322}{figure.caption.620}\protected@file@percent }
\newlabel{fig:chapter10_weight_update_ratio}{{10.16}{322}{Monitoring weight update to weight magnitude ratio, an important stability metric during training}{figure.caption.620}{}}
\BKM@entry{id=381,dest={73756273656374696F6E2E31302E322E35},srcline={425}}{5C3337365C3337375C3030304D5C3030306F5C303030645C303030655C3030306C5C3030305C3034305C303030455C3030306E5C303030735C303030655C3030306D5C303030625C3030306C5C303030655C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030415C303030765C303030655C303030725C303030615C303030675C303030695C3030306E5C303030675C3030305C3034305C303030545C303030655C303030635C303030685C3030306E5C303030695C303030715C303030755C303030655C30303073}
\BKM@entry{id=382,dest={73756273656374696F6E2E31302E322E36},srcline={445}}{5C3337365C3337375C303030455C303030785C303030705C3030306F5C3030306E5C303030655C3030306E5C303030745C303030695C303030615C3030306C5C3030305C3034305C3030304D5C3030306F5C303030765C303030695C3030306E5C303030675C3030305C3034305C303030415C303030765C303030655C303030725C303030615C303030675C303030655C3030305C3034305C3030305C3035305C303030455C3030304D5C303030415C3030305C3035315C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030505C3030306F5C3030306C5C303030795C303030615C3030306B5C3030305C3034305C303030415C303030765C303030655C303030725C303030615C303030675C303030695C3030306E5C30303067}
\abx@aux@cite{0}{polyak1992_averagegradient}
\abx@aux@segm{0}{0}{polyak1992_averagegradient}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.5}Model Ensembles and Averaging Techniques}{323}{subsection.10.2.5}\protected@file@percent }
\newlabel{subsec:model_ensembles}{{10.2.5}{323}{Model Ensembles and Averaging Techniques}{subsection.10.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.17}{\ignorespaces Visualization of model ensemble using different checkpoints from a single model trained with a cyclic learning rate schedule.}}{323}{figure.caption.621}\protected@file@percent }
\newlabel{fig:chapter10_ensemble_checkpoints}{{10.17}{323}{Visualization of model ensemble using different checkpoints from a single model trained with a cyclic learning rate schedule}{figure.caption.621}{}}
\abx@aux@cite{0}{ioffe2015_batchnorm}
\abx@aux@segm{0}{0}{ioffe2015_batchnorm}
\BKM@entry{id=383,dest={73656374696F6E2E31302E33},srcline={463}}{5C3337365C3337375C303030545C303030725C303030615C3030306E5C303030735C303030665C303030655C303030725C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.6}Exponential Moving Average (EMA) and Polyak Averaging}{324}{subsection.10.2.6}\protected@file@percent }
\newlabel{subsec:polyak_averaging}{{10.2.6}{324}{Exponential Moving Average (EMA) and Polyak Averaging}{subsection.10.2.6}{}}
\abx@aux@backref{192}{polyak1992_averagegradient}{0}{324}{324}
\abx@aux@backref{193}{ioffe2015_batchnorm}{0}{324}{324}
\@writefile{lof}{\contentsline {figure}{\numberline {10.18}{\ignorespaces Visualization of Polyak averaging, showing how model weights are updated via an exponential moving average to reduce noise and stabilize training.}}{324}{figure.caption.622}\protected@file@percent }
\newlabel{fig:chapter10_polyak_averaging}{{10.18}{324}{Visualization of Polyak averaging, showing how model weights are updated via an exponential moving average to reduce noise and stabilize training}{figure.caption.622}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Transfer Learning}{324}{section.10.3}\protected@file@percent }
\newlabel{subsec:transfer_learning}{{10.3}{324}{Transfer Learning}{section.10.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.19}{\ignorespaces Visualization of the transfer learning process and its impact on the Caltech-101 dataset, which is relatively small compared to ImageNet.}}{325}{figure.caption.623}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_caltech}{{10.19}{325}{Visualization of the transfer learning process and its impact on the Caltech-101 dataset, which is relatively small compared to ImageNet}{figure.caption.623}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.20}{\ignorespaces Transfer learning outperforms dataset-specific solutions across multiple classification tasks (objects, scenes, birds, flowers, human attributes, etc.).}}{325}{figure.caption.624}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_tasks}{{10.20}{325}{Transfer learning outperforms dataset-specific solutions across multiple classification tasks (objects, scenes, birds, flowers, human attributes, etc.)}{figure.caption.624}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.21}{\ignorespaces Transfer learning applied to image retrieval tasks, surpassing tailored solutions for tasks like Paris Buildings, Oxford Buildings, and Sculpture retrieval.}}{326}{figure.caption.625}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_retrieval}{{10.21}{326}{Transfer learning applied to image retrieval tasks, surpassing tailored solutions for tasks like Paris Buildings, Oxford Buildings, and Sculpture retrieval}{figure.caption.625}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.22}{\ignorespaces Fine-tuning a pretrained model: freezing early layers, training a classifier, then gradually unfreezing later layers while lowering the learning rate.}}{326}{figure.caption.626}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_finetuning}{{10.22}{326}{Fine-tuning a pretrained model: freezing early layers, training a classifier, then gradually unfreezing later layers while lowering the learning rate}{figure.caption.626}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.23}{\ignorespaces Fine-tuning provides significant performance improvements on multiple object detection tasks (VOC 2007 and ILSVRC 2013).}}{327}{figure.caption.627}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_boost}{{10.23}{327}{Fine-tuning provides significant performance improvements on multiple object detection tasks (VOC 2007 and ILSVRC 2013)}{figure.caption.627}{}}
\BKM@entry{id=384,dest={73756273656374696F6E2E31302E332E31},srcline={547}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030745C3030306F5C3030305C3034305C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C303030655C303030725C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030435C3030304E5C3030304E5C303030735C3030303F}
\@writefile{lof}{\contentsline {figure}{\numberline {10.24}{\ignorespaces Advancements in ImageNet models over the years have led to significant improvements in object detection performance on COCO.}}{328}{figure.caption.628}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_coco}{{10.24}{328}{Advancements in ImageNet models over the years have led to significant improvements in object detection performance on COCO}{figure.caption.628}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.1}How to Perform Transfer Learning with CNNs?}{328}{subsection.10.3.1}\protected@file@percent }
\newlabel{subsec:how_to_transfer_learning}{{10.3.1}{328}{How to Perform Transfer Learning with CNNs?}{subsection.10.3.1}{}}
\BKM@entry{id=385,dest={73756273656374696F6E2E31302E332E32},srcline={571}}{5C3337365C3337375C303030545C303030725C303030615C3030306E5C303030735C303030665C303030655C303030725C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{zhou2019_unifiedvqa}
\abx@aux@segm{0}{0}{zhou2019_unifiedvqa}
\abx@aux@cite{0}{zhou2019_unifiedvqa}
\abx@aux@segm{0}{0}{zhou2019_unifiedvqa}
\abx@aux@cite{0}{zhou2019_unifiedvqa}
\abx@aux@segm{0}{0}{zhou2019_unifiedvqa}
\@writefile{lof}{\contentsline {figure}{\numberline {10.25}{\ignorespaces Guidelines for performing transfer learning based on dataset size and similarity to ImageNet.}}{329}{figure.caption.629}\protected@file@percent }
\newlabel{fig:chapter10_transfer_learning_table}{{10.25}{329}{Guidelines for performing transfer learning based on dataset size and similarity to ImageNet}{figure.caption.629}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.2}Transfer Learning Beyond Classification}{329}{subsection.10.3.2}\protected@file@percent }
\newlabel{subsec:transfer_learning_beyond}{{10.3.2}{329}{Transfer Learning Beyond Classification}{subsection.10.3.2}{}}
\abx@aux@backref{194}{zhou2019_unifiedvqa}{0}{329}{329}
\@writefile{lof}{\contentsline {figure}{\numberline {10.26}{\ignorespaces Multi-stage transfer learning applied to vision-language tasks \blx@tocontentsinit {0}\cite {zhou2019_unifiedvqa}.}}{329}{figure.caption.630}\protected@file@percent }
\abx@aux@backref{196}{zhou2019_unifiedvqa}{0}{329}{329}
\newlabel{fig:chapter10_transfer_learning_vqa}{{10.26}{329}{Multi-stage transfer learning applied to vision-language tasks \cite {zhou2019_unifiedvqa}}{figure.caption.630}{}}
\BKM@entry{id=386,dest={73756273656374696F6E2E31302E332E33},srcline={593}}{5C3337365C3337375C303030445C3030306F5C303030655C303030735C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C303030655C303030725C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030415C3030306C5C303030775C303030615C303030795C303030735C3030305C3034305C303030575C303030695C3030306E5C3030303F}
\abx@aux@cite{0}{he2018_rethinkingimagenet}
\abx@aux@segm{0}{0}{he2018_rethinkingimagenet}
\abx@aux@cite{0}{he2018_rethinkingimagenet}
\abx@aux@segm{0}{0}{he2018_rethinkingimagenet}
\abx@aux@cite{0}{he2018_rethinkingimagenet}
\abx@aux@segm{0}{0}{he2018_rethinkingimagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.3}Does Transfer Learning Always Win?}{330}{subsection.10.3.3}\protected@file@percent }
\newlabel{subsec:transfer_learning_vs_scratch}{{10.3.3}{330}{Does Transfer Learning Always Win?}{subsection.10.3.3}{}}
\abx@aux@backref{197}{he2018_rethinkingimagenet}{0}{330}{330}
\@writefile{lof}{\contentsline {figure}{\numberline {10.27}{\ignorespaces Comparison of training from scratch (orange) vs. pretraining + fine-tuning (blue) on COCO object detection \blx@tocontentsinit {0}\cite {he2018_rethinkingimagenet}.}}{330}{figure.caption.631}\protected@file@percent }
\abx@aux@backref{199}{he2018_rethinkingimagenet}{0}{330}{330}
\newlabel{fig:chapter10_transfer_learning_vs_scratch}{{10.27}{330}{Comparison of training from scratch (orange) vs. pretraining + fine-tuning (blue) on COCO object detection \cite {he2018_rethinkingimagenet}}{figure.caption.631}{}}
\BKM@entry{id=387,dest={636861707465722E3131},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030315C3030303A5C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C303030735C3030305C3034305C303030495C30303049}
\BKM@entry{id=388,dest={73656374696F6E2E31312E31},srcline={10}}{5C3337365C3337375C303030505C3030306F5C303030735C303030745C3030302D5C303030525C303030655C303030735C3030304E5C303030655C303030745C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Lecture 11: CNN Architectures II}{331}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@10}}
\ttl@writefile{ptc}{\ttl@starttoc{default@11}}
\pgfsyspdfmark {pgfid27}{0}{52099153}
\pgfsyspdfmark {pgfid26}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Post-ResNet Architectures}{331}{section.11.1}\protected@file@percent }
\newlabel{sec:post_resnet}{{11.1}{331}{Post-ResNet Architectures}{section.11.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Comparison of ResNet variants and their top-1 accuracy on ImageNet. Improvements beyond ResNet-101 yield diminishing returns relative to the increased computational cost.}}{331}{figure.caption.632}\protected@file@percent }
\newlabel{fig:chapter11_resnet_variants}{{11.1}{331}{Comparison of ResNet variants and their top-1 accuracy on ImageNet. Improvements beyond ResNet-101 yield diminishing returns relative to the increased computational cost}{figure.caption.632}{}}
\BKM@entry{id=389,dest={73656374696F6E2E31312E32},srcline={35}}{5C3337365C3337375C303030475C303030725C3030306F5C303030755C303030705C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Grouped Convolutions}{332}{section.11.2}\protected@file@percent }
\newlabel{sec:grouped_convs}{{11.2}{332}{Grouped Convolutions}{section.11.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces Regular convolution: each filter operates on all input channels and produces a single feature map.}}{332}{figure.caption.633}\protected@file@percent }
\newlabel{fig:chapter11_regular_convs}{{11.2}{332}{Regular convolution: each filter operates on all input channels and produces a single feature map}{figure.caption.633}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Grouped convolution: input channels are split into groups, where each filter processes only its assigned subset. Example shown for $G=2$.}}{333}{figure.caption.634}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs}{{11.3}{333}{Grouped convolution: input channels are split into groups, where each filter processes only its assigned subset. Example shown for $G=2$}{figure.caption.634}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces Each group of filters processes only a subset of the input channels, producing its corresponding output channels.}}{333}{figure.caption.635}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_process}{{11.4}{333}{Each group of filters processes only a subset of the input channels, producing its corresponding output channels}{figure.caption.635}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces The first group creates one output plane (darker blue), using its assigned input channels.}}{334}{figure.caption.636}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_step1}{{11.5}{334}{The first group creates one output plane (darker blue), using its assigned input channels}{figure.caption.636}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces The first group produces another output plane using a different filter.}}{334}{figure.caption.637}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_step2}{{11.6}{334}{The first group produces another output plane using a different filter}{figure.caption.637}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.7}{\ignorespaces The second group processes its assigned channels, producing an output plane (darker green).}}{335}{figure.caption.638}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_step3}{{11.7}{335}{The second group processes its assigned channels, producing an output plane (darker green)}{figure.caption.638}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.8}{\ignorespaces The second group produces another output channel using a different filter, producing another output plane (darker green).}}{335}{figure.caption.639}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_step3}{{11.8}{335}{The second group produces another output channel using a different filter, producing another output plane (darker green)}{figure.caption.639}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.9}{\ignorespaces Grouped convolution example with $G=4$, where each group is assigned a different color.}}{336}{figure.caption.640}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_g4}{{11.9}{336}{Grouped convolution example with $G=4$, where each group is assigned a different color}{figure.caption.640}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.10}{\ignorespaces Depthwise convolution as a special case of grouped convolution, where each group corresponds to a single input channel. In this example, we have several filters per Group, as $C_\text  {out}>C_\text  {in}$. More specifically, we have 2 filters in each group, as the output channels are twice the input channels ($C_\text  {out}=2C_\text  {in}$)}}{336}{figure.caption.641}\protected@file@percent }
\newlabel{fig:chapter11_depthwise_convs}{{11.10}{336}{Depthwise convolution as a special case of grouped convolution, where each group corresponds to a single input channel. In this example, we have several filters per Group, as $C_\text {out}>C_\text {in}$. More specifically, we have 2 filters in each group, as the output channels are twice the input channels ($C_\text {out}=2C_\text {in}$)}{figure.caption.641}{}}
\BKM@entry{id=390,dest={73756273656374696F6E2E31312E322E31},srcline={139}}{5C3337365C3337375C303030475C303030725C3030306F5C303030755C303030705C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C303030795C303030545C3030306F5C303030725C303030635C30303068}
\@writefile{lof}{\contentsline {figure}{\numberline {11.11}{\ignorespaces Summary of grouped convolutions: input splitting, processing by groups, and computational efficiency.}}{337}{figure.caption.642}\protected@file@percent }
\newlabel{fig:chapter11_grouped_convs_summary}{{11.11}{337}{Summary of grouped convolutions: input splitting, processing by groups, and computational efficiency}{figure.caption.642}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Grouped Convolutions in PyTorch}{337}{subsection.11.2.1}\protected@file@percent }
\newlabel{subsec:grouped_convs_pytorch}{{11.2.1}{337}{Grouped Convolutions in PyTorch}{subsection.11.2.1}{}}
\BKM@entry{id=391,dest={73656374696F6E2E31312E33},srcline={211}}{5C3337365C3337375C303030525C303030655C303030735C3030304E5C303030655C303030585C303030745C3030303A5C3030305C3034305C3030304E5C303030655C303030785C303030745C3030302D5C303030475C303030655C3030306E5C303030655C303030725C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030525C303030655C303030735C303030695C303030645C303030755C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\abx@aux@cite{0}{xie2017_aggregated}
\abx@aux@segm{0}{0}{xie2017_aggregated}
\BKM@entry{id=392,dest={73756273656374696F6E2E31312E332E31},srcline={216}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030575C303030685C303030795C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030585C303030745C3030303F}
\@writefile{toc}{\contentsline {subsubsection}{Key Observations}{338}{section*.643}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{When to Use Grouped Convolutions?}{338}{section*.644}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}ResNeXt: Next-Generation Residual Networks}{338}{section.11.3}\protected@file@percent }
\newlabel{sec:resnext}{{11.3}{338}{ResNeXt: Next-Generation Residual Networks}{section.11.3}{}}
\abx@aux@backref{200}{xie2017_aggregated}{0}{338}{338}
\BKM@entry{id=393,dest={73756273656374696F6E2E31312E332E32},srcline={221}}{5C3337365C3337375C3030304B5C303030655C303030795C3030305C3034305C303030495C3030306E5C3030306E5C3030306F5C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030415C303030675C303030675C303030725C303030655C303030675C303030615C303030745C303030655C303030645C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}Motivation: Why ResNeXt?}{339}{subsection.11.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.2}Key Innovation: Aggregated Transformations}{339}{subsection.11.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.12}{\ignorespaces Comparison of the bottleneck residual block (left) with the ResNeXt block using G parallel pathways (right).}}{339}{figure.caption.645}\protected@file@percent }
\newlabel{fig:chapter11_resnext_block}{{11.12}{339}{Comparison of the bottleneck residual block (left) with the ResNeXt block using G parallel pathways (right)}{figure.caption.645}{}}
\BKM@entry{id=394,dest={73756273656374696F6E2E31312E332E33},srcline={261}}{5C3337365C3337375C303030525C303030655C303030735C3030304E5C303030655C303030585C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030475C303030725C3030306F5C303030755C303030705C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=395,dest={73756273656374696F6E2E31312E332E34},srcline={278}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030585C303030745C3030305C3034305C3030304F5C303030765C303030655C303030725C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C30303074}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.3}ResNeXt and Grouped Convolutions}{340}{subsection.11.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.13}{\ignorespaces ResNeXt bottleneck block using grouped convolutions: Conv($1\times 1$, $4C \to Gc$), Conv($3\times 3$, $Gc \to Gc$, groups=$G$), Conv($1\times 1$, $Gc \to 4C$).}}{340}{figure.caption.646}\protected@file@percent }
\newlabel{fig:chapter11_resnext_grouped}{{11.13}{340}{ResNeXt bottleneck block using grouped convolutions: Conv($1\times 1$, $4C \to Gc$), Conv($3\times 3$, $Gc \to Gc$, groups=$G$), Conv($1\times 1$, $Gc \to 4C$)}{figure.caption.646}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.4}Advantages of ResNeXt Over ResNet}{340}{subsection.11.3.4}\protected@file@percent }
\BKM@entry{id=396,dest={73756273656374696F6E2E31312E332E35},srcline={293}}{5C3337365C3337375C303030525C303030655C303030735C3030304E5C303030655C303030585C303030745C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C3030305C3034305C3030304E5C303030615C3030306D5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030765C303030655C3030306E5C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=397,dest={73656374696F6E2E31312E34},srcline={303}}{5C3337365C3337375C303030535C303030715C303030755C303030655C303030655C3030307A5C303030655C3030302D5C303030615C3030306E5C303030645C3030302D5C303030455C303030785C303030635C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030535C303030455C3030304E5C303030655C303030745C3030305C303531}
\abx@aux@cite{0}{hu2018_senet}
\abx@aux@segm{0}{0}{hu2018_senet}
\BKM@entry{id=398,dest={73756273656374696F6E2E31312E342E31},srcline={310}}{5C3337365C3337375C303030535C303030715C303030755C303030655C303030655C3030307A5C303030655C3030302D5C303030615C3030306E5C303030645C3030302D5C303030455C303030785C303030635C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030535C303030455C3030305C3035315C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B}
\@writefile{lof}{\contentsline {figure}{\numberline {11.14}{\ignorespaces Increasing the number of groups while reducing the width of each group enhances performance without increasing computational cost. This improvement is achieved by expanding the number of parallel transformation pathways (without increasing network depth! meaning, without changing the number of ResNeXt blocks). For instance, ResNeXt-101-32x4d outperforms ResNeXt-101-4x24d despite having an equivalent number of FLOPs.}}{341}{figure.caption.647}\protected@file@percent }
\newlabel{fig:chapter11_resnext_performance}{{11.14}{341}{Increasing the number of groups while reducing the width of each group enhances performance without increasing computational cost. This improvement is achieved by expanding the number of parallel transformation pathways (without increasing network depth! meaning, without changing the number of ResNeXt blocks). For instance, ResNeXt-101-32x4d outperforms ResNeXt-101-4x24d despite having an equivalent number of FLOPs}{figure.caption.647}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.5}ResNeXt Model Naming Convention}{341}{subsection.11.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Squeeze-and-Excitation Networks (SENet)}{341}{section.11.4}\protected@file@percent }
\newlabel{sec:senet}{{11.4}{341}{Squeeze-and-Excitation Networks (SENet)}{section.11.4}{}}
\abx@aux@backref{201}{hu2018_senet}{0}{341}{341}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.1}Squeeze-and-Excitation (SE) Block}{342}{subsection.11.4.1}\protected@file@percent }
\newlabel{subsec:se_block}{{11.4.1}{342}{Squeeze-and-Excitation (SE) Block}{subsection.11.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Squeeze: Global Information Embedding}{342}{section*.648}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Excitation: Adaptive Recalibration}{342}{section*.649}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Channel Recalibration}{343}{section*.650}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.15}{\ignorespaces The SE block incorporated into a ResNet bottleneck block. The SE mechanism applies global pooling (squeeze), learns channel-wise scaling factors (excitation), and rescales feature maps accordingly.}}{343}{figure.caption.651}\protected@file@percent }
\newlabel{fig:chapter11_se_block}{{11.15}{343}{The SE block incorporated into a ResNet bottleneck block. The SE mechanism applies global pooling (squeeze), learns channel-wise scaling factors (excitation), and rescales feature maps accordingly}{figure.caption.651}{}}
\@writefile{toc}{\contentsline {subsubsection}{How SE Blocks Enhance ResNet Bottleneck Blocks}{343}{section*.652}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why Does SE Improve Performance?}{344}{section*.653}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Performance Gains, Scalability, and Integration of SE Blocks}{344}{section*.654}\protected@file@percent }
\newlabel{subsubsec:se_performance_scalability}{{11.4.1}{344}{Performance Gains, Scalability, and Integration of SE Blocks}{section*.654}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.16}{\ignorespaces Performance improvements from integrating SE blocks into ResNet, ResNeXt, Inception, and VGG architectures. Each gains roughly a 1–2\% boost in accuracy without requiring additional changes.}}{344}{figure.caption.655}\protected@file@percent }
\newlabel{fig:chapter11_se_performance}{{11.16}{344}{Performance improvements from integrating SE blocks into ResNet, ResNeXt, Inception, and VGG architectures. Each gains roughly a 1–2\% boost in accuracy without requiring additional changes}{figure.caption.655}{}}
\@writefile{toc}{\contentsline {subsubsection}{Impact on Various Tasks}{344}{section*.656}\protected@file@percent }
\BKM@entry{id=399,dest={73756273656374696F6E2E31312E342E32},srcline={421}}{5C3337365C3337375C303030535C303030455C3030305C3034305C303030425C3030306C5C3030306F5C303030635C3030306B5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030455C3030306E5C303030645C3030305C3034305C3030306F5C303030665C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030304E5C303030655C303030745C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C30303065}
\@writefile{toc}{\contentsline {subsubsection}{Practical Applications and Widespread Adoption}{345}{section*.657}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.2}SE Blocks and the End of the ImageNet Classification Challenge}{345}{subsection.11.4.2}\protected@file@percent }
\newlabel{subsec:senet_end_imagenet}{{11.4.2}{345}{SE Blocks and the End of the ImageNet Classification Challenge}{subsection.11.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.17}{\ignorespaces The evolution of top-performing models in the ImageNet classification challenge over the years. SENet achieved the lowest top-5 error rate in 2017, marking the effective end of the challenge.}}{345}{figure.caption.658}\protected@file@percent }
\newlabel{fig:chapter11_imagenet_completion}{{11.17}{345}{The evolution of top-performing models in the ImageNet classification challenge over the years. SENet achieved the lowest top-5 error rate in 2017, marking the effective end of the challenge}{figure.caption.658}{}}
\BKM@entry{id=400,dest={73656374696F6E2E31312E35},srcline={453}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030455C303030645C303030675C303030655C3030305C3034305C303030445C303030655C303030765C303030695C303030635C303030655C30303073}
\@writefile{toc}{\contentsline {subsubsection}{Shifting Research Directions: Efficiency and Mobile Deployability}{346}{section*.659}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{What Comes Next?}{346}{section*.660}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Efficient Architectures for Edge Devices}{346}{section.11.5}\protected@file@percent }
\newlabel{sec:efficient_edge_devices}{{11.5}{346}{Efficient Architectures for Edge Devices}{section.11.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.18}{\ignorespaces Rather than building the largest, most accurate networks, research in the years following SENet focuses on small, efficient models that optimize the accuracy/complexity trade-off. A superior model family shifts the entire accuracy-versus-complexity curve upward and to the left.}}{346}{figure.caption.661}\protected@file@percent }
\newlabel{fig:chapter11_accuracy_vs_complexity}{{11.18}{346}{Rather than building the largest, most accurate networks, research in the years following SENet focuses on small, efficient models that optimize the accuracy/complexity trade-off. A superior model family shifts the entire accuracy-versus-complexity curve upward and to the left}{figure.caption.661}{}}
\BKM@entry{id=401,dest={73756273656374696F6E2E31312E352E31},srcline={469}}{5C3337365C3337375C3030304D5C3030306F5C303030625C303030695C3030306C5C303030655C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030445C303030655C303030705C303030745C303030685C303030775C303030695C303030735C303030655C3030305C3034305C303030535C303030655C303030705C303030615C303030725C303030615C303030625C3030306C5C303030655C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5.1}MobileNet: Depthwise Separable Convolutions}{347}{subsection.11.5.1}\protected@file@percent }
\newlabel{subsec:mobilenet_v1}{{11.5.1}{347}{MobileNet: Depthwise Separable Convolutions}{subsection.11.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.19}{\ignorespaces Standard convolution block (left) vs. Depthwise Separable Convolution (right). The latter significantly reduces computation while maintaining competitive accuracy.}}{347}{figure.caption.662}\protected@file@percent }
\newlabel{fig:chapter11_depthwise_vs_standard}{{11.19}{347}{Standard convolution block (left) vs. Depthwise Separable Convolution (right). The latter significantly reduces computation while maintaining competitive accuracy}{figure.caption.662}{}}
\@writefile{toc}{\contentsline {subsubsection}{Width Multiplier: Thinner Models}{348}{section*.663}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Resolution Multiplier: Reduced Representations}{348}{section*.664}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Computational Cost of Depthwise Separable Convolutions}{348}{section*.665}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary of Multipliers}{349}{section*.666}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{MobileNetV1 vs. Traditional Architectures}{349}{section*.667}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11.1}{\ignorespaces Comparison of MobileNet-224, GoogLeNet, and VGG-16 on ImageNet. MobileNet significantly reduces computational cost while maintaining competitive accuracy.}}{349}{table.caption.668}\protected@file@percent }
\newlabel{tab:mobilenet_vs_classical}{{11.1}{349}{Comparison of MobileNet-224, GoogLeNet, and VGG-16 on ImageNet. MobileNet significantly reduces computational cost while maintaining competitive accuracy}{table.caption.668}{}}
\@writefile{toc}{\contentsline {subsubsection}{Depthwise Separable vs. Standard Convolutions in MobileNet}{349}{section*.669}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11.2}{\ignorespaces Comparison of MobileNet with standard convolutions vs. depthwise separable convolutions on ImageNet.}}{349}{table.caption.670}\protected@file@percent }
\newlabel{tab:mobile_depthwise_vs_standard}{{11.2}{349}{Comparison of MobileNet with standard convolutions vs. depthwise separable convolutions on ImageNet}{table.caption.670}{}}
\@writefile{toc}{\contentsline {subsubsection}{Summary and Next Steps}{349}{section*.671}\protected@file@percent }
\newlabel{subsubsec:mobile_to_shufflenet}{{11.5.1}{349}{Summary and Next Steps}{section*.671}{}}
\BKM@entry{id=402,dest={73756273656374696F6E2E31312E352E32},srcline={611}}{5C3337365C3337375C303030535C303030685C303030755C303030665C303030665C3030306C5C303030655C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C303030685C303030615C3030306E5C3030306E5C303030655C3030306C5C3030305C3034305C3030304D5C303030695C303030785C303030695C3030306E5C303030675C3030305C3034305C303030765C303030695C303030615C3030305C3034305C303030475C303030725C3030306F5C303030755C303030705C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C30303073}
\abx@aux@cite{0}{zhang2018_shufflenet}
\abx@aux@segm{0}{0}{zhang2018_shufflenet}
\@writefile{lof}{\contentsline {figure}{\numberline {11.20}{\ignorespaces Problem: Grouped convolutions do not mix information across groups. Each output channel depends only on its corresponding input group, limiting feature learning.}}{350}{figure.caption.672}\protected@file@percent }
\newlabel{fig:chapter11_grouped_conv_problem}{{11.20}{350}{Problem: Grouped convolutions do not mix information across groups. Each output channel depends only on its corresponding input group, limiting feature learning}{figure.caption.672}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5.2}ShuffleNet: Efficient Channel Mixing via Grouped Convolutions}{350}{subsection.11.5.2}\protected@file@percent }
\newlabel{subsec:shufflenet}{{11.5.2}{350}{ShuffleNet: Efficient Channel Mixing via Grouped Convolutions}{subsection.11.5.2}{}}
\abx@aux@backref{202}{zhang2018_shufflenet}{0}{350}{350}
\@writefile{lof}{\contentsline {figure}{\numberline {11.21}{\ignorespaces Solution: By introducing channel shuffling after a grouped convolution, ShuffleNet ensures that every output channel incorporates information from different groups.}}{351}{figure.caption.673}\protected@file@percent }
\newlabel{fig:chapter11_channel_shuffle}{{11.21}{351}{Solution: By introducing channel shuffling after a grouped convolution, ShuffleNet ensures that every output channel incorporates information from different groups}{figure.caption.673}{}}
\@writefile{toc}{\contentsline {subsubsection}{The ShuffleNet Unit}{351}{section*.674}\protected@file@percent }
\newlabel{subsubsec:shufflenet_unit}{{11.5.2}{351}{The ShuffleNet Unit}{section*.674}{}}
\@writefile{toc}{\contentsline {paragraph}{Core Design Features}{351}{section*.675}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Structure of a ShuffleNet Unit}{351}{section*.676}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.22}{\ignorespaces ShuffleNet Units: (a) Standard bottleneck unit with depthwise convolution (DWConv), (b) ShuffleNet unit incorporating pointwise group convolution (GConv) and channel shuffle, (c) ShuffleNet unit with stride = 2, where element-wise addition is replaced with channel concatenation.}}{352}{figure.caption.677}\protected@file@percent }
\newlabel{fig:chapter11_shufflenet_block}{{11.22}{352}{ShuffleNet Units: (a) Standard bottleneck unit with depthwise convolution (DWConv), (b) ShuffleNet unit incorporating pointwise group convolution (GConv) and channel shuffle, (c) ShuffleNet unit with stride = 2, where element-wise addition is replaced with channel concatenation}{figure.caption.677}{}}
\@writefile{toc}{\contentsline {paragraph}{Stride-2 Modification}{352}{section*.678}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{ShuffleNet Architecture}{352}{section*.679}\protected@file@percent }
\newlabel{subsubsec:shufflenet_architecture}{{11.5.2}{352}{ShuffleNet Architecture}{section*.679}{}}
\@writefile{toc}{\contentsline {paragraph}{Stage-wise Construction:}{352}{section*.680}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Scaling Factor}{353}{section*.681}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Design Rationale}{353}{section*.682}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Computational Efficiency of ShuffleNet}{353}{section*.683}\protected@file@percent }
\newlabel{subsubsec:shufflenet_efficiency}{{11.5.2}{353}{Computational Efficiency of ShuffleNet}{section*.683}{}}
\@writefile{toc}{\contentsline {subsubsection}{Inference Speed and Practical Performance}{353}{section*.684}\protected@file@percent }
\newlabel{subsubsec:shufflenet_inference}{{11.5.2}{353}{Inference Speed and Practical Performance}{section*.684}{}}
\BKM@entry{id=403,dest={73756273656374696F6E2E31312E352E33},srcline={740}}{5C3337365C3337375C3030304D5C3030306F5C303030625C303030695C3030306C5C303030655C3030304E5C303030655C303030745C303030565C303030325C3030303A5C3030305C3034305C303030495C3030306E5C303030765C303030655C303030725C303030745C303030655C303030645C3030305C3034305C303030425C3030306F5C303030745C303030745C3030306C5C303030655C3030306E5C303030655C303030635C3030306B5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030525C303030655C303030735C303030695C303030645C303030755C303030615C3030306C}
\abx@aux@cite{0}{sandler2018_mobilenetv2}
\abx@aux@segm{0}{0}{sandler2018_mobilenetv2}
\@writefile{toc}{\contentsline {subsubsection}{Performance Comparison: ShuffleNet vs. MobileNet}{354}{section*.685}\protected@file@percent }
\newlabel{subsubsec:shufflenet_vs_mobilenet}{{11.5.2}{354}{Performance Comparison: ShuffleNet vs. MobileNet}{section*.685}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.3}{\ignorespaces ShuffleNet 1× outperforms MobileNetV1 on ImageNet by achieving higher accuracy with fewer Multi-Adds, albeit with a slightly higher parameter count.}}{354}{table.caption.686}\protected@file@percent }
\newlabel{tab:shufflenet_vs_mobilenet}{{11.3}{354}{ShuffleNet 1× outperforms MobileNetV1 on ImageNet by achieving higher accuracy with fewer Multi-Adds, albeit with a slightly higher parameter count}{table.caption.686}{}}
\@writefile{toc}{\contentsline {subsubsection}{Beyond ShuffleNet: Evolution of Efficient CNN Architectures}{354}{section*.687}\protected@file@percent }
\newlabel{subsubsec:efficient_cnn_trends}{{11.5.2}{354}{Beyond ShuffleNet: Evolution of Efficient CNN Architectures}{section*.687}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5.3}MobileNetV2: Inverted Bottleneck and Linear Residual}{354}{subsection.11.5.3}\protected@file@percent }
\newlabel{subsec:mobilenetv2}{{11.5.3}{354}{MobileNetV2: Inverted Bottleneck and Linear Residual}{subsection.11.5.3}{}}
\abx@aux@backref{203}{sandler2018_mobilenetv2}{0}{354}{354}
\@writefile{toc}{\contentsline {paragraph}{Understanding Feature Representations and Manifolds}{354}{section*.688}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ReLU and Information Collapse}{354}{section*.689}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.23}{\ignorespaces Visualization of ReLU transformations on low-dimensional manifolds embedded in higher-dimensional spaces. For small $n$ (e.g., $n=2$ or $n=3$), ReLU collapses structural information, while for $n \geq 15$, the transformation largely preserves it.}}{355}{figure.caption.690}\protected@file@percent }
\newlabel{fig:chapter11_relu_transformations}{{11.23}{355}{Visualization of ReLU transformations on low-dimensional manifolds embedded in higher-dimensional spaces. For small $n$ (e.g., $n=2$ or $n=3$), ReLU collapses structural information, while for $n \geq 15$, the transformation largely preserves it}{figure.caption.690}{}}
\@writefile{toc}{\contentsline {subsubsection}{The MobileNetV2 Block: Inverted Residuals and Linear Bottleneck}{355}{section*.691}\protected@file@percent }
\newlabel{subsubsec:mobilenetv2_block}{{11.5.3}{355}{The MobileNetV2 Block: Inverted Residuals and Linear Bottleneck}{section*.691}{}}
\@writefile{toc}{\contentsline {paragraph}{Detailed Block Architecture}{355}{section*.692}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.24}{\ignorespaces Comparison of a standard ResNet bottleneck block and the MobileNetV2 inverted block. MobileNetV2 expands the feature space before applying non-linearity and projects back to a narrow representation in the end.}}{356}{figure.caption.693}\protected@file@percent }
\newlabel{fig:chapter11_mobilenetv2_vs_resnet}{{11.24}{356}{Comparison of a standard ResNet bottleneck block and the MobileNetV2 inverted block. MobileNetV2 expands the feature space before applying non-linearity and projects back to a narrow representation in the end}{figure.caption.693}{}}
\@writefile{toc}{\contentsline {subsubsection}{Why is the Inverted Block Fitting to Efficient Networks?}{356}{section*.694}\protected@file@percent }
\newlabel{subsubsec:inverted_block_efficiency}{{11.5.3}{356}{Why is the Inverted Block Fitting to Efficient Networks?}{section*.694}{}}
\@writefile{toc}{\contentsline {paragraph}{1. Depthwise Convolutions Maintain Low Computational Cost}{356}{section*.695}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Moderate Expansion Factor \((t)\) Balances Efficiency}{356}{section*.696}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Comparison to MobileNetV1}{356}{section*.697}\protected@file@percent }
\abx@aux@cite{0}{krishnamoorthi2018_quantizing}
\abx@aux@segm{0}{0}{krishnamoorthi2018_quantizing}
\@writefile{toc}{\contentsline {paragraph}{4. Comparison to ResNet Bottleneck Blocks}{357}{section*.698}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{5. Linear Bottleneck Preserves Subtle Features}{357}{section*.699}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary}{357}{section*.700}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{ReLU6 and Its Role in Low-Precision Inference}{357}{section*.701}\protected@file@percent }
\newlabel{subsubsec:relu6_mobilenetv2}{{11.5.3}{357}{ReLU6 and Its Role in Low-Precision Inference}{section*.701}{}}
\@writefile{toc}{\contentsline {paragraph}{Practical Observations and Alternatives}{358}{section*.702}\protected@file@percent }
\abx@aux@backref{204}{krishnamoorthi2018_quantizing}{0}{358}{358}
\@writefile{lof}{\contentsline {figure}{\numberline {11.25}{\ignorespaces Visualization of ReLU6, which bounds activations within a maximum value of 6. This was initially intended for quantization but later found to be suboptimal in certain cases.}}{358}{figure.caption.703}\protected@file@percent }
\newlabel{fig:chapter11_relu6_visualization}{{11.25}{358}{Visualization of ReLU6, which bounds activations within a maximum value of 6. This was initially intended for quantization but later found to be suboptimal in certain cases}{figure.caption.703}{}}
\@writefile{toc}{\contentsline {subsubsection}{MobileNetV2 Architecture and Performance}{358}{section*.704}\protected@file@percent }
\newlabel{subsubsec:mobilenetv2_architecture}{{11.5.3}{358}{MobileNetV2 Architecture and Performance}{section*.704}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.4}{\ignorespaces MobileNetV2 Architecture: Expansion ratios and output channels per block.}}{358}{table.caption.705}\protected@file@percent }
\newlabel{tab:chapter11_mobilenetv2_architecture}{{11.4}{358}{MobileNetV2 Architecture: Expansion ratios and output channels per block}{table.caption.705}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison to MobileNetV1, ShuffleNet, and NASNet}{359}{section*.706}\protected@file@percent }
\newlabel{subsubsec:mobilenetv2_comparison}{{11.5.3}{359}{Comparison to MobileNetV1, ShuffleNet, and NASNet}{section*.706}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.5}{\ignorespaces Performance comparison of MobileNetV2 with other efficient architectures on ImageNet. The last column reports inference time on a Google Pixel 1 CPU using TF-Lite.}}{359}{table.caption.707}\protected@file@percent }
\newlabel{tab:chapter11_mobilenetv2_comparison}{{11.5}{359}{Performance comparison of MobileNetV2 with other efficient architectures on ImageNet. The last column reports inference time on a Google Pixel 1 CPU using TF-Lite}{table.caption.707}{}}
\BKM@entry{id=404,dest={73756273656374696F6E2E31312E352E34},srcline={958}}{5C3337365C3337375C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030535C303030655C303030615C303030725C303030635C303030685C3030305C3034305C3030305C3035305C3030304E5C303030415C303030535C3030305C3035315C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304D5C3030306F5C303030625C303030695C3030306C5C303030655C3030304E5C303030655C303030745C303030565C30303033}
\abx@aux@cite{0}{zoph2017_nas}
\abx@aux@segm{0}{0}{zoph2017_nas}
\abx@aux@cite{0}{zoph2018_learning}
\abx@aux@segm{0}{0}{zoph2018_learning}
\abx@aux@cite{0}{williams1992_simple}
\abx@aux@segm{0}{0}{williams1992_simple}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5.4}Neural Architecture Search (NAS) and MobileNetV3}{360}{subsection.11.5.4}\protected@file@percent }
\newlabel{subsec:nas_mobilenetv3}{{11.5.4}{360}{Neural Architecture Search (NAS) and MobileNetV3}{subsection.11.5.4}{}}
\abx@aux@backref{205}{zoph2017_nas}{0}{360}{360}
\abx@aux@backref{206}{zoph2018_learning}{0}{360}{360}
\@writefile{toc}{\contentsline {subsubsection}{How NAS Works? Policy Gradient Optimization}{360}{section*.708}\protected@file@percent }
\newlabel{subsubsec:nas_policy_gradient}{{11.5.4}{360}{How NAS Works? Policy Gradient Optimization}{section*.708}{}}
\@writefile{toc}{\contentsline {paragraph}{What is a Policy Gradient?}{360}{section*.709}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Updating the Controller Using Policy Gradients}{360}{section*.710}\protected@file@percent }
\abx@aux@backref{207}{williams1992_simple}{0}{360}{360}
\@writefile{lof}{\contentsline {figure}{\numberline {11.26}{\ignorespaces Neural Architecture Search (NAS) The controller network samples architectures, trains child networks, evaluates them, and updates itself using policy gradient optimization}}{361}{figure.caption.711}\protected@file@percent }
\newlabel{fig:chapter11_nas_process}{{11.26}{361}{Neural Architecture Search (NAS) The controller network samples architectures, trains child networks, evaluates them, and updates itself using policy gradient optimization}{figure.caption.711}{}}
\@writefile{toc}{\contentsline {paragraph}{Searching for Reusable Block Designs}{361}{section*.712}\protected@file@percent }
\abx@aux@cite{0}{howard2019_mobilenetv3}
\abx@aux@segm{0}{0}{howard2019_mobilenetv3}
\abx@aux@cite{0}{howard2019_mobilenetv3}
\abx@aux@segm{0}{0}{howard2019_mobilenetv3}
\@writefile{lof}{\contentsline {figure}{\numberline {11.27}{\ignorespaces Examples of NAS-discovered \textbf  {Normal} and \textbf  {Reduction} cells, which are then stacked to form an overall architecture.}}{362}{figure.caption.713}\protected@file@percent }
\newlabel{fig:chapter11_nas_cells}{{11.27}{362}{Examples of NAS-discovered \textbf {Normal} and \textbf {Reduction} cells, which are then stacked to form an overall architecture}{figure.caption.713}{}}
\@writefile{toc}{\contentsline {subsubsection}{MobileNetV3: NAS-Optimized Mobile Network}{362}{section*.714}\protected@file@percent }
\newlabel{subsubsec:mobilenetv3}{{11.5.4}{362}{MobileNetV3: NAS-Optimized Mobile Network}{section*.714}{}}
\abx@aux@backref{208}{howard2019_mobilenetv3}{0}{362}{362}
\@writefile{toc}{\contentsline {subsubsection}{The MobileNetV3 Block Architecture and Refinements}{362}{section*.715}\protected@file@percent }
\newlabel{subsubsec:mobilenetv3_block}{{11.5.4}{362}{The MobileNetV3 Block Architecture and Refinements}{section*.715}{}}
\abx@aux@backref{209}{howard2019_mobilenetv3}{0}{362}{362}
\@writefile{toc}{\contentsline {paragraph}{Structure of the MobileNetV3 Block}{362}{section*.716}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Differences from Previous MobileNet Blocks}{362}{section*.717}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why is MobileNetV3 More Efficient?}{362}{section*.718}\protected@file@percent }
\newlabel{subsubsec:mobilenetv3_efficiency}{{11.5.4}{362}{Why is MobileNetV3 More Efficient?}{section*.718}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Optimizations That Improve Efficiency}{363}{section*.719}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11.6}{\ignorespaces Comparison of MobileNet variants and other efficient models on ImageNet MobileNetV3 achieves the best accuracy while maintaining low latency}}{363}{table.caption.720}\protected@file@percent }
\newlabel{tab:chapter11_mobilenetv3_comparison}{{11.6}{363}{Comparison of MobileNet variants and other efficient models on ImageNet MobileNetV3 achieves the best accuracy while maintaining low latency}{table.caption.720}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.28}{\ignorespaces Comparison between MobileNetV2 and MobileNetV3. MobileNetV3 achieves superior performance while maintaining or reducing computational cost.}}{364}{figure.caption.721}\protected@file@percent }
\newlabel{fig:chapter11_mobilenetv3_vs_mobilenetv2}{{11.28}{364}{Comparison between MobileNetV2 and MobileNetV3. MobileNetV3 achieves superior performance while maintaining or reducing computational cost}{figure.caption.721}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Computational Cost of NAS and Its Limitations}{364}{section*.722}\protected@file@percent }
\newlabel{subsubsec:nas_limitations}{{11.5.4}{364}{The Computational Cost of NAS and Its Limitations}{section*.722}{}}
\@writefile{toc}{\contentsline {paragraph}{Why is NAS Expensive?}{364}{section*.723}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.29}{\ignorespaces NAS requires training thousands of models, making it prohibitively expensive.}}{364}{figure.caption.724}\protected@file@percent }
\newlabel{fig:chapter11_nas_cost}{{11.29}{364}{NAS requires training thousands of models, making it prohibitively expensive}{figure.caption.724}{}}
\abx@aux@cite{0}{ma2018_shufflenetv2}
\abx@aux@segm{0}{0}{ma2018_shufflenetv2}
\@writefile{toc}{\contentsline {subsubsection}{ShuffleNetV2 and Practical Design Rules}{365}{section*.725}\protected@file@percent }
\newlabel{subsubsec:shufflenetv2}{{11.5.4}{365}{ShuffleNetV2 and Practical Design Rules}{section*.725}{}}
\@writefile{toc}{\contentsline {paragraph}{Why ShuffleNetV2?}{365}{section*.726}\protected@file@percent }
\abx@aux@backref{210}{ma2018_shufflenetv2}{0}{365}{365}
\@writefile{toc}{\contentsline {paragraph}{Four Key Guidelines for Practical Efficiency}{365}{section*.727}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{From ShuffleNetV1 to ShuffleNetV2}{365}{section*.728}\protected@file@percent }
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\@writefile{toc}{\contentsline {paragraph}{Performance vs.\ MobileNetV3}{366}{section*.729}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Need for Model Scaling and EfficientNets}{366}{section*.730}\protected@file@percent }
\newlabel{subsubsec:efficientnet_motivation}{{11.5.4}{366}{The Need for Model Scaling and EfficientNets}{section*.730}{}}
\@writefile{toc}{\contentsline {paragraph}{Beyond Hand-Designed and NAS-Optimized Models}{366}{section*.731}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Introducing EfficientNet}{366}{section*.732}\protected@file@percent }
\abx@aux@backref{211}{tan2019_efficientnet}{0}{366}{366}
\BKM@entry{id=405,dest={73656374696F6E2E31312E36},srcline={1202}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030305C3034305C303030435C3030306F5C3030306D5C303030705C3030306F5C303030755C3030306E5C303030645C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C3030305C3034305C303030535C303030635C303030615C3030306C5C303030695C3030306E5C30303067}
\BKM@entry{id=406,dest={73756273656374696F6E2E31312E362E31},srcline={1205}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030535C303030685C3030306F5C303030755C3030306C5C303030645C3030305C3034305C303030575C303030655C3030305C3034305C303030535C303030635C303030615C3030306C5C303030655C3030305C3034305C303030615C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}EfficientNet Compound Model Scaling}{367}{section.11.6}\protected@file@percent }
\newlabel{subsec:efficientnet}{{11.6}{367}{EfficientNet Compound Model Scaling}{section.11.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.1}How Should We Scale a Model}{367}{subsection.11.6.1}\protected@file@percent }
\newlabel{subsubsec:efficientnet_scaling}{{11.6.1}{367}{How Should We Scale a Model}{subsection.11.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.30}{\ignorespaces Different ways to scale a model: width, depth, resolution, or all jointly (compound scaling).}}{367}{figure.caption.733}\protected@file@percent }
\newlabel{fig:chapter11_model_scaling}{{11.30}{367}{Different ways to scale a model: width, depth, resolution, or all jointly (compound scaling)}{figure.caption.733}{}}
\@writefile{toc}{\contentsline {paragraph}{The Problem with Independent Scaling}{367}{section*.734}\protected@file@percent }
\BKM@entry{id=407,dest={73756273656374696F6E2E31312E362E32},srcline={1245}}{5C3337365C3337375C303030485C3030306F5C303030775C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030305C3034305C303030575C3030306F5C303030725C3030306B5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {11.31}{\ignorespaces Scaling only one dimension leads to diminishing returns; scaling all dimensions jointly yields better results.}}{368}{figure.caption.735}\protected@file@percent }
\newlabel{fig:chapter11_scaling_diminishing_returns}{{11.31}{368}{Scaling only one dimension leads to diminishing returns; scaling all dimensions jointly yields better results}{figure.caption.735}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.2}How EfficientNet Works}{368}{subsection.11.6.2}\protected@file@percent }
\newlabel{subsubsec:efficientnet_method}{{11.6.2}{368}{How EfficientNet Works}{subsection.11.6.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 1: Designing a Baseline Architecture}{368}{section*.736}\protected@file@percent }
\BKM@entry{id=408,dest={73756273656374696F6E2E31312E362E33},srcline={1311}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030695C303030735C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030305C3034305C3030304D5C3030306F5C303030725C303030655C3030305C3034305C303030455C303030665C303030665C303030655C303030635C303030745C303030695C303030765C30303065}
\@writefile{toc}{\contentsline {paragraph}{EfficientNet-B0 Architecture}{369}{section*.737}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11.7}{\ignorespaces EfficientNet-B0 baseline architecture. MBConv blocks are used throughout. These are the MobileNetV2 inverted bottleneck blocks.}}{369}{table.caption.738}\protected@file@percent }
\newlabel{tab:chapter11_efficientnet_b0_arch}{{11.7}{369}{EfficientNet-B0 baseline architecture. MBConv blocks are used throughout. These are the MobileNetV2 inverted bottleneck blocks}{table.caption.738}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 2: Finding Optimal Scaling Factors}{369}{section*.739}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 3: Scaling to Different Model Sizes}{369}{section*.740}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.3}Why is EfficientNet More Effective}{369}{subsection.11.6.3}\protected@file@percent }
\newlabel{subsubsec:efficientnet_advantages}{{11.6.3}{369}{Why is EfficientNet More Effective}{subsection.11.6.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Balanced Scaling Improves Efficiency}{369}{section*.741}\protected@file@percent }
\BKM@entry{id=409,dest={73756273656374696F6E2E31312E362E34},srcline={1339}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C30303074}
\@writefile{toc}{\contentsline {paragraph}{Comparison with MobileNetV3}{370}{section*.742}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Comparison with Other Networks}{370}{section*.743}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.32}{\ignorespaces EfficientNet achieves superior accuracy with fewer FLOPs and parameters compared to previous models.}}{370}{figure.caption.744}\protected@file@percent }
\newlabel{fig:chapter11_efficientnet_efficiency}{{11.32}{370}{EfficientNet achieves superior accuracy with fewer FLOPs and parameters compared to previous models}{figure.caption.744}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.4}Limitations of EfficientNet}{370}{subsection.11.6.4}\protected@file@percent }
\newlabel{subsubsec:efficientnet_limitations}{{11.6.4}{370}{Limitations of EfficientNet}{subsection.11.6.4}{}}
\BKM@entry{id=410,dest={73656374696F6E2E31312E37},srcline={1365}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030302D5C3030304C5C303030695C303030745C303030655C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030455C303030645C303030675C303030655C3030305C3034305C303030445C303030655C303030765C303030695C303030635C303030655C30303073}
\BKM@entry{id=411,dest={73756273656374696F6E2E31312E372E31},srcline={1368}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030302D5C3030304C5C303030695C303030745C30303065}
\abx@aux@cite{0}{tensorflow2020_efficientnetlite}
\abx@aux@segm{0}{0}{tensorflow2020_efficientnetlite}
\BKM@entry{id=412,dest={73756273656374696F6E2E31312E372E32},srcline={1375}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030302D5C3030304C5C303030695C303030745C303030655C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\BKM@entry{id=413,dest={73756273656374696F6E2E31312E372E33},srcline={1388}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304F5C303030745C303030685C303030655C303030725C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C30303073}
\abx@aux@cite{0}{tensorflow2020_efficientnetlite}
\abx@aux@segm{0}{0}{tensorflow2020_efficientnetlite}
\abx@aux@cite{0}{tensorflow2020_efficientnetlite}
\abx@aux@segm{0}{0}{tensorflow2020_efficientnetlite}
\@writefile{toc}{\contentsline {paragraph}{What’s Next? EfficientNetV2 and Beyond}{371}{section*.745}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{371}{section*.746}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.7}EfficientNet-Lite Optimizing EfficientNet for Edge Devices}{371}{section.11.7}\protected@file@percent }
\newlabel{subsec:efficientnet_lite}{{11.7}{371}{EfficientNet-Lite Optimizing EfficientNet for Edge Devices}{section.11.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.7.1}Motivation for EfficientNet-Lite}{371}{subsection.11.7.1}\protected@file@percent }
\newlabel{subsubsec:efficientnet_lite_motivation}{{11.7.1}{371}{Motivation for EfficientNet-Lite}{subsection.11.7.1}{}}
\abx@aux@backref{212}{tensorflow2020_efficientnetlite}{0}{371}{371}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.7.2}EfficientNet-Lite Architecture}{371}{subsection.11.7.2}\protected@file@percent }
\newlabel{subsubsec:efficientnet_lite_arch}{{11.7.2}{371}{EfficientNet-Lite Architecture}{subsection.11.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.7.3}Performance and Comparison with Other Models}{371}{subsection.11.7.3}\protected@file@percent }
\newlabel{subsubsec:efficientnet_lite_comparison}{{11.7.3}{371}{Performance and Comparison with Other Models}{subsection.11.7.3}{}}
\abx@aux@cite{0}{tensorflow2020_efficientnetlite}
\abx@aux@segm{0}{0}{tensorflow2020_efficientnetlite}
\abx@aux@cite{0}{tensorflow2020_efficientnetlite}
\abx@aux@segm{0}{0}{tensorflow2020_efficientnetlite}
\@writefile{lof}{\contentsline {figure}{\numberline {11.33}{\ignorespaces EfficientNet-Lite significantly outperforms MobileNetV2 in accuracy while maintaining competitive inference speed. It also runs much faster than ResNet on edge devices. Image credit TensorFlow Blog \blx@tocontentsinit {0}\cite {tensorflow2020_efficientnetlite}.}}{372}{figure.caption.747}\protected@file@percent }
\abx@aux@backref{214}{tensorflow2020_efficientnetlite}{0}{372}{372}
\newlabel{fig:chapter11_efficientnet_lite_latency_accuracy}{{11.33}{372}{EfficientNet-Lite significantly outperforms MobileNetV2 in accuracy while maintaining competitive inference speed. It also runs much faster than ResNet on edge devices. Image credit TensorFlow Blog \cite {tensorflow2020_efficientnetlite}}{figure.caption.747}{}}
\@writefile{toc}{\contentsline {paragraph}{Model Size vs. Accuracy Trade-off}{372}{section*.748}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.34}{\ignorespaces EfficientNet-Lite achieves better accuracy than MobileNetV2 at similar model sizes and outperforms ResNet in edge inference efficiency. Image credit TensorFlow Blog \blx@tocontentsinit {0}\cite {tensorflow2020_efficientnetlite}.}}{372}{figure.caption.749}\protected@file@percent }
\abx@aux@backref{216}{tensorflow2020_efficientnetlite}{0}{372}{372}
\newlabel{fig:chapter11_efficientnet_lite_model_size_accuracy}{{11.34}{372}{EfficientNet-Lite achieves better accuracy than MobileNetV2 at similar model sizes and outperforms ResNet in edge inference efficiency. Image credit TensorFlow Blog \cite {tensorflow2020_efficientnetlite}}{figure.caption.749}{}}
\BKM@entry{id=414,dest={73656374696F6E2E31312E38},srcline={1411}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C303030565C303030325C3030303A5C3030305C3034305C303030465C303030615C303030735C303030745C303030655C303030725C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C303030645C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030635C30303079}
\BKM@entry{id=415,dest={73756273656374696F6E2E31312E382E31},srcline={1414}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C303030565C30303032}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\BKM@entry{id=416,dest={73756273656374696F6E2E31312E382E32},srcline={1431}}{5C3337365C3337375C303030465C303030755C303030735C303030655C303030645C3030302D5C3030304D5C303030425C303030435C3030306F5C3030306E5C303030765C3030303A5C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030695C3030306E5C303030675C3030305C3034305C303030455C303030615C303030725C3030306C5C303030795C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {11.8}EfficientNetV2: Faster Training and Improved Efficiency}{373}{section.11.8}\protected@file@percent }
\newlabel{subsec:efficientnetv2}{{11.8}{373}{EfficientNetV2: Faster Training and Improved Efficiency}{section.11.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.1}Motivation for EfficientNetV2}{373}{subsection.11.8.1}\protected@file@percent }
\newlabel{subsubsec:efficientnetv2_motivation}{{11.8.1}{373}{Motivation for EfficientNetV2}{subsection.11.8.1}{}}
\abx@aux@backref{217}{tan2021_efficientnetv2}{0}{373}{373}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.2}Fused-MBConv: Improving Early Layers}{373}{subsection.11.8.2}\protected@file@percent }
\newlabel{subsubsec:fused_mbconv}{{11.8.2}{373}{Fused-MBConv: Improving Early Layers}{subsection.11.8.2}{}}
\BKM@entry{id=417,dest={73756273656374696F6E2E31312E382E33},srcline={1449}}{5C3337365C3337375C303030505C303030725C3030306F5C303030675C303030725C303030655C303030735C303030735C303030695C303030765C303030655C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030303A5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030535C3030306D5C303030615C3030306C5C3030306C5C303030655C303030725C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C30303073}
\BKM@entry{id=418,dest={73756273656374696F6E2E31312E382E34},srcline={1464}}{5C3337365C3337375C303030465C303030695C303030785C303030525C303030655C303030735C3030303A5C3030305C3034305C303030415C303030645C303030645C303030725C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C3030302D5C303030545C303030655C303030735C303030745C3030305C3034305C303030525C303030655C303030735C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030445C303030695C303030735C303030635C303030725C303030655C303030705C303030615C3030306E5C303030635C30303079}
\abx@aux@cite{0}{touvron2019_fixres}
\abx@aux@segm{0}{0}{touvron2019_fixres}
\@writefile{lof}{\contentsline {figure}{\numberline {11.35}{\ignorespaces Comparison of MBConv (left) and Fused-MBConv (right). Fused-MBConv replaces the separate expansion and depthwise convolution layers with a single $3\times 3$ convolution, improving efficiency in early layers.}}{374}{figure.caption.750}\protected@file@percent }
\newlabel{fig:chapter11_fused_mbconv}{{11.35}{374}{Comparison of MBConv (left) and Fused-MBConv (right). Fused-MBConv replaces the separate expansion and depthwise convolution layers with a single $3\times 3$ convolution, improving efficiency in early layers}{figure.caption.750}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.3}Progressive Learning: Efficient Training with Smaller Images}{374}{subsection.11.8.3}\protected@file@percent }
\newlabel{subsubsec:progressive_learning}{{11.8.3}{374}{Progressive Learning: Efficient Training with Smaller Images}{subsection.11.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.4}FixRes: Addressing Train-Test Resolution Discrepancy}{374}{subsection.11.8.4}\protected@file@percent }
\newlabel{subsubsec:fixres}{{11.8.4}{374}{FixRes: Addressing Train-Test Resolution Discrepancy}{subsection.11.8.4}{}}
\abx@aux@backref{218}{touvron2019_fixres}{0}{374}{374}
\@writefile{toc}{\contentsline {paragraph}{The Problem: Region of Classification (RoC) Mismatch}{374}{section*.751}\protected@file@percent }
\abx@aux@cite{0}{touvron2019_fixres}
\abx@aux@segm{0}{0}{touvron2019_fixres}
\abx@aux@cite{0}{touvron2019_fixres}
\abx@aux@segm{0}{0}{touvron2019_fixres}
\BKM@entry{id=419,dest={73756273656374696F6E2E31312E382E35},srcline={1496}}{5C3337365C3337375C3030304E5C3030306F5C3030306E5C3030302D5C303030555C3030306E5C303030695C303030665C3030306F5C303030725C3030306D5C3030305C3034305C303030535C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C303030645C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030635C30303079}
\BKM@entry{id=420,dest={73756273656374696F6E2E31312E382E36},srcline={1508}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C303030565C303030325C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {paragraph}{FixRes Solution}{375}{section*.752}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.36}{\ignorespaces FixRes visualization \blx@tocontentsinit {0}\cite {touvron2019_fixres}. The red classification region is resampled as a crop fed to the neural network. Standard augmentations can make objects larger at training time than at test time (second column). FixRes mitigates this by either reducing the train-time resolution or increasing the test-time resolution (third and fourth columns), ensuring objects appear at similar sizes in both phases.}}{375}{figure.caption.753}\protected@file@percent }
\abx@aux@backref{220}{touvron2019_fixres}{0}{375}{375}
\newlabel{fig:chapter11_fixres_visualized}{{11.36}{375}{FixRes visualization \cite {touvron2019_fixres}. The red classification region is resampled as a crop fed to the neural network. Standard augmentations can make objects larger at training time than at test time (second column). FixRes mitigates this by either reducing the train-time resolution or increasing the test-time resolution (third and fourth columns), ensuring objects appear at similar sizes in both phases}{figure.caption.753}{}}
\@writefile{toc}{\contentsline {paragraph}{Implementation in EfficientNetV2}{375}{section*.754}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.5}Non-Uniform Scaling for Improved Efficiency}{375}{subsection.11.8.5}\protected@file@percent }
\newlabel{subsubsec:nonuniform_scaling}{{11.8.5}{375}{Non-Uniform Scaling for Improved Efficiency}{subsection.11.8.5}{}}
\BKM@entry{id=421,dest={73756273656374696F6E2E31312E382E37},srcline={1538}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C303030565C303030325C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C303030565C30303031}
\BKM@entry{id=422,dest={73756273656374696F6E2E31312E382E38},srcline={1548}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C303030565C303030325C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C3030304F5C303030745C303030685C303030655C303030725C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C30303073}
\abx@aux@cite{0}{he2016_resnet}
\abx@aux@segm{0}{0}{he2016_resnet}
\abx@aux@cite{0}{he2016_resnet}
\abx@aux@segm{0}{0}{he2016_resnet}
\abx@aux@cite{0}{touvron2021_deit}
\abx@aux@segm{0}{0}{touvron2021_deit}
\abx@aux@cite{0}{howard2017_mobilenets}
\abx@aux@segm{0}{0}{howard2017_mobilenets}
\abx@aux@cite{0}{sandler2018_mobilenetv2}
\abx@aux@segm{0}{0}{sandler2018_mobilenetv2}
\abx@aux@cite{0}{howard2019_mobilenetv3}
\abx@aux@segm{0}{0}{howard2019_mobilenetv3}
\abx@aux@cite{0}{zhang2018_shufflenet}
\abx@aux@segm{0}{0}{zhang2018_shufflenet}
\abx@aux@cite{0}{ma2018_shufflenetv2}
\abx@aux@segm{0}{0}{ma2018_shufflenetv2}
\abx@aux@cite{0}{radosavovic2020_regnet}
\abx@aux@segm{0}{0}{radosavovic2020_regnet}
\abx@aux@cite{0}{radosavovic2020_regnet}
\abx@aux@segm{0}{0}{radosavovic2020_regnet}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.6}EfficientNetV2 Architecture}{376}{subsection.11.8.6}\protected@file@percent }
\newlabel{subsubsec:efficientnetv2_architecture}{{11.8.6}{376}{EfficientNetV2 Architecture}{subsection.11.8.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.8}{\ignorespaces EfficientNetV2-S architecture. Early layers use Fused-MBConv for faster training, while later layers retain MBConv for efficiency.}}{376}{table.caption.755}\protected@file@percent }
\newlabel{tab:chapter11_efficientnetv2_architecture}{{11.8}{376}{EfficientNetV2-S architecture. Early layers use Fused-MBConv for faster training, while later layers retain MBConv for efficiency}{table.caption.755}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.7}EfficientNetV2 vs. EfficientNetV1}{376}{subsection.11.8.7}\protected@file@percent }
\newlabel{subsubsec:efficientnetv2_vs_v1}{{11.8.7}{376}{EfficientNetV2 vs. EfficientNetV1}{subsection.11.8.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.8.8}EfficientNetV2 vs. Other Models}{376}{subsection.11.8.8}\protected@file@percent }
\newlabel{subsubsec:efficientnetv2_comparison}{{11.8.8}{376}{EfficientNetV2 vs. Other Models}{subsection.11.8.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Comparison in Accuracy, FLOPs, and Parameters}{377}{section*.756}\protected@file@percent }
\abx@aux@backref{221}{he2016_resnet}{0}{377}{377}
\abx@aux@backref{222}{he2016_resnet}{0}{377}{377}
\abx@aux@backref{223}{touvron2021_deit}{0}{377}{377}
\abx@aux@backref{224}{howard2017_mobilenets}{0}{377}{377}
\abx@aux@backref{225}{sandler2018_mobilenetv2}{0}{377}{377}
\abx@aux@backref{226}{howard2019_mobilenetv3}{0}{377}{377}
\abx@aux@backref{227}{zhang2018_shufflenet}{0}{377}{377}
\abx@aux@backref{228}{ma2018_shufflenetv2}{0}{377}{377}
\abx@aux@backref{229}{radosavovic2020_regnet}{0}{377}{377}
\abx@aux@backref{230}{radosavovic2020_regnet}{0}{377}{377}
\abx@aux@backref{231}{tan2019_efficientnet}{0}{377}{377}
\abx@aux@backref{232}{tan2019_efficientnet}{0}{377}{377}
\abx@aux@backref{233}{tan2019_efficientnet}{0}{377}{377}
\abx@aux@backref{234}{tan2021_efficientnetv2}{0}{377}{377}
\abx@aux@backref{235}{tan2021_efficientnetv2}{0}{377}{377}
\abx@aux@backref{236}{tan2021_efficientnetv2}{0}{377}{377}
\@writefile{lot}{\contentsline {table}{\numberline {11.9}{\ignorespaces Performance comparison of various models on ImageNet. Inference times (if available) are measured on an NVIDIA V100 GPU with FP16 precision and a batch size of 16, as reported in \blx@tocontentsinit {0}\cite {tan2021_efficientnetv2}. Entries with '--' indicate missing inference time data for those models.}}{377}{table.caption.757}\protected@file@percent }
\abx@aux@backref{238}{tan2021_efficientnetv2}{0}{377}{377}
\newlabel{tab:model_comparison}{{11.9}{377}{Performance comparison of various models on ImageNet. Inference times (if available) are measured on an NVIDIA V100 GPU with FP16 precision and a batch size of 16, as reported in \cite {tan2021_efficientnetv2}. Entries with '--' indicate missing inference time data for those models}{table.caption.757}{}}
\@writefile{toc}{\contentsline {paragraph}{Training Speed and Efficiency}{378}{section*.758}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11.10}{\ignorespaces Training efficiency comparison of EfficientNetV2 vs. EfficientNetV1. EfficientNetV2-L converges \textbf  {11× faster} while requiring fewer epochs.}}{378}{table.caption.759}\protected@file@percent }
\newlabel{tab:chapter11_efficientnetv2_training}{{11.10}{378}{Training efficiency comparison of EfficientNetV2 vs. EfficientNetV1. EfficientNetV2-L converges \textbf {11× faster} while requiring fewer epochs}{table.caption.759}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Takeaways}{378}{section*.760}\protected@file@percent }
\BKM@entry{id=423,dest={73656374696F6E2E31312E39},srcline={1621}}{5C3337365C3337375C3030304E5C303030465C3030304E5C303030655C303030745C303030735C3030303A5C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030655C303030725C3030302D5C303030465C303030725C303030655C303030655C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030745C30303073}
\BKM@entry{id=424,dest={73756273656374696F6E2E31312E392E31},srcline={1624}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030575C303030685C303030795C3030305C3034305C303030445C3030306F5C3030305C3034305C303030575C303030655C3030305C3034305C3030304E5C303030655C303030655C303030645C3030305C3034305C3030304E5C303030465C3030304E5C303030655C303030745C303030735C3030303F}
\abx@aux@cite{0}{brock2021_nfnet}
\abx@aux@segm{0}{0}{brock2021_nfnet}
\BKM@entry{id=425,dest={73756273656374696F6E2E31312E392E32},srcline={1644}}{5C3337365C3337375C303030565C303030615C303030725C303030695C303030615C3030306E5C303030635C303030655C3030305C3034305C303030455C303030785C303030705C3030306C5C3030306F5C303030735C303030695C3030306F5C3030306E5C3030305C3034305C303030575C303030695C303030745C303030685C3030306F5C303030755C303030745C3030305C3034305C303030425C303030615C303030745C303030635C303030685C3030304E5C3030306F5C303030725C3030306D}
\abx@aux@cite{0}{zhang2019_fixup}
\abx@aux@segm{0}{0}{zhang2019_fixup}
\BKM@entry{id=426,dest={73756273656374696F6E2E31312E392E33},srcline={1661}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C3030304E5C3030306F5C303030745C3030305C3034305C303030525C303030655C303030735C303030635C303030615C3030306C5C303030655C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030525C303030655C303030735C303030695C303030645C303030755C303030615C3030306C5C3030305C3034305C303030425C303030725C303030615C3030306E5C303030635C303030685C3030303F}
\@writefile{toc}{\contentsline {section}{\numberline {11.9}NFNets: Normalizer-Free ResNets}{379}{section.11.9}\protected@file@percent }
\newlabel{subsec:nfnets}{{11.9}{379}{NFNets: Normalizer-Free ResNets}{section.11.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.1}Motivation: Why Do We Need NFNets?}{379}{subsection.11.9.1}\protected@file@percent }
\newlabel{subsubsec:nfnets_motivation}{{11.9.1}{379}{Motivation: Why Do We Need NFNets?}{subsection.11.9.1}{}}
\abx@aux@backref{239}{brock2021_nfnet}{0}{379}{379}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.2}Variance Explosion Without BatchNorm}{379}{subsection.11.9.2}\protected@file@percent }
\newlabel{subsubsec:nfnets_no_bn_variance}{{11.9.2}{379}{Variance Explosion Without BatchNorm}{subsection.11.9.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Variance Scaling in Residual Networks}{379}{section*.761}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Role of Weight Initialization}{379}{section*.762}\protected@file@percent }
\abx@aux@backref{240}{zhang2019_fixup}{0}{379}{379}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.3}Why Not Rescale the Residual Branch?}{379}{subsection.11.9.3}\protected@file@percent }
\newlabel{subsubsec:residual_reparameterization}{{11.9.3}{379}{Why Not Rescale the Residual Branch?}{subsection.11.9.3}{}}
\BKM@entry{id=427,dest={73756273656374696F6E2E31312E392E34},srcline={1686}}{5C3337365C3337375C3030304E5C303030465C3030304E5C303030655C303030745C303030735C3030303A5C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030495C3030306E5C303030735C303030745C303030655C303030615C303030645C3030305C3034305C3030306F5C303030665C3030305C3034305C303030425C3030304E}
\BKM@entry{id=428,dest={73756273656374696F6E2E31312E392E35},srcline={1717}}{5C3337365C3337375C3030304E5C303030465C3030304E5C303030655C303030745C303030735C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030745C3030302D5C30303044}
\abx@aux@cite{0}{he2018_resnetd}
\abx@aux@segm{0}{0}{he2018_resnetd}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.4}NFNets: Weight Normalization Instead of BN}{380}{subsection.11.9.4}\protected@file@percent }
\newlabel{subsubsec:nfnets_weight_normalization}{{11.9.4}{380}{NFNets: Weight Normalization Instead of BN}{subsection.11.9.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Why This Works}{380}{section*.763}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Relation to Earlier Weight Standardization}{380}{section*.764}\protected@file@percent }
\BKM@entry{id=429,dest={73756273656374696F6E2E31312E392E36},srcline={1733}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C303030415C303030635C303030725C3030306F5C303030735C303030735C3030305C3034305C303030445C303030695C303030765C303030655C303030725C303030735C303030655C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C30303073}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{brock2021_nfnet}
\abx@aux@segm{0}{0}{brock2021_nfnet}
\abx@aux@cite{0}{radosavovic2020_regnet}
\abx@aux@segm{0}{0}{radosavovic2020_regnet}
\abx@aux@cite{0}{zhang2020_resnest}
\abx@aux@segm{0}{0}{zhang2020_resnest}
\abx@aux@cite{0}{vit2020_transformers}
\abx@aux@segm{0}{0}{vit2020_transformers}
\abx@aux@cite{0}{touvron2021_deit}
\abx@aux@segm{0}{0}{touvron2021_deit}
\abx@aux@cite{0}{he2016_resnet}
\abx@aux@segm{0}{0}{he2016_resnet}
\abx@aux@cite{0}{radosavovic2020_regnet}
\abx@aux@segm{0}{0}{radosavovic2020_regnet}
\abx@aux@cite{0}{brock2021_nfnet}
\abx@aux@segm{0}{0}{brock2021_nfnet}
\abx@aux@cite{0}{brock2021_nfnet}
\abx@aux@segm{0}{0}{brock2021_nfnet}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{tan2019_efficientnet}
\abx@aux@segm{0}{0}{tan2019_efficientnet}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{vit2020_transformers}
\abx@aux@segm{0}{0}{vit2020_transformers}
\abx@aux@cite{0}{touvron2021_deit}
\abx@aux@segm{0}{0}{touvron2021_deit}
\abx@aux@cite{0}{touvron2021_deit}
\abx@aux@segm{0}{0}{touvron2021_deit}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{brock2021_nfnet}
\abx@aux@segm{0}{0}{brock2021_nfnet}
\abx@aux@cite{0}{tan2021_efficientnetv2}
\abx@aux@segm{0}{0}{tan2021_efficientnetv2}
\abx@aux@cite{0}{brock2021_nfnet}
\abx@aux@segm{0}{0}{brock2021_nfnet}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.5}NFNets Architecture and ResNet-D}{381}{subsection.11.9.5}\protected@file@percent }
\newlabel{subsubsec:nfnets_resnetd}{{11.9.5}{381}{NFNets Architecture and ResNet-D}{subsection.11.9.5}{}}
\abx@aux@backref{241}{he2018_resnetd}{0}{381}{381}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.6}Comparison Across Diverse Architectures}{381}{subsection.11.9.6}\protected@file@percent }
\newlabel{subsubsec:nfnets_comparison_more}{{11.9.6}{381}{Comparison Across Diverse Architectures}{subsection.11.9.6}{}}
\abx@aux@backref{242}{brock2021_nfnet}{0}{381}{381}
\abx@aux@backref{243}{vit2020_transformers}{0}{381}{381}
\abx@aux@backref{244}{radosavovic2020_regnet}{0}{381}{381}
\abx@aux@backref{245}{tan2021_efficientnetv2}{0}{381}{381}
\abx@aux@backref{246}{touvron2021_deit}{0}{381}{381}
\abx@aux@backref{247}{zhang2020_resnest}{0}{381}{381}
\abx@aux@backref{248}{he2016_resnet}{0}{381}{381}
\abx@aux@backref{249}{radosavovic2020_regnet}{0}{381}{381}
\abx@aux@backref{250}{brock2021_nfnet}{0}{381}{381}
\abx@aux@backref{251}{brock2021_nfnet}{0}{381}{381}
\abx@aux@backref{252}{tan2019_efficientnet}{0}{381}{381}
\abx@aux@backref{253}{tan2019_efficientnet}{0}{381}{381}
\abx@aux@backref{254}{tan2021_efficientnetv2}{0}{381}{381}
\abx@aux@backref{255}{tan2021_efficientnetv2}{0}{381}{381}
\abx@aux@backref{256}{tan2021_efficientnetv2}{0}{381}{381}
\abx@aux@backref{257}{vit2020_transformers}{0}{381}{381}
\abx@aux@backref{258}{touvron2021_deit}{0}{381}{381}
\abx@aux@backref{259}{touvron2021_deit}{0}{381}{381}
\@writefile{lot}{\contentsline {table}{\numberline {11.11}{\ignorespaces \textbf  {Comparison of NFNets with leading architectures}, including RegNet, EfficientNetV2, and Vision Transformers on ImageNet. \textbf  {All models were pre-trained on ImageNet.} The \textit  {inference time} refers to single-batch inference on an NVIDIA V100 GPU in FP16 precision with batch size 16, as reported in \blx@tocontentsinit {0}\cite {tan2021_efficientnetv2,brock2021_nfnet}. The \textit  {train time} (hrs) assumes a standard TPUv3 configuration (32–64 cores). $^\dagger $ViT-B/16 at 384 input can vary in accuracy (77--79\%) depending on hyperparameters.}}{381}{table.caption.765}\protected@file@percent }
\abx@aux@backref{262}{brock2021_nfnet}{0}{381}{381}
\abx@aux@backref{263}{tan2021_efficientnetv2}{0}{381}{381}
\newlabel{tab:compare_effnetv2_main}{{11.11}{381}{\textbf {Comparison of NFNets with leading architectures}, including RegNet, EfficientNetV2, and Vision Transformers on ImageNet. \textbf {All models were pre-trained on ImageNet.} The \textit {inference time} refers to single-batch inference on an NVIDIA V100 GPU in FP16 precision with batch size 16, as reported in \cite {tan2021_efficientnetv2,brock2021_nfnet}. The \textit {train time} (hrs) assumes a standard TPUv3 configuration (32–64 cores). $^\dagger $ViT-B/16 at 384 input can vary in accuracy (77--79\%) depending on hyperparameters}{table.caption.765}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Takeaways}{381}{section*.766}\protected@file@percent }
\BKM@entry{id=430,dest={73756273656374696F6E2E31312E392E37},srcline={1781}}{5C3337365C3337375C303030465C303030755C303030725C303030745C303030685C303030655C303030725C3030305C3034305C303030525C303030655C303030615C303030645C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030525C303030655C303030735C3030306F5C303030755C303030725C303030635C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.9.7}Further Reading and Resources}{382}{subsection.11.9.7}\protected@file@percent }
\newlabel{subsubsec:nfnets_further_reading}{{11.9.7}{382}{Further Reading and Resources}{subsection.11.9.7}{}}
\BKM@entry{id=431,dest={73656374696F6E2E31312E3130},srcline={1793}}{5C3337365C3337375C303030525C303030655C303030765C303030695C303030735C303030695C303030745C303030695C3030306E5C303030675C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030745C303030735C3030303A5C3030305C3034305C303030495C3030306D5C303030705C303030725C3030306F5C303030765C303030655C303030645C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030535C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030535C303030745C303030725C303030615C303030745C303030655C303030675C303030695C303030655C30303073}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\BKM@entry{id=432,dest={73756273656374696F6E2E31312E31302E31},srcline={1798}}{5C3337365C3337375C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030455C3030306E5C303030685C303030615C3030306E5C303030635C303030655C3030306D5C303030655C3030306E5C303030745C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030745C30303073}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\BKM@entry{id=433,dest={73756273656374696F6E2E31312E31302E32},srcline={1837}}{5C3337365C3337375C303030535C303030635C303030615C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C303030745C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {section}{\numberline {11.10}Revisiting ResNets: Improved Training and Scaling Strategies}{383}{section.11.10}\protected@file@percent }
\newlabel{subsec:revisiting_resnets}{{11.10}{383}{Revisiting ResNets: Improved Training and Scaling Strategies}{section.11.10}{}}
\abx@aux@backref{264}{bello2021_revisitingresnets}{0}{383}{383}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.10.1}Training Enhancements for ResNets}{383}{subsection.11.10.1}\protected@file@percent }
\newlabel{subsubsec:resnet_training_improvements}{{11.10.1}{383}{Training Enhancements for ResNets}{subsection.11.10.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.12}{\ignorespaces \textbf  {Training improvements for ResNet-200} \blx@tocontentsinit {0}\cite {bello2021_revisitingresnets}. Applying these modifications systematically increases accuracy, demonstrating the potential of ResNet-style architectures when trained properly.}}{383}{table.caption.767}\protected@file@percent }
\abx@aux@backref{266}{bello2021_revisitingresnets}{0}{383}{383}
\newlabel{tab:resnet_training_improvements}{{11.12}{383}{\textbf {Training improvements for ResNet-200} \cite {bello2021_revisitingresnets}. Applying these modifications systematically increases accuracy, demonstrating the potential of ResNet-style architectures when trained properly}{table.caption.767}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Enhancements}{383}{section*.768}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.10.2}Scaling ResNets for Efficient Training}{383}{subsection.11.10.2}\protected@file@percent }
\newlabel{subsubsec:resnet_scaling}{{11.10.2}{383}{Scaling ResNets for Efficient Training}{subsection.11.10.2}{}}
\BKM@entry{id=434,dest={73756273656374696F6E2E31312E31302E33},srcline={1848}}{5C3337365C3337375C303030525C303030655C303030735C3030304E5C303030655C303030745C3030302D5C303030525C303030535C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030415C3030305C3034305C303030525C303030655C3030302D5C303030455C303030765C303030615C3030306C5C303030755C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.10.3}ResNet-RS vs. EfficientNet: A Re-Evaluation}{384}{subsection.11.10.3}\protected@file@percent }
\newlabel{subsubsec:chapter11_resnetrs_vs_efficientnet}{{11.10.3}{384}{ResNet-RS vs. EfficientNet: A Re-Evaluation}{subsection.11.10.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.37}{\ignorespaces \textbf  {Training time comparison:} Optimized ResNets train significantly faster than EfficientNets at the same accuracy level \blx@tocontentsinit {0}\cite {bello2021_revisitingresnets}.}}{384}{figure.caption.769}\protected@file@percent }
\abx@aux@backref{268}{bello2021_revisitingresnets}{0}{384}{384}
\newlabel{fig:chapter11_resnet_vs_efficientnet}{{11.37}{384}{\textbf {Training time comparison:} Optimized ResNets train significantly faster than EfficientNets at the same accuracy level \cite {bello2021_revisitingresnets}}{figure.caption.769}{}}
\@writefile{toc}{\contentsline {paragraph}{Comparison of ResNet-RS and EfficientNet}{384}{section*.770}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11.13}{\ignorespaces \textbf  {Comparison of ResNet-RS and EfficientNet} \blx@tocontentsinit {0}\cite {bello2021_revisitingresnets}. Despite having more parameters and FLOPs, ResNet-RS models are significantly faster in both training and inference. TPU latency is measured per training step for 1024 images on 8 TPUv3 cores, while memory usage is reported for 32 images per core, using bfloat16 precision without fusion or rematerialization.}}{384}{table.caption.771}\protected@file@percent }
\abx@aux@backref{270}{bello2021_revisitingresnets}{0}{384}{384}
\newlabel{tab:chapter11_resnetrs_vs_efficientnet}{{11.13}{384}{\textbf {Comparison of ResNet-RS and EfficientNet} \cite {bello2021_revisitingresnets}. Despite having more parameters and FLOPs, ResNet-RS models are significantly faster in both training and inference. TPU latency is measured per training step for 1024 images on 8 TPUv3 cores, while memory usage is reported for 32 images per core, using bfloat16 precision without fusion or rematerialization}{table.caption.771}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Observations}{384}{section*.772}\protected@file@percent }
\abx@aux@cite{0}{bello2021_revisitingresnets}
\abx@aux@segm{0}{0}{bello2021_revisitingresnets}
\BKM@entry{id=435,dest={73656374696F6E2E31312E3131},srcline={1891}}{5C3337365C3337375C303030525C303030655C303030675C3030304E5C303030655C303030745C303030735C3030303A5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C3030305C3034305C303030445C303030655C303030735C303030695C303030675C3030306E5C3030305C3034305C303030535C303030705C303030615C303030635C303030655C30303073}
\abx@aux@cite{0}{radosavovic2020_regnet}
\abx@aux@segm{0}{0}{radosavovic2020_regnet}
\BKM@entry{id=436,dest={73756273656374696F6E2E31312E31312E31},srcline={1898}}{5C3337365C3337375C303030525C303030655C303030675C3030304E5C303030655C303030745C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{385}{section*.773}\protected@file@percent }
\abx@aux@backref{271}{bello2021_revisitingresnets}{0}{385}{385}
\@writefile{toc}{\contentsline {section}{\numberline {11.11}RegNets: Network Design Spaces}{385}{section.11.11}\protected@file@percent }
\newlabel{subsec:regnets}{{11.11}{385}{RegNets: Network Design Spaces}{section.11.11}{}}
\abx@aux@backref{272}{radosavovic2020_regnet}{0}{385}{385}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.11.1}RegNet Architecture}{385}{subsection.11.11.1}\protected@file@percent }
\newlabel{subsubsec:regnet_architecture}{{11.11.1}{385}{RegNet Architecture}{subsection.11.11.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.38}{\ignorespaces \textbf  {RegNet architecture}: A simple backbone with a stem, four-stage body, and head. Each stage consists of multiple blocks with defined parameters. These building blocks will allows us to construct architectures at different sizes that are efficient \& producing competitive accuracy.}}{385}{figure.caption.774}\protected@file@percent }
\newlabel{fig:chapter11_regnet_architecture}{{11.38}{385}{\textbf {RegNet architecture}: A simple backbone with a stem, four-stage body, and head. Each stage consists of multiple blocks with defined parameters. These building blocks will allows us to construct architectures at different sizes that are efficient \& producing competitive accuracy}{figure.caption.774}{}}
\BKM@entry{id=437,dest={73756273656374696F6E2E31312E31312E32},srcline={1934}}{5C3337365C3337375C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030445C303030655C303030735C303030695C303030675C3030306E5C3030305C3034305C303030535C303030705C303030615C303030635C30303065}
\abx@aux@cite{0}{radosavovic2020_regnet}
\abx@aux@segm{0}{0}{radosavovic2020_regnet}
\@writefile{toc}{\contentsline {paragraph}{Block Design: Generalizing ResNeXt}{386}{section*.775}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.39}{\ignorespaces \textbf  {RegNet block structure}: A generalization of ResNeXt, where each stage is defined by four parameters only.}}{386}{figure.caption.776}\protected@file@percent }
\newlabel{fig:chapter11_regnet_block}{{11.39}{386}{\textbf {RegNet block structure}: A generalization of ResNeXt, where each stage is defined by four parameters only}{figure.caption.776}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.11.2}Optimizing the Design Space}{386}{subsection.11.11.2}\protected@file@percent }
\newlabel{subsubsec:regnet_optimization}{{11.11.2}{386}{Optimizing the Design Space}{subsection.11.11.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Random Sampling and Performance Trends}{386}{section*.777}\protected@file@percent }
\abx@aux@backref{273}{radosavovic2020_regnet}{0}{386}{386}
\@writefile{toc}{\contentsline {paragraph}{Reducing the Design Space}{387}{section*.778}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Final Six Parameters}{387}{section*.779}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.40}{\ignorespaces \textbf  {RegNet design space optimization}: The initial 16 parameters were reduced to 6, enabling efficient architecture search.}}{387}{figure.caption.780}\protected@file@percent }
\newlabel{fig:chapter11_regnet_design_space}{{11.40}{387}{\textbf {RegNet design space optimization}: The initial 16 parameters were reduced to 6, enabling efficient architecture search}{figure.caption.780}{}}
\@writefile{toc}{\contentsline {paragraph}{Why This Works}{387}{section*.781}\protected@file@percent }
\BKM@entry{id=438,dest={73756273656374696F6E2E31312E31312E33},srcline={1993}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030415C303030705C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{388}{section*.782}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.11.3}Performance and Applications}{388}{subsection.11.11.3}\protected@file@percent }
\newlabel{subsubsec:regnet_performance}{{11.11.3}{388}{Performance and Applications}{subsection.11.11.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.41}{\ignorespaces RegNet models match EfficientNet accuracy but train up to 5$\times $ faster per iteration.}}{388}{figure.caption.783}\protected@file@percent }
\newlabel{fig:chapter11_regnet_vs_efficientnet}{{11.41}{388}{RegNet models match EfficientNet accuracy but train up to 5$\times $ faster per iteration}{figure.caption.783}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.42}{\ignorespaces \textbf  {RegNet in real-world deployment}: Tesla uses RegNet-based architectures for processing inputs from multiple cameras.}}{389}{figure.caption.784}\protected@file@percent }
\newlabel{fig:chapter11_regnet_tesla}{{11.42}{389}{\textbf {RegNet in real-world deployment}: Tesla uses RegNet-based architectures for processing inputs from multiple cameras}{figure.caption.784}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Takeaways}{389}{section*.785}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{389}{section*.786}\protected@file@percent }
\BKM@entry{id=439,dest={73656374696F6E2E31312E3132},srcline={2030}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C303030795C3030305C3034305C3030306F5C303030665C3030305C3034305C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {11.12}Summary of Efficient Network Architectures}{390}{section.11.12}\protected@file@percent }
\newlabel{subsec:chapter11_summary}{{11.12}{390}{Summary of Efficient Network Architectures}{section.11.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{Grouped Convolutions and ResNeXt}{390}{section*.787}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Squeeze-and-Excitation (SE) Blocks}{390}{section*.788}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{MobileNet and ShuffleNet: Depthwise Separable Convolutions and Channel Mixing}{390}{section*.789}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{MobileNetV2: Inverted Residual Blocks}{390}{section*.790}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{NAS and MobileNetV3, ShuffleNetV2 Insights}{390}{section*.791}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{EfficientNet: Compound Scaling}{390}{section*.792}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{EfficientNet-Lite and EfficientNetV2}{391}{section*.793}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{NFNets: BN-Free Training}{391}{section*.794}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Revisiting ResNets: Scaling and Training Recipes}{391}{section*.795}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{RegNets: Optimizing the Design Space}{391}{section*.796}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Key Takeaways}{391}{section*.797}\protected@file@percent }
\BKM@entry{id=440,dest={636861707465722E3132},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030325C3030303A5C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030535C3030306F5C303030665C303030745C303030775C303030615C303030725C30303065}
\BKM@entry{id=441,dest={73656374696F6E2E31322E31},srcline={10}}{5C3337365C3337375C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030465C303030725C303030615C3030306D5C303030655C303030775C3030306F5C303030725C3030306B5C303030735C3030303A5C3030305C3034305C303030455C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030615C3030306E5C303030645C303030735C303030635C303030615C303030705C30303065}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Lecture 12: Deep Learning Software}{392}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@11}}
\ttl@writefile{ptc}{\ttl@starttoc{default@12}}
\pgfsyspdfmark {pgfid32}{0}{52099153}
\pgfsyspdfmark {pgfid31}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Deep Learning Frameworks: Evolution and Landscape}{392}{section.12.1}\protected@file@percent }
\newlabel{sec:chapter12_frameworks}{{12.1}{392}{Deep Learning Frameworks: Evolution and Landscape}{section.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Overview of major deep learning frameworks and their affiliations.}}{392}{figure.caption.798}\protected@file@percent }
\newlabel{fig:chapter12_frameworks}{{12.1}{392}{Overview of major deep learning frameworks and their affiliations}{figure.caption.798}{}}
\BKM@entry{id=442,dest={73756273656374696F6E2E31322E312E31},srcline={35}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030505C303030755C303030725C303030705C3030306F5C303030735C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030465C303030725C303030615C3030306D5C303030655C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=443,dest={73756273656374696F6E2E31322E312E32},srcline={46}}{5C3337365C3337375C303030525C303030655C303030635C303030615C3030306C5C3030306C5C3030303A5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.1}The Purpose of Deep Learning Frameworks}{393}{subsection.12.1.1}\protected@file@percent }
\newlabel{subsec:chapter12_purpose}{{12.1.1}{393}{The Purpose of Deep Learning Frameworks}{subsection.12.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.2}Recall: Computational Graphs}{393}{subsection.12.1.2}\protected@file@percent }
\newlabel{subsubsec:chapter12_computational_graphs}{{12.1.2}{393}{Recall: Computational Graphs}{subsection.12.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces \textbf  {Computational graphs in deep learning.} These graphs define the sequence of operations for training and inference, enabling automatic differentiation and optimization.}}{393}{figure.caption.799}\protected@file@percent }
\newlabel{fig:chapter12_computational_graphs}{{12.2}{393}{\textbf {Computational graphs in deep learning.} These graphs define the sequence of operations for training and inference, enabling automatic differentiation and optimization}{figure.caption.799}{}}
\BKM@entry{id=444,dest={73656374696F6E2E31322E32},srcline={72}}{5C3337365C3337375C303030505C303030795C303030545C3030306F5C303030725C303030635C303030685C3030303A5C3030305C3034305C303030465C303030755C3030306E5C303030645C303030615C3030306D5C303030655C3030306E5C303030745C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306E5C303030635C303030655C303030705C303030745C30303073}
\BKM@entry{id=445,dest={73756273656374696F6E2E31322E322E31},srcline={83}}{5C3337365C3337375C303030545C303030655C3030306E5C303030735C3030306F5C303030725C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030425C303030615C303030735C303030695C303030635C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}PyTorch: Fundamental Concepts}{394}{section.12.2}\protected@file@percent }
\newlabel{subsec:chapter12_pytorch}{{12.2}{394}{PyTorch: Fundamental Concepts}{section.12.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.1}Tensors and Basic Computation}{394}{subsection.12.2.1}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_tensors}{{12.2.1}{394}{Tensors and Basic Computation}{subsection.12.2.1}{}}
\BKM@entry{id=446,dest={73756273656374696F6E2E31322E322E32},srcline={123}}{5C3337365C3337375C303030415C303030755C303030745C3030306F5C303030675C303030725C303030615C303030645C3030303A5C3030305C3034305C303030415C303030755C303030745C3030306F5C3030306D5C303030615C303030745C303030695C303030635C3030305C3034305C303030445C303030695C303030665C303030665C303030655C303030725C303030655C3030306E5C303030745C303030695C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=447,dest={73756273656374696F6E2E31322E322E33},srcline={163}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304D5C3030306F5C303030645C303030755C3030306C5C303030615C303030725C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.2}Autograd: Automatic Differentiation}{395}{subsection.12.2.2}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_autograd}{{12.2.2}{395}{Autograd: Automatic Differentiation}{subsection.12.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.3}Computational Graphs and Modular Computation}{396}{subsection.12.2.3}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_graph}{{12.2.3}{396}{Computational Graphs and Modular Computation}{subsection.12.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Building the Computational Graph}{396}{section*.800}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_graph_building}{{12.2.3}{396}{Building the Computational Graph}{section*.800}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces \textbf  {First computational node in the graph.} The matrix multiplication \texttt  {x.mm(w1)} creates the first node in the computational graph.}}{396}{figure.caption.801}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_mm_graph}{{12.3}{396}{\textbf {First computational node in the graph.} The matrix multiplication \texttt {x.mm(w1)} creates the first node in the computational graph}{figure.caption.801}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces \textbf  {ReLU activation node.} The ReLU function introduces a non-linearity while maintaining the computational graph structure.}}{397}{figure.caption.802}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_relu_graph}{{12.4}{397}{\textbf {ReLU activation node.} The ReLU function introduces a non-linearity while maintaining the computational graph structure}{figure.caption.802}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces \textbf  {Final matrix multiplication node.} The output prediction \texttt  {y\_pred} is produced by matrix multiplication with \texttt  {w2}.}}{397}{figure.caption.803}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_mm2_graph}{{12.5}{397}{\textbf {Final matrix multiplication node.} The output prediction \texttt {y\_pred} is produced by matrix multiplication with \texttt {w2}}{figure.caption.803}{}}
\@writefile{toc}{\contentsline {subsubsection}{Loss Computation and Backpropagation}{397}{section*.804}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_loss_backprop}{{12.2.3}{397}{Loss Computation and Backpropagation}{section*.804}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces \textbf  {Loss computation node.} The final loss is computed as a scalar output in the computational graph, allowing backpropagation to all inputs requiring gradients.}}{398}{figure.caption.805}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_loss_graph}{{12.6}{398}{\textbf {Loss computation node.} The final loss is computed as a scalar output in the computational graph, allowing backpropagation to all inputs requiring gradients}{figure.caption.805}{}}
\@writefile{toc}{\contentsline {subsubsection}{Extending Computational Graphs with Python Functions}{398}{section*.806}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_modular}{{12.2.3}{398}{Extending Computational Graphs with Python Functions}{section*.806}{}}
\@writefile{toc}{\contentsline {subsubsection}{Custom Autograd Functions}{399}{section*.807}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_custom_autograd}{{12.2.3}{399}{Custom Autograd Functions}{section*.807}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces \textbf  {Custom autograd function for sigmoid.} This method creates a single node in the computational graph (on the right) instead of multiple primitive operations (on the left).}}{399}{figure.caption.808}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_custom_autograd}{{12.7}{399}{\textbf {Custom autograd function for sigmoid.} This method creates a single node in the computational graph (on the right) instead of multiple primitive operations (on the left)}{figure.caption.808}{}}
\BKM@entry{id=448,dest={73756273656374696F6E2E31322E322E34},srcline={331}}{5C3337365C3337375C303030485C303030695C303030675C303030685C3030302D5C3030304C5C303030655C303030765C303030655C3030306C5C3030305C3034305C303030415C303030625C303030735C303030745C303030725C303030615C303030635C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C303030795C303030545C3030306F5C303030725C303030635C303030685C3030303A5C3030305C3034305C303030745C3030306F5C303030725C303030635C303030685C3030302E5C3030306E5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {subsubsection}{Summary: Backpropagation and Graph Optimization}{400}{section*.809}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_graph_summary}{{12.2.3}{400}{Summary: Backpropagation and Graph Optimization}{section*.809}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.4}High-Level Abstractions in PyTorch: \texttt  {torch.nn} and Optimizers}{400}{subsection.12.2.4}\protected@file@percent }
\newlabel{subsec:chapter12_pytorch_nn}{{12.2.4}{400}{High-Level Abstractions in PyTorch: \texttt {torch.nn} and Optimizers}{subsection.12.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Using \texttt  {torch.nn.Sequential}}{400}{section*.810}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_sequential}{{12.2.4}{400}{Using \texttt {torch.nn.Sequential}}{section*.810}{}}
\@writefile{toc}{\contentsline {subsubsection}{Using Optimizers: Automating Gradient Descent}{401}{section*.811}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_optimizers}{{12.2.4}{401}{Using Optimizers: Automating Gradient Descent}{section*.811}{}}
\BKM@entry{id=449,dest={73756273656374696F6E2E31322E322E35},srcline={466}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030625C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030435C303030755C303030735C303030745C3030306F5C3030306D5C3030305C3034305C3030304D5C3030306F5C303030645C303030755C3030306C5C303030655C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030535C303030655C303030715C303030755C303030655C3030306E5C303030745C303030695C303030615C3030306C5C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C30303073}
\@writefile{toc}{\contentsline {subsubsection}{Defining Custom \texttt  {nn.Module} Subclasses}{402}{section*.812}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_nn_module}{{12.2.4}{402}{Defining Custom \texttt {nn.Module} Subclasses}{section*.812}{}}
\@writefile{toc}{\contentsline {subsubsection}{Key Takeaways}{402}{section*.813}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.5}Combining Custom Modules with Sequential Models}{402}{subsection.12.2.5}\protected@file@percent }
\newlabel{subsec:chapter12_pytorch_custom_sequential}{{12.2.5}{402}{Combining Custom Modules with Sequential Models}{subsection.12.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example: Parallel Block}{403}{section*.814}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_parallel_block}{{12.2.5}{403}{Example: Parallel Block}{section*.814}{}}
\BKM@entry{id=450,dest={73756273656374696F6E2E31322E322E36},srcline={533}}{5C3337365C3337375C303030455C303030665C303030665C303030695C303030635C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030615C303030745C303030615C3030305C3034305C3030304C5C3030306F5C303030615C303030645C303030695C3030306E5C303030675C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030745C3030306F5C303030725C303030635C303030685C3030302E5C303030755C303030745C303030695C3030306C5C303030735C3030302E5C303030645C303030615C303030745C30303061}
\@writefile{lof}{\contentsline {figure}{\numberline {12.8}{\ignorespaces \textbf  {ParallelBlock module design:} The implementation of the \texttt  {ParallelBlock} and its corresponding computational graph visualization.}}{404}{figure.caption.815}\protected@file@percent }
\newlabel{fig:chapter12_parallel_block}{{12.8}{404}{\textbf {ParallelBlock module design:} The implementation of the \texttt {ParallelBlock} and its corresponding computational graph visualization}{figure.caption.815}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.9}{\ignorespaces \textbf  {Stacking multiple \texttt  {ParallelBlock} instances in a Sequential model.} The left side of the figure shows the computational graph produced.}}{404}{figure.caption.816}\protected@file@percent }
\newlabel{fig:chapter12_parallel_block_graph}{{12.9}{404}{\textbf {Stacking multiple \texttt {ParallelBlock} instances in a Sequential model.} The left side of the figure shows the computational graph produced}{figure.caption.816}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.6}Efficient Data Loading with \texttt  {torch.utils.data}}{404}{subsection.12.2.6}\protected@file@percent }
\newlabel{subsec:chapter12_pytorch_dataloader}{{12.2.6}{404}{Efficient Data Loading with \texttt {torch.utils.data}}{subsection.12.2.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example: Using \texttt  {DataLoader} for Mini-batching}{404}{section*.817}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_dataloader_example}{{12.2.6}{404}{Example: Using \texttt {DataLoader} for Mini-batching}{section*.817}{}}
\BKM@entry{id=451,dest={73756273656374696F6E2E31322E322E37},srcline={573}}{5C3337365C3337375C303030555C303030735C303030695C3030306E5C303030675C3030305C3034305C303030505C303030725C303030655C303030745C303030725C303030615C303030695C3030306E5C303030655C303030645C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030545C3030306F5C303030725C303030635C303030685C303030565C303030695C303030735C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.7}Using Pretrained Models with TorchVision}{405}{subsection.12.2.7}\protected@file@percent }
\newlabel{subsec:chapter12_pytorch_torchvision}{{12.2.7}{405}{Using Pretrained Models with TorchVision}{subsection.12.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Key Takeaways}{405}{section*.818}\protected@file@percent }
\BKM@entry{id=452,dest={73656374696F6E2E31322E33},srcline={601}}{5C3337365C3337375C303030445C303030795C3030306E5C303030615C3030306D5C303030695C303030635C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C303030795C303030545C3030306F5C303030725C303030635C30303068}
\BKM@entry{id=453,dest={73756273656374696F6E2E31322E332E31},srcline={622}}{5C3337365C3337375C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304A5C303030755C303030735C303030745C3030302D5C303030695C3030306E5C3030302D5C303030545C303030695C3030306D5C303030655C3030305C3034305C3030305C3035305C3030304A5C303030495C303030545C3030305C3035315C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030695C3030306C5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Dynamic vs. Static Computational Graphs in PyTorch}{406}{section.12.3}\protected@file@percent }
\newlabel{subsec:chapter12_pytorch_dynamic_vs_static}{{12.3}{406}{Dynamic vs. Static Computational Graphs in PyTorch}{section.12.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example: Dynamic Graph Construction}{406}{section*.819}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_dynamic_example}{{12.3}{406}{Example: Dynamic Graph Construction}{section*.819}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.10}{\ignorespaces \textbf  {Example of a dynamically constructed graph:} The model structure changes at each iteration based on previous loss values.}}{406}{figure.caption.820}\protected@file@percent }
\newlabel{fig:chapter12_dynamic_graph}{{12.10}{406}{\textbf {Example of a dynamically constructed graph:} The model structure changes at each iteration based on previous loss values}{figure.caption.820}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.1}Static Graphs and Just-in-Time (JIT) Compilation}{406}{subsection.12.3.1}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_static_graphs}{{12.3.1}{406}{Static Graphs and Just-in-Time (JIT) Compilation}{subsection.12.3.1}{}}
\BKM@entry{id=454,dest={73756273656374696F6E2E31322E332E32},srcline={633}}{5C3337365C3337375C303030555C303030735C303030695C3030306E5C303030675C3030305C3034305C3030304A5C303030495C303030545C3030305C3034305C303030745C3030306F5C3030305C3034305C303030435C303030725C303030655C303030615C303030745C303030655C3030305C3034305C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030705C303030685C30303073}
\BKM@entry{id=455,dest={73756273656374696F6E2E31322E332E33},srcline={664}}{5C3337365C3337375C303030485C303030615C3030306E5C303030645C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306E5C303030645C303030695C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030705C303030685C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.2}Using JIT to Create Static Graphs}{407}{subsection.12.3.2}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_jit}{{12.3.2}{407}{Using JIT to Create Static Graphs}{subsection.12.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.11}{\ignorespaces \textbf  {TorchScript:} Using JIT compilation to convert PyTorch models into static graphs for optimization.}}{407}{figure.caption.821}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_jit}{{12.11}{407}{\textbf {TorchScript:} Using JIT compilation to convert PyTorch models into static graphs for optimization}{figure.caption.821}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.3}Handling Conditionals in Static Graphs}{407}{subsection.12.3.3}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_jit_conditionals}{{12.3.3}{407}{Handling Conditionals in Static Graphs}{subsection.12.3.3}{}}
\BKM@entry{id=456,dest={73756273656374696F6E2E31322E332E34},srcline={678}}{5C3337365C3337375C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304A5C303030495C30303054}
\BKM@entry{id=457,dest={73756273656374696F6E2E31322E332E35},srcline={692}}{5C3337365C3337375C303030425C303030655C3030306E5C303030655C303030665C303030695C303030745C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030705C303030685C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {12.12}{\ignorespaces \textbf  {Conditionals in static graphs:} JIT inserts a conditional node to handle different execution paths.}}{408}{figure.caption.822}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_jit_conditionals}{{12.12}{408}{\textbf {Conditionals in static graphs:} JIT inserts a conditional node to handle different execution paths}{figure.caption.822}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.4}Optimizing Computation Graphs with JIT}{408}{subsection.12.3.4}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_graph_optimization}{{12.3.4}{408}{Optimizing Computation Graphs with JIT}{subsection.12.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.13}{\ignorespaces \textbf  {Operation fusion in static graphs:} Layers such as Conv + ReLU are combined into a single operation to improve efficiency.}}{408}{figure.caption.823}\protected@file@percent }
\newlabel{fig:chapter12_pytorch_fusion}{{12.13}{408}{\textbf {Operation fusion in static graphs:} Layers such as Conv + ReLU are combined into a single operation to improve efficiency}{figure.caption.823}{}}
\BKM@entry{id=458,dest={73756273656374696F6E2E31322E332E36},srcline={709}}{5C3337365C3337375C303030575C303030685C303030655C3030306E5C3030305C3034305C303030415C303030725C303030655C3030305C3034305C303030445C303030795C3030306E5C303030615C3030306D5C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C3030304E5C303030655C303030635C303030655C303030735C303030735C303030615C303030725C303030795C3030303F}
\abx@aux@cite{0}{johnson2017_infering}
\abx@aux@segm{0}{0}{johnson2017_infering}
\BKM@entry{id=459,dest={73656374696F6E2E31322E34},srcline={722}}{5C3337365C3337375C303030545C303030655C3030306E5C303030735C3030306F5C303030725C303030465C3030306C5C3030306F5C303030775C3030303A5C3030305C3034305C303030445C303030795C3030306E5C303030615C3030306D5C303030695C303030635C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C30303073}
\BKM@entry{id=460,dest={73756273656374696F6E2E31322E342E31},srcline={727}}{5C3337365C3337375C303030445C303030655C303030665C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030545C303030655C3030306E5C303030735C3030306F5C303030725C303030465C3030306C5C3030306F5C303030775C3030305C3034305C303030325C3030302E5C30303030}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.5}Benefits and Limitations of Static Graphs}{409}{subsection.12.3.5}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_static_benefits_challenges}{{12.3.5}{409}{Benefits and Limitations of Static Graphs}{subsection.12.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.6}When Are Dynamic Graphs Necessary?}{409}{subsection.12.3.6}\protected@file@percent }
\newlabel{subsubsec:chapter12_pytorch_dynamic_needed}{{12.3.6}{409}{When Are Dynamic Graphs Necessary?}{subsection.12.3.6}{}}
\abx@aux@backref{274}{johnson2017_infering}{0}{409}{409}
\@writefile{toc}{\contentsline {section}{\numberline {12.4}TensorFlow: Dynamic and Static Computational Graphs}{409}{section.12.4}\protected@file@percent }
\newlabel{subsec:chapter12_tensorflow}{{12.4}{409}{TensorFlow: Dynamic and Static Computational Graphs}{section.12.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.4.1}Defining Computational Graphs in TensorFlow 2.0}{409}{subsection.12.4.1}\protected@file@percent }
\newlabel{subsubsec:chapter12_tensorflow_dynamic}{{12.4.1}{409}{Defining Computational Graphs in TensorFlow 2.0}{subsection.12.4.1}{}}
\BKM@entry{id=461,dest={73756273656374696F6E2E31322E342E32},srcline={757}}{5C3337365C3337375C303030535C303030745C303030615C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030705C303030685C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030745C303030665C3030302E5C303030665C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=462,dest={73656374696F6E2E31322E35},srcline={781}}{5C3337365C3337375C3030304B5C303030655C303030725C303030615C303030735C3030303A5C3030305C3034305C303030485C303030695C303030675C303030685C3030302D5C3030304C5C303030655C303030765C303030655C3030306C5C3030305C3034305C303030415C303030505C303030495C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030545C303030655C3030306E5C303030735C3030306F5C303030725C303030465C3030306C5C3030306F5C30303077}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.4.2}Static Graphs with \texttt  {tf.function}}{410}{subsection.12.4.2}\protected@file@percent }
\newlabel{subsubsec:chapter12_tensorflow_static}{{12.4.2}{410}{Static Graphs with \texttt {tf.function}}{subsection.12.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}Keras: High-Level API for TensorFlow}{410}{section.12.5}\protected@file@percent }
\newlabel{subsec:chapter12_keras}{{12.5}{410}{Keras: High-Level API for TensorFlow}{section.12.5}{}}
\BKM@entry{id=463,dest={73656374696F6E2E31322E36},srcline={834}}{5C3337365C3337375C303030545C303030655C3030306E5C303030735C3030306F5C303030725C303030425C3030306F5C303030615C303030725C303030645C3030303A5C3030305C3034305C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304D5C303030655C303030745C303030725C303030695C303030635C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}TensorBoard: Visualizing Training Metrics}{411}{section.12.6}\protected@file@percent }
\newlabel{subsec:chapter12_tensorboard}{{12.6}{411}{TensorBoard: Visualizing Training Metrics}{section.12.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.14}{\ignorespaces \textbf  {TensorBoard visualization:} Loss curves and weight distributions during training.}}{411}{figure.caption.824}\protected@file@percent }
\newlabel{fig:chapter12_tensorboard}{{12.14}{411}{\textbf {TensorBoard visualization:} Loss curves and weight distributions during training}{figure.caption.824}{}}
\BKM@entry{id=464,dest={73656374696F6E2E31322E37},srcline={855}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030303A5C3030305C3034305C303030505C303030795C303030545C3030306F5C303030725C303030635C303030685C3030305C3034305C303030765C303030735C3030302E5C3030305C3034305C303030545C303030655C3030306E5C303030735C3030306F5C303030725C303030465C3030306C5C3030306F5C30303077}
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Comparison: PyTorch vs. TensorFlow}{412}{section.12.7}\protected@file@percent }
\newlabel{subsec:chapter12_comparison}{{12.7}{412}{Comparison: PyTorch vs. TensorFlow}{section.12.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{412}{section*.825}\protected@file@percent }
\BKM@entry{id=465,dest={636861707465722E3133},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030335C3030303A5C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=466,dest={73656374696F6E2E31332E31},srcline={10}}{5C3337365C3337375C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=467,dest={73756273656374696F6E2E31332E312E31},srcline={17}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030615C303030735C3030306B5C303030735C3030303A5C3030305C3034305C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Lecture 13: Object Detection}{413}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@12}}
\ttl@writefile{ptc}{\ttl@starttoc{default@13}}
\pgfsyspdfmark {pgfid62}{0}{52099153}
\pgfsyspdfmark {pgfid61}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Object Detection: Introduction}{413}{section.13.1}\protected@file@percent }
\newlabel{subsec:chapter13_intro}{{13.1}{413}{Object Detection: Introduction}{section.13.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.1}Computer Vision Tasks: Beyond Classification}{413}{subsection.13.1.1}\protected@file@percent }
\newlabel{subsubsec:chapter13_cv_tasks}{{13.1.1}{413}{Computer Vision Tasks: Beyond Classification}{subsection.13.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces \textbf  {Comparison of common computer vision tasks.}}}{413}{figure.caption.826}\protected@file@percent }
\newlabel{fig:chapter13_cv_tasks}{{13.1}{413}{\textbf {Comparison of common computer vision tasks.}}{figure.caption.826}{}}
\BKM@entry{id=468,dest={73756273656374696F6E2E31332E312E32},srcline={31}}{5C3337365C3337375C303030575C303030685C303030615C303030745C3030305C3034305C303030695C303030735C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030303F}
\BKM@entry{id=469,dest={73756273656374696F6E2E31332E312E33},srcline={40}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=470,dest={73756273656374696F6E2E31332E312E34},srcline={52}}{5C3337365C3337375C303030425C3030306F5C303030755C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306F5C303030785C303030655C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030735C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030765C303030655C303030725C3030305C3034305C303030555C3030306E5C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030495C3030306F5C303030555C3030305C303531}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.2}What is Object Detection?}{414}{subsection.13.1.2}\protected@file@percent }
\newlabel{subsubsec:chapter13_what_is_detection}{{13.1.2}{414}{What is Object Detection?}{subsection.13.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.3}Challenges in Object Detection}{414}{subsection.13.1.3}\protected@file@percent }
\newlabel{subsubsec:chapter13_detection_challenges}{{13.1.3}{414}{Challenges in Object Detection}{subsection.13.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.4}Bounding Boxes and Intersection over Union (IoU)}{414}{subsection.13.1.4}\protected@file@percent }
\newlabel{subsubsec:chapter13_bboxes_iou}{{13.1.4}{414}{Bounding Boxes and Intersection over Union (IoU)}{subsection.13.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces \textbf  {Axis-aligned vs. Oriented bounding boxes.} Although an oriented box provides a more accurate fit, most models predict axis-aligned boxes for simplicity.}}{414}{figure.caption.827}\protected@file@percent }
\newlabel{fig:chapter13_bbox_orientation}{{13.2}{414}{\textbf {Axis-aligned vs. Oriented bounding boxes.} Although an oriented box provides a more accurate fit, most models predict axis-aligned boxes for simplicity}{figure.caption.827}{}}
\BKM@entry{id=471,dest={73756273656374696F6E2E31332E312E35},srcline={77}}{5C3337365C3337375C303030455C303030765C303030615C3030306C5C303030755C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306F5C303030755C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306F5C303030785C303030655C303030735C3030303A5C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030735C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030765C303030655C303030725C3030305C3034305C303030555C3030306E5C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030495C3030306F5C303030555C3030305C303531}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces \textbf  {Modal vs. Amodal bounding boxes.} The blue box (modal) covers only the visible portion of the cat, while the green box (amodal) extends to include occluded regions.}}{415}{figure.caption.828}\protected@file@percent }
\newlabel{fig:chapter13_modal_amodal}{{13.3}{415}{\textbf {Modal vs. Amodal bounding boxes.} The blue box (modal) covers only the visible portion of the cat, while the green box (amodal) extends to include occluded regions}{figure.caption.828}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.5}Evaluating Bounding Boxes: Intersection over Union (IoU)}{415}{subsection.13.1.5}\protected@file@percent }
\newlabel{subsubsec:chapter13_iou}{{13.1.5}{415}{Evaluating Bounding Boxes: Intersection over Union (IoU)}{subsection.13.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces \textbf  {Intersection over Union (IoU).} Left: Intersection of predicted and ground-truth bounding boxes (orange). Right: Union of predicted and ground-truth boxes (purple).}}{415}{figure.caption.829}\protected@file@percent }
\newlabel{fig:chapter13_iou_definition}{{13.4}{415}{\textbf {Intersection over Union (IoU).} Left: Intersection of predicted and ground-truth bounding boxes (orange). Right: Union of predicted and ground-truth boxes (purple)}{figure.caption.829}{}}
\BKM@entry{id=472,dest={73756273656374696F6E2E31332E312E36},srcline={112}}{5C3337365C3337375C3030304D5C303030755C3030306C5C303030745C303030695C303030745C303030615C303030735C3030306B5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030303A5C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C303030695C303030665C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030525C303030655C303030675C303030725C303030655C303030735C303030735C303030695C3030306F5C3030306E}
\BKM@entry{id=473,dest={73656374696F6E2E31332E32},srcline={128}}{5C3337365C3337375C303030465C303030725C3030306F5C3030306D5C3030305C3034305C303030535C303030695C3030306E5C303030675C3030306C5C303030655C3030302D5C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030745C3030306F5C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces \textbf  {Intersection over Union (IoU) Examples.} Left: IoU \(\sim 0.5\) (acceptable). Middle: IoU \(\sim 0.7\) (good). Right: IoU \(\sim 0.9\) (almost perfect).}}{416}{figure.caption.830}\protected@file@percent }
\newlabel{fig:chapter13_iou_examples}{{13.5}{416}{\textbf {Intersection over Union (IoU) Examples.} Left: IoU \(\sim 0.5\) (acceptable). Middle: IoU \(\sim 0.7\) (good). Right: IoU \(\sim 0.9\) (almost perfect)}{figure.caption.830}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.6}Multitask Loss: Classification and Regression}{416}{subsection.13.1.6}\protected@file@percent }
\newlabel{subsubsec:chapter13_multitask_loss}{{13.1.6}{416}{Multitask Loss: Classification and Regression}{subsection.13.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}From Single-Object to Multi-Object Detection}{416}{section.13.2}\protected@file@percent }
\newlabel{subsubsec:chapter13_single_vs_multi}{{13.2}{416}{From Single-Object to Multi-Object Detection}{section.13.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces \textbf  {Single-object localization pipeline.} A CNN extracts a feature vector that is used for both classification (predicting the category) and regression (predicting bounding box coordinates). This simple approach works well for a single object but does not generalize well.}}{416}{figure.caption.831}\protected@file@percent }
\newlabel{fig:chapter13_single_object}{{13.6}{416}{\textbf {Single-object localization pipeline.} A CNN extracts a feature vector that is used for both classification (predicting the category) and regression (predicting bounding box coordinates). This simple approach works well for a single object but does not generalize well}{figure.caption.831}{}}
\BKM@entry{id=474,dest={73756273656374696F6E2E31332E322E31},srcline={140}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306E5C303030675C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030655C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C30303073}
\BKM@entry{id=475,dest={73756273656374696F6E2E31332E322E32},srcline={153}}{5C3337365C3337375C303030535C3030306C5C303030695C303030645C303030695C3030306E5C303030675C3030305C3034305C303030575C303030695C3030306E5C303030645C3030306F5C303030775C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C30303068}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.1}Challenges in Detecting Multiple Objects}{417}{subsection.13.2.1}\protected@file@percent }
\newlabel{subsec:chapter13_multiple_objects}{{13.2.1}{417}{Challenges in Detecting Multiple Objects}{subsection.13.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.2}Sliding Window Approach}{417}{subsection.13.2.2}\protected@file@percent }
\newlabel{subsubsec:chapter13_sliding_window}{{13.2.2}{417}{Sliding Window Approach}{subsection.13.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces \textbf  {Sliding window classification.} Each image crop is classified as either an object (e.g., dog, cat) or background.}}{417}{figure.caption.832}\protected@file@percent }
\newlabel{fig:chapter13_sliding_window}{{13.7}{417}{\textbf {Sliding window classification.} Each image crop is classified as either an object (e.g., dog, cat) or background}{figure.caption.832}{}}
\BKM@entry{id=476,dest={73756273656374696F6E2E31332E322E33},srcline={187}}{5C3337365C3337375C303030525C303030655C303030675C303030695C3030306F5C3030306E5C3030305C3034305C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030615C3030306C5C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {13.8}{\ignorespaces \textbf  {Positive detection:} The classifier correctly identifies the presence of a dog in the selected region.}}{418}{figure.caption.833}\protected@file@percent }
\newlabel{fig:chapter13_sliding_window_positive}{{13.8}{418}{\textbf {Positive detection:} The classifier correctly identifies the presence of a dog in the selected region}{figure.caption.833}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.3}Region Proposal Methods}{418}{subsection.13.2.3}\protected@file@percent }
\newlabel{subsubsec:chapter13_region_proposals}{{13.2.3}{418}{Region Proposal Methods}{subsection.13.2.3}{}}
\abx@aux@cite{0}{alexe2012_objectness}
\abx@aux@segm{0}{0}{alexe2012_objectness}
\abx@aux@cite{0}{uijlings2013_selective}
\abx@aux@segm{0}{0}{uijlings2013_selective}
\abx@aux@cite{0}{cheng2014_bing}
\abx@aux@segm{0}{0}{cheng2014_bing}
\abx@aux@cite{0}{zitnick2014_edgeboxes}
\abx@aux@segm{0}{0}{zitnick2014_edgeboxes}
\BKM@entry{id=477,dest={73656374696F6E2E31332E33},srcline={218}}{5C3337365C3337375C3030304E5C303030615C303030695C303030765C303030655C3030305C3034305C303030535C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030525C303030655C303030675C303030695C3030306F5C3030306E5C3030302D5C303030425C303030615C303030735C303030655C303030645C3030305C3034305C303030435C3030304E5C3030304E5C3030305C3034305C3030305C3035305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030305C303531}
\abx@aux@cite{0}{girshick2014_rcnn}
\abx@aux@segm{0}{0}{girshick2014_rcnn}
\@writefile{lof}{\contentsline {figure}{\numberline {13.9}{\ignorespaces \textbf  {Region Proposal Example.} Selective Search identifies potential object locations before classification, significantly reducing the number of regions to evaluate.}}{419}{figure.caption.834}\protected@file@percent }
\newlabel{fig:chapter13_region_proposals}{{13.9}{419}{\textbf {Region Proposal Example.} Selective Search identifies potential object locations before classification, significantly reducing the number of regions to evaluate}{figure.caption.834}{}}
\abx@aux@backref{275}{alexe2012_objectness}{0}{419}{419}
\abx@aux@backref{276}{uijlings2013_selective}{0}{419}{419}
\abx@aux@backref{277}{cheng2014_bing}{0}{419}{419}
\abx@aux@backref{278}{zitnick2014_edgeboxes}{0}{419}{419}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Naive Solution: Region-Based CNN (R-CNN)}{419}{section.13.3}\protected@file@percent }
\newlabel{subsubsec:chapter13_rcnn}{{13.3}{419}{Naive Solution: Region-Based CNN (R-CNN)}{section.13.3}{}}
\abx@aux@backref{279}{girshick2014_rcnn}{0}{419}{419}
\BKM@entry{id=478,dest={73756273656374696F6E2E31332E332E31},srcline={241}}{5C3337365C3337375C303030425C3030306F5C303030755C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306F5C303030785C3030305C3034305C303030525C303030655C303030675C303030725C303030655C303030735C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030525C303030655C303030665C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C3030304C5C3030306F5C303030635C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {13.10}{\ignorespaces \textbf  {R-CNN Pipeline.} Each proposed region is resized and classified independently. A single CNN is used to extract features for classification and regression, making it more efficient than sliding windows but still computationally expensive.}}{420}{figure.caption.835}\protected@file@percent }
\newlabel{fig:chapter13_rcnn}{{13.10}{420}{\textbf {R-CNN Pipeline.} Each proposed region is resized and classified independently. A single CNN is used to extract features for classification and regression, making it more efficient than sliding windows but still computationally expensive}{figure.caption.835}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Bounding Box Regression: Refining Object Localization}{420}{subsection.13.3.1}\protected@file@percent }
\newlabel{subsubsec:chapter13_bbox_regression}{{13.3.1}{420}{Bounding Box Regression: Refining Object Localization}{subsection.13.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.11}{\ignorespaces \textbf  {Bounding Box Regression.} A transformation adjusts the region proposal (blue) to improve alignment. We can see the resultant output box after the transformation as well (orange).}}{421}{figure.caption.836}\protected@file@percent }
\newlabel{fig:chapter13_bbox_regression}{{13.11}{421}{\textbf {Bounding Box Regression.} A transformation adjusts the region proposal (blue) to improve alignment. We can see the resultant output box after the transformation as well (orange)}{figure.caption.836}{}}
\@writefile{toc}{\contentsline {paragraph}{Why a Logarithmic Transformation?}{421}{section*.837}\protected@file@percent }
\BKM@entry{id=479,dest={73756273656374696F6E2E31332E332E32},srcline={298}}{5C3337365C3337375C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.2}Training R-CNN}{422}{subsection.13.3.2}\protected@file@percent }
\newlabel{subsubsec:training_rcnn}{{13.3.2}{422}{Training R-CNN}{subsection.13.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{1) Collecting Positive and Negative Examples}{422}{section*.838}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.12}{\ignorespaces \textbf  {Positive vs.\ Negative vs.\ Neutral Region Proposals.} An example image (green bounding boxes are ground-truth). Each region proposal is categorized as: \textbf  {Positive} (blue) if its IoU with a ground-truth box is above 0.5, \textbf  {Negative} (red) if its IoU is below 0.3, \textbf  {Neutral} (gray) otherwise. Neutral proposals are typically ignored when training SVMs or fine-tuning, thus avoiding ambiguous overlap ranges.}}{422}{figure.caption.839}\protected@file@percent }
\newlabel{fig:chapter13_slide73}{{13.12}{422}{\textbf {Positive vs.\ Negative vs.\ Neutral Region Proposals.} An example image (green bounding boxes are ground-truth). Each region proposal is categorized as: \textbf {Positive} (blue) if its IoU with a ground-truth box is above 0.5, \textbf {Negative} (red) if its IoU is below 0.3, \textbf {Neutral} (gray) otherwise. Neutral proposals are typically ignored when training SVMs or fine-tuning, thus avoiding ambiguous overlap ranges}{figure.caption.839}{}}
\@writefile{toc}{\contentsline {paragraph}{2) Fine-Tuning the CNN on Region Proposals (Classification Only)}{422}{section*.840}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3) Training the Bounding Box Regressors}{423}{section*.841}\protected@file@percent }
\newlabel{paragraph:training_bbox_regressors}{{13.3.2}{423}{3) Training the Bounding Box Regressors}{section*.841}{}}
\@writefile{toc}{\contentsline {paragraph}{4) Forming the Final Detector}{424}{section*.842}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training Considerations for Object Detection}{424}{section*.843}\protected@file@percent }
\BKM@entry{id=480,dest={73756273656374696F6E2E31332E332E33},srcline={414}}{5C3337365C3337375C303030535C303030655C3030306C5C303030655C303030635C303030745C303030695C3030306E5C303030675C3030305C3034305C303030465C303030695C3030306E5C303030615C3030306C5C3030305C3034305C303030505C303030725C303030655C303030645C303030695C303030635C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=481,dest={73656374696F6E2E31332E34},srcline={428}}{5C3337365C3337375C3030304E5C3030306F5C3030306E5C3030302D5C3030304D5C303030615C303030785C303030695C3030306D5C303030755C3030306D5C3030305C3034305C303030535C303030755C303030705C303030705C303030725C303030655C303030735C303030735C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C3030304E5C3030304D5C303030535C3030305C303531}
\BKM@entry{id=482,dest={73756273656374696F6E2E31332E342E31},srcline={431}}{5C3337365C3337375C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C3030304E5C303030655C303030655C303030645C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304E5C3030304D5C30303053}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.3}Selecting Final Predictions for Object Detection}{425}{subsection.13.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Non-Maximum Suppression (NMS)}{425}{section.13.4}\protected@file@percent }
\newlabel{subsec:chapter13_nms}{{13.4}{425}{Non-Maximum Suppression (NMS)}{section.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.1}Motivation: The Need for NMS}{425}{subsection.13.4.1}\protected@file@percent }
\newlabel{subsec:nms_motivation}{{13.4.1}{425}{Motivation: The Need for NMS}{subsection.13.4.1}{}}
\BKM@entry{id=483,dest={73756273656374696F6E2E31332E342E32},srcline={440}}{5C3337365C3337375C3030304E5C3030304D5C303030535C3030305C3034305C303030415C3030306C5C303030675C3030306F5C303030725C303030695C303030745C303030685C3030306D}
\BKM@entry{id=484,dest={73756273656374696F6E2E31332E342E33},srcline={453}}{5C3337365C3337375C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030535C303030745C303030655C303030705C3030302D5C303030625C303030795C3030302D5C303030535C303030745C303030655C303030705C3030305C3034305C303030455C303030785C303030655C303030635C303030755C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.2}NMS Algorithm}{426}{subsection.13.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.3}Example: Step-by-Step Execution}{426}{subsection.13.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.13}{\ignorespaces \textbf  {Step 1: Selecting the highest-scoring bounding box and comparing IoUs.} The blue box (\(P(\text  {dog})=0.9\)) is selected first. The orange box (\(P(\text  {dog})=0.8\)) has an \(\text  {IoU} = 0.78\), which exceeds the threshold (0.7), so it is removed. Other boxes with lower IoU remain.}}{426}{figure.caption.844}\protected@file@percent }
\newlabel{fig:chapter13_nms_step1}{{13.13}{426}{\textbf {Step 1: Selecting the highest-scoring bounding box and comparing IoUs.} The blue box (\(P(\text {dog})=0.9\)) is selected first. The orange box (\(P(\text {dog})=0.8\)) has an \(\text {IoU} = 0.78\), which exceeds the threshold (0.7), so it is removed. Other boxes with lower IoU remain}{figure.caption.844}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.14}{\ignorespaces \textbf  {Step 2: Processing the next highest-scoring box.} The purple box is selected next. The yellow box has \(\text  {IoU} = 0.74\) with the purple box, which exceeds the threshold, so it is removed.}}{426}{figure.caption.845}\protected@file@percent }
\newlabel{fig:chapter13_nms_step2}{{13.14}{426}{\textbf {Step 2: Processing the next highest-scoring box.} The purple box is selected next. The yellow box has \(\text {IoU} = 0.74\) with the purple box, which exceeds the threshold, so it is removed}{figure.caption.845}{}}
\BKM@entry{id=485,dest={73756273656374696F6E2E31332E342E34},srcline={475}}{5C3337365C3337375C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304E5C3030304D5C30303053}
\BKM@entry{id=486,dest={73756273656374696F6E2E31332E342E35},srcline={486}}{5C3337365C3337375C303030525C303030655C303030665C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C3030304E5C3030304D5C303030535C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304F5C303030765C303030655C303030725C3030306C5C303030615C303030705C303030705C303030695C3030306E5C303030675C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C30303073}
\BKM@entry{id=487,dest={73656374696F6E2E31332E35},srcline={497}}{5C3337365C3337375C303030455C303030765C303030615C3030306C5C303030755C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C3030306F5C303030725C303030735C3030303A5C3030305C3034305C3030304D5C303030655C303030615C3030306E5C3030305C3034305C303030415C303030765C303030655C303030725C303030615C303030675C303030655C3030305C3034305C303030505C303030725C303030655C303030635C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C3030306D5C303030415C303030505C3030305C303531}
\BKM@entry{id=488,dest={73756273656374696F6E2E31332E352E31},srcline={502}}{5C3337365C3337375C3030304B5C303030655C303030795C3030305C3034305C303030455C303030765C303030615C3030306C5C303030755C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304D5C303030655C303030745C303030725C303030695C303030635C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.4}Limitations of NMS}{427}{subsection.13.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.15}{\ignorespaces \textbf  {NMS Failure Case: Highly Overlapping Objects.} When objects are close together, NMS may incorrectly eliminate valid detections, reducing detection accuracy.}}{427}{figure.caption.846}\protected@file@percent }
\newlabel{fig:chapter13_nms_failure}{{13.15}{427}{\textbf {NMS Failure Case: Highly Overlapping Objects.} When objects are close together, NMS may incorrectly eliminate valid detections, reducing detection accuracy}{figure.caption.846}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.5}Refining NMS for Overlapping Objects}{427}{subsection.13.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.5}Evaluating Object Detectors: Mean Average Precision (mAP)}{427}{section.13.5}\protected@file@percent }
\newlabel{sec:chapter13_map}{{13.5}{427}{Evaluating Object Detectors: Mean Average Precision (mAP)}{section.13.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.1}Key Evaluation Metrics}{428}{subsection.13.5.1}\protected@file@percent }
\newlabel{subsec:chapter13_eval_metrics}{{13.5.1}{428}{Key Evaluation Metrics}{subsection.13.5.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Precision and Recall}{428}{section*.847}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Trade-offs Between Precision and Recall}}{428}{section*.848}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Isn't F1 Score Suffice?}}{428}{section*.849}\protected@file@percent }
\BKM@entry{id=489,dest={73756273656374696F6E2E31332E352E32},srcline={567}}{5C3337365C3337375C303030535C303030745C303030655C303030705C3030302D5C303030625C303030795C3030302D5C303030535C303030745C303030655C303030705C3030305C3034305C303030455C303030785C303030615C3030306D5C303030705C3030306C5C303030655C3030303A5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030695C3030306E5C303030675C3030305C3034305C303030415C303030505C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030615C3030305C3034305C303030535C303030695C3030306E5C303030675C3030306C5C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C30303073}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Precision-Recall (PR) Curve and Average Precision (AP)}}{429}{section*.850}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Why the 0.5 IoU Threshold?}}{429}{section*.851}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Why AP is Preferable to the F1 Score:}}{429}{section*.852}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.2}Step-by-Step Example: Computing AP for a Single Class}{430}{subsection.13.5.2}\protected@file@percent }
\newlabel{subsec:chapter13_ap_example}{{13.5.2}{430}{Step-by-Step Example: Computing AP for a Single Class}{subsection.13.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.16}{\ignorespaces \textbf  {Step 1: First match.} The highest-scoring detection correctly matches a ground-truth box.}}{430}{figure.caption.853}\protected@file@percent }
\newlabel{fig:chapter13_slide86}{{13.16}{430}{\textbf {Step 1: First match.} The highest-scoring detection correctly matches a ground-truth box}{figure.caption.853}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.17}{\ignorespaces \textbf  {Step 2: Second match.} The second highest detection correctly matches another ground-truth box.}}{430}{figure.caption.854}\protected@file@percent }
\newlabel{fig:chapter13_slide87}{{13.17}{430}{\textbf {Step 2: Second match.} The second highest detection correctly matches another ground-truth box}{figure.caption.854}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.18}{\ignorespaces \textbf  {Step 3: False Positive.} A detection fails to match any ground-truth box.}}{431}{figure.caption.855}\protected@file@percent }
\newlabel{fig:chapter13_slide88}{{13.18}{431}{\textbf {Step 3: False Positive.} A detection fails to match any ground-truth box}{figure.caption.855}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.19}{\ignorespaces \textbf  {Step 4: Another False Positive.} More false detections further lower precision.}}{431}{figure.caption.856}\protected@file@percent }
\newlabel{fig:chapter13_slide89}{{13.19}{431}{\textbf {Step 4: Another False Positive.} More false detections further lower precision}{figure.caption.856}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.20}{\ignorespaces \textbf  {Final Step: All ground-truth boxes matched.} Recall reaches 1.0, while the precision ends up being $3/5=0.6$.}}{432}{figure.caption.857}\protected@file@percent }
\newlabel{fig:chapter13_slide90}{{13.20}{432}{\textbf {Final Step: All ground-truth boxes matched.} Recall reaches 1.0, while the precision ends up being $3/5=0.6$}{figure.caption.857}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.21}{\ignorespaces The final AP score for the dog class is the area under the precision-recall curve, summing up to 0.87 in this case, which is pretty decent but can be further improved if we'll the reduce false-positives.}}{432}{figure.caption.858}\protected@file@percent }
\newlabel{fig:chapter13_slide91}{{13.21}{432}{The final AP score for the dog class is the area under the precision-recall curve, summing up to 0.87 in this case, which is pretty decent but can be further improved if we'll the reduce false-positives}{figure.caption.858}{}}
\BKM@entry{id=490,dest={73756273656374696F6E2E31332E352E33},srcline={647}}{5C3337365C3337375C3030304D5C303030655C303030615C3030306E5C3030305C3034305C303030415C303030765C303030655C303030725C303030615C303030675C303030655C3030305C3034305C303030505C303030725C303030655C303030635C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C3030306D5C303030415C303030505C3030305C303531}
\BKM@entry{id=491,dest={73756273656374696F6E2E31332E352E34},srcline={665}}{5C3337365C3337375C303030435C3030304F5C303030435C3030304F5C3030305C3034305C3030306D5C303030415C303030505C3030303A5C3030305C3034305C303030415C3030305C3034305C303030535C303030745C303030725C303030695C303030635C303030745C303030655C303030725C3030305C3034305C3030304D5C303030655C303030615C303030735C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.3}Mean Average Precision (mAP)}{433}{subsection.13.5.3}\protected@file@percent }
\newlabel{subsec:chapter13_map}{{13.5.3}{433}{Mean Average Precision (mAP)}{subsection.13.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.4}COCO mAP: A Stricter Measure}{433}{subsection.13.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{COCO mAP for Different Object Sizes}{433}{section*.859}\protected@file@percent }
\newlabel{subsec:chapter13_coco_map_sizes}{{13.5.4}{433}{COCO mAP for Different Object Sizes}{section*.859}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13.1}{\ignorespaces COCO mAP computed for different object size categories. The choice of which category to prioritize depends on the specific use case of the detection system.}}{433}{table.caption.860}\protected@file@percent }
\newlabel{tab:coco_ap_object_sizes}{{13.1}{433}{COCO mAP computed for different object size categories. The choice of which category to prioritize depends on the specific use case of the detection system}{table.caption.860}{}}
\BKM@entry{id=492,dest={73756273656374696F6E2E31332E352E35},srcline={767}}{5C3337365C3337375C303030455C303030765C303030615C3030306C5C303030755C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C3030306F5C303030725C303030735C3030303A5C3030305C3034305C3030304B5C303030655C303030795C3030305C3034305C303030545C303030615C3030306B5C303030655C303030615C303030775C303030615C303030795C30303073}
\@writefile{toc}{\contentsline {paragraph}{When and Why Object Size-Specific mAP Matters}{434}{section*.861}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Prioritizing Specific Classes in Object Detection}{434}{section*.862}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.5}Evaluating Object Detectors: Key Takeaways}{435}{subsection.13.5.5}\protected@file@percent }
\BKM@entry{id=493,dest={636861707465722E3134},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030345C3030303A5C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C3030306F5C303030725C30303073}
\BKM@entry{id=494,dest={73656374696F6E2E31342E31},srcline={10}}{5C3337365C3337375C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030303A5C3030305C3034305C303030415C303030645C303030765C303030615C3030306E5C303030635C303030695C3030306E5C303030675C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=495,dest={73756273656374696F6E2E31342E312E31},srcline={17}}{5C3337365C3337375C3030304C5C3030306F5C3030306F5C3030306B5C303030695C3030306E5C303030675C3030305C3034305C303030415C303030685C303030655C303030615C303030645C3030303A5C3030305C3034305C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030435C3030304E5C3030304E5C3030302D5C303030425C303030615C303030735C303030655C303030645C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C3030306F5C303030725C30303073}
\abx@aux@cite{0}{carion2020_detr}
\abx@aux@segm{0}{0}{carion2020_detr}
\abx@aux@cite{0}{zhang2022_dino}
\abx@aux@segm{0}{0}{zhang2022_dino}
\abx@aux@cite{0}{oquab2023_dinov2}
\abx@aux@segm{0}{0}{oquab2023_dinov2}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Lecture 14: Object Detectors}{436}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@13}}
\ttl@writefile{ptc}{\ttl@starttoc{default@14}}
\pgfsyspdfmark {pgfid64}{0}{52099153}
\pgfsyspdfmark {pgfid63}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Beyond R-CNN: Advancing Object Detection}{436}{section.14.1}\protected@file@percent }
\newlabel{sec:chapter14_intro}{{14.1}{436}{Beyond R-CNN: Advancing Object Detection}{section.14.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.1}Looking Ahead: Beyond CNN-Based Object Detectors}{436}{subsection.14.1.1}\protected@file@percent }
\newlabel{subsec:chapter14_future_object_detection}{{14.1.1}{436}{Looking Ahead: Beyond CNN-Based Object Detectors}{subsection.14.1.1}{}}
\abx@aux@backref{280}{carion2020_detr}{0}{436}{436}
\abx@aux@backref{281}{zhang2022_dino}{0}{436}{436}
\abx@aux@backref{282}{oquab2023_dinov2}{0}{436}{436}
\BKM@entry{id=496,dest={73656374696F6E2E31342E32},srcline={39}}{5C3337365C3337375C303030465C303030615C303030735C303030745C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030303A5C3030305C3034305C303030415C303030635C303030635C303030655C3030306C5C303030655C303030725C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{girshick2015_fastrcnn}
\abx@aux@segm{0}{0}{girshick2015_fastrcnn}
\BKM@entry{id=497,dest={73756273656374696F6E2E31342E322E31},srcline={46}}{5C3337365C3337375C3030304B5C303030655C303030795C3030305C3034305C303030495C303030645C303030655C303030615C3030303A5C3030305C3034305C303030535C303030685C303030615C303030725C303030655C303030645C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030455C303030785C303030745C303030725C303030615C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Fast R-CNN: Accelerating Object Detection}{437}{section.14.2}\protected@file@percent }
\newlabel{sec:chapter14_fast_rcnn}{{14.2}{437}{Fast R-CNN: Accelerating Object Detection}{section.14.2}{}}
\abx@aux@backref{283}{girshick2015_fastrcnn}{0}{437}{437}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.1}Key Idea: Shared Feature Extraction}{437}{subsection.14.2.1}\protected@file@percent }
\newlabel{subsec:chapter14_fast_rcnn_idea}{{14.2.1}{437}{Key Idea: Shared Feature Extraction}{subsection.14.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces \textbf  {Fast R-CNN architecture:} A backbone CNN processes the full image, generating a feature map. RoI Pooling extracts regions from this shared representation, followed by classification and bounding box refinement.}}{437}{figure.caption.863}\protected@file@percent }
\newlabel{fig:chapter14_fast_rcnn}{{14.1}{437}{\textbf {Fast R-CNN architecture:} A backbone CNN processes the full image, generating a feature map. RoI Pooling extracts regions from this shared representation, followed by classification and bounding box refinement}{figure.caption.863}{}}
\BKM@entry{id=498,dest={73756273656374696F6E2E31342E322E32},srcline={60}}{5C3337365C3337375C303030555C303030735C303030695C3030306E5C303030675C3030305C3034305C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C303030425C303030615C303030635C3030306B5C303030625C3030306F5C3030306E5C303030655C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030455C303030785C303030745C303030725C303030615C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.2}Using Fully Convolutional Deep Backbones for Feature Extraction}{438}{subsection.14.2.2}\protected@file@percent }
\newlabel{subsec:chapter14_fast_rcnn_backbone}{{14.2.2}{438}{Using Fully Convolutional Deep Backbones for Feature Extraction}{subsection.14.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces \textbf  {AlexNet as a backbone:} Early implementations of Fast R-CNN explored the use of AlexNet for feature extraction. Only the last two FC layers were used for the per-region network.}}{438}{figure.caption.864}\protected@file@percent }
\newlabel{fig:chapter14_alexnet}{{14.2}{438}{\textbf {AlexNet as a backbone:} Early implementations of Fast R-CNN explored the use of AlexNet for feature extraction. Only the last two FC layers were used for the per-region network}{figure.caption.864}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces \textbf  {ResNet as a backbone:} More modern implementations utilize ResNet for feature extraction, leveraging deeper architectures for improved accuracy. In this case, only the last stage of the network was used for the per-region network, while the rest of the network was used as a backbone deriving features from the entire image.}}{438}{figure.caption.865}\protected@file@percent }
\newlabel{fig:chapter14_resnet}{{14.3}{438}{\textbf {ResNet as a backbone:} More modern implementations utilize ResNet for feature extraction, leveraging deeper architectures for improved accuracy. In this case, only the last stage of the network was used for the per-region network, while the rest of the network was used as a backbone deriving features from the entire image}{figure.caption.865}{}}
\BKM@entry{id=499,dest={73756273656374696F6E2E31342E322E33},srcline={86}}{5C3337365C3337375C303030525C303030655C303030675C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030655C303030735C303030745C3030305C3034305C3030305C3035305C303030525C3030306F5C303030495C3030305C3035315C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.3}Region of Interest (RoI) Pooling}{439}{subsection.14.2.3}\protected@file@percent }
\newlabel{subsec:chapter14_roi_pooling}{{14.2.3}{439}{Region of Interest (RoI) Pooling}{subsection.14.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Mapping Region Proposals onto the Feature Map}{439}{section*.866}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dividing the Region into Fixed Bins}{439}{section*.867}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Max Pooling within Each Bin}{439}{section*.868}\protected@file@percent }
\abx@aux@cite{0}{patnaik2020_roi_pool}
\abx@aux@segm{0}{0}{patnaik2020_roi_pool}
\abx@aux@cite{0}{erdem2020_RoIAlign}
\abx@aux@segm{0}{0}{erdem2020_RoIAlign}
\abx@aux@cite{0}{erdem2020_RoIAlign}
\abx@aux@segm{0}{0}{erdem2020_RoIAlign}
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces \textbf  {RoI Pooling Process.} Each region proposal is mapped onto the feature map, divided into fixed bins, and max-pooled to a fixed output size for classification and bounding box refinement.}}{440}{figure.caption.869}\protected@file@percent }
\newlabel{fig:chapter14_roi_pooling}{{14.4}{440}{\textbf {RoI Pooling Process.} Each region proposal is mapped onto the feature map, divided into fixed bins, and max-pooled to a fixed output size for classification and bounding box refinement}{figure.caption.869}{}}
\@writefile{toc}{\contentsline {paragraph}{Summary: Key Steps in RoI Pooling}{440}{section*.870}\protected@file@percent }
\abx@aux@backref{284}{patnaik2020_roi_pool}{0}{440}{440}
\@writefile{toc}{\contentsline {paragraph}{Limitations of RoI Pooling}{440}{section*.871}\protected@file@percent }
\BKM@entry{id=500,dest={73756273656374696F6E2E31342E322E34},srcline={144}}{5C3337365C3337375C303030525C3030306F5C303030495C303030415C3030306C5C303030695C303030675C3030306E}
\abx@aux@cite{0}{patnaik2020_roi_pool}
\abx@aux@segm{0}{0}{patnaik2020_roi_pool}
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces Impact of quantization in RoI Pooling. When mapping a region proposal onto the feature map (red), quantization (orange) can result in the loss of relevant object information (highlighted in \emph  {dark blue}) while also introducing unwanted features from adjacent areas (\emph  {green}). This misalignment reduces localization precision, as certain parts of the object may be omitted, while non-object features may be included in the pooled representation. Figure taken from \blx@tocontentsinit {0}\cite {erdem2020_RoIAlign}.}}{441}{figure.caption.872}\protected@file@percent }
\abx@aux@backref{286}{erdem2020_RoIAlign}{0}{441}{441}
\newlabel{fig:chapter14_roi_pooling_downside}{{14.5}{441}{Impact of quantization in RoI Pooling. When mapping a region proposal onto the feature map (red), quantization (orange) can result in the loss of relevant object information (highlighted in \emph {dark blue}) while also introducing unwanted features from adjacent areas (\emph {green}). This misalignment reduces localization precision, as certain parts of the object may be omitted, while non-object features may be included in the pooled representation. Figure taken from \cite {erdem2020_RoIAlign}}{figure.caption.872}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.4}RoIAlign}{441}{subsection.14.2.4}\protected@file@percent }
\newlabel{subsubsec:roi_align_intro}{{14.2.4}{441}{RoIAlign}{subsection.14.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{RoIAlign: A Visual Example}{442}{section*.873}\protected@file@percent }
\newlabel{subsubsec:roi_align_example}{{14.2.4}{442}{RoIAlign: A Visual Example}{section*.873}{}}
\abx@aux@backref{287}{patnaik2020_roi_pool}{0}{442}{442}
\@writefile{toc}{\contentsline {paragraph}{Step 1: Projection of Region Proposal onto the Feature Map}{442}{section*.874}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.6}{\ignorespaces Projection of the region proposal onto the feature map, dividing it into $2 \times 2$ bins.}}{442}{figure.caption.875}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_projection}{{14.6}{442}{Projection of the region proposal onto the feature map, dividing it into $2 \times 2$ bins}{figure.caption.875}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 2: Selecting Interpolation Points in Each Bin}{442}{section*.876}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.7}{\ignorespaces Selection of four interpolation points in each sub-region for bilinear interpolation.}}{443}{figure.caption.877}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_interpolation_points}{{14.7}{443}{Selection of four interpolation points in each sub-region for bilinear interpolation}{figure.caption.877}{}}
\@writefile{toc}{\contentsline {subparagraph}{Why Choose 0.25 and 0.75 for Sampling?}{443}{subparagraph*.878}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 3: Mapping Sampled Points onto the Feature Grid}{444}{section*.879}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.8}{\ignorespaces Mapping of the selected interpolation points onto the discrete grid of the feature map. Each sampled point is enclosed by four neighboring grid points, which will be used in bilinear interpolation.}}{444}{figure.caption.880}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_interpolation_grid}{{14.8}{444}{Mapping of the selected interpolation points onto the discrete grid of the feature map. Each sampled point is enclosed by four neighboring grid points, which will be used in bilinear interpolation}{figure.caption.880}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 4: Computing Bilinear Interpolation Weights}{445}{section*.881}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Normalization Constant and Its Interpretation}{445}{subparagraph*.882}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Weight Computation for Each Corner}{445}{subparagraph*.883}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.9}{\ignorespaces Computing interpolation weight for the top-left corner ($w_a$). Since the sampled point is far from this corner, its weight is relatively low: ($w_a=0.1$).}}{446}{figure.caption.884}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_interpolation_weight_a}{{14.9}{446}{Computing interpolation weight for the top-left corner ($w_a$). Since the sampled point is far from this corner, its weight is relatively low: ($w_a=0.1$)}{figure.caption.884}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.10}{\ignorespaces Computing interpolation weight for the top-right corner ($w_c$). Since this point is equidistant from $w_a$, the weights are equal ($w_a = w_c = 0.1$).}}{447}{figure.caption.885}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_interpolation_weight_c}{{14.10}{447}{Computing interpolation weight for the top-right corner ($w_c$). Since this point is equidistant from $w_a$, the weights are equal ($w_a = w_c = 0.1$)}{figure.caption.885}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.11}{\ignorespaces Computing interpolation weight for the bottom-left corner ($w_b$). Since the sampled point is much closer to this corner, its weight is significantly higher: ($w_b=0.4$).}}{447}{figure.caption.886}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_interpolation_weight_b}{{14.11}{447}{Computing interpolation weight for the bottom-left corner ($w_b$). Since the sampled point is much closer to this corner, its weight is significantly higher: ($w_b=0.4$)}{figure.caption.886}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.12}{\ignorespaces Computing interpolation weight for the bottom-right corner ($w_d$). This weight is identical to $w_b$, because the sampled point $(x,y)$ is symmetrically placed between $b, d$.}}{448}{figure.caption.887}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_interpolation_weight_d}{{14.12}{448}{Computing interpolation weight for the bottom-right corner ($w_d$). This weight is identical to $w_b$, because the sampled point $(x,y)$ is symmetrically placed between $b, d$}{figure.caption.887}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 5: Computing the Interpolated Feature Value}{448}{section*.888}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{\textbf  {Example Computation}}{448}{subparagraph*.889}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 6: Aggregating Interpolated Values}{449}{section*.890}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{\textbf  {Final Output}}{449}{subparagraph*.891}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.13}{\ignorespaces Final RoIAlign result: Each bin's value is determined via bilinear interpolation and pooling.}}{449}{figure.caption.892}\protected@file@percent }
\newlabel{fig:chapter14_roi_align_final}{{14.13}{449}{Final RoIAlign result: Each bin's value is determined via bilinear interpolation and pooling}{figure.caption.892}{}}
\@writefile{toc}{\contentsline {paragraph}{Key Takeaways}{449}{section*.893}\protected@file@percent }
\abx@aux@cite{0}{patnaik2020_roi_pool}
\abx@aux@segm{0}{0}{patnaik2020_roi_pool}
\@writefile{toc}{\contentsline {paragraph}{RoIAlign Important Implementation Parts in PyTorch}{450}{section*.894}\protected@file@percent }
\abx@aux@backref{288}{patnaik2020_roi_pool}{0}{450}{450}
\BKM@entry{id=501,dest={73656374696F6E2E31342E33},srcline={541}}{5C3337365C3337375C303030465C303030615C303030735C303030745C303030655C303030725C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030303A5C3030305C3034305C303030465C303030615C303030735C303030745C303030655C303030725C3030305C3034305C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030615C3030306C5C303030735C3030305C3034305C303030555C303030735C303030695C3030306E5C303030675C3030305C3034305C303030525C303030505C3030304E5C30303073}
\BKM@entry{id=502,dest={73756273656374696F6E2E31342E332E31},srcline={544}}{5C3337365C3337375C303030465C303030615C303030735C303030745C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030305C3034305C303030425C3030306F5C303030745C303030745C3030306C5C303030655C3030306E5C303030655C303030635C3030306B5C3030303A5C3030305C3034305C303030525C303030655C303030675C303030695C3030306F5C3030306E5C3030305C3034305C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030615C3030306C5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=503,dest={73756273656374696F6E2E31342E332E32},srcline={556}}{5C3337365C3337375C303030545C3030306F5C303030775C303030615C303030725C303030645C303030735C3030305C3034305C303030465C303030615C303030735C303030745C303030655C303030725C3030305C3034305C303030525C303030655C303030675C303030695C3030306F5C3030306E5C3030305C3034305C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030615C3030306C5C303030735C3030303A5C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030615C3030306C5C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030435C3030304E5C3030304E5C30303073}
\abx@aux@cite{0}{ren2016_fasterrcnn}
\abx@aux@segm{0}{0}{ren2016_fasterrcnn}
\BKM@entry{id=504,dest={73756273656374696F6E2E31342E332E33},srcline={568}}{5C3337365C3337375C303030525C303030655C303030675C303030695C3030306F5C3030306E5C3030305C3034305C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030525C303030505C3030304E5C303030735C3030305C303531}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Faster R-CNN: Faster Proposals Using RPNs}{453}{section.14.3}\protected@file@percent }
\newlabel{sec:chapter14_faster_rcnn}{{14.3}{453}{Faster R-CNN: Faster Proposals Using RPNs}{section.14.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.1}Fast R-CNN Bottleneck: Region Proposal Computation}{453}{subsection.14.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.14}{\ignorespaces Problem: Despite Fast R-CNN’s optimizations, runtime is still dominated by region proposal computation. Selective Search runs on the CPU and remains the slowest part of the pipeline.}}{453}{figure.caption.895}\protected@file@percent }
\newlabel{fig:chapter14_runtime_bottleneck}{{14.14}{453}{Problem: Despite Fast R-CNN’s optimizations, runtime is still dominated by region proposal computation. Selective Search runs on the CPU and remains the slowest part of the pipeline}{figure.caption.895}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.2}Towards Faster Region Proposals: Learning Proposals with CNNs}{453}{subsection.14.3.2}\protected@file@percent }
\abx@aux@backref{289}{ren2016_fasterrcnn}{0}{453}{453}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.3}Region Proposal Networks (RPNs)}{454}{subsection.14.3.3}\protected@file@percent }
\newlabel{subsec:chapter14_rpn}{{14.3.3}{454}{Region Proposal Networks (RPNs)}{subsection.14.3.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {How RPNs Work}}{454}{section*.896}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Anchor Boxes: Handling Scale and Aspect Ratio Variations}}{454}{section*.897}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.15}{\ignorespaces Anchor boxes and their classification: Positive (green) anchors contain objects, while negative (red) anchors do not.}}{454}{figure.caption.898}\protected@file@percent }
\newlabel{fig:chapter14_rpn_anchor_classification}{{14.15}{454}{Anchor boxes and their classification: Positive (green) anchors contain objects, while negative (red) anchors do not}{figure.caption.898}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.16}{\ignorespaces Examples of $K$ anchor boxes at a single location, illustrating different sizes and aspect ratios.}}{455}{figure.caption.899}\protected@file@percent }
\newlabel{fig:chapter14_rpn_anchors_sizes}{{14.16}{455}{Examples of $K$ anchor boxes at a single location, illustrating different sizes and aspect ratios}{figure.caption.899}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.17}{\ignorespaces RPN predicting objectness scores and bounding box transforms for each anchor.}}{455}{figure.caption.900}\protected@file@percent }
\newlabel{fig:chapter14_rpn_predictions}{{14.17}{455}{RPN predicting objectness scores and bounding box transforms for each anchor}{figure.caption.900}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Bounding Box Refinement: Aligning Anchors to Objects}}{456}{section*.901}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.18}{\ignorespaces For positive anchors (green), the RPN predicts a transformation (orange) that converts the anchor to the ground-truth bounding box (gold).}}{456}{figure.caption.902}\protected@file@percent }
\newlabel{fig:chapter14_rpn_box_transform}{{14.18}{456}{For positive anchors (green), the RPN predicts a transformation (orange) that converts the anchor to the ground-truth bounding box (gold)}{figure.caption.902}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Training RPNs: Assigning Labels to Anchors}}{456}{section*.903}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Loss Function for RPN Training}}{457}{section*.904}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{\textbf  {Assigning Ground-Truth Bounding Boxes to Anchors}}{457}{subparagraph*.905}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Smooth \( L_1 \) Loss for Bounding Box Regression}}{457}{section*.906}\protected@file@percent }
\BKM@entry{id=505,dest={73756273656374696F6E2E31342E332E34},srcline={738}}{5C3337365C3337375C303030465C303030615C303030735C303030745C303030655C303030725C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C303030725C303030615C303030635C303030745C303030695C303030635C303030655C3030303A5C3030305C3034305C3030304A5C3030306F5C303030695C3030306E5C303030745C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030465C3030306F5C303030755C303030725C3030305C3034305C3030304C5C3030306F5C303030735C303030735C303030655C30303073}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Why Use Negative Anchors?}}{458}{section*.907}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Inference: Generating Region Proposals}}{458}{section*.908}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {RPNs Improve Region Proposal Generation}}{458}{section*.909}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.4}Faster R-CNN Loss in Practice: Joint Training with Four Losses}{459}{subsection.14.3.4}\protected@file@percent }
\newlabel{subsec:chapter14_faster_rcnn_loss}{{14.3.4}{459}{Faster R-CNN Loss in Practice: Joint Training with Four Losses}{subsection.14.3.4}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Joint Training in Faster R-CNN}}{459}{section*.910}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {How RPN Improves Inference Speed}}{459}{section*.911}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.19}{\ignorespaces Comparison of inference time between R-CNN, SPP-Net, Fast R-CNN, and Faster R-CNN. RPN reduces the test-time speed from 2.3s in Fast R-CNN to 0.2s in Faster R-CNN.}}{459}{figure.caption.912}\protected@file@percent }
\newlabel{fig:chapter14_faster_rcnn_speed_comparison}{{14.19}{459}{Comparison of inference time between R-CNN, SPP-Net, Fast R-CNN, and Faster R-CNN. RPN reduces the test-time speed from 2.3s in Fast R-CNN to 0.2s in Faster R-CNN}{figure.caption.912}{}}
\BKM@entry{id=506,dest={73756273656374696F6E2E31342E332E35},srcline={776}}{5C3337365C3337375C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030505C303030795C303030725C303030615C3030306D5C303030695C303030645C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030465C303030505C3030304E5C303030735C3030305C3035315C3030303A5C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C303030535C303030635C303030615C3030306C5C303030655C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\abx@aux@cite{0}{lin2017_fpn}
\abx@aux@segm{0}{0}{lin2017_fpn}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.5}Feature Pyramid Networks (FPNs): Multi-Scale Feature Learning}{460}{subsection.14.3.5}\protected@file@percent }
\newlabel{subsec:chapter14_fpn}{{14.3.5}{460}{Feature Pyramid Networks (FPNs): Multi-Scale Feature Learning}{subsection.14.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.20}{\ignorespaces Illustration of the classic image pyramid approach, where the detector is applied to multiple resized versions of the image to improve small-object detection. However, this method is computationally expensive.}}{460}{figure.caption.913}\protected@file@percent }
\newlabel{fig:chapter14_image_pyramid}{{14.20}{460}{Illustration of the classic image pyramid approach, where the detector is applied to multiple resized versions of the image to improve small-object detection. However, this method is computationally expensive}{figure.caption.913}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Pyramid Networks: A More Efficient Approach}{460}{section*.914}\protected@file@percent }
\abx@aux@backref{290}{lin2017_fpn}{0}{460}{460}
\@writefile{lof}{\contentsline {figure}{\numberline {14.21}{\ignorespaces Applying object detectors at different stages of a CNN backbone. However, early-stage features suffer from limited receptive fields and lack access to high-level semantic information, reducing detection performance.}}{461}{figure.caption.915}\protected@file@percent }
\newlabel{fig:chapter14_fpn_early_stages}{{14.21}{461}{Applying object detectors at different stages of a CNN backbone. However, early-stage features suffer from limited receptive fields and lack access to high-level semantic information, reducing detection performance}{figure.caption.915}{}}
\@writefile{toc}{\contentsline {subsubsection}{Enhancing Low-Level Features with High-Level Semantics}{461}{section*.916}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.22}{\ignorespaces Top-down feature fusion in Feature Pyramid Networks. High-level features are progressively upsampled and combined with low-level features to enhance their semantic richness before detection.}}{461}{figure.caption.917}\protected@file@percent }
\newlabel{fig:chapter14_fpn_topdown}{{14.22}{461}{Top-down feature fusion in Feature Pyramid Networks. High-level features are progressively upsampled and combined with low-level features to enhance their semantic richness before detection}{figure.caption.917}{}}
\@writefile{toc}{\contentsline {paragraph}{How Upsampling Works in FPNs}{462}{section*.918}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Combining Results from Multiple Feature Levels}{462}{section*.919}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages of FPNs}{462}{section*.920}\protected@file@percent }
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\abx@aux@cite{0}{tian2019_fcos}
\abx@aux@segm{0}{0}{tian2019_fcos}
\abx@aux@cite{0}{carion2020_detr}
\abx@aux@segm{0}{0}{carion2020_detr}
\BKM@entry{id=507,dest={73656374696F6E2E31342E34},srcline={882}}{5C3337365C3337375C303030525C303030655C303030745C303030695C3030306E5C303030615C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030415C3030305C3034305C303030425C303030725C303030655C303030615C3030306B5C303030745C303030685C303030725C3030306F5C303030755C303030675C303030685C3030305C3034305C303030695C3030306E5C3030305C3034305C303030535C303030695C3030306E5C303030675C3030306C5C303030655C3030302D5C303030535C303030745C303030615C303030675C303030655C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {The Two-Stage Object Detection Pipeline}}{463}{section*.921}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.23}{\ignorespaces Visualization of Faster R-CNN as a two-stage object detector. The \textbf  {first stage} (blue) generates region proposals, while the \textbf  {second stage} (green) classifies objects and refines the proposals.}}{463}{figure.caption.922}\protected@file@percent }
\newlabel{fig:chapter14_faster_rcnn_pipeline}{{14.23}{463}{Visualization of Faster R-CNN as a two-stage object detector. The \textbf {first stage} (blue) generates region proposals, while the \textbf {second stage} (green) classifies objects and refines the proposals}{figure.caption.922}{}}
\abx@aux@backref{291}{lin2018_focalloss}{0}{463}{463}
\abx@aux@backref{292}{tian2019_fcos}{0}{463}{463}
\abx@aux@backref{293}{carion2020_detr}{0}{463}{463}
\BKM@entry{id=508,dest={73756273656374696F6E2E31342E342E31},srcline={887}}{5C3337365C3337375C303030575C303030685C303030795C3030305C3034305C303030535C303030695C3030306E5C303030675C3030306C5C303030655C3030302D5C303030535C303030745C303030615C303030675C303030655C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C3030306F5C303030725C303030735C3030305C3034305C303030435C303030615C3030306E5C3030305C3034305C303030425C303030655C3030305C3034305C303030465C303030615C303030735C303030745C303030655C30303072}
\BKM@entry{id=509,dest={73756273656374696F6E2E31342E342E32},srcline={904}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C3030305C3034305C303030495C3030306D5C303030625C303030615C3030306C5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030505C303030725C3030306F5C303030625C3030306C5C303030655C3030306D5C3030305C3034305C303030695C3030306E5C3030305C3034305C303030445C303030655C3030306E5C303030735C303030655C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}RetinaNet: A Breakthrough in Single-Stage Object Detection}{464}{section.14.4}\protected@file@percent }
\newlabel{subsec:chapter14_retinanet}{{14.4}{464}{RetinaNet: A Breakthrough in Single-Stage Object Detection}{section.14.4}{}}
\abx@aux@backref{294}{lin2018_focalloss}{0}{464}{464}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.1}Why Single-Stage Detectors Can Be Faster}{464}{subsection.14.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.24}{\ignorespaces Inference speed comparison of RetinaNet and other detectors. Single-stage detectors like RetinaNet are significantly faster than two-stage detectors, such as FPN Faster R-CNN.}}{464}{figure.caption.923}\protected@file@percent }
\newlabel{fig:chapter14_retinanet_inference}{{14.24}{464}{Inference speed comparison of RetinaNet and other detectors. Single-stage detectors like RetinaNet are significantly faster than two-stage detectors, such as FPN Faster R-CNN}{figure.caption.923}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.2}The Class Imbalance Problem in Dense Detection}{464}{subsection.14.4.2}\protected@file@percent }
\BKM@entry{id=510,dest={73756273656374696F6E2E31342E342E33},srcline={916}}{5C3337365C3337375C303030465C3030306F5C303030635C303030615C3030306C5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030303A5C3030305C3034305C303030415C303030645C303030645C303030725C303030655C303030735C303030735C303030695C3030306E5C303030675C3030305C3034305C303030435C3030306C5C303030615C303030735C303030735C3030305C3034305C303030495C3030306D5C303030625C303030615C3030306C5C303030615C3030306E5C303030635C30303065}
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.3}Focal Loss: Addressing Class Imbalance}{465}{subsection.14.4.3}\protected@file@percent }
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\@writefile{lof}{\contentsline {figure}{\numberline {14.25}{\ignorespaces Focal loss modifies the standard cross-entropy loss by incorporating a modulating factor \((1-p_t)^\gamma \). This factor down-weights the loss for well-classified examples. For instance, when \(\gamma =2\), the loss for examples with high confidence (e.g., \(p_t \approx 0.9\)) is significantly reduced, while the loss for moderately difficult examples (e.g., \(p_t \approx 0.5\) or \(p_t \approx 0.2\)) remains similar to that of the standard cross-entropy loss. Setting \(\gamma \) too high (such as \(\gamma =5\)) can overly suppress the loss even for examples that are not trivial, potentially eliminating valuable learning signals. Thus, \(\gamma =2\) is often chosen as a good compromise, effectively reducing the loss from very easy examples while preserving enough gradient for harder examples. Source: \blx@tocontentsinit {0}\cite {lin2018_focalloss}.}}{466}{figure.caption.924}\protected@file@percent }
\abx@aux@backref{296}{lin2018_focalloss}{0}{466}{466}
\newlabel{fig:chapter14_focal_loss}{{14.25}{466}{Focal loss modifies the standard cross-entropy loss by incorporating a modulating factor \((1-p_t)^\gamma \). This factor down-weights the loss for well-classified examples. For instance, when \(\gamma =2\), the loss for examples with high confidence (e.g., \(p_t \approx 0.9\)) is significantly reduced, while the loss for moderately difficult examples (e.g., \(p_t \approx 0.5\) or \(p_t \approx 0.2\)) remains similar to that of the standard cross-entropy loss. Setting \(\gamma \) too high (such as \(\gamma =5\)) can overly suppress the loss even for examples that are not trivial, potentially eliminating valuable learning signals. Thus, \(\gamma =2\) is often chosen as a good compromise, effectively reducing the loss from very easy examples while preserving enough gradient for harder examples. Source: \cite {lin2018_focalloss}}{figure.caption.924}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.26}{\ignorespaces Cumulative distribution functions (CDFs) of the normalized loss for background (negative) and foreground (positive) examples under different values of \(\gamma \). As \(\gamma \) increases, the loss contribution from easy negatives is dramatically reduced, which flattens the loss distribution for background examples. Importantly, with \(\gamma =2\), the loss for foreground examples remains nearly unchanged, ensuring that the model still learns effectively from the scarce positive examples. This selective down-weighting is crucial for mitigating class imbalance. Source: \blx@tocontentsinit {0}\cite {lin2018_focalloss}.}}{466}{figure.caption.925}\protected@file@percent }
\abx@aux@backref{298}{lin2018_focalloss}{0}{466}{466}
\newlabel{fig:chapter14_focal_loss_distribution}{{14.26}{466}{Cumulative distribution functions (CDFs) of the normalized loss for background (negative) and foreground (positive) examples under different values of \(\gamma \). As \(\gamma \) increases, the loss contribution from easy negatives is dramatically reduced, which flattens the loss distribution for background examples. Importantly, with \(\gamma =2\), the loss for foreground examples remains nearly unchanged, ensuring that the model still learns effectively from the scarce positive examples. This selective down-weighting is crucial for mitigating class imbalance. Source: \cite {lin2018_focalloss}}{figure.caption.925}{}}
\BKM@entry{id=511,dest={73756273656374696F6E2E31342E342E34},srcline={971}}{5C3337365C3337375C303030525C303030655C303030745C303030695C3030306E5C303030615C3030304E5C303030655C303030745C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030505C303030695C303030705C303030655C3030306C5C303030695C3030306E5C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.4}RetinaNet Architecture and Pipeline}{467}{subsection.14.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.27}{\ignorespaces RetinaNet pipeline. Like RPN, it predicts object categories and bounding box refinements, but in a single stage.}}{467}{figure.caption.926}\protected@file@percent }
\newlabel{fig:chapter14_retinanet_pipeline}{{14.27}{467}{RetinaNet pipeline. Like RPN, it predicts object categories and bounding box refinements, but in a single stage}{figure.caption.926}{}}
\BKM@entry{id=512,dest={73656374696F6E2E31342E35},srcline={990}}{5C3337365C3337375C303030465C303030435C3030304F5C303030535C3030303A5C3030305C3034305C303030415C3030306E5C3030305C3034305C303030415C3030306E5C303030635C303030685C3030306F5C303030725C3030302D5C303030465C303030725C303030655C303030655C3030302C5C3030305C3034305C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C3030306F5C30303072}
\abx@aux@cite{0}{tian2019_fcos}
\abx@aux@segm{0}{0}{tian2019_fcos}
\abx@aux@cite{0}{law2019_cornernet}
\abx@aux@segm{0}{0}{law2019_cornernet}
\BKM@entry{id=513,dest={73756273656374696F6E2E31342E352E31},srcline={997}}{5C3337365C3337375C303030435C3030306F5C303030725C303030655C3030305C3034305C303030505C303030695C303030705C303030655C3030306C5C303030695C3030306E5C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C3030304D5C303030615C303030705C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030705C303030725C303030655C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}FCOS: An Anchor-Free, Fully Convolutional Detector}{468}{section.14.5}\protected@file@percent }
\newlabel{subsec:chapter14_fcos}{{14.5}{468}{FCOS: An Anchor-Free, Fully Convolutional Detector}{section.14.5}{}}
\abx@aux@backref{299}{tian2019_fcos}{0}{468}{468}
\abx@aux@backref{300}{law2019_cornernet}{0}{468}{468}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.1}Core Pipeline and Feature Map Interpretation}{468}{subsection.14.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.28}{\ignorespaces On the left: an example prediction of the 4D localization output of FCOS, fitting a bounding box surrounding the object, according to its predicted distances from the edges. On the right: an example of an ambiguous case in FCOS. When a feature map location falls within multiple ground-truth boxes, to which bounding box shall we assign it? The authors proposed solution is to assign it to the box with the smallest area. This makes sense as smaller objects are harder to detect, so we'll want to give it more weight, and improve our chances to detect it well.}}{469}{figure.caption.927}\protected@file@percent }
\newlabel{fig:chapter14_fcos_edge_case}{{14.28}{469}{On the left: an example prediction of the 4D localization output of FCOS, fitting a bounding box surrounding the object, according to its predicted distances from the edges. On the right: an example of an ambiguous case in FCOS. When a feature map location falls within multiple ground-truth boxes, to which bounding box shall we assign it? The authors proposed solution is to assign it to the box with the smallest area. This makes sense as smaller objects are harder to detect, so we'll want to give it more weight, and improve our chances to detect it well}{figure.caption.927}{}}
\BKM@entry{id=514,dest={73756273656374696F6E2E31342E352E32},srcline={1046}}{5C3337365C3337375C303030425C3030306F5C303030755C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030425C3030306F5C303030785C3030305C3034305C303030525C303030655C303030675C303030725C303030655C303030735C303030735C303030695C3030306F5C3030306E}
\BKM@entry{id=515,dest={73756273656374696F6E2E31342E352E33},srcline={1063}}{5C3337365C3337375C303030435C303030655C3030306E5C303030745C303030655C303030725C3030306E5C303030655C303030735C303030735C3030303A5C3030305C3034305C303030465C303030695C3030306C5C303030745C303030655C303030725C303030695C3030306E5C303030675C3030305C3034305C3030304C5C3030306F5C303030775C3030302D5C303030515C303030755C303030615C3030306C5C303030695C303030745C303030795C3030305C3034305C303030505C303030725C303030655C303030645C303030695C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.2}Bounding Box Regression}{470}{subsection.14.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.3}Centerness: Filtering Low-Quality Predictions}{470}{subsection.14.5.3}\protected@file@percent }
\BKM@entry{id=516,dest={73756273656374696F6E2E31342E352E34},srcline={1085}}{5C3337365C3337375C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C3030304C5C303030655C303030765C303030655C3030306C5C3030305C3034305C303030465C303030655C303030615C303030745C303030755C303030725C303030655C3030305C3034305C303030505C303030725C303030655C303030645C303030695C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030465C303030505C3030304E}
\BKM@entry{id=517,dest={73756273656374696F6E2E31342E352E35},srcline={1100}}{5C3337365C3337375C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030465C3030306F5C303030635C303030615C3030306C5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030495C3030306F5C303030555C3030305C3034305C3030304C5C3030306F5C303030735C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {14.29}{\ignorespaces FCOS pipeline: The backbone CNN extracts a multi-scale feature map from the input image. For each spatial location, FCOS predicts class scores, bounding box offsets \((l,t,r,b)\), and a centerness score that reflects the reliability of the prediction based on its distance from the center.}}{471}{figure.caption.928}\protected@file@percent }
\newlabel{fig:chapter14_fcos_pipeline}{{14.29}{471}{FCOS pipeline: The backbone CNN extracts a multi-scale feature map from the input image. For each spatial location, FCOS predicts class scores, bounding box offsets \((l,t,r,b)\), and a centerness score that reflects the reliability of the prediction based on its distance from the center}{figure.caption.928}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.4}Multi-Level Feature Prediction with FPN}{471}{subsection.14.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.30}{\ignorespaces FCOS utilizes an FPN for multi-scale detection. Each feature level is responsible for detecting objects within a specific size range.}}{471}{figure.caption.929}\protected@file@percent }
\newlabel{fig:chapter14_fcos_fpn}{{14.30}{471}{FCOS utilizes an FPN for multi-scale detection. Each feature level is responsible for detecting objects within a specific size range}{figure.caption.929}{}}
\abx@aux@cite{0}{lin2018_focalloss}
\abx@aux@segm{0}{0}{lin2018_focalloss}
\BKM@entry{id=518,dest={73756273656374696F6E2E31342E352E36},srcline={1114}}{5C3337365C3337375C303030495C3030306E5C303030665C303030655C303030725C303030655C3030306E5C303030635C303030655C3030303A5C3030305C3034305C303030535C303030655C3030306C5C303030655C303030635C303030745C303030695C3030306E5C303030675C3030305C3034305C303030465C303030695C3030306E5C303030615C3030306C5C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=519,dest={73756273656374696F6E2E31342E352E37},srcline={1124}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030745C303030615C303030675C303030655C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030465C303030435C3030304F5C30303053}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.5}Loss Function: Focal Loss and IoU Loss}{472}{subsection.14.5.5}\protected@file@percent }
\abx@aux@backref{301}{lin2018_focalloss}{0}{472}{472}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.6}Inference: Selecting Final Detections}{472}{subsection.14.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.7}Advantages of FCOS}{472}{subsection.14.5.7}\protected@file@percent }
\BKM@entry{id=520,dest={73656374696F6E2A2E393330},srcline={1136}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030345C3030302E5C303030365C3030303A5C3030305C3034305C303030595C3030304F5C3030304C5C3030304F5C3030305C3034305C3030302D5C3030305C3034305C303030595C3030306F5C303030755C3030305C3034305C3030304F5C3030306E5C3030306C5C303030795C3030305C3034305C3030304C5C3030306F5C3030306F5C3030306B5C3030305C3034305C3030304F5C3030306E5C303030635C30303065}
\BKM@entry{id=521,dest={73656374696F6E2A2E393331},srcline={1137}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030345C3030302E5C303030365C3030302E5C303030315C3030303A5C3030305C3034305C303030425C303030615C303030635C3030306B5C303030675C303030725C3030306F5C303030755C3030306E5C30303064}
\abx@aux@cite{0}{redmon2016_yolo}
\abx@aux@segm{0}{0}{redmon2016_yolo}
\BKM@entry{id=522,dest={73656374696F6E2A2E393332},srcline={1148}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030345C3030302E5C303030365C3030302E5C303030325C3030303A5C3030305C3034305C303030535C303030745C303030655C303030705C3030302D5C303030625C303030795C3030302D5C303030535C303030745C303030655C303030705C3030303A5C3030305C3034305C303030485C3030306F5C303030775C3030305C3034305C303030595C3030304F5C3030304C5C3030304F5C303030765C303030315C3030305C3034305C303030505C303030725C3030306F5C303030635C303030655C303030735C303030735C303030655C303030735C3030305C3034305C303030615C3030306E5C3030305C3034305C303030495C3030306E5C303030705C303030755C303030745C3030305C3034305C303030495C3030306D5C303030615C303030675C30303065}
\@writefile{toc}{\contentsline {section}{Enrichment 14.6: YOLO - You Only Look Once}{473}{section*.930}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 14.6.1: Background}{473}{section*.931}\protected@file@percent }
\abx@aux@backref{302}{redmon2016_yolo}{0}{473}{473}
\@writefile{toc}{\contentsline {subsection}{Enrichment 14.6.2: Step-by-Step: How YOLOv1 Processes an Input Image}{473}{section*.932}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Input Image and Preprocessing}{473}{section*.933}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Feature Extraction (DarkNet + Additional Convolution Layers)}{473}{section*.934}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Flattening and Fully Connected Layers}{473}{section*.935}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{4. Understanding the Output Format}{474}{section*.936}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{5. Why a Sigmoid?}{474}{section*.937}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{6. Converting Predictions to Actual Bounding Boxes}{474}{section*.938}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{7. Loss and Training (High Level)}{475}{section*.939}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{8. Why It Works (and Its Trade-offs)}{475}{section*.940}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{9. Final Detections and NMS}{475}{section*.941}\protected@file@percent }
\abx@aux@cite{0}{redmon2016_yolo}
\abx@aux@segm{0}{0}{redmon2016_yolo}
\abx@aux@cite{0}{redmon2016_yolo}
\abx@aux@segm{0}{0}{redmon2016_yolo}
\BKM@entry{id=523,dest={73656374696F6E2A2E393434},srcline={1299}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030345C3030302E5C303030365C3030302E5C303030335C3030303A5C3030305C3034305C303030455C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030595C3030304F5C3030304C5C3030304F}
\abx@aux@cite{0}{redmon2017_yolo9000}
\abx@aux@segm{0}{0}{redmon2017_yolo9000}
\abx@aux@cite{0}{redmon2018_yolov3}
\abx@aux@segm{0}{0}{redmon2018_yolov3}
\abx@aux@cite{0}{bochkovskiy2020_yolov4}
\abx@aux@segm{0}{0}{bochkovskiy2020_yolov4}
\@writefile{toc}{\contentsline {paragraph}{Summary}{476}{section*.942}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.31}{\ignorespaces YOLO pipeline: A single CNN processes the entire image, predicts bounding boxes and class probabilities, and applies NMS to refine detections. Source: \blx@tocontentsinit {0}\cite {redmon2016_yolo}.}}{476}{figure.caption.943}\protected@file@percent }
\abx@aux@backref{304}{redmon2016_yolo}{0}{476}{476}
\newlabel{fig:chapter14_yolo_pipeline}{{14.31}{476}{YOLO pipeline: A single CNN processes the entire image, predicts bounding boxes and class probabilities, and applies NMS to refine detections. Source: \cite {redmon2016_yolo}}{figure.caption.943}{}}
\@writefile{toc}{\contentsline {subsection}{Enrichment 14.6.3: Evolution of YOLO}{476}{section*.944}\protected@file@percent }
\abx@aux@backref{305}{redmon2017_yolo9000}{0}{476}{476}
\abx@aux@backref{306}{redmon2018_yolov3}{0}{476}{476}
\abx@aux@backref{307}{bochkovskiy2020_yolov4}{0}{476}{476}
\BKM@entry{id=524,dest={73656374696F6E2E31342E37},srcline={1314}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030455C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {14.7}Conclusion: The Evolution of Object Detection}{477}{section.14.7}\protected@file@percent }
\newlabel{sec:chapter14_conclusion}{{14.7}{477}{Conclusion: The Evolution of Object Detection}{section.14.7}{}}
\@writefile{toc}{\contentsline {paragraph}{From R-CNN to Faster R-CNN: Learning Region Proposals}{477}{section*.945}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Improving Multi-Scale Detection: Feature Pyramid Networks (FPN)}{477}{section*.946}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{RetinaNet: A Breakthrough for One-Stage Detectors}{477}{section*.947}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FCOS: Moving Toward Anchor-Free Detection}{477}{section*.948}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{YOLO: A Widely Used Real-Time Detector}{478}{section*.949}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Looking Ahead: Transformers and SOTA Detectors}{478}{section*.950}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary}{478}{section*.951}\protected@file@percent }
\BKM@entry{id=525,dest={636861707465722E3135},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030355C3030303A5C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=526,dest={73656374696F6E2E31352E31},srcline={10}}{5C3337365C3337375C303030465C303030725C3030306F5C3030306D5C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{ren2016_fasterrcnn}
\abx@aux@segm{0}{0}{ren2016_fasterrcnn}
\abx@aux@cite{0}{redmon2016_yolo}
\abx@aux@segm{0}{0}{redmon2016_yolo}
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Lecture 15: Image Segmentation}{479}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@14}}
\ttl@writefile{ptc}{\ttl@starttoc{default@15}}
\pgfsyspdfmark {pgfid72}{0}{52099153}
\pgfsyspdfmark {pgfid71}{5966969}{45620378}
\@writefile{toc}{\contentsline {section}{\numberline {15.1}From Object Detection to Segmentation}{479}{section.15.1}\protected@file@percent }
\abx@aux@backref{308}{ren2016_fasterrcnn}{0}{479}{479}
\abx@aux@backref{309}{redmon2016_yolo}{0}{479}{479}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces Comparison of different computer vision tasks: classification, object detection, and semantic and instance segmentation. We begin with Semantic Segmentation.}}{479}{figure.caption.952}\protected@file@percent }
\newlabel{fig:chapter15_cv_tasks}{{15.1}{479}{Comparison of different computer vision tasks: classification, object detection, and semantic and instance segmentation. We begin with Semantic Segmentation}{figure.caption.952}{}}
\BKM@entry{id=527,dest={73656374696F6E2A2E393533},srcline={32}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030325C3030303A5C3030305C3034305C303030575C303030685C303030795C3030305C3034305C303030695C303030735C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304E5C3030306F5C303030745C3030305C3034305C303030455C3030306E5C3030306F5C303030755C303030675C303030685C3030303F}
\@writefile{toc}{\contentsline {section}{Enrichment 15.2: Why is Object Detection Not Enough?}{480}{section*.953}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces Segmentation differentiates between \textit  {things} (discrete objects like cars, people) and \textit  {stuff} (amorphous regions like sky, road).}}{480}{figure.caption.954}\protected@file@percent }
\newlabel{fig:chapter15_things_stuff}{{15.2}{480}{Segmentation differentiates between \textit {things} (discrete objects like cars, people) and \textit {stuff} (amorphous regions like sky, road)}{figure.caption.954}{}}
\BKM@entry{id=528,dest={73656374696F6E2E31352E33},srcline={56}}{5C3337365C3337375C303030415C303030645C303030765C303030615C3030306E5C303030635C303030655C3030306D5C303030655C3030306E5C303030745C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030535C303030655C3030306D5C303030615C3030306E5C303030745C303030695C303030635C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=529,dest={73756273656374696F6E2E31352E332E31},srcline={60}}{5C3337365C3337375C303030455C303030615C303030725C3030306C5C303030795C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C303030685C303030655C303030735C3030303A5C3030305C3034305C303030535C3030306C5C303030695C303030645C303030695C3030306E5C303030675C3030305C3034305C303030575C303030695C3030306E5C303030645C3030306F5C303030775C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C30303064}
\BKM@entry{id=530,dest={73756273656374696F6E2E31352E332E32},srcline={73}}{5C3337365C3337375C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030465C303030435C3030304E5C303030735C3030305C303531}
\abx@aux@cite{0}{long2015_fcn}
\abx@aux@segm{0}{0}{long2015_fcn}
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Advancements in Semantic Segmentation}{481}{section.15.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3.1}Early Approaches: Sliding Window Method}{481}{subsection.15.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.3}{\ignorespaces Sliding window approach for semantic segmentation, illustrating the inefficiency due to redundant computations over overlapping patches.}}{481}{figure.caption.955}\protected@file@percent }
\newlabel{fig:chapter15_sliding_window}{{15.3}{481}{Sliding window approach for semantic segmentation, illustrating the inefficiency due to redundant computations over overlapping patches}{figure.caption.955}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3.2}Fully Convolutional Networks (FCNs)}{481}{subsection.15.3.2}\protected@file@percent }
\abx@aux@backref{310}{long2015_fcn}{0}{481}{481}
\BKM@entry{id=531,dest={73756273656374696F6E2E31352E332E33},srcline={86}}{5C3337365C3337375C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030465C303030435C3030304E5C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030535C303030655C3030306D5C303030615C3030306E5C303030745C303030695C303030635C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=532,dest={73756273656374696F6E2E31352E332E34},srcline={95}}{5C3337365C3337375C303030455C3030306E5C303030635C3030306F5C303030645C303030655C303030725C3030302D5C303030445C303030655C303030635C3030306F5C303030645C303030655C303030725C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C30303073}
\abx@aux@cite{0}{noh2015_deconvnet}
\abx@aux@segm{0}{0}{noh2015_deconvnet}
\@writefile{lof}{\contentsline {figure}{\numberline {15.4}{\ignorespaces Architecture of a Fully Convolutional Network maintaining input spatial dimensions, producing a feature map with $C \times H \times W$, where $C$ is the number of classes.}}{482}{figure.caption.956}\protected@file@percent }
\newlabel{fig:chapter15_fcn_architecture}{{15.4}{482}{Architecture of a Fully Convolutional Network maintaining input spatial dimensions, producing a feature map with $C \times H \times W$, where $C$ is the number of classes}{figure.caption.956}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3.3}Challenges in FCNs for Semantic Segmentation}{482}{subsection.15.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3.4}Encoder-Decoder Architectures}{482}{subsection.15.3.4}\protected@file@percent }
\abx@aux@backref{311}{noh2015_deconvnet}{0}{482}{482}
\abx@aux@cite{0}{raffel2020_t5}
\abx@aux@segm{0}{0}{raffel2020_t5}
\abx@aux@cite{0}{lewis2020_bart}
\abx@aux@segm{0}{0}{lewis2020_bart}
\abx@aux@cite{0}{ronneberger2015_unet}
\abx@aux@segm{0}{0}{ronneberger2015_unet}
\abx@aux@cite{0}{ledig2017_srgan}
\abx@aux@segm{0}{0}{ledig2017_srgan}
\BKM@entry{id=533,dest={73656374696F6E2E31352E34},srcline={124}}{5C3337365C3337375C303030555C303030705C303030735C303030615C3030306D5C303030705C3030306C5C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030555C3030306E5C303030705C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\abx@aux@backref{312}{raffel2020_t5}{0}{483}{483}
\abx@aux@backref{313}{lewis2020_bart}{0}{483}{483}
\abx@aux@backref{314}{ronneberger2015_unet}{0}{483}{483}
\abx@aux@backref{315}{ledig2017_srgan}{0}{483}{483}
\@writefile{lof}{\contentsline {figure}{\numberline {15.5}{\ignorespaces Encoder-decoder architecture for semantic segmentation, featuring downsampling in the encoder and upsampling in the decoder to achieve pixel-wise classification.}}{483}{figure.caption.957}\protected@file@percent }
\newlabel{fig:chapter15_encoder_decoder}{{15.5}{483}{Encoder-decoder architecture for semantic segmentation, featuring downsampling in the encoder and upsampling in the decoder to achieve pixel-wise classification}{figure.caption.957}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.4}Upsampling and Unpooling}{483}{section.15.4}\protected@file@percent }
\BKM@entry{id=534,dest={73756273656374696F6E2E31352E342E31},srcline={136}}{5C3337365C3337375C303030425C303030655C303030645C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304E5C303030615C303030695C3030306C5C303030735C3030305C3034305C303030555C3030306E5C303030705C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.1}Bed of Nails Unpooling}{484}{subsection.15.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Limitations of Bed of Nails Unpooling}{484}{section*.958}\protected@file@percent }
\abx@aux@cite{0}{wiki_Aliasing}
\abx@aux@segm{0}{0}{wiki_Aliasing}
\abx@aux@cite{0}{wiki_Aliasing}
\abx@aux@segm{0}{0}{wiki_Aliasing}
\BKM@entry{id=535,dest={73756273656374696F6E2E31352E342E32},srcline={172}}{5C3337365C3337375C3030304E5C303030655C303030615C303030725C303030655C303030735C303030745C3030302D5C3030304E5C303030655C303030695C303030675C303030685C303030625C3030306F5C303030725C3030305C3034305C303030555C3030306E5C303030705C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {15.6}{\ignorespaces Comparison of a well-sampled image (left) versus one affected by aliasing (right). The right image exhibits moiré patterns due to insufficient sampling, a phenomenon similar to the high-frequency distortions introduced by Bed of Nails unpooling. Source: \blx@tocontentsinit {0}\cite {wiki_Aliasing}.}}{485}{figure.caption.959}\protected@file@percent }
\abx@aux@backref{317}{wiki_Aliasing}{0}{485}{485}
\newlabel{fig:chapter15_bed_of_nails_artifacts}{{15.6}{485}{Comparison of a well-sampled image (left) versus one affected by aliasing (right). The right image exhibits moiré patterns due to insufficient sampling, a phenomenon similar to the high-frequency distortions introduced by Bed of Nails unpooling. Source: \cite {wiki_Aliasing}}{figure.caption.959}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.2}Nearest-Neighbor Unpooling}{485}{subsection.15.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.7}{\ignorespaces Comparison of Bed of Nails unpooling (left) and Nearest-Neighbor unpooling (right).}}{485}{figure.caption.960}\protected@file@percent }
\newlabel{fig:chapter15_unpooling}{{15.7}{485}{Comparison of Bed of Nails unpooling (left) and Nearest-Neighbor unpooling (right)}{figure.caption.960}{}}
\BKM@entry{id=536,dest={73756273656374696F6E2E31352E342E33},srcline={205}}{5C3337365C3337375C303030425C303030695C3030306C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030705C3030306F5C3030306C5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030555C303030705C303030735C303030615C3030306D5C303030705C3030306C5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.3}Bilinear Interpolation for Upsampling}{486}{subsection.15.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bilinear Interpolation: Generalized Case}{486}{section*.961}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.8}{\ignorespaces Bilinear interpolation applied to a $C \times 2 \times 2$ input tensor, producing a $C \times 4 \times 4$ output. Each upsampled value is computed as a weighted sum of its four nearest neighbors in the original feature map.}}{487}{figure.caption.962}\protected@file@percent }
\newlabel{fig:chapter15_bilinear_interpolation}{{15.8}{487}{Bilinear interpolation applied to a $C \times 2 \times 2$ input tensor, producing a $C \times 4 \times 4$ output. Each upsampled value is computed as a weighted sum of its four nearest neighbors in the original feature map}{figure.caption.962}{}}
\BKM@entry{id=537,dest={73756273656374696F6E2E31352E342E34},srcline={213}}{5C3337365C3337375C303030425C303030695C303030635C303030755C303030625C303030695C303030635C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030705C3030306F5C3030306C5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030555C303030705C303030735C303030615C3030306D5C303030705C3030306C5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsubsection}{Advantages of Bilinear Interpolation}{488}{section*.963}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Limitations and Transition to Bicubic Interpolation}{488}{section*.964}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.4}Bicubic Interpolation for Upsampling}{488}{subsection.15.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why Bicubic Interpolation?}{488}{section*.965}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mathematical Reasoning}{488}{section*.966}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bicubic Interpolation: Generalized Case}{489}{section*.967}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.9}{\ignorespaces Bicubic interpolation demonstrated on a \(C \times 2 \times 2\) feature map, generating a \(C \times 4 \times 4\) output. Each interpolated value is computed by applying a cubic weighting to the nearest sixteen pixels.}}{489}{figure.caption.968}\protected@file@percent }
\newlabel{fig:chapter15_bicubic_interpolation}{{15.9}{489}{Bicubic interpolation demonstrated on a \(C \times 2 \times 2\) feature map, generating a \(C \times 4 \times 4\) output. Each interpolated value is computed by applying a cubic weighting to the nearest sixteen pixels}{figure.caption.968}{}}
\BKM@entry{id=538,dest={73756273656374696F6E2E31352E342E35},srcline={282}}{5C3337365C3337375C3030304D5C303030615C303030785C3030305C3034305C303030555C3030306E5C303030705C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsubsection}{Advantages and Limitations}{490}{section*.969}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.5}Max Unpooling}{490}{subsection.15.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Max Unpooling in the Context of Noh et al. (ICCV 2015)}{490}{section*.970}\protected@file@percent }
\BKM@entry{id=539,dest={73756273656374696F6E2E31352E342E36},srcline={343}}{5C3337365C3337375C303030545C303030725C303030615C3030306E5C303030735C303030705C3030306F5C303030735C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {15.10}{\ignorespaces Illustration of \textbf  {max unpooling} using recorded pooling indices to restore spatial activations. Unlike interpolation-based methods, \textbf  {max unpooling} reinstates feature activations at their original locations.}}{491}{figure.caption.971}\protected@file@percent }
\newlabel{fig:chapter15_max_unpooling}{{15.10}{491}{Illustration of \textbf {max unpooling} using recorded pooling indices to restore spatial activations. Unlike interpolation-based methods, \textbf {max unpooling} reinstates feature activations at their original locations}{figure.caption.971}{}}
\@writefile{toc}{\contentsline {subsubsection}{Why Max Unpooling is More Effective Than Bed of Nails Unpooling}{491}{section*.972}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bridging to Transposed Convolution}{491}{section*.973}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.6}Transposed Convolution}{492}{subsection.15.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Understanding the Similarity to Standard Convolution}{492}{section*.974}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Step-by-Step Process of Transposed Convolution}{492}{section*.975}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.11}{\ignorespaces Illustration of the first step in transposed convolution: applying the filter to the first input element.}}{493}{figure.caption.976}\protected@file@percent }
\newlabel{fig:chapter15_transposed_conv_first_step}{{15.11}{493}{Illustration of the first step in transposed convolution: applying the filter to the first input element}{figure.caption.976}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15.12}{\ignorespaces The second input element is processed: its weighted filter values are placed in the output grid, with overlapping values summed.}}{493}{figure.caption.977}\protected@file@percent }
\newlabel{fig:chapter15_transposed_conv_second_step}{{15.12}{493}{The second input element is processed: its weighted filter values are placed in the output grid, with overlapping values summed}{figure.caption.977}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15.13}{\ignorespaces Final constructed output after processing all input elements.}}{494}{figure.caption.978}\protected@file@percent }
\newlabel{fig:chapter15_transposed_conv_final_output}{{15.13}{494}{Final constructed output after processing all input elements}{figure.caption.978}{}}
\@writefile{toc}{\contentsline {subsubsection}{1D Transposed Convolution}{494}{section*.979}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.14}{\ignorespaces Illustration of 1D transposed convolution: a 2-element input and a 3-element filter produce a 5-element output.}}{494}{figure.caption.980}\protected@file@percent }
\newlabel{fig:chapter15_transposed_conv_1D}{{15.14}{494}{Illustration of 1D transposed convolution: a 2-element input and a 3-element filter produce a 5-element output}{figure.caption.980}{}}
\BKM@entry{id=540,dest={73756273656374696F6E2E31352E342E37},srcline={456}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030705C3030306F5C303030735C303030655C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C303030735C3030305C3034305C3030304D5C303030615C303030745C303030725C303030695C303030785C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsubsection}{Advantages of Transposed Convolution}{495}{section*.981}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Connection to Standard Convolution}{495}{section*.982}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.7}Convolution and Transposed Convolution as Matrix Multiplication}{495}{subsection.15.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convolution via Matrix Multiplication}{495}{section*.983}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.15}{\ignorespaces 1D convolution represented as matrix multiplication.}}{496}{figure.caption.984}\protected@file@percent }
\newlabel{fig:conv_matrix_mul}{{15.15}{496}{1D convolution represented as matrix multiplication}{figure.caption.984}{}}
\@writefile{toc}{\contentsline {subsubsection}{Transposed Convolution via Matrix Multiplication (Stride = 1)}{496}{section*.985}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.16}{\ignorespaces Transposed convolution as the transpose of the convolution matrix (for stride=1).}}{497}{figure.caption.986}\protected@file@percent }
\newlabel{fig:trans_conv_matrix_mul}{{15.16}{497}{Transposed convolution as the transpose of the convolution matrix (for stride=1)}{figure.caption.986}{}}
\@writefile{toc}{\contentsline {subsubsection}{Transposed Convolution and Gradient Derivation}{497}{section*.987}\protected@file@percent }
\BKM@entry{id=541,dest={73756273656374696F6E2E31352E342E38},srcline={571}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030435C303030685C3030306F5C3030306F5C303030735C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030525C303030695C303030675C303030685C303030745C3030305C3034305C303030555C303030705C303030735C303030615C3030306D5C303030705C3030306C5C303030695C3030306E5C303030675C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C30303064}
\@writefile{toc}{\contentsline {subsubsection}{Advantages of Transposed Convolution}{498}{section*.988}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Challenges and Considerations}{498}{section*.989}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.8}Conclusion: Choosing the Right Upsampling Method}{498}{subsection.15.4.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {15.1}{\ignorespaces Comparison of upsampling methods based on their properties.}}{498}{table.caption.990}\protected@file@percent }
\newlabel{tab:upsampling_comparison}{{15.1}{498}{Comparison of upsampling methods based on their properties}{table.caption.990}{}}
\@writefile{toc}{\contentsline {subsubsection}{Guidelines for Choosing an Upsampling Method}{498}{section*.991}\protected@file@percent }
\BKM@entry{id=542,dest={73656374696F6E2E31352E35},srcline={630}}{5C3337365C3337375C303030495C3030306E5C303030735C303030745C303030615C3030306E5C303030635C303030655C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsubsection}{Final Thoughts}{499}{section*.992}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.5}Instance Segmentation}{499}{section.15.5}\protected@file@percent }
\BKM@entry{id=543,dest={73756273656374696F6E2E31352E352E31},srcline={647}}{5C3337365C3337375C3030304D5C303030615C303030735C3030306B5C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E5C3030303A5C3030305C3034305C303030415C3030305C3034305C303030545C303030775C3030306F5C3030302D5C303030535C303030745C303030615C303030675C303030655C3030305C3034305C303030465C303030725C303030615C3030306D5C303030655C303030775C3030306F5C303030725C3030306B5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030495C3030306E5C303030735C303030745C303030615C3030306E5C303030635C303030655C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.5.1}Mask R-CNN: A Two-Stage Framework for Instance Segmentation}{500}{subsection.15.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Faster R-CNN Backbone}{500}{section*.993}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Key Additions in Mask R-CNN}{500}{section*.994}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Segmentation Mask Prediction: Fixed Size Output}{500}{section*.995}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training Mask R-CNN and Loss Functions}{500}{section*.996}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bilinear Interpolation vs. Bicubic Interpolation}{501}{section*.997}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Class-Aware Mask Selection}{501}{section*.998}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Gradient Flow in Mask R-CNN}{501}{section*.999}\protected@file@percent }
\BKM@entry{id=544,dest={73756273656374696F6E2E31352E352E32},srcline={745}}{5C3337365C3337375C303030455C303030785C303030745C303030655C3030306E5C303030645C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C3030304F5C303030625C3030306A5C303030655C303030635C303030745C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030505C303030615C303030725C303030615C303030645C303030695C303030675C3030306D}
\abx@aux@cite{0}{johnson2015_densecap}
\abx@aux@segm{0}{0}{johnson2015_densecap}
\@writefile{toc}{\contentsline {subsubsection}{Summary}{502}{section*.1000}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.5.2}Extending the Object Detection Paradigm}{502}{subsection.15.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.17}{\ignorespaces Mask R-CNN extended for keypoint estimation, predicting key locations such as joints for human pose estimation.}}{502}{figure.caption.1001}\protected@file@percent }
\newlabel{fig:chapter15_keypoints}{{15.17}{502}{Mask R-CNN extended for keypoint estimation, predicting key locations such as joints for human pose estimation}{figure.caption.1001}{}}
\abx@aux@backref{318}{johnson2015_densecap}{0}{502}{502}
\abx@aux@cite{0}{gkioxari2020_meshrcnn}
\abx@aux@segm{0}{0}{gkioxari2020_meshrcnn}
\@writefile{lof}{\contentsline {figure}{\numberline {15.18}{\ignorespaces Dense Captioning (DenseCap) extends object detection by adding a captioning head, enabling textual descriptions of detected objects.}}{503}{figure.caption.1002}\protected@file@percent }
\newlabel{fig:chapter15_densecap}{{15.18}{503}{Dense Captioning (DenseCap) extends object detection by adding a captioning head, enabling textual descriptions of detected objects}{figure.caption.1002}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15.19}{\ignorespaces Example output of DenseCap: Generated captions describe detected regions with natural language.}}{503}{figure.caption.1003}\protected@file@percent }
\newlabel{fig:chapter15_densecap_example}{{15.19}{503}{Example output of DenseCap: Generated captions describe detected regions with natural language}{figure.caption.1003}{}}
\abx@aux@backref{319}{gkioxari2020_meshrcnn}{0}{503}{503}
\@writefile{lof}{\contentsline {figure}{\numberline {15.20}{\ignorespaces Mesh R-CNN extends Mask R-CNN with a mesh prediction head, enabling 3D shape reconstruction from 2D images.}}{504}{figure.caption.1004}\protected@file@percent }
\newlabel{fig:chapter15_mesh_rcnn}{{15.20}{504}{Mesh R-CNN extends Mask R-CNN with a mesh prediction head, enabling 3D shape reconstruction from 2D images}{figure.caption.1004}{}}
\BKM@entry{id=545,dest={73656374696F6E2A2E31303035},srcline={788}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030303A5C3030305C3034305C303030555C3030302D5C3030304E5C303030655C303030745C3030303A5C3030305C3034305C303030415C3030305C3034305C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030535C303030655C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=546,dest={73656374696F6E2A2E31303036},srcline={790}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030302E5C303030315C3030303A5C3030305C3034305C3030304F5C303030765C303030655C303030725C303030765C303030695C303030655C30303077}
\abx@aux@cite{0}{ronneberger2015_unet}
\abx@aux@segm{0}{0}{ronneberger2015_unet}
\BKM@entry{id=547,dest={73656374696F6E2A2E31303037},srcline={796}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030302E5C303030325C3030303A5C3030305C3034305C303030555C3030302D5C3030304E5C303030655C303030745C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\abx@aux@cite{0}{ronneberger2015_unet}
\abx@aux@segm{0}{0}{ronneberger2015_unet}
\abx@aux@cite{0}{ronneberger2015_unet}
\abx@aux@segm{0}{0}{ronneberger2015_unet}
\BKM@entry{id=548,dest={73656374696F6E2A2E31303039},srcline={825}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030302E5C303030335C3030303A5C3030305C3034305C303030535C3030306B5C303030695C303030705C3030305C3034305C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030635C303030615C303030745C303030655C3030306E5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{Enrichment 15.6: U-Net: A Fully Conv Architecture for Segmentation}{505}{section*.1005}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 15.6.1: Overview}{505}{section*.1006}\protected@file@percent }
\abx@aux@backref{320}{ronneberger2015_unet}{0}{505}{505}
\@writefile{toc}{\contentsline {subsection}{Enrichment 15.6.2: U-Net Architecture}{505}{section*.1007}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.21}{\ignorespaces U-Net architecture: The encoder (left) captures context, while the decoder (right) restores details using transposed convolutions and skip connections. Source: \blx@tocontentsinit {0}\cite {ronneberger2015_unet}.}}{505}{figure.caption.1008}\protected@file@percent }
\abx@aux@backref{322}{ronneberger2015_unet}{0}{505}{505}
\newlabel{fig:unet_architecture}{{15.21}{505}{U-Net architecture: The encoder (left) captures context, while the decoder (right) restores details using transposed convolutions and skip connections. Source: \cite {ronneberger2015_unet}}{figure.caption.1008}{}}
\BKM@entry{id=549,dest={73656374696F6E2A2E31303130},srcline={853}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030302E5C303030345C3030303A5C3030305C3034305C303030545C303030725C303030615C303030695C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030555C3030302D5C3030304E5C303030655C30303074}
\BKM@entry{id=550,dest={73656374696F6E2A2E31303131},srcline={886}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030302E5C303030355C3030303A5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304D5C303030615C303030735C3030306B5C3030305C3034305C303030525C3030302D5C303030435C3030304E5C3030304E}
\BKM@entry{id=551,dest={73656374696F6E2A2E31303132},srcline={898}}{5C3337365C3337375C303030455C3030306E5C303030725C303030695C303030635C303030685C3030306D5C303030655C3030306E5C303030745C3030305C3034305C303030315C303030355C3030302E5C303030365C3030302E5C303030365C3030303A5C3030305C3034305C303030495C3030306D5C303030705C303030615C303030635C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030455C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030555C3030302D5C3030304E5C303030655C30303074}
\@writefile{toc}{\contentsline {subsection}{Enrichment 15.6.3: Skip Connections and Concatenation}{506}{section*.1009}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 15.6.4: Training U-Net}{506}{section*.1010}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Enrichment 15.6.5: Comparison with Mask R-CNN}{506}{section*.1011}\protected@file@percent }
\abx@aux@cite{0}{zhou2018_unetpp}
\abx@aux@segm{0}{0}{zhou2018_unetpp}
\abx@aux@cite{0}{cciccek2016_3dunet}
\abx@aux@segm{0}{0}{cciccek2016_3dunet}
\abx@aux@cite{0}{zhang2018_resunet}
\abx@aux@segm{0}{0}{zhang2018_resunet}
\abx@aux@cite{0}{oktay2018_attentionunet}
\abx@aux@segm{0}{0}{oktay2018_attentionunet}
\@writefile{toc}{\contentsline {subsection}{Enrichment 15.6.6: Impact and Evolution of U-Net}{507}{section*.1012}\protected@file@percent }
\abx@aux@backref{323}{zhou2018_unetpp}{0}{507}{507}
\abx@aux@backref{324}{cciccek2016_3dunet}{0}{507}{507}
\abx@aux@backref{325}{zhang2018_resunet}{0}{507}{507}
\abx@aux@backref{326}{oktay2018_attentionunet}{0}{507}{507}
\BKM@entry{id=552,dest={636861707465722E3136},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030365C3030303A5C3030305C3034305C303030525C303030655C303030635C303030755C303030725C303030725C303030655C3030306E5C303030745C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Lecture 16: Recurrent Networks}{508}{chapter.16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@15}}
\ttl@writefile{ptc}{\ttl@starttoc{default@16}}
\pgfsyspdfmark {pgfid74}{0}{52099153}
\pgfsyspdfmark {pgfid73}{5966969}{45620378}
\BKM@entry{id=553,dest={636861707465722E3137},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030375C3030303A5C3030305C3034305C303030415C303030745C303030745C303030655C3030306E5C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {17}Lecture 17: Attention}{509}{chapter.17}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@16}}
\ttl@writefile{ptc}{\ttl@starttoc{default@17}}
\pgfsyspdfmark {pgfid76}{0}{52099153}
\pgfsyspdfmark {pgfid75}{5966969}{45620378}
\BKM@entry{id=554,dest={636861707465722E3138},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030385C3030303A5C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {18}Lecture 18: Vision Transformers}{510}{chapter.18}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@17}}
\ttl@writefile{ptc}{\ttl@starttoc{default@18}}
\pgfsyspdfmark {pgfid78}{0}{52099153}
\pgfsyspdfmark {pgfid77}{5966969}{45620378}
\BKM@entry{id=555,dest={636861707465722E3139},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030315C303030395C3030303A5C3030305C3034305C303030475C303030655C3030306E5C303030655C303030725C303030615C303030745C303030695C303030765C303030655C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C30303049}
\@writefile{toc}{\contentsline {chapter}{\numberline {19}Lecture 19: Generative Models I}{511}{chapter.19}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@18}}
\ttl@writefile{ptc}{\ttl@starttoc{default@19}}
\pgfsyspdfmark {pgfid80}{0}{52099153}
\pgfsyspdfmark {pgfid79}{5966969}{45620378}
\BKM@entry{id=556,dest={636861707465722E3230},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030325C303030305C3030303A5C3030305C3034305C303030475C303030655C3030306E5C303030655C303030725C303030615C303030745C303030695C303030765C303030655C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C303030495C30303049}
\@writefile{toc}{\contentsline {chapter}{\numberline {20}Lecture 20: Generative Models II}{512}{chapter.20}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@19}}
\ttl@writefile{ptc}{\ttl@starttoc{default@20}}
\pgfsyspdfmark {pgfid82}{0}{52099153}
\pgfsyspdfmark {pgfid81}{5966969}{45620378}
\BKM@entry{id=557,dest={636861707465722E3231},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030325C303030315C3030303A5C3030305C3034305C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C3030305C3034365C3030305C3034305C303030475C303030655C3030306E5C303030655C303030725C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030495C3030306D5C303030615C303030675C303030655C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {21}Lecture 21: Visualizing Models \& Generating Images}{513}{chapter.21}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@20}}
\ttl@writefile{ptc}{\ttl@starttoc{default@21}}
\pgfsyspdfmark {pgfid84}{0}{52099153}
\pgfsyspdfmark {pgfid83}{5966969}{45620378}
\BKM@entry{id=558,dest={636861707465722E3232},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030325C303030325C3030303A5C3030305C3034305C303030535C303030655C3030306C5C303030665C3030302D5C303030535C303030755C303030705C303030655C303030725C303030765C303030695C303030735C303030655C303030645C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {chapter}{\numberline {22}Lecture 22: Self-Supervised Learning}{514}{chapter.22}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@21}}
\ttl@writefile{ptc}{\ttl@starttoc{default@22}}
\pgfsyspdfmark {pgfid86}{0}{52099153}
\pgfsyspdfmark {pgfid85}{5966969}{45620378}
\BKM@entry{id=559,dest={636861707465722E3233},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030325C303030335C3030303A5C3030305C3034305C303030335C303030445C3030305C3034305C303030765C303030695C303030735C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {23}Lecture 23: 3D vision}{515}{chapter.23}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@22}}
\ttl@writefile{ptc}{\ttl@starttoc{default@23}}
\pgfsyspdfmark {pgfid88}{0}{52099153}
\pgfsyspdfmark {pgfid87}{5966969}{45620378}
\BKM@entry{id=560,dest={636861707465722E3234},srcline={4}}{5C3337365C3337375C3030304C5C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030325C303030345C3030303A5C3030305C3034305C303030565C303030695C303030645C303030655C3030306F5C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {24}Lecture 24: Videos}{516}{chapter.24}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@23}}
\ttl@writefile{ptc}{\ttl@starttoc{default@24}}
\pgfsyspdfmark {pgfid90}{0}{52099153}
\pgfsyspdfmark {pgfid89}{5966969}{45620378}
\BKM@entry{id=561,dest={636861707465722E3235},srcline={4}}{5C3337365C3337375C3030304D5C3030306F5C303030645C303030655C3030306C5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030725C303030655C303030735C303030735C303030695C3030306F5C3030306E5C3030303A5C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030505C303030725C303030755C3030306E5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {chapter}{\numberline {25}Model Compression: Quantization and Pruning}{517}{chapter.25}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@24}}
\ttl@writefile{ptc}{\ttl@starttoc{default@25}}
\pgfsyspdfmark {pgfid92}{0}{52099153}
\pgfsyspdfmark {pgfid91}{5966969}{45620378}
\BKM@entry{id=562,dest={636861707465722E3236},srcline={4}}{5C3337365C3337375C303030465C3030306F5C303030755C3030306E5C303030645C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {26}Foundation Models in Computer Vision}{518}{chapter.26}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@25}}
\ttl@writefile{ptc}{\ttl@starttoc{default@26}}
\pgfsyspdfmark {pgfid94}{0}{52099153}
\pgfsyspdfmark {pgfid93}{5966969}{45620378}
\BKM@entry{id=563,dest={636861707465722E3237},srcline={4}}{5C3337365C3337375C3030304D5C303030415C3030304D5C303030425C303030415C3030303A5C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C303030415C303030675C303030655C3030306E5C303030745C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C303030425C3030306F5C303030645C303030795C3030305C3034305C303030415C3030306E5C303030615C3030306C5C303030795C303030735C303030695C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {27}MAMBA: Multi-Agent Multi-Body Analysis}{519}{chapter.27}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@26}}
\ttl@writefile{ptc}{\ttl@starttoc{default@27}}
\pgfsyspdfmark {pgfid96}{0}{52099153}
\pgfsyspdfmark {pgfid95}{5966969}{45620378}
\pgfsyspdfmark {pgfid98}{0}{52099153}
\pgfsyspdfmark {pgfid97}{5966969}{45620378}
\ttl@finishall
\abx@aux@read@bbl@mdfivesum{8BE4CD9E99A23F1CD999E01FB4A13149}
\abx@aux@read@bblrerun
\abx@aux@defaultrefcontext{0}{flamingo2022_fewshot}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alexe2012_objectness}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alger2019_data}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{appen_road_annotation}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{bello2021_revisitingresnets}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{bergstra2012_randomsearch}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{bochkovskiy2020_yolov4}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lake2015_human}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{brock2021_highperformance}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{brock2021_nfnet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{brooks1979_modelbased}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{buolamwini2018_gendershades}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{canny1986_edgedetection}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{carion2020_detr}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{dino2021_selfsupervised}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{chen2017_deeplab}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{cheng2014_bing}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{chollet2017_xception}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{cciccek2016_3dunet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{clevert2015_fast}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{imagenet2009_hierarchicaldatabase}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{devlin2015_imagetocaption}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{devlin2019_bert}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{devries2017_cutout}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{donahue2015_ltrcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{levy2016_medicalimaging}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{vit2020_transformers}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{erdem2020_RoIAlign}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{pascal2010_visualchallenge}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{fischler1973_pictorialstructures}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{fukushima1980_neocognitron}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{girshick2015_fastrcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{girshick2014_rcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{gkioxari2020_meshrcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{glorot2010_understanding}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{goodfellow2014_adversarial}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{graham2015_fractionalmaxpool}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mamba2023_selective}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{harris1988_combined}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2018_rethinkingimagenet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2016_resnet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2015_delving}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2016identity}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2017_maskrcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2018_resnetd}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hendrycks2016_gelu}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hlav2023_kaiming}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hlav2023_xavier}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hochreiter1997_lstm}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{howard2017_mobilenets}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{howard2019_mobilenetv3}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hu2018_senet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{huang2016_stochasticdepth}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{huang2020_tfixup}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hubel1959_receptivefields}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{becominghuman2018_allaboutnorm}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ioffe2015_batchnorm}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{johnson2015_densecap}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{johnson2017_infering}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{karpathy2015_visualsemantic}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{sam2023_segmentation}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{klambauer2017_selu}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{krishnamoorthi2018_quantizing}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{krizhevsky2009_learning}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{krizhevsky2012_alexnet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{law2019_cornernet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lecun1998_lenet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ledig2017_srgan}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lewis2020_bart}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2022_dino}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lin2014microsoft}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lin2017_fpn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lin2018_focalloss}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{liu2019_roberta}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{long2015_fcn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lowe1987_objectrecognition}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lowe1999_sift}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ma2018_shufflenetv2}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{marr1982_vision}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{minsky1969_perceptrons}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{noh2015_deconvnet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{oktay2018_attentionunet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{oquab2023_dinov2}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{vinyals2015_captioning}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{patnaik2020_roi_pool}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{polyak1992_averagegradient}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{clip2021_multimodal}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{radosavovic2020_regnet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{raffel2020_t5}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ramachandran2017_searching}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ramachandran2017_swish}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{dalle2021_texttoimage}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{redmon2017_yolo9000}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{redmon2018_yolov3}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{redmon2016_yolo}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ren2015_fasterrcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ren2016_fasterrcnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{roberts1963_3dsolids}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ronneberger2015_unet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rosenblatt1958_perceptron}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rumelhart1986_backpropagation}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{dieleman2014_galaxycnn}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{sandler2018_mobilenetv2}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{santurkar2018_howdoesbatchnormhelp}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{blog2023_separable_convolutions}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{shi1997_normalizedcuts}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{simonyan2014_twostream}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{simonyan2014_vgg}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{solai2023_backpropconv}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{srivastava2014_dropout}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{szegedy2015_googlenet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{tan2021_efficientnetv2}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{tan2019_efficientnet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{tensorflow2020_efficientnetlite}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{tian2019_fcos}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{toshev2014pose_estimation}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{touvron2021_deit}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{touvron2019_fixres}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{sh-tsang2018_groupnorm}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{uijlings2013_selective}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{vaswani2017_attention}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{viola2001_boosteddetection}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{wan2013_dropconnect}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{wiki_Aliasing}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{williams1992_simple}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{guo2014_atari}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{xie2017_aggregated}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{yenigun_overfitting}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zakka2016_batchnorm}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zeiler2014_visualizing}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2020_resnest}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2019_fixup}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2018_mixup}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2018_shufflenet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2018_resunet}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhou2017_places}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhou2019_unifiedvqa}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhou2018_unetpp}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zitnick2014_edgeboxes}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zoph2017_nas}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zoph2018_learning}{nty/global//global/global/global}
\xdef \mintedoldcachechecksum{\detokenize{C16A9A7F725C62A4367BF5775A53163F:32}}
\gdef \@abspage@last{529}
