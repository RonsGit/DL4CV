%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Important note:
% Chapter heading images should have a 2:1 width:height ratio,
% e.g. 920px width and 460px height.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\DocumentMetadata{}
\documentclass[11pt,fleqn,openany]{book} % Default font size and left-justified equations. One can remove the 'openany' part to remove unwanted pages between sections. 
\raggedbottom

\usepackage[top=3cm,bottom=3cm,left=3.2cm,right=3.2cm,headsep=10pt,letterpaper]{geometry} % Page margins

\usepackage[dvipsnames]{xcolor} % Required for specifying colors by name

% --- color definitions -----------------
\definecolor{ocre}{RGB}{52,177,201} % Define the ocre color used for highlighting throughout the book

% Font Settings
\usepackage{avant} % Use the Avantgarde font for headings
%\usepackage{times} % Use the Times font for headings
\usepackage{mathptmx} % Use Adobe Times Roman as the default text font together with math symbols from the Sym­bol, Chancery, and Com­puter Modern fonts
\usepackage{microtype} % Slightly tweak font spacing for aesthetics
\usepackage[utf8]{inputenc} % Required for including letters with accents
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{amsthm}
\usepackage{bm}

\usepackage{enumitem}
\setlist[enumerate]{topsep=0.5cm}

% Bibliography
\usepackage[backend=biber,style=numeric,sortcites,sorting=nty,backref,natbib,hyperref]{biblatex}
\usepackage{csquotes}
\addbibresource{bibliography.bib} % BibTeX bibliography file
\defbibheading{bibempty}{}

\input{structure} % Insert the commands.tex file which contains the majority of the structure behind the template

%----------------------------------------------------------------------------------------
%	Definitions of new commands
%----------------------------------------------------------------------------------------

\def\R{\mathbb{R}}
\newcommand{\ind}{\mathbf{1}}
\newcommand{\cvx}{convex}

% --- simple tick / cross definitions -----------------
\usepackage{pifont}          % gives \ding
\newcommand{\cmark}{\ding{51}}   % ✓  (check mark)
\newcommand{\xmark}{\ding{55}}   % ✗  (cross mark)
% -----------------------------------------------------

\begin{document}
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begingroup
\thispagestyle{empty}
\setlength{\parskip}{0pt} % remove extra paragraph gaps
\AddToShipoutPicture*{\put(0,0){\includegraphics[scale=1.25]{esahubble}}} % background
\centering
\vspace*{4.3cm} % <-- adjust this to position the whole block vertically (smaller = higher)
\par\normalfont\fontsize{35}{35}\sffamily\selectfont
\textbf{EECS498 - Deep Learning for Computer Vision}\\
{\LARGE An essential guide to modern computer vision based on UMich's EECS498 (Instructor: Justin Johnson)}\par
\vspace*{0.7cm}
{\LARGE Ron Korine, 2025}\\[-0.35em] % tighten the gap to the thanks line
{\large With thanks to the computer vision research community}\par
\endgroup

%----------------------------------------------------------------------------------------
%	COPYRIGHT PAGE
%----------------------------------------------------------------------------------------

\newpage
~\vfill
\thispagestyle{empty}

%\noindent Copyright \copyright\ 2014 Andrea Hidalgo\\ % Copyright notice

\noindent \textsc{github.com/RonsGit/}\\ % URL
This document is based on content from various sources—including books and lecture notes. Each source used is duly cited to give proper credit to the original authors. If you find any content in this document that you would prefer to be removed, please feel free to contact me by clicking \textbf{\href{mailto:eecs498summary@gmail.com}{here}}, and I will address your request promptly.\\ % License information

\noindent \textit{Pre Release, November 2025} % Printing/edition date

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

\chapterimage{head1.png} % Table of contents heading image

\pagestyle{empty} % No headers

\tableofcontents % Print the table of contents itself

%\cleardoublepage % Forces the first chapter to start on an odd page so it's on the right

\pagestyle{fancy} % Print headers again

\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

\section{Getting Started: About the Project and How to Navigate It}

\subsection{Why This Document?}

\noindent
This document is intended as a structured, accessible on-ramp to deep learning and computer vision—both for students and early-stage practitioners, and for experienced engineers who want a quick way to enter new subfields or refresh core ideas. The aim is to replace resource overload with a coherent path: concise explanations, consistent notation, and curated references that connect lectures, key papers, and practical recipes into a navigable whole.

\medskip
\noindent
This volume originated in the summer of 2024 as a structured companion to the University of Michigan’s EECS498 curriculum, taught by \href{https://web.eecs.umich.edu/~justincj/}{Justin Johnson}. By revisiting each lecture and distilling its core ideas, the text organizes the material into a practical, pedagogically coherent resource that extends the course with clarified explanations, curated references, and contextual notes designed to support durable understanding.

The material is tailored for undergraduate and early graduate students in computer science, electrical engineering, software engineering, and related fields. Readers are expected to have foundational knowledge in Python programming, calculus, and linear algebra. If you feel uncertain about these prerequisites, I recommend reviewing the following: 
\begin{itemize}
	\item \href{https://www.learnpython.org/}{Learn Python} for programming fundamentals,
	\item \href{https://www.khanacademy.org/math/calculus-1}{Khan Academy Calculus} for introductory calculus, and
	\item \href{https://www.3blue1brown.com/topics/linear-algebra}{3Blue1Brown's Linear Algebra series} for geometric intuition and matrix operations.
\end{itemize}

\medskip
\noindent
While prior coursework in machine learning is not strictly required, it can be highly beneficial. For a beginner-friendly option, I recommend \href{https://www.coursera.org/learn/machine-learning}{Andrew Ng's Machine Learning course on Coursera}. For those seeking a more theoretical treatment, \href{https://cs229.stanford.edu/}{Stanford’s CS229: Machine Learning} offers a rigorous mathematical perspective.

\newpage
\noindent
\textbf{A Living Resource.}  
This document is intended to evolve into a living resource—open, modular, and continuously improved by the community. In the near future, I plan to release the full source files and compilation scripts (e.g., LaTeX + Markdown + BibTeX) to support versioning, feedback, and collaborative contributions. Readers will be able to:
\begin{itemize}
	\item Suggest clarifications, corrections, and additions,
	\item Contribute new sections, figures, or examples,
	\item Help maintain up-to-date coverage of evolving topics in the field.
\end{itemize}

The goal is to build a shared, reliable foundation for learning deep learning and computer vision—one that reflects the generosity and rigor of the research community it draws from.

\subsection{Your Feedback Matters}

This project was created independently during my personal time and at the time of the first publication, has been reviewed by only a small number of readers. As such, your feedback—whether in the form of corrections, clarifications, or suggestions—is highly appreciated and vital to improving the clarity, accuracy, and usefulness of the text.

As previously mentioned, looking ahead, I plan to make this project fully open-source to support broader collaboration. If you are interested in contributing—whether by expanding coverage, improving explanations, suggesting exercises, or proposing structural changes—I would love to hear from you. Please don’t hesitate to reach out via \href{mailto:eecs498summary@gmail.com}{email}, suggest pull requests via the \href{https://github.com/RonsGit/EECS498---Summary}{project GitHub} and thank you in advance for helping shape this resource into a living, community-driven guide for deep learning and computer vision.

\subsection{How to Use This Document Effectively}

This document is designed to support a wide range of learners—from students discovering deep learning for the first time to practitioners revisiting foundational concepts. It is not intended to be read linearly from start to finish. Instead, treat it as a flexible reference that can adapt to your goals and level of experience. Here are some recommended strategies:

\begin{enumerate}
	\item \textbf{If You’re New to the Field:}  
	Begin by following the 
	\href{https://www.youtube.com/watch?v=dJYGatp4SvA\&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r\&index=1\&ab_channel=MichiganOnline}{EECS498 lecture series on YouTube}, and read the corresponding sections in parallel. Use this document to:
	\begin{itemize}
		\item Clarify ideas presented quickly in the video.
		\item Reference equations or diagrams while watching.
		\item Revisit chapters after the lecture to solidify your understanding.
	\end{itemize}
	Try pausing to reflect on key definitions or derivations before reading through the explanations—they’re designed to help you reason things out.
	
	\item \textbf{If You’re a Practitioner or Advanced Learner:}  
	Use the table of contents to jump directly to the topics that interest you. This document is structured to support:
	\begin{itemize}
		\item Quick lookups and topic refreshers.
		\item In-depth conceptual reviews when needed.
		\item Bridging gaps between foundational material and modern techniques.
	\end{itemize}
	
	\item \textbf{Use It Selectively:}  
	There is no expectation that you read the entire document. Each section is written to stand on its own (as much as possible), so feel free to explore topics nonlinearly. If you're preparing for a specific project, paper, or interview, jump directly to relevant chapters—such as optimization, normalization, transformers, or generative models.
	
	\newpage
	
	\item \textbf{Refresh your knowledge over time}  
	Use this as a long-term companion. When you return after months to backpropagation, attention, or KL divergence, jump directly to the relevant section. Short definitions, worked mini-examples, and “enrichment” boxes are designed to support both first-pass learning and quick second-pass review
	
	\item \textbf{Turn the notes into an interactive guide (RAG + podcast workflows)}  
	Upload this document—together with a short reading list of papers on your target topic—into retrieval-augmented tools such as \textbf{NotebookLM} or \textbf{ChatGPT/Gemini with file support}. You can then:
	\begin{itemize}
		\item Generate \emph{podcast-style briefings} or episode outlines that walk through the papers in a narrative order.
		\item Ask follow-up questions in natural language and get citations back to specific sections, figures, or equations.
		\item Summarize long derivations, contrast methods head-to-head, and extract recurring themes or assumptions.
		\item Auto-create quizzes, flashcards, and timelines to reinforce retention.
	\end{itemize}
	This workflow turns a static reading list into an interactive study companion, letting you survey a subfield, revisit concepts, or spin up a quick refresher with minimal friction.
\end{enumerate}

\subsection{Staying Updated in the Field}

While this document aims to provide a reliable and up-to-date foundation, deep learning continues to evolve at a remarkable pace—often with new methods, architectures, and theoretical insights emerging daily. As such, readers are encouraged to treat this material as a starting point rather than an endpoint.

To stay current with developments:
\begin{itemize}
	\item Use tools like \href{https://www.connectedpapers.com/}{\textbf{Connected Papers}} to explore the citation graph and discover related work.
	\item Follow \href{https://huggingface.co/papers/trending}{\textbf{Trending Papers}} to track trending papers, benchmark results, and open-source implementations.
	\item Subscribe to \href{https://www.dailyarxiv.com/}{\textbf{DailyArxiv}} to receive daily email digests of new arXiv submissions in machine learning, computer vision, and related fields.
	\item Watch high-level paper reviews and discussions on YouTube channels such as \href{https://www.youtube.com/@yannickilcher}{Yannic Kilcher} and \href{https://www.youtube.com/@andrejkarpathy}{Andrej Karpathy}.
	\item Follow key researchers and labs on \textbf{X} (formerly Twitter), such as \texttt{@ylecun}, \texttt{@karpathy}, \texttt{@smerity}, and \texttt{@david\_ha}, to stay informed about emerging ideas and discussions that may precede formal publication.
	\item Review accepted papers and tutorials from top-tier conferences such as \textbf{CVPR}, \textbf{ICCV}, \textbf{ECCV}, \textbf{NeurIPS}, \textbf{ICLR}, and \textbf{ICML}.
	\item Bookmark curated repositories like the \href{https://www.github.com/chicleee/Image-Matching-Paper-List}{Image Matching Papers List} to explore focused subfields efficiently.
\end{itemize}

By combining this foundational document with regular engagement in the broader research ecosystem, you can maintain both conceptual depth and up-to-date knowledge as the field progresses.

\subsection{Dependency Tree}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{Pictures/book_dependencies.png}
	\caption{\textbf{Book chapter dependencies}  
		Arrows indicate prerequisite relationships between chapters. Earlier foundations support later topics such as self-supervised learning, segmentation, video understanding, and 3D vision.}
	\label{fig:book_dependencies}
\end{figure}

\newpage

\subsection{Contributors}

\begin{itemize}
	\item \textbf{Lead author and editor} — Ron Korine: compilation, writing, and curation across all sections.
	\item \textbf{Curriculum source} — Justin Johnson’s EECS498 (University of Michigan): structure, topic sequencing, and foundational materials.
	\item \textbf{Figure and asset creators} — authors of publicly available figures, tutorials, and visualizations cited in-context throughout.
\end{itemize}

\paragraph{Named contributors}
\begin{itemize}
	\item \textbf{Adi Arbel} — contributions to the \emph{ReLIC} family and \emph{Plenoxels} sections; broad manuscript feedback on clarity, organization, and emphasis.
\end{itemize}

\paragraph{Community feedback}
\noindent
Thanks to colleagues and readers who suggested clarifications, spotted errors, and recommended references.  
If you have contributed content or identify material that should be credited differently or removed, please write to \href{mailto:eecs498summary@gmail.com}{eecs498summary@gmail.com}. Updates will be reflected in subsequent revisions.

\newpage

\subsection{The Importance of Practice}
“What I cannot build, I do not understand”. Hands-on work is essential for mastering vision. Pair the lectures with the EECS498 assignments (\href{https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/}{link}) to solidify core ideas through implementation. Use \href{https://colab.research.google.com/}{Google Colab} for experiments and \href{https://www.kaggle.com/}{Kaggle} for applied challenges, and track runs with \href{https://wandb.ai/}{WandB}, \href{https://clear.ml/}{ClearML}, or \href{https://www.tensorflow.org/tensorboard}{TensorBoard}. Building as you learn deepens theory and yields practical intuition for real-world tasks.

\subsection{Final Remarks}

Thank you for engaging with this material. Whether you are a student, researcher, or practitioner, I hope this document supports your efforts to develop a deeper and more structured understanding of deep learning and computer vision.

This resource is intended not only as a learning companion but also as a reference you can revisit over time. The field continues to evolve rapidly, and while the foundational ideas remain central, new architectures, techniques, and theoretical tools are introduced regularly. A solid conceptual base will enable you to adapt confidently to these developments.

I am also sincerely grateful to readers who have taken the time to share suggestions, point out errors, or recommend improvements. Your feedback helps refine and expand this work, and ensures that it remains a relevant and valuable resource for future learners.

\vspace{1em}
\begin{flushright}
	\textit{“Live as if you were to die tomorrow. Learn as if you were to live forever.”} \\
	— Mahatma Gandhi
\end{flushright}

% Include chapters
\input{Chapters/Chapter_1_Lecture_1_Course_Introduction}
\input{Chapters/Chapter_2_Lecture_2_Image_Classification}
\input{Chapters/Chapter_3_Lecture_3_Linear_Classifiers}
\input{Chapters/Chapter_4_Lecture_4_Regularization__Optimization}
\input{Chapters/Chapter_5_Lecture_5_Neural_Networks}
\input{Chapters/Chapter_6_Lecture_6_Backpropagation}
\input{Chapters/Chapter_7_Lecture_7_Convolutional_Networks}
\input{Chapters/Chapter_8_Lecture_8_CNN_Architectures_I}
\input{Chapters/Chapter_9_Lecture_9_Training_Neural_Networks_I}
\input{Chapters/Chapter_10_Lecture_10_Training_Neural_Networks_II}
\input{Chapters/Chapter_11_Lecture_11_CNN_Architectures_II}
\input{Chapters/Chapter_12_Lecture_12_Deep_Learning_Software}
\input{Chapters/Chapter_13_Lecture_13_Object_Detection}
\input{Chapters/Chapter_14_Lecture_14_Object_Detectors}
\input{Chapters/Chapter_15_Lecture_15_Image_Segmentation}
\input{Chapters/Chapter_16_Lecture_16_Recurrent_Networks}
\input{Chapters/Chapter_17_Lecture_17_Attention}
\input{Chapters/Chapter_18_Lecture_18_Vision_Transformers}
\input{Chapters/Chapter_19_Lecture_19_Generative_Models_I}
\input{Chapters/Chapter_20_Lecture_20_Generative_Models_II}
\input{Chapters/Chapter_21_Lecture_21_Visualizing_Models__Generating_Images}
\input{Chapters/Chapter_22_Lecture_22_SelfSupervised_Learning}
\input{Chapters/Chapter_23_Lecture_23_3D_vision}
\input{Chapters/Chapter_24_Lecture_24_Videos}
\printbibliography
\end{document}