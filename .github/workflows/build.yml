name: Build Book & Website

on:
  push:
    branches: [ "main", "master" ]
  pull_request:

permissions:
  contents: write
  packages: read
  pages: write
  id-token: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 180

    # Use pre-built Docker image with all tools pre-installed
    # This saves ~15-20 minutes vs installing texlive-full fresh
    container:
      image: ghcr.io/ronsgit/dl4cv/latex-builder:latest
      options: --user root
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Verify Environment
      run: |
        echo "=== Container Environment Check ==="
        echo "LaTeX: $(pdflatex --version | head -1)"
        echo "Biber: $(biber --version | head -1)"
        echo "Python: $(python3 --version)"
        echo "Node: $(node --version)"
        echo "Pagefind: $(pagefind --version)"
        echo "Ghostscript: $(gs --version | head -1)"
        echo "WebP: $(cwebp -version 2>&1 | head -1)"
        echo "ImageMagick: $(convert --version | head -1)"
        python3 -c "import pymupdf; print(f'PyMuPDF: {pymupdf.__version__}')"
        python3 -c "import bs4; print('BeautifulSoup: OK')"
        echo "=== All tools ready ==="

    #=========================================================================
    # STEP 1: Build Manager (HTML + Main PDF)
    #=========================================================================
    - name: "Step 1: Run Build Manager (HTML + PDF)"
      run: |
        chmod +x scripts/*.py 2>/dev/null || true
        python3 scripts/build_manager.py --skip-nav

    #=========================================================================
    # STEP 2-3: Split PDF + Build Bibliography (in parallel)
    #=========================================================================
    - name: "Step 2-3: Split PDF & Build Bibliography (Parallel)"
      continue-on-error: true
      run: |
        if [ -f "html_output/downloads/main.pdf" ] && [ -f "html_output/main.toc" ]; then
          echo "=== Starting PDF split + Bibliography build in parallel ==="
          python3 scripts/split_pdf.py --main-pdf html_output/downloads/main.pdf \
            --toc html_output/main.toc --out-dir html_output/downloads &
          PID_SPLIT=$!

          python3 scripts/build_bib_pdf.py --out html_output/downloads/Bibliography.pdf &
          PID_BIB=$!

          wait $PID_SPLIT && echo "PDF split completed" || echo "PDF split failed (non-fatal)"
          wait $PID_BIB && echo "Bibliography build completed" || echo "Bibliography build failed (non-fatal)"
        else
          echo "Skipping PDF split (main.pdf or main.toc missing)"
          python3 scripts/build_bib_pdf.py --out html_output/downloads/Bibliography.pdf || echo "Bibliography PDF build failed (non-fatal)"
        fi

    #=========================================================================
    # STEP 4: Run Post-Processor (Navigation & Styling)
    #=========================================================================
    - name: "Step 4: Generate Navigation & Style Pages"
      run: |
        echo "=== Running HTML Post-Processor ==="
        python3 scripts/run_post_processor.py

    #=========================================================================
    # STEP 5: Build Pagefind Search Index
    #=========================================================================
    - name: "Step 5: Build Search Index"
      run: |
        cd html_output
        pagefind --site . --output-subdir pagefind
        echo "Pagefind index built"

    #=========================================================================
    # STEP 6: Final Verification
    #=========================================================================
    - name: "Step 6: Verify Build Output"
      run: |
        echo "=== Checking build output ==="

        if [ ! -f "html_output/index.html" ]; then
          echo "ERROR: Missing index.html"
          exit 1
        fi

        echo "HTML files: $(find html_output -maxdepth 1 -name '*.html' | wc -l)"
        echo "Figures: $(find html_output/Figures -type f 2>/dev/null | wc -l || echo '0')"
        echo "Pictures: $(find html_output/Pictures -type f 2>/dev/null | wc -l || echo '0')"
        echo "Search index: $(find html_output/pagefind -type f 2>/dev/null | wc -l || echo '0')"
        echo "PDFs: $(find html_output/downloads -name '*.pdf' 2>/dev/null | wc -l || echo '0')"

        [ -f "html_output/bibliography.html" ] && echo "âœ“ bibliography.html" || echo "âš  bibliography.html missing"
        [ -f "html_output/dependency_graph.html" ] && echo "âœ“ dependency_graph.html" || echo "âš  dependency_graph.html missing"

        touch html_output/.nojekyll

    #=========================================================================
    # STEP 7: Optimize Artifact Size
    #=========================================================================
    - name: "Step 7: Optimize Artifact Size"
      run: |
        echo "=== Optimizing artifact size ==="
        echo "Initial size: $(du -sh html_output/ | cut -f1)"

        # Remove temporary LaTeX build files
        find html_output/ -type f \( -name "*.aux" -o -name "*.log" -o -name "*.out" -o -name "*.toc" -o -name "*.4ct" -o -name "*.4tc" -o -name "*.idv" -o -name "*.lg" -o -name "*.tmp" -o -name "*.xref" -o -name "*.dvi" -o -name "*.bbl" -o -name "*.blg" -o -name "*.fls" -o -name "*.fdb_latexmk" \) -delete 2>/dev/null || true
        find html_output/ -type f \( -name ".DS_Store" -o -name "Thumbs.db" -o -name "desktop.ini" \) -delete 2>/dev/null || true

        NPROC=$(nproc)
        echo "CPU cores: $NPROC"

        # =====================================================================
        # PDF Compression: Compress PDFs >50MB using ghostscript
        # =====================================================================
        echo ""
        echo "=== Compressing large PDFs (>50MB) ==="
        for pdf in html_output/downloads/*.pdf; do
          [ -f "$pdf" ] || continue
          size=$(stat -c%s "$pdf" 2>/dev/null || echo "0")
          if [ "$size" -gt 52428800 ]; then
            echo "  Compressing: $pdf ($(numfmt --to=iec $size))"
            gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/ebook \
               -dNOPAUSE -dQUIET -dBATCH \
               -sOutputFile="${pdf}.tmp" "$pdf" 2>/dev/null
            if [ -f "${pdf}.tmp" ]; then
              new_size=$(stat -c%s "${pdf}.tmp" 2>/dev/null || echo "0")
              if [ "$new_size" -lt "$size" ] && [ "$new_size" -gt 0 ]; then
                mv "${pdf}.tmp" "$pdf"
                echo "    -> $(numfmt --to=iec $new_size) (saved $(numfmt --to=iec $((size - new_size))))"
              else
                rm -f "${pdf}.tmp"
                echo "    -> kept original"
              fi
            fi
          else
            echo "  Skipping: $(basename $pdf) ($(numfmt --to=iec $size)) - under 50MB"
          fi
        done

        # =====================================================================
        # Image Optimization: Resize + Convert to WebP
        # =====================================================================
        echo ""
        echo "=== Resizing oversized images (>1920px) ==="
        find html_output/ -type f \( -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" \) \
          -not -path "*/downloads/*" -not -path "*/pagefind/*" 2>/dev/null | while read img; do
          width=$(identify -format "%w" "$img" 2>/dev/null || echo "0")
          if [ "$width" -gt 1920 ]; then
            echo "  Resizing: $(basename $img) (${width}px)"
            convert "$img" -resize '1920x>' -quality 95 "$img" 2>/dev/null || true
          fi
        done

        echo ""
        echo "=== Converting images to WebP ==="
        converted=0
        find html_output/ -type f \( -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" \) \
          -not -path "*/downloads/*" -not -path "*/pagefind/*" 2>/dev/null | while read img; do
          webp_path="${img%.*}.webp"
          if cwebp -q 85 -m 6 "$img" -o "$webp_path" 2>/dev/null; then
            rm -f "$img"
          fi
        done
        echo "WebP conversion complete"

        echo ""
        echo "=== Updating HTML image references ==="
        find html_output/ -name "*.html" -exec sed -i \
            -e 's/\(src="[^"]*\)\.png"/\1.webp"/g' \
            -e 's/\(src="[^"]*\)\.jpg"/\1.webp"/g' \
            -e 's/\(src="[^"]*\)\.jpeg"/\1.webp"/g' \
            -e 's/\(src="[^"]*\)\.PNG"/\1.webp"/g' \
            -e 's/\(src="[^"]*\)\.JPG"/\1.webp"/g' \
            -e "s/\(src='[^']*\)\.png'/\1.webp'/g" \
            -e "s/\(src='[^']*\)\.jpg'/\1.webp'/g" \
            -e "s/\(src='[^']*\)\.jpeg'/\1.webp'/g" {} \;

        # Final report
        echo ""
        echo "=== Final artifact size ==="
        du -sh html_output/
        echo "WebP: $(find html_output/ -name '*.webp' 2>/dev/null | wc -l) files"
        echo "PNG:  $(find html_output/ -name '*.png' 2>/dev/null | wc -l) files"
        echo "PDF:  $(find html_output/ -name '*.pdf' 2>/dev/null | wc -l) files"

    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: book-website
        path: html_output/
        retention-days: 30

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
    - name: Download Artifacts
      uses: actions/download-artifact@v4
      with:
        name: book-website
        path: deploy_ready/

    - name: Upload Pages Artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: deploy_ready/

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4

    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        ref: main
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Update README with Page URL
      continue-on-error: true
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"

        PAGE_URL="${{ steps.deployment.outputs.page_url }}"
        echo "Deployed URL: $PAGE_URL"

        if [ -z "$PAGE_URL" ]; then
          echo "No page URL available, skipping README update"
          exit 0
        fi

        sed -i -E "s|(<a href=\")[^\"]*(\"><strong>ðŸ“– READ THE BOOK HERE Â»</strong></a>)|\1$PAGE_URL\2|g" README.md

        if [[ -n $(git status -s README.md) ]]; then
          echo "Updating README link..."
          git add README.md
          git commit -m "docs: auto-update docs link to $PAGE_URL [skip ci]"
          git push origin main
        else
          echo "No changes to README.md needed."
        fi
