\begin{MintedVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{tensorflow} \PYG{k}{as} \PYG{n+nn}{tf}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{InputLayer}\PYG{p}{,} \PYG{n}{Dense}

\PYG{n}{N}\PYG{p}{,} \PYG{n}{Din}\PYG{p}{,} \PYG{n}{H}\PYG{p}{,} \PYG{n}{Dout} \PYG{o}{=} \PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{1000}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{l+m+mi}{10}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{[}
\PYG{n}{InputLayer}\PYG{p}{(}\PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{n}{Din}\PYG{p}{,}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
\PYG{n}{Dense}\PYG{p}{(}\PYG{n}{units}\PYG{o}{=}\PYG{n}{H}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{relu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{n}{Dense}\PYG{p}{(}\PYG{n}{units}\PYG{o}{=}\PYG{n}{Dout}\PYG{p}{)}
\PYG{p}{]}\PYG{p}{)}

\PYG{n}{loss\PYGZus{}fn} \PYG{o}{=} \PYG{n}{tf}\PYG{o}{.}\PYG{n}{keras}\PYG{o}{.}\PYG{n}{losses}\PYG{o}{.}\PYG{n}{MeanSquaredError}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{opt} \PYG{o}{=} \PYG{n}{tf}\PYG{o}{.}\PYG{n}{keras}\PYG{o}{.}\PYG{n}{optimizers}\PYG{o}{.}\PYG{n}{SGD}\PYG{p}{(}\PYG{n}{learning\PYGZus{}rate}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}6}\PYG{p}{)}

\PYG{n}{x} \PYG{o}{=} \PYG{n}{tf}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{Din}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{tf}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{Dout}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{t} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1000}\PYG{p}{)}\PYG{p}{:}
\PYG{k}{with} \PYG{n}{tf}\PYG{o}{.}\PYG{n}{GradientTape}\PYG{p}{(}\PYG{p}{)} \PYG{k}{as} \PYG{n}{tape}\PYG{p}{:}
\PYG{n}{y\PYGZus{}pred} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{n}{loss} \PYG{o}{=} \PYG{n}{loss\PYGZus{}fn}\PYG{p}{(}\PYG{n}{y\PYGZus{}pred}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n}{grads} \PYG{o}{=} \PYG{n}{tape}\PYG{o}{.}\PYG{n}{gradient}\PYG{p}{(}\PYG{n}{loss}\PYG{p}{,} \PYG{n}{model}\PYG{o}{.}\PYG{n}{trainable\PYGZus{}variables}\PYG{p}{)}
\PYG{n}{opt}\PYG{o}{.}\PYG{n}{apply\PYGZus{}gradients}\PYG{p}{(}\PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{grads}\PYG{p}{,} \PYG{n}{model}\PYG{o}{.}\PYG{n}{trainable\PYGZus{}variables}\PYG{p}{)}\PYG{p}{)}
\end{MintedVerbatim}
